[
  {
    "T": "?",
    "model": "go-bruins-v2.1.1",
    "average": 74.95,
    "arc": 72.87,
    "hellaswag": 88.33,
    "mmlu": 65.18,
    "truthfulqa": 69.8,
    "winogrande": 82.24,
    "gsm8k": 71.27,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bd56295eab54eaacbb3af6ecb88b9434d9966d4e",
    "model_name_for_query": "rwitz2/go-bruins-v2.1.1",
    "link": "https://huggingface.co/rwitz2/go-bruins-v2.1.1",
    "author": "rwitz2"
  },
  {
    "T": "\ud83d\udd36",
    "model": "quantum-dpo-v0.1",
    "average": 74.87,
    "arc": 72.53,
    "hellaswag": 88.37,
    "mmlu": 65.29,
    "truthfulqa": 69.92,
    "winogrande": 82.32,
    "gsm8k": 70.81,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "09cbfe6569bcdddf623e9990498e9ad07345ad6a",
    "model_name_for_query": "quantumaikr/quantum-dpo-v0.1",
    "link": "https://huggingface.co/quantumaikr/quantum-dpo-v0.1",
    "author": "quantumaikr"
  },
  {
    "T": "\ud83d\udd36",
    "model": "trinity-v1",
    "average": 74.8,
    "arc": 72.27,
    "hellaswag": 88.36,
    "mmlu": 65.2,
    "truthfulqa": 69.31,
    "winogrande": 82.0,
    "gsm8k": 71.65,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "09da1a24f84c96b8c09f2c07038986e28cc24ad5",
    "model_name_for_query": "janai-hq/trinity-v1",
    "link": "https://huggingface.co/janai-hq/trinity-v1",
    "author": "janai-hq"
  },
  {
    "T": "\ud83d\udd36",
    "model": "trinity-v1",
    "average": 74.8,
    "arc": 72.27,
    "hellaswag": 88.36,
    "mmlu": 65.2,
    "truthfulqa": 69.31,
    "winogrande": 82.0,
    "gsm8k": 71.65,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "34974ae99668c381be0871778e3c42958544f70e",
    "model_name_for_query": "jan-hq/trinity-v1",
    "link": "https://huggingface.co/jan-hq/trinity-v1",
    "author": "jan-hq"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GreenNodeLM-v3olet-7B",
    "average": 74.75,
    "arc": 72.27,
    "hellaswag": 88.25,
    "mmlu": 65.27,
    "truthfulqa": 69.52,
    "winogrande": 82.48,
    "gsm8k": 70.74,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "94b36a4573657d7815f55b917b204e6b73f7a634",
    "model_name_for_query": "GreenNode/GreenNodeLM-v3olet-7B",
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-v3olet-7B",
    "author": "GreenNode"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LeoScorpius-GreenNode-Alpaca-7B-v1",
    "average": 74.74,
    "arc": 72.35,
    "hellaswag": 88.16,
    "mmlu": 65.23,
    "truthfulqa": 69.35,
    "winogrande": 82.32,
    "gsm8k": 71.04,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "00827d42d79b7e10ddfc92c800cbb0636704e379",
    "model_name_for_query": "ignos/LeoScorpius-GreenNode-Alpaca-7B-v1",
    "link": "https://huggingface.co/ignos/LeoScorpius-GreenNode-Alpaca-7B-v1",
    "author": "ignos"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LeoScorpius-GreenNode-7B-v1",
    "average": 74.74,
    "arc": 72.1,
    "hellaswag": 88.14,
    "mmlu": 65.28,
    "truthfulqa": 69.41,
    "winogrande": 82.32,
    "gsm8k": 71.19,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "b833bde0eb8511fd81f7bb4970db68835a37a611",
    "model_name_for_query": "Toten5/LeoScorpius-GreenNode-7B-v1",
    "link": "https://huggingface.co/Toten5/LeoScorpius-GreenNode-7B-v1",
    "author": "Toten5"
  },
  {
    "T": "\ud83d\udd36",
    "model": "quantum-trinity-v0.1",
    "average": 74.67,
    "arc": 72.53,
    "hellaswag": 88.28,
    "mmlu": 65.19,
    "truthfulqa": 69.28,
    "winogrande": 82.56,
    "gsm8k": 70.2,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4e3eb8c21ff1689a348cc9ffdacd675aff3dde2b",
    "model_name_for_query": "quantumaikr/quantum-trinity-v0.1",
    "link": "https://huggingface.co/quantumaikr/quantum-trinity-v0.1",
    "author": "quantumaikr"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "mistral-7b-dpo-merge-v1.1",
    "average": 74.53,
    "arc": 72.53,
    "hellaswag": 88.15,
    "mmlu": 64.83,
    "truthfulqa": 68.48,
    "winogrande": 82.32,
    "gsm8k": 70.89,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7fc6c09477cc606e91025c38b9963bc47dd396da",
    "model_name_for_query": "mncai/mistral-7b-dpo-merge-v1.1",
    "link": "https://huggingface.co/mncai/mistral-7b-dpo-merge-v1.1",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "go-bruins-v2.1",
    "average": 74.5,
    "arc": 71.93,
    "hellaswag": 88.33,
    "mmlu": 65.0,
    "truthfulqa": 69.16,
    "winogrande": 82.16,
    "gsm8k": 70.43,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1e785d545369d201262bcc740ff127bb120d7a6b",
    "model_name_for_query": "rwitz2/go-bruins-v2.1",
    "link": "https://huggingface.co/rwitz2/go-bruins-v2.1",
    "author": "rwitz2"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "mistral-7b-dpo-v6",
    "average": 74.5,
    "arc": 72.53,
    "hellaswag": 88.1,
    "mmlu": 64.68,
    "truthfulqa": 68.24,
    "winogrande": 82.56,
    "gsm8k": 70.89,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "206be3fd589dd62817343c53525ab7fb1b752faf",
    "model_name_for_query": "mncai/mistral-7b-dpo-v6",
    "link": "https://huggingface.co/mncai/mistral-7b-dpo-v6",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "SOLAR-10.7B-Instruct-v1.0",
    "average": 74.2,
    "arc": 71.08,
    "hellaswag": 88.16,
    "mmlu": 66.21,
    "truthfulqa": 71.43,
    "winogrande": 83.58,
    "gsm8k": 64.75,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d3167df97a44b8632538b32ee8cd887893ea1435",
    "model_name_for_query": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "link": "https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0",
    "author": "upstage"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "GreenNodeLM-7B-v4leo",
    "average": 74.18,
    "arc": 71.25,
    "hellaswag": 88.24,
    "mmlu": 65.01,
    "truthfulqa": 69.65,
    "winogrande": 82.32,
    "gsm8k": 68.61,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9286f6fac1df497203e110070322c93dab33fdd2",
    "model_name_for_query": "GreenNode/GreenNodeLM-7B-v4leo",
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-7B-v4leo",
    "author": "GreenNode"
  },
  {
    "T": "\ud83d\udd36",
    "model": "una-xaberius-34b-v1beta has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/444\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #444</a>",
    "average": 74.18,
    "arc": 70.39,
    "hellaswag": 86.77,
    "mmlu": 78.15,
    "truthfulqa": 61.45,
    "winogrande": 84.93,
    "gsm8k": 63.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-4.0",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "233b63015f389d0023cfa21727632b340cadbdb5",
    "model_name_for_query": "fblgit/una-xaberius-34b-v1beta",
    "link": "https://huggingface.co/fblgit/una-xaberius-34b-v1beta",
    "author": "fblgit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "una-cybertron-7b-v3-OMA",
    "average": 74.01,
    "arc": 73.04,
    "hellaswag": 87.94,
    "mmlu": 63.44,
    "truthfulqa": 69.85,
    "winogrande": 82.08,
    "gsm8k": 67.7,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "29c9ff0a9f5daa5adc797a34508bcca50205f34f",
    "model_name_for_query": "fblgit/una-cybertron-7b-v3-OMA",
    "link": "https://huggingface.co/fblgit/una-cybertron-7b-v3-OMA",
    "author": "fblgit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "meow",
    "average": 73.94,
    "arc": 70.48,
    "hellaswag": 88.08,
    "mmlu": 66.25,
    "truthfulqa": 70.49,
    "winogrande": 83.43,
    "gsm8k": 64.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d933dcd7cbb19916f4732ae7e3892a656a8c3d27",
    "model_name_for_query": "rishiraj/meow",
    "link": "https://huggingface.co/rishiraj/meow",
    "author": "rishiraj"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "LeoScorpius-7B-Chat-DPO",
    "average": 73.92,
    "arc": 70.48,
    "hellaswag": 87.97,
    "mmlu": 65.08,
    "truthfulqa": 68.83,
    "winogrande": 82.08,
    "gsm8k": 69.07,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6e6e0a6e5c309acbe124a8055138ea5a4f2e56d1",
    "model_name_for_query": "viethq188/LeoScorpius-7B-Chat-DPO",
    "link": "https://huggingface.co/viethq188/LeoScorpius-7B-Chat-DPO",
    "author": "viethq188"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "mistral-7b-dpo-v5",
    "average": 73.87,
    "arc": 72.01,
    "hellaswag": 87.57,
    "mmlu": 63.85,
    "truthfulqa": 66.86,
    "winogrande": 82.24,
    "gsm8k": 70.66,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8108f313d878ce848ceceeaf55ce8b3ecaaee792",
    "model_name_for_query": "mncai/mistral-7b-dpo-v5",
    "link": "https://huggingface.co/mncai/mistral-7b-dpo-v5",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ShiningValiant",
    "average": 73.78,
    "arc": 71.33,
    "hellaswag": 90.96,
    "mmlu": 71.21,
    "truthfulqa": 70.29,
    "winogrande": 84.21,
    "gsm8k": 54.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 69.21,
    "likes": 63.0,
    "still_on_hub": true,
    "revision": "7c4401cddc462c5f35d8984c90e293faee37bf8e",
    "model_name_for_query": "ValiantLabs/ShiningValiant",
    "link": "https://huggingface.co/ValiantLabs/ShiningValiant",
    "author": "ValiantLabs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SunsetBoulevard",
    "average": 73.78,
    "arc": 71.33,
    "hellaswag": 90.96,
    "mmlu": 71.21,
    "truthfulqa": 70.29,
    "winogrande": 84.21,
    "gsm8k": 54.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 69.11,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b6070e47699fa55aac2002f579b05e6b4268cebb",
    "model_name_for_query": "sequelbox/SunsetBoulevard",
    "link": "https://huggingface.co/sequelbox/SunsetBoulevard",
    "author": "sequelbox"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "v1olet_merged_dpo_7B_v3",
    "average": 73.68,
    "arc": 72.61,
    "hellaswag": 87.7,
    "mmlu": 63.51,
    "truthfulqa": 69.07,
    "winogrande": 82.32,
    "gsm8k": 66.87,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "63b69bf2588f3b108d3427389d3c707f6b50d2ba",
    "model_name_for_query": "v1olet/v1olet_merged_dpo_7B_v3",
    "link": "https://huggingface.co/v1olet/v1olet_merged_dpo_7B_v3",
    "author": "v1olet"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "GreenNodeLM-7B-v1olet",
    "average": 73.68,
    "arc": 72.61,
    "hellaswag": 87.7,
    "mmlu": 63.51,
    "truthfulqa": 69.07,
    "winogrande": 82.32,
    "gsm8k": 66.87,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "4f0d53e65814390b8a260dd23fe5a30ced239176",
    "model_name_for_query": "GreenNode/GreenNodeLM-7B-v1olet",
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-7B-v1olet",
    "author": "GreenNode"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Qwen-72B",
    "average": 73.6,
    "arc": 65.19,
    "hellaswag": 85.94,
    "mmlu": 77.37,
    "truthfulqa": 60.19,
    "winogrande": 82.48,
    "gsm8k": 70.43,
    "model_type": "pretrained",
    "architecture": "QWenLMHeadModel",
    "precision": "bfloat16",
    "license": null,
    "params": 72.29,
    "likes": 168.0,
    "still_on_hub": true,
    "revision": "f62c59844a8de3c27cf22735218d77e9fa9f6b17",
    "model_name_for_query": "Qwen/Qwen-72B",
    "link": "https://huggingface.co/Qwen/Qwen-72B",
    "author": "Qwen"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BruinHermes",
    "average": 73.42,
    "arc": 70.14,
    "hellaswag": 87.07,
    "mmlu": 65.22,
    "truthfulqa": 65.6,
    "winogrande": 81.29,
    "gsm8k": 71.19,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "unknown",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "59db3aa4f37411d5c97a6182dcf5ecfe1757ee4a",
    "model_name_for_query": "cookinai/BruinHermes",
    "link": "https://huggingface.co/cookinai/BruinHermes",
    "author": "cookinai"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "GreenNodeLM-7B-v2leo",
    "average": 73.29,
    "arc": 69.8,
    "hellaswag": 88.02,
    "mmlu": 65.0,
    "truthfulqa": 67.83,
    "winogrande": 82.0,
    "gsm8k": 67.1,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "e5a0955eb36568aa850cd73debbe9815a9d1e60a",
    "model_name_for_query": "GreenNode/GreenNodeLM-7B-v2leo",
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-7B-v2leo",
    "author": "GreenNode"
  },
  {
    "T": "\u2b55",
    "model": "SUS-Chat-34B",
    "average": 73.22,
    "arc": 66.3,
    "hellaswag": 83.91,
    "mmlu": 76.41,
    "truthfulqa": 57.04,
    "winogrande": 83.5,
    "gsm8k": 72.18,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.0,
    "likes": 51.0,
    "still_on_hub": true,
    "revision": "01f1a7861667c4869bb03251dfd10526bf846e9c",
    "model_name_for_query": "SUSTech/SUS-Chat-34B",
    "link": "https://huggingface.co/SUSTech/SUS-Chat-34B",
    "author": "SUSTech"
  },
  {
    "T": "?",
    "model": "Pandora-10.7B-v1",
    "average": 72.93,
    "arc": 71.08,
    "hellaswag": 87.06,
    "mmlu": 64.95,
    "truthfulqa": 70.67,
    "winogrande": 81.37,
    "gsm8k": 62.47,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0e06af9adc32a44f307f96c387b4e803a1868291",
    "model_name_for_query": "jan-ai/Pandora-10.7B-v1",
    "link": "https://huggingface.co/jan-ai/Pandora-10.7B-v1",
    "author": "jan-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "v1olet_marcoroni-go-bruins-merge-7B",
    "average": 72.81,
    "arc": 70.05,
    "hellaswag": 87.17,
    "mmlu": 65.17,
    "truthfulqa": 61.42,
    "winogrande": 81.45,
    "gsm8k": 71.57,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aca5d9df596ac1f9ddffbec3de282ecbe3b32d68",
    "model_name_for_query": "v1olet/v1olet_marcoroni-go-bruins-merge-7B",
    "link": "https://huggingface.co/v1olet/v1olet_marcoroni-go-bruins-merge-7B",
    "author": "v1olet"
  },
  {
    "T": "\u2b55",
    "model": "Mixtral-8x7B-Instruct-v0.1",
    "average": 72.62,
    "arc": 70.22,
    "hellaswag": 87.63,
    "mmlu": 71.16,
    "truthfulqa": 64.58,
    "winogrande": 81.37,
    "gsm8k": 60.73,
    "model_type": "instruction-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 46.7,
    "likes": 383.0,
    "still_on_hub": true,
    "revision": "3de0408ae8b591d9ac516a2384925dd98ebc66f4",
    "model_name_for_query": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "author": "mistralai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-7B-v3",
    "average": 72.53,
    "arc": 69.45,
    "hellaswag": 86.78,
    "mmlu": 65.0,
    "truthfulqa": 60.4,
    "winogrande": 81.45,
    "gsm8k": 72.1,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6ec546141522aef9b42d1a014f1a539fcc485c45",
    "model_name_for_query": "AIDC-ai-business/Marcoroni-7B-v3",
    "link": "https://huggingface.co/AIDC-ai-business/Marcoroni-7B-v3",
    "author": "AIDC-ai-business"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-v3-neural-chat-v3-3-Slerp",
    "average": 72.51,
    "arc": 68.77,
    "hellaswag": 86.55,
    "mmlu": 64.51,
    "truthfulqa": 62.7,
    "winogrande": 80.74,
    "gsm8k": 71.8,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0223ffb3f70272009d0d76923f40cb31f3d2347e",
    "model_name_for_query": "Toten5/Marcoroni-v3-neural-chat-v3-3-Slerp",
    "link": "https://huggingface.co/Toten5/Marcoroni-v3-neural-chat-v3-3-Slerp",
    "author": "Toten5"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pee",
    "average": 72.5,
    "arc": 69.88,
    "hellaswag": 86.89,
    "mmlu": 64.95,
    "truthfulqa": 60.56,
    "winogrande": 81.77,
    "gsm8k": 70.96,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "eb3b3b6b25c31a7805d672059e06d4eace586a28",
    "model_name_for_query": "rwitz2/pee",
    "link": "https://huggingface.co/rwitz2/pee",
    "author": "rwitz2"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-neural-chat-7B-v2",
    "average": 72.5,
    "arc": 68.6,
    "hellaswag": 86.33,
    "mmlu": 64.65,
    "truthfulqa": 61.84,
    "winogrande": 80.43,
    "gsm8k": 73.16,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "15808c683e8e1125d54498a16a620b0e8520ed2b",
    "model_name_for_query": "Toten5/Marcoroni-neural-chat-7B-v2",
    "link": "https://huggingface.co/Toten5/Marcoroni-neural-chat-7B-v2",
    "author": "Toten5"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-8x7B-v3-MoE",
    "average": 72.45,
    "arc": 69.37,
    "hellaswag": 86.78,
    "mmlu": 65.01,
    "truthfulqa": 60.4,
    "winogrande": 81.45,
    "gsm8k": 71.72,
    "model_type": "fine-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 46.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "901a733d1c01035bcbe69afd25dd9b4f982cb216",
    "model_name_for_query": "perlthoughts/Marcoroni-8x7B-v3-MoE",
    "link": "https://huggingface.co/perlthoughts/Marcoroni-8x7B-v3-MoE",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mindy-7b",
    "average": 72.34,
    "arc": 69.11,
    "hellaswag": 86.57,
    "mmlu": 64.69,
    "truthfulqa": 60.89,
    "winogrande": 81.06,
    "gsm8k": 71.72,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "ce0d461a6de81d5b8ec4d338fb0c6e7991d0b1ff",
    "model_name_for_query": "mindy-labs/mindy-7b",
    "link": "https://huggingface.co/mindy-labs/mindy-7b",
    "author": "mindy-labs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "supermario-v2",
    "average": 72.34,
    "arc": 68.52,
    "hellaswag": 86.51,
    "mmlu": 64.88,
    "truthfulqa": 60.58,
    "winogrande": 81.37,
    "gsm8k": 72.18,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d66c7d87fc3670c9292177e4cfc59e8a9d71322d",
    "model_name_for_query": "janhq/supermario-v2",
    "link": "https://huggingface.co/janhq/supermario-v2",
    "author": "janhq"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-deepseek-67b-v15.2",
    "average": 72.33,
    "arc": 68.6,
    "hellaswag": 86.37,
    "mmlu": 71.5,
    "truthfulqa": 56.2,
    "winogrande": 84.45,
    "gsm8k": 66.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 67.42,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c3caef28f8402d52d6a646a7e1e00a971db1c507",
    "model_name_for_query": "OpenBuddy/openbuddy-deepseek-67b-v15.2",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-deepseek-67b-v15.2",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "supermario-slerp",
    "average": 72.32,
    "arc": 68.94,
    "hellaswag": 86.58,
    "mmlu": 64.93,
    "truthfulqa": 60.11,
    "winogrande": 81.29,
    "gsm8k": 72.1,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "83bcf51c709bcb4fcb3c8f0f91de22f458a07ee4",
    "model_name_for_query": "janhq/supermario-slerp",
    "link": "https://huggingface.co/janhq/supermario-slerp",
    "author": "janhq"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CatPPT",
    "average": 72.32,
    "arc": 68.09,
    "hellaswag": 86.69,
    "mmlu": 65.16,
    "truthfulqa": 61.55,
    "winogrande": 81.61,
    "gsm8k": 70.81,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "65d316ec5f213b7d9abbe2116372e0e90b579319",
    "model_name_for_query": "rishiraj/CatPPT",
    "link": "https://huggingface.co/rishiraj/CatPPT",
    "author": "rishiraj"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Solar-10.7B-SLERP",
    "average": 72.31,
    "arc": 70.73,
    "hellaswag": 87.87,
    "mmlu": 65.77,
    "truthfulqa": 65.72,
    "winogrande": 82.48,
    "gsm8k": 61.26,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "786e6492919d0d1eb07b5988f67e0ee61aa05c21",
    "model_name_for_query": "jan-ai/Solar-10.7B-SLERP",
    "link": "https://huggingface.co/jan-ai/Solar-10.7B-SLERP",
    "author": "jan-ai"
  },
  {
    "T": "\u2b55",
    "model": "yi-34B-v3",
    "average": 72.26,
    "arc": 67.06,
    "hellaswag": 85.11,
    "mmlu": 75.8,
    "truthfulqa": 57.54,
    "winogrande": 83.5,
    "gsm8k": 64.52,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7605af56f29b42e72f9c2cbbd4ad8e443a8dae0",
    "model_name_for_query": "mncai/yi-34B-v3",
    "link": "https://huggingface.co/mncai/yi-34B-v3",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LeoScorpius-7B",
    "average": 72.21,
    "arc": 69.28,
    "hellaswag": 87.01,
    "mmlu": 65.04,
    "truthfulqa": 63.95,
    "winogrande": 81.53,
    "gsm8k": 66.41,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "02e11fa83d18975f95c5d5047d0439897308c73b",
    "model_name_for_query": "viethq188/LeoScorpius-7B",
    "link": "https://huggingface.co/viethq188/LeoScorpius-7B",
    "author": "viethq188"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "grindin",
    "average": 72.18,
    "arc": 69.88,
    "hellaswag": 87.02,
    "mmlu": 64.98,
    "truthfulqa": 59.34,
    "winogrande": 80.9,
    "gsm8k": 70.96,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9bdce071e0f87fe047cd2446be42edf91175c3be",
    "model_name_for_query": "rwitz2/grindin",
    "link": "https://huggingface.co/rwitz2/grindin",
    "author": "rwitz2"
  },
  {
    "T": "\u2b55",
    "model": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
    "average": 72.15,
    "arc": 67.41,
    "hellaswag": 85.77,
    "mmlu": 77.44,
    "truthfulqa": 57.84,
    "winogrande": 83.11,
    "gsm8k": 61.33,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "17fe477d833b16aab50bef843bc8bf196a2710ac",
    "model_name_for_query": "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
    "link": "https://huggingface.co/brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
    "author": "brucethemoose"
  },
  {
    "T": "\u2b55",
    "model": "yi-34B-v2",
    "average": 72.12,
    "arc": 66.13,
    "hellaswag": 85.0,
    "mmlu": 75.64,
    "truthfulqa": 57.34,
    "winogrande": 83.66,
    "gsm8k": 64.97,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bf7696c10077e73d06752c564ea35cc7e5e336ca",
    "model_name_for_query": "mncai/yi-34B-v2",
    "link": "https://huggingface.co/mncai/yi-34B-v2",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "72B-preview",
    "average": 72.12,
    "arc": 65.19,
    "hellaswag": 83.23,
    "mmlu": 77.14,
    "truthfulqa": 52.58,
    "winogrande": 82.48,
    "gsm8k": 72.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "gpl-3.0",
    "params": 72.0,
    "likes": 47.0,
    "still_on_hub": true,
    "revision": "508ee8ddfd8b823fcd4b0366a72c7981c8b447d8",
    "model_name_for_query": "CausalLM/72B-preview",
    "link": "https://huggingface.co/CausalLM/72B-preview",
    "author": "CausalLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "go-bruins-v2",
    "average": 72.07,
    "arc": 69.8,
    "hellaswag": 87.05,
    "mmlu": 64.75,
    "truthfulqa": 59.7,
    "winogrande": 81.45,
    "gsm8k": 69.67,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "24f8ce81d25c433bc6be147928779fb2d00ae0e7",
    "model_name_for_query": "rwitz/go-bruins-v2",
    "link": "https://huggingface.co/rwitz/go-bruins-v2",
    "author": "rwitz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "72B-preview",
    "average": 72.06,
    "arc": 64.85,
    "hellaswag": 83.28,
    "mmlu": 77.21,
    "truthfulqa": 52.51,
    "winogrande": 82.48,
    "gsm8k": 72.02,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 72.0,
    "likes": 57.0,
    "still_on_hub": true,
    "revision": "508ee8ddfd8b823fcd4b0366a72c7981c8b447d8",
    "model_name_for_query": "CausalLM/72B-preview",
    "link": "https://huggingface.co/CausalLM/72B-preview",
    "author": "CausalLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dec10",
    "average": 72.05,
    "arc": 69.11,
    "hellaswag": 86.46,
    "mmlu": 64.98,
    "truthfulqa": 60.42,
    "winogrande": 80.74,
    "gsm8k": 70.58,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d12ade4c823d9f42949c7902d0f01b2e996a7d7e",
    "model_name_for_query": "rwitz/dec10",
    "link": "https://huggingface.co/rwitz/dec10",
    "author": "rwitz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dec10",
    "average": 72.01,
    "arc": 69.2,
    "hellaswag": 86.48,
    "mmlu": 64.91,
    "truthfulqa": 60.52,
    "winogrande": 80.43,
    "gsm8k": 70.51,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d12ade4c823d9f42949c7902d0f01b2e996a7d7e",
    "model_name_for_query": "rwitz/dec10",
    "link": "https://huggingface.co/rwitz/dec10",
    "author": "rwitz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "go-bruins-v2",
    "average": 71.95,
    "arc": 69.8,
    "hellaswag": 87.06,
    "mmlu": 64.95,
    "truthfulqa": 59.68,
    "winogrande": 81.22,
    "gsm8k": 68.99,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "49c730c9e00299eaefeb5ada30a9ec53659729a5",
    "model_name_for_query": "rwitz/go-bruins-v2",
    "link": "https://huggingface.co/rwitz/go-bruins-v2",
    "author": "rwitz"
  },
  {
    "T": "\u2b55",
    "model": "COKAL-v1-70B",
    "average": 71.87,
    "arc": 87.46,
    "hellaswag": 83.29,
    "mmlu": 68.13,
    "truthfulqa": 72.79,
    "winogrande": 80.27,
    "gsm8k": 39.27,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 69.44,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6898ebe887fd7debab6b26aa650f2876c1e2f4cf",
    "model_name_for_query": "DopeorNope/COKAL-v1-70B",
    "link": "https://huggingface.co/DopeorNope/COKAL-v1-70B",
    "author": "DopeorNope"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Seraph-7B",
    "average": 71.86,
    "arc": 67.83,
    "hellaswag": 86.22,
    "mmlu": 65.07,
    "truthfulqa": 59.49,
    "winogrande": 80.66,
    "gsm8k": 71.87,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2c6ea500b4b33bc9231b56ee6a495cd96e63064a",
    "model_name_for_query": "Weyaxi/Seraph-7B",
    "link": "https://huggingface.co/Weyaxi/Seraph-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "go-bruins",
    "average": 71.81,
    "arc": 69.11,
    "hellaswag": 86.73,
    "mmlu": 64.94,
    "truthfulqa": 58.71,
    "winogrande": 81.45,
    "gsm8k": 69.9,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a544f70a290738787bf3edc167f0bc95999e5702",
    "model_name_for_query": "rwitz/go-bruins",
    "link": "https://huggingface.co/rwitz/go-bruins",
    "author": "rwitz"
  },
  {
    "T": "\u2b55",
    "model": "deepseek-llm-67b-chat",
    "average": 71.79,
    "arc": 67.75,
    "hellaswag": 86.82,
    "mmlu": 72.42,
    "truthfulqa": 55.85,
    "winogrande": 84.21,
    "gsm8k": 63.68,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 67.0,
    "likes": 58.0,
    "still_on_hub": true,
    "revision": "79648bef7658bb824e4630740f6e1484c1b0620b",
    "model_name_for_query": "deepseek-ai/deepseek-llm-67b-chat",
    "link": "https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat",
    "author": "deepseek-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "go-bruins",
    "average": 71.79,
    "arc": 69.11,
    "hellaswag": 86.68,
    "mmlu": 64.96,
    "truthfulqa": 58.72,
    "winogrande": 81.37,
    "gsm8k": 69.9,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a544f70a290738787bf3edc167f0bc95999e5702",
    "model_name_for_query": "rwitz/go-bruins",
    "link": "https://huggingface.co/rwitz/go-bruins",
    "author": "rwitz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-deepseek-67b-v15.1",
    "average": 71.76,
    "arc": 67.66,
    "hellaswag": 86.49,
    "mmlu": 70.3,
    "truthfulqa": 54.42,
    "winogrande": 84.77,
    "gsm8k": 66.94,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 67.42,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3120e204e1b4928fd784ae78fa754bc937352c98",
    "model_name_for_query": "OpenBuddy/openbuddy-deepseek-67b-v15.1",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-deepseek-67b-v15.1",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-M-Creative-v1.0",
    "average": 71.73,
    "arc": 66.81,
    "hellaswag": 85.14,
    "mmlu": 75.54,
    "truthfulqa": 57.68,
    "winogrande": 83.11,
    "gsm8k": 62.09,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 30.0,
    "still_on_hub": true,
    "revision": "26923a2648b9864e2ec6f0cc66b8b6fcfbbdd491",
    "model_name_for_query": "migtissera/Tess-M-Creative-v1.0",
    "link": "https://huggingface.co/migtissera/Tess-M-Creative-v1.0",
    "author": "migtissera"
  },
  {
    "T": "\u2b55",
    "model": "platypus-yi-34b",
    "average": 71.69,
    "arc": 68.43,
    "hellaswag": 85.21,
    "mmlu": 78.13,
    "truthfulqa": 54.48,
    "winogrande": 84.06,
    "gsm8k": 59.82,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "66abec7cba89b35c7b6cab2140c3532049de0157",
    "model_name_for_query": "bhenrym14/platypus-yi-34b",
    "link": "https://huggingface.co/bhenrym14/platypus-yi-34b",
    "author": "bhenrym14"
  },
  {
    "T": "\u2b55",
    "model": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
    "average": 71.57,
    "arc": 66.89,
    "hellaswag": 85.69,
    "mmlu": 77.35,
    "truthfulqa": 57.63,
    "winogrande": 82.0,
    "gsm8k": 59.82,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "71c95f1971c4a47adc331859b91502bd0b790ce0",
    "model_name_for_query": "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
    "link": "https://huggingface.co/brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
    "author": "brucethemoose"
  },
  {
    "T": "\u2b55",
    "model": "Deacon-34b-qlora-adapter",
    "average": 71.39,
    "arc": 64.85,
    "hellaswag": 85.56,
    "mmlu": 76.38,
    "truthfulqa": 56.21,
    "winogrande": 83.11,
    "gsm8k": 62.24,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "97d19d88f629f6d5270126de7ba1400d3b89a6c6",
    "model_name_for_query": "KnutJaegersberg/Deacon-34b-qlora-adapter",
    "link": "https://huggingface.co/KnutJaegersberg/Deacon-34b-qlora-adapter",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "average": 71.38,
    "arc": 68.09,
    "hellaswag": 86.2,
    "mmlu": 64.26,
    "truthfulqa": 62.78,
    "winogrande": 79.16,
    "gsm8k": 67.78,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "91f18df3f5c3d36f1293086113f810f662970449",
    "model_name_for_query": "PulsarAI/OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "link": "https://huggingface.co/PulsarAI/OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DiscoLM-70b",
    "average": 71.37,
    "arc": 68.77,
    "hellaswag": 86.1,
    "mmlu": 68.58,
    "truthfulqa": 57.64,
    "winogrande": 83.58,
    "gsm8k": 63.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.98,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5eab2c8ec1c079e53a60ebdb7811756c2faebd9b",
    "model_name_for_query": "DiscoResearch/DiscoLM-70b",
    "link": "https://huggingface.co/DiscoResearch/DiscoLM-70b",
    "author": "DiscoResearch"
  },
  {
    "T": "\u2b55",
    "model": "MoMo-70B-LoRA-V1.2_1",
    "average": 71.36,
    "arc": 70.65,
    "hellaswag": 86.4,
    "mmlu": 69.9,
    "truthfulqa": 61.41,
    "winogrande": 83.19,
    "gsm8k": 56.63,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 70.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "178d03ccf7e7f83019266396f326fe11382eb20a",
    "model_name_for_query": "leejunhyeok/MoMo-70B-LoRA-V1.2_1",
    "link": "https://huggingface.co/leejunhyeok/MoMo-70B-LoRA-V1.2_1",
    "author": "leejunhyeok"
  },
  {
    "T": "\ud83d\udd36",
    "model": "supermario-slerp-v2",
    "average": 71.35,
    "arc": 69.37,
    "hellaswag": 86.6,
    "mmlu": 64.91,
    "truthfulqa": 62.96,
    "winogrande": 80.82,
    "gsm8k": 63.46,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "662c68ece38bcc8cb7b04dc2c0f5d6c03f8d56e0",
    "model_name_for_query": "janhq/supermario-slerp-v2",
    "link": "https://huggingface.co/janhq/supermario-slerp-v2",
    "author": "janhq"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-Cybertron-Starling",
    "average": 71.35,
    "arc": 67.75,
    "hellaswag": 86.23,
    "mmlu": 65.24,
    "truthfulqa": 55.94,
    "winogrande": 81.45,
    "gsm8k": 71.49,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c274ec29903792dfdc584dc840cc16e952bd3122",
    "model_name_for_query": "Q-bert/MetaMath-Cybertron-Starling",
    "link": "https://huggingface.co/Q-bert/MetaMath-Cybertron-Starling",
    "author": "Q-bert"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CapyTessBorosYi-34B-200K-DARE-Ties",
    "average": 71.31,
    "arc": 64.93,
    "hellaswag": 85.92,
    "mmlu": 76.18,
    "truthfulqa": 55.84,
    "winogrande": 83.03,
    "gsm8k": 61.94,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "0475128a0e57fc103e65c601be75013f28987e62",
    "model_name_for_query": "brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties",
    "link": "https://huggingface.co/brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties",
    "author": "brucethemoose"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "ipo-test",
    "average": 71.29,
    "arc": 67.92,
    "hellaswag": 85.99,
    "mmlu": 65.05,
    "truthfulqa": 55.87,
    "winogrande": 80.9,
    "gsm8k": 72.02,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "b75cf49b19d31ae6c4f8d2a6f3a1484d143024e0",
    "model_name_for_query": "rwitz2/ipo-test",
    "link": "https://huggingface.co/rwitz2/ipo-test",
    "author": "rwitz2"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-Cybertron-Starling",
    "average": 71.25,
    "arc": 67.41,
    "hellaswag": 86.26,
    "mmlu": 65.09,
    "truthfulqa": 55.95,
    "winogrande": 81.29,
    "gsm8k": 71.49,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "17c8d4cadb814eaef0fab1d93b29cc150f413205",
    "model_name_for_query": "Q-bert/MetaMath-Cybertron-Starling",
    "link": "https://huggingface.co/Q-bert/MetaMath-Cybertron-Starling",
    "author": "Q-bert"
  },
  {
    "T": "\u2b55",
    "model": "sheep-duck-llama-2-70b-v1.1",
    "average": 71.22,
    "arc": 73.12,
    "hellaswag": 87.77,
    "mmlu": 70.77,
    "truthfulqa": 64.55,
    "winogrande": 83.11,
    "gsm8k": 47.99,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 70.0,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "978c3cc8d44ad37eb764a53e026ae1fa8d334eb2",
    "model_name_for_query": "Riiid/sheep-duck-llama-2-70b-v1.1",
    "link": "https://huggingface.co/Riiid/sheep-duck-llama-2-70b-v1.1",
    "author": "Riiid"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-3-Slerp",
    "average": 71.19,
    "arc": 66.64,
    "hellaswag": 85.43,
    "mmlu": 62.19,
    "truthfulqa": 63.2,
    "winogrande": 79.72,
    "gsm8k": 69.98,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cbd4f663365e40d50ed9834016bf840971b35db5",
    "model_name_for_query": "Intel/neural-chat-7b-v3-3-Slerp",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-3-Slerp",
    "author": "Intel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-v3-3-8x7b-MoE",
    "average": 71.17,
    "arc": 66.64,
    "hellaswag": 85.43,
    "mmlu": 62.22,
    "truthfulqa": 63.2,
    "winogrande": 79.72,
    "gsm8k": 69.83,
    "model_type": "fine-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 46.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ef354e7938f1c38bb1f73f4ee9a7f325ae32fc2e",
    "model_name_for_query": "perlthoughts/neural-chat-v3-3-8x7b-MoE",
    "link": "https://huggingface.co/perlthoughts/neural-chat-v3-3-8x7b-MoE",
    "author": "perlthoughts"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-Llama-Q",
    "average": 71.13,
    "arc": 65.7,
    "hellaswag": 85.22,
    "mmlu": 78.78,
    "truthfulqa": 53.64,
    "winogrande": 83.03,
    "gsm8k": 60.42,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b786e11fafdd446f155fdb14c6112800f210801b",
    "model_name_for_query": "kyujinpy/PlatYi-34B-Llama-Q",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q",
    "author": "kyujinpy"
  },
  {
    "T": "\u2b55",
    "model": "shark_tank_ai_7_b",
    "average": 71.1,
    "arc": 66.89,
    "hellaswag": 86.61,
    "mmlu": 65.27,
    "truthfulqa": 60.19,
    "winogrande": 81.93,
    "gsm8k": 65.73,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "feafb4e14863e893ee3d6737ac5b07ac5241f452",
    "model_name_for_query": "NExtNewChattingAI/shark_tank_ai_7_b",
    "link": "https://huggingface.co/NExtNewChattingAI/shark_tank_ai_7_b",
    "author": "NExtNewChattingAI"
  },
  {
    "T": "\u2b55",
    "model": "Yi-34B-200K-AEZAKMI-v2",
    "average": 71.0,
    "arc": 67.92,
    "hellaswag": 85.61,
    "mmlu": 75.22,
    "truthfulqa": 56.74,
    "winogrande": 81.61,
    "gsm8k": 58.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a7c90fa652ca4b65f4e2db1126be0f884748b7ab",
    "model_name_for_query": "adamo1139/Yi-34B-200K-AEZAKMI-v2",
    "link": "https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2",
    "author": "adamo1139"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-34B-Llama",
    "average": 70.95,
    "arc": 64.59,
    "hellaswag": 85.63,
    "mmlu": 76.31,
    "truthfulqa": 55.6,
    "winogrande": 82.79,
    "gsm8k": 60.8,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "52feecf18e46dd8ed1db297345957007c3e45de1",
    "model_name_for_query": "chargoddard/Yi-34B-Llama",
    "link": "https://huggingface.co/chargoddard/Yi-34B-Llama",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-7B-v2",
    "average": 70.92,
    "arc": 68.26,
    "hellaswag": 86.27,
    "mmlu": 63.39,
    "truthfulqa": 61.96,
    "winogrande": 80.11,
    "gsm8k": 65.5,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3929ff947202a530d89a2287e19873141a0136c5",
    "model_name_for_query": "AIDC-ai-business/Marcoroni-7B-v2",
    "link": "https://huggingface.co/AIDC-ai-business/Marcoroni-7B-v2",
    "author": "AIDC-ai-business"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-34B-200K",
    "average": 70.81,
    "arc": 65.36,
    "hellaswag": 85.58,
    "mmlu": 76.06,
    "truthfulqa": 53.64,
    "winogrande": 82.56,
    "gsm8k": 61.64,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 153.0,
    "still_on_hub": true,
    "revision": "bb196389dbbfdf271b5564ce840027f8cd3386ef",
    "model_name_for_query": "01-ai/Yi-34B-200K",
    "link": "https://huggingface.co/01-ai/Yi-34B-200K",
    "author": "01-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Terminis-7B",
    "average": 70.73,
    "arc": 67.92,
    "hellaswag": 86.22,
    "mmlu": 64.07,
    "truthfulqa": 67.31,
    "winogrande": 81.29,
    "gsm8k": 57.54,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c3cde866d7d3da1173be8593c91e5bf143ea616e",
    "model_name_for_query": "Q-bert/Terminis-7B",
    "link": "https://huggingface.co/Q-bert/Terminis-7B",
    "author": "Q-bert"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nyxene-v3-11B",
    "average": 70.72,
    "arc": 69.62,
    "hellaswag": 85.33,
    "mmlu": 64.75,
    "truthfulqa": 60.91,
    "winogrande": 80.19,
    "gsm8k": 63.53,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "706e71043ed40e53bfee7f25a3f2b4a8def36ae8",
    "model_name_for_query": "beberik/Nyxene-v3-11B",
    "link": "https://huggingface.co/beberik/Nyxene-v3-11B",
    "author": "beberik"
  },
  {
    "T": "\ud83d\udd36",
    "model": "una-neural-chat-v3-3-P2-OMA",
    "average": 70.72,
    "arc": 67.32,
    "hellaswag": 86.33,
    "mmlu": 63.14,
    "truthfulqa": 65.49,
    "winogrande": 79.79,
    "gsm8k": 62.24,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7bab67e479c192927c4a781efdf5be27eaa315a8",
    "model_name_for_query": "one-man-army/una-neural-chat-v3-3-P2-OMA",
    "link": "https://huggingface.co/one-man-army/una-neural-chat-v3-3-P2-OMA",
    "author": "one-man-army"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Merged-AGI-7B",
    "average": 70.68,
    "arc": 68.6,
    "hellaswag": 86.16,
    "mmlu": 65.02,
    "truthfulqa": 60.24,
    "winogrande": 80.66,
    "gsm8k": 63.38,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7b818236625de433802bfe8b32ab8b17a7e58912",
    "model_name_for_query": "Q-bert/Merged-AGI-7B",
    "link": "https://huggingface.co/Q-bert/Merged-AGI-7B",
    "author": "Q-bert"
  },
  {
    "T": "\u2b55",
    "model": "dolphin-2.2-70b",
    "average": 70.6,
    "arc": 70.05,
    "hellaswag": 85.97,
    "mmlu": 69.18,
    "truthfulqa": 60.14,
    "winogrande": 81.45,
    "gsm8k": 56.79,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 70.0,
    "likes": 23.0,
    "still_on_hub": true,
    "revision": "6a2ddfb2ddde603dae91420db019682378aa9d5e",
    "model_name_for_query": "ehartford/dolphin-2.2-70b",
    "link": "https://huggingface.co/ehartford/dolphin-2.2-70b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-Cybertron",
    "average": 70.6,
    "arc": 66.47,
    "hellaswag": 85.54,
    "mmlu": 63.71,
    "truthfulqa": 57.71,
    "winogrande": 79.64,
    "gsm8k": 70.51,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4fca0e0002db56237fc155f572a34204229e9620",
    "model_name_for_query": "Q-bert/MetaMath-Cybertron",
    "link": "https://huggingface.co/Q-bert/MetaMath-Cybertron",
    "author": "Q-bert"
  },
  {
    "T": "?",
    "model": "Capybara-Tess-Yi-34B-200K",
    "average": 70.57,
    "arc": 66.13,
    "hellaswag": 86.24,
    "mmlu": 74.89,
    "truthfulqa": 56.37,
    "winogrande": 82.4,
    "gsm8k": 57.39,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "28a4464d357d9a4d91238d20ed30ecd2ee377be5",
    "model_name_for_query": "brucethemoose/Capybara-Tess-Yi-34B-200K",
    "link": "https://huggingface.co/brucethemoose/Capybara-Tess-Yi-34B-200K",
    "author": "brucethemoose"
  },
  {
    "T": "\ud83d\udd36",
    "model": "una-neural-chat-v3-3-P2-OMA",
    "average": 70.55,
    "arc": 67.24,
    "hellaswag": 86.34,
    "mmlu": 63.18,
    "truthfulqa": 65.48,
    "winogrande": 79.64,
    "gsm8k": 61.41,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7bab67e479c192927c4a781efdf5be27eaa315a8",
    "model_name_for_query": "one-man-army/una-neural-chat-v3-3-P2-OMA",
    "link": "https://huggingface.co/one-man-army/una-neural-chat-v3-3-P2-OMA",
    "author": "one-man-army"
  },
  {
    "T": "?",
    "model": "kaori-70b-v1",
    "average": 70.54,
    "arc": 69.8,
    "hellaswag": 87.36,
    "mmlu": 70.82,
    "truthfulqa": 58.81,
    "winogrande": 84.06,
    "gsm8k": 52.39,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fcce042311a54925ae4acdbe33cff535859300b2",
    "model_name_for_query": "KaeriJenti/kaori-70b-v1",
    "link": "https://huggingface.co/KaeriJenti/kaori-70b-v1",
    "author": "KaeriJenti"
  },
  {
    "T": "\u2b55",
    "model": "Pallas-0.2",
    "average": 70.51,
    "arc": 64.59,
    "hellaswag": 83.44,
    "mmlu": 75.53,
    "truthfulqa": 55.29,
    "winogrande": 81.61,
    "gsm8k": 62.62,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2a367db35e91a1cac5abad8e5101e85d391e0551",
    "model_name_for_query": "Mihaiii/Pallas-0.2",
    "link": "https://huggingface.co/Mihaiii/Pallas-0.2",
    "author": "Mihaiii"
  },
  {
    "T": "\u2b55",
    "model": "Pallas-0.2",
    "average": 70.49,
    "arc": 64.51,
    "hellaswag": 83.47,
    "mmlu": 75.64,
    "truthfulqa": 55.27,
    "winogrande": 81.37,
    "gsm8k": 62.7,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2a367db35e91a1cac5abad8e5101e85d391e0551",
    "model_name_for_query": "Mihaiii/Pallas-0.2",
    "link": "https://huggingface.co/Mihaiii/Pallas-0.2",
    "author": "Mihaiii"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-7B-v2.01",
    "average": 70.43,
    "arc": 68.86,
    "hellaswag": 86.12,
    "mmlu": 63.9,
    "truthfulqa": 63.5,
    "winogrande": 80.51,
    "gsm8k": 59.67,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "438642201e2a91e9456d2a8ca1d7443e5ec55a40",
    "model_name_for_query": "perlthoughts/Chupacabra-7B-v2.01",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.01",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-8x7B-MoE",
    "average": 70.4,
    "arc": 68.77,
    "hellaswag": 86.11,
    "mmlu": 63.86,
    "truthfulqa": 63.5,
    "winogrande": 80.51,
    "gsm8k": 59.67,
    "model_type": "fine-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 46.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4df8e16bb4adeff6cfdd6c064819650ae27ff8fa",
    "model_name_for_query": "perlthoughts/Chupacabra-8x7B-MoE",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-8x7B-MoE",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tulpar-7b-v2",
    "average": 70.36,
    "arc": 67.49,
    "hellaswag": 84.89,
    "mmlu": 63.02,
    "truthfulqa": 63.65,
    "winogrande": 79.48,
    "gsm8k": 63.61,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b466113c7726cfcd98ba602ec4000ae323f112fa",
    "model_name_for_query": "HyperbeeAI/Tulpar-7b-v2",
    "link": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v2",
    "author": "HyperbeeAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Falkor-7b",
    "average": 70.33,
    "arc": 68.26,
    "hellaswag": 85.84,
    "mmlu": 63.98,
    "truthfulqa": 63.08,
    "winogrande": 80.35,
    "gsm8k": 60.5,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b2e3c235196ba859b26ee14fb8c86e632bcf3e88",
    "model_name_for_query": "perlthoughts/Falkor-7b",
    "link": "https://huggingface.co/perlthoughts/Falkor-7b",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "una-neural-chat-v3-3-P1-OMA",
    "average": 70.32,
    "arc": 66.81,
    "hellaswag": 85.92,
    "mmlu": 63.37,
    "truthfulqa": 64.35,
    "winogrande": 79.64,
    "gsm8k": 61.87,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "014600373086ea46c7cdc4754c984a804b28a070",
    "model_name_for_query": "one-man-army/una-neural-chat-v3-3-P1-OMA",
    "link": "https://huggingface.co/one-man-army/una-neural-chat-v3-3-P1-OMA",
    "author": "one-man-army"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "v1olet_merged_dpo_7B",
    "average": 70.26,
    "arc": 71.33,
    "hellaswag": 87.34,
    "mmlu": 64.13,
    "truthfulqa": 63.37,
    "winogrande": 82.0,
    "gsm8k": 53.37,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "299011bf619d9b89f4e545dde8ef7853ec0557b6",
    "model_name_for_query": "v1olet/v1olet_merged_dpo_7B",
    "link": "https://huggingface.co/v1olet/v1olet_merged_dpo_7B",
    "author": "v1olet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-Chupacabra-7B-v2.01-Slerp",
    "average": 70.21,
    "arc": 66.13,
    "hellaswag": 85.46,
    "mmlu": 63.92,
    "truthfulqa": 56.15,
    "winogrande": 79.48,
    "gsm8k": 70.13,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dcc6fff61bfd608d8e14a040dff22cd8dae78b1e",
    "model_name_for_query": "PulsarAI/MetaMath-Chupacabra-7B-v2.01-Slerp",
    "link": "https://huggingface.co/PulsarAI/MetaMath-Chupacabra-7B-v2.01-Slerp",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-Tulpar-7b-v2-Slerp",
    "average": 70.2,
    "arc": 65.61,
    "hellaswag": 85.16,
    "mmlu": 63.49,
    "truthfulqa": 56.5,
    "winogrande": 79.48,
    "gsm8k": 70.96,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "41612eecf338ae2b1cbb63a3729ce7b125c6ca3c",
    "model_name_for_query": "PulsarAI/MetaMath-Tulpar-7b-v2-Slerp",
    "link": "https://huggingface.co/PulsarAI/MetaMath-Tulpar-7b-v2-Slerp",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-2.5-neural-chat-v3-2-Slerp",
    "average": 70.2,
    "arc": 67.49,
    "hellaswag": 85.42,
    "mmlu": 64.13,
    "truthfulqa": 61.05,
    "winogrande": 80.03,
    "gsm8k": 63.08,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bf9ef6df7732dbef3cd0001d9e5cba846cb47306",
    "model_name_for_query": "PulsarAI/OpenHermes-2.5-neural-chat-v3-2-Slerp",
    "link": "https://huggingface.co/PulsarAI/OpenHermes-2.5-neural-chat-v3-2-Slerp",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-Merge-14-v0",
    "average": 70.17,
    "arc": 65.87,
    "hellaswag": 85.52,
    "mmlu": 64.66,
    "truthfulqa": 58.58,
    "winogrande": 79.64,
    "gsm8k": 66.72,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aaddbb19f126843e816f4ba529a2f6e61a406c8f",
    "model_name_for_query": "EmbeddedLLM/Mistral-7B-Merge-14-v0",
    "link": "https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0",
    "author": "EmbeddedLLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "average": 70.11,
    "arc": 64.59,
    "hellaswag": 85.39,
    "mmlu": 64.27,
    "truthfulqa": 55.14,
    "winogrande": 79.64,
    "gsm8k": 71.65,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "111ae8b3fb38d550a32f04dbd977f8cd447a3a92",
    "model_name_for_query": "PulsarAI/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "link": "https://huggingface.co/PulsarAI/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-34B-v1.4",
    "average": 70.11,
    "arc": 64.59,
    "hellaswag": 83.37,
    "mmlu": 75.02,
    "truthfulqa": 56.79,
    "winogrande": 81.22,
    "gsm8k": 59.67,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "173d834656c3965cbaa49be6aab0772c3ce57821",
    "model_name_for_query": "migtissera/Tess-34B-v1.4",
    "link": "https://huggingface.co/migtissera/Tess-34B-v1.4",
    "author": "migtissera"
  },
  {
    "T": "\u2b55",
    "model": "SOLAR-0-70b-16bit",
    "average": 70.11,
    "arc": 71.08,
    "hellaswag": 87.89,
    "mmlu": 70.58,
    "truthfulqa": 62.25,
    "winogrande": 83.58,
    "gsm8k": 45.26,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 214.0,
    "still_on_hub": true,
    "revision": "5f9c77b2c0397cf83d2f97740483f107c7109e8c",
    "model_name_for_query": "upstage/SOLAR-0-70b-16bit",
    "link": "https://huggingface.co/upstage/SOLAR-0-70b-16bit",
    "author": "upstage"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FashionGPT-70B-V1.1",
    "average": 70.05,
    "arc": 71.76,
    "hellaswag": 88.2,
    "mmlu": 70.99,
    "truthfulqa": 65.26,
    "winogrande": 82.64,
    "gsm8k": 41.47,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 38.0,
    "still_on_hub": true,
    "revision": "05941a3eaacff0dead79b09d2175b5d7b98c525b",
    "model_name_for_query": "ICBU-NPU/FashionGPT-70B-V1.1",
    "link": "https://huggingface.co/ICBU-NPU/FashionGPT-70B-V1.1",
    "author": "ICBU-NPU"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BruinsV2-OpHermesNeu-11B",
    "average": 69.88,
    "arc": 68.09,
    "hellaswag": 84.7,
    "mmlu": 64.19,
    "truthfulqa": 62.76,
    "winogrande": 79.48,
    "gsm8k": 60.05,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 10.69,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9a5567cf04d6bd8bbd77743f303ce7ecebec78c5",
    "model_name_for_query": "Ba2han/BruinsV2-OpHermesNeu-11B",
    "link": "https://huggingface.co/Ba2han/BruinsV2-OpHermesNeu-11B",
    "author": "Ba2han"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-Q",
    "average": 69.86,
    "arc": 66.89,
    "hellaswag": 85.14,
    "mmlu": 77.66,
    "truthfulqa": 53.03,
    "winogrande": 82.48,
    "gsm8k": 53.98,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "187442aa0d250dc3c44451d71bf8fcdd556bdb24",
    "model_name_for_query": "kyujinpy/PlatYi-34B-Q",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Q",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "StellarBright",
    "average": 69.86,
    "arc": 72.95,
    "hellaswag": 87.82,
    "mmlu": 71.17,
    "truthfulqa": 64.46,
    "winogrande": 83.27,
    "gsm8k": 39.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 69.24,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "43efad8bfdb47139934e810906c1e59c25b5e269",
    "model_name_for_query": "sequelbox/StellarBright",
    "link": "https://huggingface.co/sequelbox/StellarBright",
    "author": "sequelbox"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-3",
    "average": 69.83,
    "arc": 66.89,
    "hellaswag": 85.26,
    "mmlu": 63.07,
    "truthfulqa": 63.01,
    "winogrande": 79.64,
    "gsm8k": 61.11,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fac83ab297a1c9ecc8affd97c998d864c10b9ff4",
    "model_name_for_query": "Intel/neural-chat-7b-v3-3",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-3",
    "author": "Intel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-7B-v2.02",
    "average": 69.82,
    "arc": 67.66,
    "hellaswag": 83.9,
    "mmlu": 61.98,
    "truthfulqa": 64.06,
    "winogrande": 79.4,
    "gsm8k": 61.94,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "24fb5e81b1d39d4358930a1f9054513e9e2d6373",
    "model_name_for_query": "perlthoughts/Chupacabra-7B-v2.02",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.02",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-M-v1.1",
    "average": 69.79,
    "arc": 67.15,
    "hellaswag": 84.76,
    "mmlu": 74.5,
    "truthfulqa": 54.8,
    "winogrande": 82.87,
    "gsm8k": 54.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e5a016b08aa507fe9db45436074016928bf6f939",
    "model_name_for_query": "migtissera/Tess-M-v1.1",
    "link": "https://huggingface.co/migtissera/Tess-M-v1.1",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-neural-chat-7b-v3-2-Slerp",
    "average": 69.79,
    "arc": 65.7,
    "hellaswag": 84.51,
    "mmlu": 63.5,
    "truthfulqa": 55.23,
    "winogrande": 79.95,
    "gsm8k": 69.83,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "147f8e0526768591a7a119b7ec5b8cb821dbe900",
    "model_name_for_query": "Weyaxi/MetaMath-neural-chat-7b-v3-2-Slerp",
    "link": "https://huggingface.co/Weyaxi/MetaMath-neural-chat-7b-v3-2-Slerp",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-M-v1.3",
    "average": 69.71,
    "arc": 62.54,
    "hellaswag": 83.95,
    "mmlu": 75.36,
    "truthfulqa": 56.03,
    "winogrande": 81.14,
    "gsm8k": 59.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "7d733ec8449ec0219a9f499084a94a4248846f7e",
    "model_name_for_query": "migtissera/Tess-M-v1.3",
    "link": "https://huggingface.co/migtissera/Tess-M-v1.3",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Rabbit-7B-DPO-Chat",
    "average": 69.69,
    "arc": 70.31,
    "hellaswag": 87.43,
    "mmlu": 60.5,
    "truthfulqa": 62.18,
    "winogrande": 79.16,
    "gsm8k": 58.53,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "04d42accbc808eec8c020f17392efa07c95ae565",
    "model_name_for_query": "viethq188/Rabbit-7B-DPO-Chat",
    "link": "https://huggingface.co/viethq188/Rabbit-7B-DPO-Chat",
    "author": "viethq188"
  },
  {
    "T": "\ud83d\udd36",
    "model": "una-cybertron-7b-v2-bf16",
    "average": 69.67,
    "arc": 68.26,
    "hellaswag": 85.85,
    "mmlu": 63.23,
    "truthfulqa": 64.63,
    "winogrande": 80.98,
    "gsm8k": 55.04,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "82599694771bd375c91f36dfdf30c448e4e33b3c",
    "model_name_for_query": "fblgit/una-cybertron-7b-v2-bf16",
    "link": "https://huggingface.co/fblgit/una-cybertron-7b-v2-bf16",
    "author": "fblgit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pandora-13B-v1",
    "average": 69.59,
    "arc": 67.06,
    "hellaswag": 87.53,
    "mmlu": 63.65,
    "truthfulqa": 65.77,
    "winogrande": 80.51,
    "gsm8k": 52.99,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 12.48,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "16013ee5682ef9b38c8f27a2c2b78956befdbe52",
    "model_name_for_query": "jan-ai/Pandora-13B-v1",
    "link": "https://huggingface.co/jan-ai/Pandora-13B-v1",
    "author": "jan-ai"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "DPOpenHermes-7B-v2",
    "average": 69.58,
    "arc": 66.64,
    "hellaswag": 85.22,
    "mmlu": 63.64,
    "truthfulqa": 59.22,
    "winogrande": 79.16,
    "gsm8k": 63.61,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3ebea1710b555a205a04e69c743fe90162df63c9",
    "model_name_for_query": "openaccess-ai-collective/DPOpenHermes-7B-v2",
    "link": "https://huggingface.co/openaccess-ai-collective/DPOpenHermes-7B-v2",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "una-cybertron-7b-v1-fp16",
    "average": 69.49,
    "arc": 68.43,
    "hellaswag": 85.42,
    "mmlu": 63.34,
    "truthfulqa": 63.28,
    "winogrande": 81.37,
    "gsm8k": 55.12,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7bf918ddf0878a693f24f39e9f1a520464b44268",
    "model_name_for_query": "fblgit/una-cybertron-7b-v1-fp16",
    "link": "https://huggingface.co/fblgit/una-cybertron-7b-v1-fp16",
    "author": "fblgit"
  },
  {
    "T": "\u2b55",
    "model": "GodziLLa2-70B",
    "average": 69.46,
    "arc": 71.42,
    "hellaswag": 87.53,
    "mmlu": 69.88,
    "truthfulqa": 61.54,
    "winogrande": 83.19,
    "gsm8k": 43.21,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.98,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "7b78087db07eec97f7b461d10758ece76d685543",
    "model_name_for_query": "MayaPH/GodziLLa2-70B",
    "link": "https://huggingface.co/MayaPH/GodziLLa2-70B",
    "author": "MayaPH"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-34B",
    "average": 69.42,
    "arc": 64.59,
    "hellaswag": 85.69,
    "mmlu": 76.35,
    "truthfulqa": 56.23,
    "winogrande": 83.03,
    "gsm8k": 50.64,
    "model_type": "pretrained",
    "architecture": "YiForCausalLM",
    "precision": "bfloat16",
    "license": "custom",
    "params": 34.0,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "cd8d59de87ea11c6453ee287ac82e5523f08c8ec",
    "model_name_for_query": "01-ai/Yi-34B",
    "link": "https://huggingface.co/01-ai/Yi-34B",
    "author": "01-ai"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "deepseek-llm-67b-base",
    "average": 69.38,
    "arc": 65.44,
    "hellaswag": 87.1,
    "mmlu": 71.78,
    "truthfulqa": 51.08,
    "winogrande": 84.14,
    "gsm8k": 56.71,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 67.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c3f813a1121c95488a20132d3a4da89f4a46452f",
    "model_name_for_query": "deepseek-ai/deepseek-llm-67b-base",
    "link": "https://huggingface.co/deepseek-ai/deepseek-llm-67b-base",
    "author": "deepseek-ai"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Rabbit-7B-v2-DPO-Chat",
    "average": 69.36,
    "arc": 66.13,
    "hellaswag": 85.18,
    "mmlu": 62.92,
    "truthfulqa": 67.06,
    "winogrande": 79.24,
    "gsm8k": 55.65,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7dae800851457f1dcccf00a2517448c9a9400b15",
    "model_name_for_query": "viethq188/Rabbit-7B-v2-DPO-Chat",
    "link": "https://huggingface.co/viethq188/Rabbit-7B-v2-DPO-Chat",
    "author": "viethq188"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-deepseek-67b-v15-base",
    "average": 69.34,
    "arc": 66.3,
    "hellaswag": 86.03,
    "mmlu": 70.97,
    "truthfulqa": 52.31,
    "winogrande": 83.58,
    "gsm8k": 56.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 67.42,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2717bb85e0cd4c1c4abfa3d4abb7f9b6e55c1322",
    "model_name_for_query": "OpenBuddy/openbuddy-deepseek-67b-v15-base",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-deepseek-67b-v15-base",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Platypus2-70B-instruct",
    "average": 69.3,
    "arc": 71.84,
    "hellaswag": 87.94,
    "mmlu": 70.48,
    "truthfulqa": 62.26,
    "winogrande": 82.72,
    "gsm8k": 40.56,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 68.72,
    "likes": 148.0,
    "still_on_hub": true,
    "revision": "a66378c15f89756215ccc64572ba69b161173703",
    "model_name_for_query": "garage-bAInd/Platypus2-70B-instruct",
    "link": "https://huggingface.co/garage-bAInd/Platypus2-70B-instruct",
    "author": "garage-bAInd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synatra-MCS-7B-v0.3-RP-Slerp",
    "average": 69.18,
    "arc": 66.64,
    "hellaswag": 84.97,
    "mmlu": 63.61,
    "truthfulqa": 53.93,
    "winogrande": 79.72,
    "gsm8k": 66.19,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "69369829e665cbcda97e7fd178f1c43720f0fce4",
    "model_name_for_query": "PistachioAlt/Synatra-MCS-7B-v0.3-RP-Slerp",
    "link": "https://huggingface.co/PistachioAlt/Synatra-MCS-7B-v0.3-RP-Slerp",
    "author": "PistachioAlt"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-l2-70b-2.2.1",
    "average": 69.13,
    "arc": 69.71,
    "hellaswag": 87.95,
    "mmlu": 69.79,
    "truthfulqa": 59.49,
    "winogrande": 82.95,
    "gsm8k": 44.88,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 68.72,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "eadc78a4a9e173bccdca7dc8d12a34e80317c66c",
    "model_name_for_query": "jondurbin/airoboros-l2-70b-2.2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-2.2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "piano-medley-7b",
    "average": 69.1,
    "arc": 67.58,
    "hellaswag": 85.36,
    "mmlu": 64.49,
    "truthfulqa": 61.42,
    "winogrande": 79.16,
    "gsm8k": 56.56,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "38da429cb28f667e8868574f32269a04dfe41280",
    "model_name_for_query": "chargoddard/piano-medley-7b",
    "link": "https://huggingface.co/chargoddard/piano-medley-7b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Optimus-7B",
    "average": 69.09,
    "arc": 65.44,
    "hellaswag": 85.41,
    "mmlu": 63.61,
    "truthfulqa": 55.79,
    "winogrande": 78.77,
    "gsm8k": 65.5,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d9dd63bc4437c2089f40ce37e689ad530060519c",
    "model_name_for_query": "Q-bert/Optimus-7B",
    "link": "https://huggingface.co/Q-bert/Optimus-7B",
    "author": "Q-bert"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "loyal-piano-m7-cdpo",
    "average": 69.08,
    "arc": 67.15,
    "hellaswag": 85.39,
    "mmlu": 64.52,
    "truthfulqa": 61.53,
    "winogrande": 79.4,
    "gsm8k": 56.48,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5f5a78bedc2d3e5314589f685489bc981890cadf",
    "model_name_for_query": "chargoddard/loyal-piano-m7-cdpo",
    "link": "https://huggingface.co/chargoddard/loyal-piano-m7-cdpo",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Neural-una-cybertron-7b",
    "average": 69.05,
    "arc": 69.03,
    "hellaswag": 84.51,
    "mmlu": 62.79,
    "truthfulqa": 64.99,
    "winogrande": 80.66,
    "gsm8k": 52.31,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "66dae63f92cac0c99b1b162383506b60ac060225",
    "model_name_for_query": "PulsarAI/Neural-una-cybertron-7b",
    "link": "https://huggingface.co/PulsarAI/Neural-una-cybertron-7b",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_v3_70b",
    "average": 69.02,
    "arc": 71.25,
    "hellaswag": 87.85,
    "mmlu": 70.18,
    "truthfulqa": 61.27,
    "winogrande": 82.72,
    "gsm8k": 40.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "c1d4f997f8ed685a6efc72229523b2e56fd0774b",
    "model_name_for_query": "psmathur/orca_mini_v3_70b",
    "link": "https://huggingface.co/psmathur/orca_mini_v3_70b",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "loyal-piano-m7-cdpo",
    "average": 69.0,
    "arc": 67.06,
    "hellaswag": 85.42,
    "mmlu": 64.54,
    "truthfulqa": 61.54,
    "winogrande": 79.08,
    "gsm8k": 56.33,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5f5a78bedc2d3e5314589f685489bc981890cadf",
    "model_name_for_query": "chargoddard/loyal-piano-m7-cdpo",
    "link": "https://huggingface.co/chargoddard/loyal-piano-m7-cdpo",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "servile-harpsichord-cdpo",
    "average": 68.98,
    "arc": 67.32,
    "hellaswag": 85.18,
    "mmlu": 64.54,
    "truthfulqa": 60.61,
    "winogrande": 79.16,
    "gsm8k": 57.09,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "13cdf6bd90df46f4fae1d31b9d3b4f7fc31a7777",
    "model_name_for_query": "chargoddard/servile-harpsichord-cdpo",
    "link": "https://huggingface.co/chargoddard/servile-harpsichord-cdpo",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LeoScorpius-GreenNode-Platypus-7B-v1",
    "average": 68.96,
    "arc": 66.04,
    "hellaswag": 86.53,
    "mmlu": 62.06,
    "truthfulqa": 52.78,
    "winogrande": 82.16,
    "gsm8k": 64.22,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "606894800b6de3fa7a21b46427c3165968fdf3b6",
    "model_name_for_query": "ignos/LeoScorpius-GreenNode-Platypus-7B-v1",
    "link": "https://huggingface.co/ignos/LeoScorpius-GreenNode-Platypus-7B-v1",
    "author": "ignos"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat-3.5-1210",
    "average": 68.89,
    "arc": 64.93,
    "hellaswag": 84.92,
    "mmlu": 64.62,
    "truthfulqa": 52.15,
    "winogrande": 80.74,
    "gsm8k": 65.96,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "e5df841b685e5b5ca11ce142f29c6c731bf087a0",
    "model_name_for_query": "openchat/openchat-3.5-1210",
    "link": "https://huggingface.co/openchat/openchat-3.5-1210",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-una-cybertron-v2-bf16-Ties",
    "average": 68.88,
    "arc": 65.02,
    "hellaswag": 83.68,
    "mmlu": 62.58,
    "truthfulqa": 55.52,
    "winogrande": 77.27,
    "gsm8k": 69.22,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e613cc45140352e2d1759f0f551021e928de006e",
    "model_name_for_query": "Weyaxi/MetaMath-una-cybertron-v2-bf16-Ties",
    "link": "https://huggingface.co/Weyaxi/MetaMath-una-cybertron-v2-bf16-Ties",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-70B-v1",
    "average": 68.83,
    "arc": 73.55,
    "hellaswag": 87.62,
    "mmlu": 70.67,
    "truthfulqa": 64.41,
    "winogrande": 83.43,
    "gsm8k": 33.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 68.72,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "55a30d29db194832c0b5de1392a6598a63582144",
    "model_name_for_query": "AIDC-ai-business/Marcoroni-70B-v1",
    "link": "https://huggingface.co/AIDC-ai-business/Marcoroni-70B-v1",
    "author": "AIDC-ai-business"
  },
  {
    "T": "\ud83d\udd36",
    "model": "A11P",
    "average": 68.73,
    "arc": 62.54,
    "hellaswag": 82.53,
    "mmlu": 70.56,
    "truthfulqa": 56.44,
    "winogrande": 79.87,
    "gsm8k": 60.42,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "gpl",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "0a14aa5fd9ae557d7dbd02e503deab50544d5a6f",
    "model_name_for_query": "AA051610/A11P",
    "link": "https://huggingface.co/AA051610/A11P",
    "author": "AA051610"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pic_7B_mistral_Full_v0.2",
    "average": 68.72,
    "arc": 65.36,
    "hellaswag": 84.03,
    "mmlu": 64.51,
    "truthfulqa": 59.2,
    "winogrande": 79.48,
    "gsm8k": 59.74,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4499c15a16b11d6491dcbe029acff64f03e1a5fd",
    "model_name_for_query": "TokenBender/pic_7B_mistral_Full_v0.2",
    "link": "https://huggingface.co/TokenBender/pic_7B_mistral_Full_v0.2",
    "author": "TokenBender"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-2.5-neural-chat-7b-v3-2-7B",
    "average": 68.71,
    "arc": 66.38,
    "hellaswag": 84.11,
    "mmlu": 62.84,
    "truthfulqa": 63.59,
    "winogrande": 78.53,
    "gsm8k": 56.79,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "585c2fca1dce1904491c40408f6dd5404eca3754",
    "model_name_for_query": "Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-2-7B",
    "link": "https://huggingface.co/Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-2-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\u2b55",
    "model": "Yi-34B-AEZAKMI-v1",
    "average": 68.67,
    "arc": 64.33,
    "hellaswag": 84.31,
    "mmlu": 73.91,
    "truthfulqa": 55.73,
    "winogrande": 80.82,
    "gsm8k": 52.92,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c56dc8471eba802f74fed756f555b718d975d00a",
    "model_name_for_query": "adamo1139/Yi-34B-AEZAKMI-v1",
    "link": "https://huggingface.co/adamo1139/Yi-34B-AEZAKMI-v1",
    "author": "adamo1139"
  },
  {
    "T": "\u2b55",
    "model": "loyal-piano-m7",
    "average": 68.67,
    "arc": 66.72,
    "hellaswag": 85.03,
    "mmlu": 64.43,
    "truthfulqa": 60.03,
    "winogrande": 79.08,
    "gsm8k": 56.71,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d74ae6cb13325e0f81797ee33c07f0e234a2caa4",
    "model_name_for_query": "chargoddard/loyal-piano-m7",
    "link": "https://huggingface.co/chargoddard/loyal-piano-m7",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "A12P",
    "average": 68.64,
    "arc": 64.42,
    "hellaswag": 82.32,
    "mmlu": 69.97,
    "truthfulqa": 62.22,
    "winogrande": 79.64,
    "gsm8k": 53.3,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "gpl",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "e2eb6a36741dfc799fd13f67cba385f6e3992393",
    "model_name_for_query": "AA051610/A12P",
    "link": "https://huggingface.co/AA051610/A12P",
    "author": "AA051610"
  },
  {
    "T": "\ud83d\udd36",
    "model": "agiin-13.6B-v0.0",
    "average": 68.63,
    "arc": 69.45,
    "hellaswag": 86.59,
    "mmlu": 61.94,
    "truthfulqa": 67.4,
    "winogrande": 78.69,
    "gsm8k": 47.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.78,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "631e80949b055193053c802437f3a31fe4e1390d",
    "model_name_for_query": "mncai/agiin-13.6B-v0.0",
    "link": "https://huggingface.co/mncai/agiin-13.6B-v0.0",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "spicyboros-70b-2.2",
    "average": 68.62,
    "arc": 70.73,
    "hellaswag": 87.58,
    "mmlu": 70.32,
    "truthfulqa": 58.31,
    "winogrande": 83.82,
    "gsm8k": 40.94,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 70.0,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "533f7dda1e3fe462a0abb00671f9a48d5fd51093",
    "model_name_for_query": "jondurbin/spicyboros-70b-2.2",
    "link": "https://huggingface.co/jondurbin/spicyboros-70b-2.2",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
    "average": 68.57,
    "arc": 64.93,
    "hellaswag": 84.99,
    "mmlu": 75.37,
    "truthfulqa": 52.84,
    "winogrande": 79.24,
    "gsm8k": 54.06,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7be35464f07307b5503d12736f732a34f3c1d8c1",
    "model_name_for_query": "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
    "link": "https://huggingface.co/brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
    "author": "brucethemoose"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_007",
    "average": 68.56,
    "arc": 71.08,
    "hellaswag": 87.65,
    "mmlu": 69.04,
    "truthfulqa": 63.12,
    "winogrande": 83.35,
    "gsm8k": 37.15,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "0f5d81b13718a866cb078bd8762ab80a41972663",
    "model_name_for_query": "psmathur/model_007",
    "link": "https://huggingface.co/psmathur/model_007",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_009",
    "average": 68.53,
    "arc": 71.59,
    "hellaswag": 87.7,
    "mmlu": 69.43,
    "truthfulqa": 60.72,
    "winogrande": 82.32,
    "gsm8k": 39.42,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5020869e6394b1ac039bf80a0a1d2bed6be6707e",
    "model_name_for_query": "psmathur/model_009",
    "link": "https://huggingface.co/psmathur/model_009",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Instruct-v0.2-Seraph-7B",
    "average": 68.48,
    "arc": 64.76,
    "hellaswag": 84.2,
    "mmlu": 62.9,
    "truthfulqa": 65.39,
    "winogrande": 79.16,
    "gsm8k": 54.44,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6ea01ce2a3b6967d9aaf968ed8015da21c979928",
    "model_name_for_query": "Weyaxi/Instruct-v0.2-Seraph-7B",
    "link": "https://huggingface.co/Weyaxi/Instruct-v0.2-Seraph-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_101",
    "average": 68.46,
    "arc": 68.69,
    "hellaswag": 86.42,
    "mmlu": 69.92,
    "truthfulqa": 58.85,
    "winogrande": 82.08,
    "gsm8k": 44.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "884c53a64a3c5faf7b0706d36a587ca1532ed8f5",
    "model_name_for_query": "psmathur/model_101",
    "link": "https://huggingface.co/psmathur/model_101",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Mixtral-8x7B-v0.1",
    "average": 68.42,
    "arc": 66.04,
    "hellaswag": 86.49,
    "mmlu": 71.82,
    "truthfulqa": 46.78,
    "winogrande": 81.93,
    "gsm8k": 57.47,
    "model_type": "pretrained",
    "architecture": "MixtralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 46.7,
    "likes": 194.0,
    "still_on_hub": true,
    "revision": "4dd4b0f2d577d7b74152732d5543a92201481fe2",
    "model_name_for_query": "mistralai/Mixtral-8x7B-v0.1",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-v0.1",
    "author": "mistralai"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "agiin-13.6B-v0.1",
    "average": 68.4,
    "arc": 69.45,
    "hellaswag": 86.64,
    "mmlu": 61.15,
    "truthfulqa": 67.97,
    "winogrande": 78.69,
    "gsm8k": 46.47,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.78,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6c93ca1d60b09b9b91e15c57dc8525827d371798",
    "model_name_for_query": "mncai/agiin-13.6B-v0.1",
    "link": "https://huggingface.co/mncai/agiin-13.6B-v0.1",
    "author": "mncai"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-Llama",
    "average": 68.37,
    "arc": 67.83,
    "hellaswag": 85.35,
    "mmlu": 78.26,
    "truthfulqa": 53.46,
    "winogrande": 82.87,
    "gsm8k": 42.46,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "e641a44c60ddf1f31d898ca53810ccb1e7a30972",
    "model_name_for_query": "kyujinpy/PlatYi-34B-Llama",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama",
    "author": "kyujinpy"
  },
  {
    "T": "\u2b55",
    "model": "genz-70b",
    "average": 68.35,
    "arc": 71.42,
    "hellaswag": 87.99,
    "mmlu": 70.78,
    "truthfulqa": 62.66,
    "winogrande": 83.5,
    "gsm8k": 33.74,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "32110b4f33e5e80073ca1f47638482fdc0e19297",
    "model_name_for_query": "budecosystem/genz-70b",
    "link": "https://huggingface.co/budecosystem/genz-70b",
    "author": "budecosystem"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-Llama-Q-FastChat",
    "average": 68.31,
    "arc": 66.13,
    "hellaswag": 85.25,
    "mmlu": 78.37,
    "truthfulqa": 53.62,
    "winogrande": 82.16,
    "gsm8k": 44.35,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "dab86ae57fe51dc5e993769ebb69a173637852bc",
    "model_name_for_query": "kyujinpy/PlatYi-34B-Llama-Q-FastChat",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q-FastChat",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Falkor-8x7B-MoE",
    "average": 68.31,
    "arc": 66.3,
    "hellaswag": 85.03,
    "mmlu": 64.13,
    "truthfulqa": 53.5,
    "winogrande": 80.19,
    "gsm8k": 60.73,
    "model_type": "fine-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 46.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8a13e5399c12811d178cea09ffa719596410c9b4",
    "model_name_for_query": "perlthoughts/Falkor-8x7B-MoE",
    "link": "https://huggingface.co/perlthoughts/Falkor-8x7B-MoE",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-2",
    "average": 68.29,
    "arc": 67.49,
    "hellaswag": 83.92,
    "mmlu": 63.55,
    "truthfulqa": 59.68,
    "winogrande": 79.95,
    "gsm8k": 55.12,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "2ecaf100bcf63da6cf87dd7bfbea5732fa74c413",
    "model_name_for_query": "Intel/neural-chat-7b-v3-2",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-2",
    "author": "Intel"
  },
  {
    "T": "\u2b55",
    "model": "chronos007-70b",
    "average": 68.25,
    "arc": 70.14,
    "hellaswag": 87.52,
    "mmlu": 69.33,
    "truthfulqa": 57.65,
    "winogrande": 82.24,
    "gsm8k": 42.61,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 68.98,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "c775f87a56f00725de4263f8d527995d40f611c4",
    "model_name_for_query": "elinas/chronos007-70b",
    "link": "https://huggingface.co/elinas/chronos007-70b",
    "author": "elinas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "NeuralHermes-2.5-Mistral-7B",
    "average": 68.22,
    "arc": 66.55,
    "hellaswag": 84.9,
    "mmlu": 63.32,
    "truthfulqa": 54.93,
    "winogrande": 78.3,
    "gsm8k": 61.33,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "351028e0532a084c2c1370029fcf2ef805da3929",
    "model_name_for_query": "mlabonne/NeuralHermes-2.5-Mistral-7B",
    "link": "https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B",
    "author": "mlabonne"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OrionStar-Yi-34B-Chat-Llama",
    "average": 68.17,
    "arc": 64.93,
    "hellaswag": 84.34,
    "mmlu": 73.67,
    "truthfulqa": 53.35,
    "winogrande": 78.85,
    "gsm8k": 53.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "333c788e0d026cdb76bb827b8dcbc14a859ae2cc",
    "model_name_for_query": "OrionStarAI/OrionStar-Yi-34B-Chat-Llama",
    "link": "https://huggingface.co/OrionStarAI/OrionStar-Yi-34B-Chat-Llama",
    "author": "OrionStarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "blossom-v3_1-yi-34b",
    "average": 68.16,
    "arc": 65.36,
    "hellaswag": 84.24,
    "mmlu": 74.37,
    "truthfulqa": 56.06,
    "winogrande": 82.08,
    "gsm8k": 46.85,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 34.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2ec5cbb112a31c62c8631b89fbde0aebaabb6e0a",
    "model_name_for_query": "Azure99/blossom-v3_1-yi-34b",
    "link": "https://huggingface.co/Azure99/blossom-v3_1-yi-34b",
    "author": "Azure99"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama2-70b-v10.1-bf16",
    "average": 68.16,
    "arc": 61.86,
    "hellaswag": 83.13,
    "mmlu": 67.41,
    "truthfulqa": 56.18,
    "winogrande": 80.11,
    "gsm8k": 60.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 68.76,
    "likes": 41.0,
    "still_on_hub": true,
    "revision": "a6ee90d262ac729f90ed8de97127766df070074c",
    "model_name_for_query": "OpenBuddy/openbuddy-llama2-70b-v10.1-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-70b-v10.1-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "AZG",
    "average": 68.16,
    "arc": 62.88,
    "hellaswag": 82.02,
    "mmlu": 70.29,
    "truthfulqa": 53.84,
    "winogrande": 79.95,
    "gsm8k": 59.97,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "gpl-3.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "36c17124ff891121c39f2d5e4d203daad5350c48",
    "model_name_for_query": "AA051610/AZG",
    "link": "https://huggingface.co/AA051610/AZG",
    "author": "AA051610"
  },
  {
    "T": "?",
    "model": "OpenZephyrChat",
    "average": 68.12,
    "arc": 64.85,
    "hellaswag": 85.08,
    "mmlu": 64.92,
    "truthfulqa": 48.24,
    "winogrande": 81.06,
    "gsm8k": 64.59,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "146727eb2ebe09ea90552b0b22cb0abbfb830999",
    "model_name_for_query": "Fredithefish/OpenZephyrChat",
    "link": "https://huggingface.co/Fredithefish/OpenZephyrChat",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "agiin-11.1B-v0.0",
    "average": 68.1,
    "arc": 67.32,
    "hellaswag": 86.35,
    "mmlu": 64.99,
    "truthfulqa": 67.67,
    "winogrande": 78.85,
    "gsm8k": 43.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.17,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0b086b46a672f450d7b2e8c307526e62d8d0cfdf",
    "model_name_for_query": "mncai/agiin-11.1B-v0.0",
    "link": "https://huggingface.co/mncai/agiin-11.1B-v0.0",
    "author": "mncai"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-LoRA",
    "average": 68.1,
    "arc": 67.15,
    "hellaswag": 85.37,
    "mmlu": 78.46,
    "truthfulqa": 53.32,
    "winogrande": 83.66,
    "gsm8k": 40.64,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5dcc36255b4632ba32a6b940fa43d53764a3fae3",
    "model_name_for_query": "kyujinpy/PlatYi-34B-LoRA",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-LoRA",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Merged-DPO-7B",
    "average": 68.06,
    "arc": 68.94,
    "hellaswag": 87.75,
    "mmlu": 55.35,
    "truthfulqa": 72.76,
    "winogrande": 78.37,
    "gsm8k": 45.19,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "1c0e61c7da6839fe4cc34433b899c5416fadbe18",
    "model_name_for_query": "GreenNode/Merged-DPO-7B",
    "link": "https://huggingface.co/GreenNode/Merged-DPO-7B",
    "author": "GreenNode"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "lil-c3po",
    "average": 68.03,
    "arc": 65.02,
    "hellaswag": 84.45,
    "mmlu": 62.36,
    "truthfulqa": 68.73,
    "winogrande": 79.16,
    "gsm8k": 48.45,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7888318c72df9f668df20b2916b651b94a6ed77c",
    "model_name_for_query": "deepnight-research/lil-c3po",
    "link": "https://huggingface.co/deepnight-research/lil-c3po",
    "author": "deepnight-research"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bagel-dpo-7b-v0.1",
    "average": 67.95,
    "arc": 66.72,
    "hellaswag": 84.16,
    "mmlu": 64.24,
    "truthfulqa": 64.05,
    "winogrande": 80.9,
    "gsm8k": 47.61,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6444a0bc809bad1322820b48707746f027e01b96",
    "model_name_for_query": "jondurbin/bagel-dpo-7b-v0.1",
    "link": "https://huggingface.co/jondurbin/bagel-dpo-7b-v0.1",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-Llama-Q-v2",
    "average": 67.88,
    "arc": 61.09,
    "hellaswag": 85.09,
    "mmlu": 76.59,
    "truthfulqa": 52.65,
    "winogrande": 82.79,
    "gsm8k": 49.05,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "10ca8ee92ce7e749b8480de603bd8599d8d1fb29",
    "model_name_for_query": "kyujinpy/PlatYi-34B-Llama-Q-v2",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q-v2",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Llama-2-70b-hf",
    "average": 67.87,
    "arc": 67.32,
    "hellaswag": 87.33,
    "mmlu": 69.83,
    "truthfulqa": 44.92,
    "winogrande": 83.74,
    "gsm8k": 54.06,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 68.98,
    "likes": 623.0,
    "still_on_hub": false,
    "revision": "ed7b07231238f836b99bf45701b9a0063576b194",
    "model_name_for_query": "meta-llama/Llama-2-70b-hf",
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-hf",
    "author": "meta-llama"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-200k-Q-FastChat",
    "average": 67.85,
    "arc": 64.93,
    "hellaswag": 84.46,
    "mmlu": 77.13,
    "truthfulqa": 48.38,
    "winogrande": 80.74,
    "gsm8k": 51.48,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "92a96144f94c24341cb6a40259be28627bc76298",
    "model_name_for_query": "kyujinpy/PlatYi-34B-200k-Q-FastChat",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-200k-Q-FastChat",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "falcon-180B",
    "average": 67.85,
    "arc": 69.45,
    "hellaswag": 88.86,
    "mmlu": 70.5,
    "truthfulqa": 45.47,
    "winogrande": 86.9,
    "gsm8k": 45.94,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "8bit",
    "license": "unknown",
    "params": 179.52,
    "likes": 830.0,
    "still_on_hub": false,
    "revision": "71a1a70b629e9963f7b4601e82f3f9079d48011e",
    "model_name_for_query": "tiiuae/falcon-180B",
    "link": "https://huggingface.co/tiiuae/falcon-180B",
    "author": "tiiuae"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nyxene-v2-11B",
    "average": 67.84,
    "arc": 67.41,
    "hellaswag": 84.54,
    "mmlu": 65.26,
    "truthfulqa": 55.62,
    "winogrande": 79.56,
    "gsm8k": 54.66,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "07d017d24117fabce2e7b67819f6689e3187404f",
    "model_name_for_query": "beberik/Nyxene-v2-11B",
    "link": "https://huggingface.co/beberik/Nyxene-v2-11B",
    "author": "beberik"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-2.5-neural-chat-7b-v3-1-7B",
    "average": 67.84,
    "arc": 66.55,
    "hellaswag": 84.47,
    "mmlu": 63.34,
    "truthfulqa": 61.22,
    "winogrande": 78.37,
    "gsm8k": 53.07,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "2e72eb3999108b7a9c7d0d0c6b8d81ad3470f1f5",
    "model_name_for_query": "Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B",
    "link": "https://huggingface.co/Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-7B",
    "average": 67.76,
    "arc": 66.81,
    "hellaswag": 83.52,
    "mmlu": 62.68,
    "truthfulqa": 52.31,
    "winogrande": 79.08,
    "gsm8k": 62.17,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "ae20703e16d89ba4a4301d12195cede64bd2ebdd",
    "model_name_for_query": "perlthoughts/Chupacabra-7B",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Bumblebee-7B",
    "average": 67.73,
    "arc": 63.4,
    "hellaswag": 84.16,
    "mmlu": 64.0,
    "truthfulqa": 50.96,
    "winogrande": 78.22,
    "gsm8k": 65.66,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "0c95c597b9c6c5563273126d1306fdd56bd31618",
    "model_name_for_query": "Q-bert/Bumblebee-7B",
    "link": "https://huggingface.co/Q-bert/Bumblebee-7B",
    "author": "Q-bert"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nyxene-11B",
    "average": 67.72,
    "arc": 68.34,
    "hellaswag": 84.54,
    "mmlu": 65.09,
    "truthfulqa": 57.5,
    "winogrande": 79.08,
    "gsm8k": 51.78,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "55e115157836e1529dd28fc56e2900a5f0e79b89",
    "model_name_for_query": "beberik/Nyxene-11B",
    "link": "https://huggingface.co/beberik/Nyxene-11B",
    "author": "beberik"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Euryale-1.3-L2-70B",
    "average": 67.66,
    "arc": 70.82,
    "hellaswag": 87.92,
    "mmlu": 70.39,
    "truthfulqa": 59.85,
    "winogrande": 82.79,
    "gsm8k": 34.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "6e3ce78eb5346bf3a5ee88cd60c25dc0d73de639",
    "model_name_for_query": "Sao10K/Euryale-1.3-L2-70B",
    "link": "https://huggingface.co/Sao10K/Euryale-1.3-L2-70B",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "NeuralOrca-7B-v1",
    "average": 67.64,
    "arc": 65.27,
    "hellaswag": 85.07,
    "mmlu": 63.68,
    "truthfulqa": 54.58,
    "winogrande": 78.77,
    "gsm8k": 58.45,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "32fb215494467cc6fa2f283a4b02f23546a26807",
    "model_name_for_query": "mrfakename/NeuralOrca-7B-v1",
    "link": "https://huggingface.co/mrfakename/NeuralOrca-7B-v1",
    "author": "mrfakename"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DPOpenHermes-7B",
    "average": 67.63,
    "arc": 65.96,
    "hellaswag": 85.9,
    "mmlu": 63.98,
    "truthfulqa": 56.92,
    "winogrande": 78.22,
    "gsm8k": 54.81,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7742bd00c7d66791e94882b196b4d96fb88e63a",
    "model_name_for_query": "openaccess-ai-collective/DPOpenHermes-7B",
    "link": "https://huggingface.co/openaccess-ai-collective/DPOpenHermes-7B",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ORCA_LLaMA_70B_QLoRA",
    "average": 67.6,
    "arc": 72.27,
    "hellaswag": 87.74,
    "mmlu": 70.23,
    "truthfulqa": 63.37,
    "winogrande": 83.66,
    "gsm8k": 28.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 49.0,
    "still_on_hub": true,
    "revision": "ef9b04ef02ccc4d96f1181467da92bb6b5baf835",
    "model_name_for_query": "fangloveskari/ORCA_LLaMA_70B_QLoRA",
    "link": "https://huggingface.co/fangloveskari/ORCA_LLaMA_70B_QLoRA",
    "author": "fangloveskari"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nyxene-v1-11B",
    "average": 67.58,
    "arc": 67.49,
    "hellaswag": 84.52,
    "mmlu": 65.12,
    "truthfulqa": 57.28,
    "winogrande": 79.01,
    "gsm8k": 52.08,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1af08865a403f3be77898d7fbc89bd3be5dfb21f",
    "model_name_for_query": "beberik/Nyxene-v1-11B",
    "link": "https://huggingface.co/beberik/Nyxene-v1-11B",
    "author": "beberik"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "DPOpenHermes-7B",
    "average": 67.58,
    "arc": 65.7,
    "hellaswag": 85.96,
    "mmlu": 63.89,
    "truthfulqa": 56.95,
    "winogrande": 78.61,
    "gsm8k": 54.36,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7742bd00c7d66791e94882b196b4d96fb88e63a",
    "model_name_for_query": "openaccess-ai-collective/DPOpenHermes-7B",
    "link": "https://huggingface.co/openaccess-ai-collective/DPOpenHermes-7B",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Platypus_QLoRA_LLaMA_70b",
    "average": 67.57,
    "arc": 72.1,
    "hellaswag": 87.46,
    "mmlu": 71.02,
    "truthfulqa": 61.18,
    "winogrande": 82.87,
    "gsm8k": 30.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "b9b8560832276f60ba6bf37ac913b230a85ac19b",
    "model_name_for_query": "fangloveskari/Platypus_QLoRA_LLaMA_70b",
    "link": "https://huggingface.co/fangloveskari/Platypus_QLoRA_LLaMA_70b",
    "author": "fangloveskari"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-neural-chat-7b-v3-2-Ties",
    "average": 67.54,
    "arc": 63.48,
    "hellaswag": 82.34,
    "mmlu": 62.25,
    "truthfulqa": 52.06,
    "winogrande": 76.87,
    "gsm8k": 68.23,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2b0436588c205a6ecae5f32617d88b087b3cc644",
    "model_name_for_query": "Weyaxi/MetaMath-neural-chat-7b-v3-2-Ties",
    "link": "https://huggingface.co/Weyaxi/MetaMath-neural-chat-7b-v3-2-Ties",
    "author": "Weyaxi"
  },
  {
    "T": "\u2b55",
    "model": "MoMo-70B-LoRA-V1.1",
    "average": 67.53,
    "arc": 66.64,
    "hellaswag": 87.16,
    "mmlu": 66.76,
    "truthfulqa": 54.98,
    "winogrande": 83.35,
    "gsm8k": 46.32,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 70.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "ade069976a810b6b7caf3173a1aa4bfb30534ec9",
    "model_name_for_query": "bongchoi/MoMo-70B-LoRA-V1.1",
    "link": "https://huggingface.co/bongchoi/MoMo-70B-LoRA-V1.1",
    "author": "bongchoi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FashionGPT-70B-V1",
    "average": 67.47,
    "arc": 71.08,
    "hellaswag": 87.32,
    "mmlu": 70.7,
    "truthfulqa": 63.92,
    "winogrande": 83.66,
    "gsm8k": 28.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "060c096af49700760f734c0102250a524d46b3eb",
    "model_name_for_query": "ICBU-NPU/FashionGPT-70B-V1",
    "link": "https://huggingface.co/ICBU-NPU/FashionGPT-70B-V1",
    "author": "ICBU-NPU"
  },
  {
    "T": "\ud83d\udd36",
    "model": "juanako-7b-UNA",
    "average": 67.46,
    "arc": 68.17,
    "hellaswag": 85.34,
    "mmlu": 62.47,
    "truthfulqa": 65.13,
    "winogrande": 78.85,
    "gsm8k": 44.81,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "3e12f691e1f442f69eaff408677a54ebc69d5dc8",
    "model_name_for_query": "fblgit/juanako-7b-UNA",
    "link": "https://huggingface.co/fblgit/juanako-7b-UNA",
    "author": "fblgit"
  },
  {
    "T": "\u2b55",
    "model": "Samantha-1.1-70b",
    "average": 67.43,
    "arc": 68.77,
    "hellaswag": 87.46,
    "mmlu": 68.6,
    "truthfulqa": 64.85,
    "winogrande": 83.27,
    "gsm8k": 31.61,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "a3819d186f5b4d52ced7ddeb7fa16bf66e8a2ea7",
    "model_name_for_query": "ehartford/Samantha-1.1-70b",
    "link": "https://huggingface.co/ehartford/Samantha-1.1-70b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "StableBeluga2",
    "average": 67.42,
    "arc": 71.08,
    "hellaswag": 86.37,
    "mmlu": 68.79,
    "truthfulqa": 59.44,
    "winogrande": 82.95,
    "gsm8k": 35.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 836.0,
    "still_on_hub": true,
    "revision": "e4944caa6ece819413b140b8dcecea79fe7e22cf",
    "model_name_for_query": "stabilityai/StableBeluga2",
    "link": "https://huggingface.co/stabilityai/StableBeluga2",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test_42_70b",
    "average": 67.38,
    "arc": 68.26,
    "hellaswag": 87.65,
    "mmlu": 70.0,
    "truthfulqa": 48.76,
    "winogrande": 83.66,
    "gsm8k": 45.94,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "ca3789cd6b683e97dcd6a5f0367f90a63d7a4e7b",
    "model_name_for_query": "psmathur/test_42_70b",
    "link": "https://huggingface.co/psmathur/test_42_70b",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-70b-instruct",
    "average": 67.38,
    "arc": 70.9,
    "hellaswag": 87.48,
    "mmlu": 69.8,
    "truthfulqa": 60.97,
    "winogrande": 82.87,
    "gsm8k": 32.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 53.0,
    "still_on_hub": true,
    "revision": "8469429924dc2e1a9394b8095753985668a4052e",
    "model_name_for_query": "upstage/Llama-2-70b-instruct",
    "link": "https://huggingface.co/upstage/Llama-2-70b-instruct",
    "author": "upstage"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SharpBalance",
    "average": 67.36,
    "arc": 69.28,
    "hellaswag": 87.59,
    "mmlu": 69.51,
    "truthfulqa": 59.05,
    "winogrande": 84.06,
    "gsm8k": 34.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 69.24,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "a87cb1756d7b7389cc5a6d4647cf53377e962aea",
    "model_name_for_query": "sequelbox/SharpBalance",
    "link": "https://huggingface.co/sequelbox/SharpBalance",
    "author": "sequelbox"
  },
  {
    "T": "\u2b55",
    "model": "Samantha-1.11-70b",
    "average": 67.28,
    "arc": 70.05,
    "hellaswag": 87.55,
    "mmlu": 67.82,
    "truthfulqa": 65.02,
    "winogrande": 83.27,
    "gsm8k": 29.95,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 30.0,
    "still_on_hub": true,
    "revision": "49e5b5ee0bed2864f0b38ba8bf9e01ccc5e0ba5f",
    "model_name_for_query": "ehartford/Samantha-1.11-70b",
    "link": "https://huggingface.co/ehartford/Samantha-1.11-70b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Ana-v1-m7",
    "average": 67.24,
    "arc": 67.41,
    "hellaswag": 85.98,
    "mmlu": 64.43,
    "truthfulqa": 55.03,
    "winogrande": 78.06,
    "gsm8k": 52.54,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "375e1a29c36bc1bf7bee972a28f47f9db1e85696",
    "model_name_for_query": "Sao10K/Ana-v1-m7",
    "link": "https://huggingface.co/Sao10K/Ana-v1-m7",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-1-OpenHermes-2.5-7B",
    "average": 67.19,
    "arc": 66.13,
    "hellaswag": 84.09,
    "mmlu": 63.22,
    "truthfulqa": 61.23,
    "winogrande": 77.58,
    "gsm8k": 50.87,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "b620ea7af98730695e051be48273cdded8923a2b",
    "model_name_for_query": "Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B",
    "link": "https://huggingface.co/Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FashionGPT-70B-V1.2",
    "average": 67.17,
    "arc": 73.04,
    "hellaswag": 88.15,
    "mmlu": 70.11,
    "truthfulqa": 65.15,
    "winogrande": 82.56,
    "gsm8k": 24.03,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "990a1664fc058de6ee2406af62c0a817d7047304",
    "model_name_for_query": "ICBU-NPU/FashionGPT-70B-V1.2",
    "link": "https://huggingface.co/ICBU-NPU/FashionGPT-70B-V1.2",
    "author": "ICBU-NPU"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Starling-LM-7B-alpha",
    "average": 67.13,
    "arc": 63.82,
    "hellaswag": 84.9,
    "mmlu": 64.67,
    "truthfulqa": 46.39,
    "winogrande": 80.58,
    "gsm8k": 62.4,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 170.0,
    "still_on_hub": true,
    "revision": "f721e85293598f2ef774e483ae95343e39811577",
    "model_name_for_query": "berkeley-nest/Starling-LM-7B-alpha",
    "link": "https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha",
    "author": "berkeley-nest"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lzlv_70b_fp16_hf",
    "average": 67.13,
    "arc": 70.14,
    "hellaswag": 87.54,
    "mmlu": 70.23,
    "truthfulqa": 60.49,
    "winogrande": 83.43,
    "gsm8k": 30.93,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-2.0",
    "params": 68.98,
    "likes": 23.0,
    "still_on_hub": true,
    "revision": "b366c0bb318ae592023cca894cc6b4421a607a0d",
    "model_name_for_query": "lizpreciatior/lzlv_70b_fp16_hf",
    "link": "https://huggingface.co/lizpreciatior/lzlv_70b_fp16_hf",
    "author": "lizpreciatior"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_007_v2",
    "average": 67.13,
    "arc": 71.42,
    "hellaswag": 87.31,
    "mmlu": 68.58,
    "truthfulqa": 62.65,
    "winogrande": 84.14,
    "gsm8k": 28.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "3d95e0f3598f7a76ab97cb2cc0e4aae957d77479",
    "model_name_for_query": "psmathur/model_007_v2",
    "link": "https://huggingface.co/psmathur/model_007_v2",
    "author": "psmathur"
  },
  {
    "T": "\u2b55",
    "model": "MelangeB-70b",
    "average": 67.12,
    "arc": 71.67,
    "hellaswag": 87.5,
    "mmlu": 70.03,
    "truthfulqa": 59.36,
    "winogrande": 83.5,
    "gsm8k": 30.63,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.98,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "08239fb1e30b1e42b14370f23e942bc51e76027c",
    "model_name_for_query": "chargoddard/MelangeB-70b",
    "link": "https://huggingface.co/chargoddard/MelangeB-70b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Starling-LM-alpha-8x7B-MoE",
    "average": 67.11,
    "arc": 63.65,
    "hellaswag": 84.9,
    "mmlu": 64.68,
    "truthfulqa": 46.39,
    "winogrande": 80.58,
    "gsm8k": 62.47,
    "model_type": "fine-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 46.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "61a66c526af1238690c815051c0f4ebe866ca588",
    "model_name_for_query": "perlthoughts/Starling-LM-alpha-8x7B-MoE",
    "link": "https://huggingface.co/perlthoughts/Starling-LM-alpha-8x7B-MoE",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "smol-7b",
    "average": 67.11,
    "arc": 63.74,
    "hellaswag": 84.77,
    "mmlu": 65.0,
    "truthfulqa": 46.17,
    "winogrande": 80.66,
    "gsm8k": 62.32,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d3e24684f38e0332cf4a6c70a37ee894e7a27fdc",
    "model_name_for_query": "rishiraj/smol-7b",
    "link": "https://huggingface.co/rishiraj/smol-7b",
    "author": "rishiraj"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Starling-LM-7B-alpha",
    "average": 67.05,
    "arc": 63.65,
    "hellaswag": 84.87,
    "mmlu": 64.7,
    "truthfulqa": 46.32,
    "winogrande": 80.43,
    "gsm8k": 62.32,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 61.0,
    "still_on_hub": true,
    "revision": "76e60ca9807f55acd8eff3ec7ae022c5fbdf1e0e",
    "model_name_for_query": "berkeley-nest/Starling-LM-7B-alpha",
    "link": "https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha",
    "author": "berkeley-nest"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-7B-v2",
    "average": 67.04,
    "arc": 65.19,
    "hellaswag": 83.39,
    "mmlu": 63.6,
    "truthfulqa": 57.17,
    "winogrande": 78.14,
    "gsm8k": 54.74,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "0c7f7c85359f15d3e6c361e8192738bdfb14ea6c",
    "model_name_for_query": "perlthoughts/Chupacabra-7B-v2",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
    "average": 67.03,
    "arc": 62.46,
    "hellaswag": 82.89,
    "mmlu": 62.25,
    "truthfulqa": 50.15,
    "winogrande": 75.14,
    "gsm8k": 69.29,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b11bbd94238e1cc568c476844b1900c6e3facfa7",
    "model_name_for_query": "Weyaxi/MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
    "link": "https://huggingface.co/Weyaxi/MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-70B-V1.0",
    "average": 67.02,
    "arc": 68.0,
    "hellaswag": 86.85,
    "mmlu": 69.31,
    "truthfulqa": 50.98,
    "winogrande": 82.32,
    "gsm8k": 44.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "783a3c7d5d0a75e6e11074f2577b90dd219ef7b1",
    "model_name_for_query": "meta-math/MetaMath-70B-V1.0",
    "link": "https://huggingface.co/meta-math/MetaMath-70B-V1.0",
    "author": "meta-math"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-70B-v1.2b",
    "average": 67.0,
    "arc": 68.77,
    "hellaswag": 87.57,
    "mmlu": 68.81,
    "truthfulqa": 57.69,
    "winogrande": 83.9,
    "gsm8k": 35.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "7b687d6e4101b8bb8cc4062f8a318d639098a55d",
    "model_name_for_query": "migtissera/Synthia-70B-v1.2b",
    "link": "https://huggingface.co/migtissera/Synthia-70B-v1.2b",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mixtral-SlimOrca-8x7B",
    "average": 66.97,
    "arc": 67.66,
    "hellaswag": 85.11,
    "mmlu": 67.98,
    "truthfulqa": 54.98,
    "winogrande": 80.51,
    "gsm8k": 45.56,
    "model_type": "fine-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 46.7,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "e06a613acf6c8cb3e5a740e2ed6348b8047d90a8",
    "model_name_for_query": "Open-Orca/Mixtral-SlimOrca-8x7B",
    "link": "https://huggingface.co/Open-Orca/Mixtral-SlimOrca-8x7B",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Misted-7B",
    "average": 66.94,
    "arc": 63.65,
    "hellaswag": 84.14,
    "mmlu": 63.94,
    "truthfulqa": 52.0,
    "winogrande": 78.3,
    "gsm8k": 59.59,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "31245dbdcd0ace447a4434ac5e393a90ac862a87",
    "model_name_for_query": "Walmart-the-bag/Misted-7B",
    "link": "https://huggingface.co/Walmart-the-bag/Misted-7B",
    "author": "Walmart-the-bag"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7B-v3-2-GPTQ",
    "average": 66.93,
    "arc": 65.96,
    "hellaswag": 83.24,
    "mmlu": 60.29,
    "truthfulqa": 59.79,
    "winogrande": 79.48,
    "gsm8k": 52.84,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "GPTQ",
    "license": "apache-2.0",
    "params": 9.59,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cfe57da77e55efcb0e1087dc3948aeaa6ca55c74",
    "model_name_for_query": "TheBloke/neural-chat-7B-v3-2-GPTQ",
    "link": "https://huggingface.co/TheBloke/neural-chat-7B-v3-2-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-70B-v1.2",
    "average": 66.9,
    "arc": 70.48,
    "hellaswag": 86.98,
    "mmlu": 70.13,
    "truthfulqa": 58.64,
    "winogrande": 83.27,
    "gsm8k": 31.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "9b92ee1093b125035ba1649dca6f4ceb9d86a656",
    "model_name_for_query": "migtissera/Synthia-70B-v1.2",
    "link": "https://huggingface.co/migtissera/Synthia-70B-v1.2",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-70B-v1.1",
    "average": 66.81,
    "arc": 70.05,
    "hellaswag": 87.12,
    "mmlu": 70.34,
    "truthfulqa": 57.84,
    "winogrande": 83.66,
    "gsm8k": 31.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "05a13f6adfe95a713dff04dc2eaa214c77c2512a",
    "model_name_for_query": "migtissera/Synthia-70B-v1.1",
    "link": "https://huggingface.co/migtissera/Synthia-70B-v1.1",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-70B",
    "average": 66.72,
    "arc": 69.45,
    "hellaswag": 87.11,
    "mmlu": 68.91,
    "truthfulqa": 59.79,
    "winogrande": 83.66,
    "gsm8k": 31.39,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "d63dfdd0baed756981f5f78f7419fd822c572362",
    "model_name_for_query": "migtissera/Synthia-70B",
    "link": "https://huggingface.co/migtissera/Synthia-70B",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Uni-TianYan",
    "average": 66.61,
    "arc": 72.1,
    "hellaswag": 87.4,
    "mmlu": 69.91,
    "truthfulqa": 65.81,
    "winogrande": 82.32,
    "gsm8k": 22.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "46b78b9a10e78283e59c28b56cb59c2f33b0816a",
    "model_name_for_query": "uni-tianyan/Uni-TianYan",
    "link": "https://huggingface.co/uni-tianyan/Uni-TianYan",
    "author": "uni-tianyan"
  },
  {
    "T": "\u2b55",
    "model": "HermesStar-OrcaWind-Synth-11B",
    "average": 66.59,
    "arc": 65.27,
    "hellaswag": 83.69,
    "mmlu": 65.31,
    "truthfulqa": 48.55,
    "winogrande": 80.11,
    "gsm8k": 56.63,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "61aefa2ac956ce0e8ce40aa2521bdb5634452766",
    "model_name_for_query": "Ba2han/HermesStar-OrcaWind-Synth-11B",
    "link": "https://huggingface.co/Ba2han/HermesStar-OrcaWind-Synth-11B",
    "author": "Ba2han"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dpopenhermes-alpha-v0",
    "average": 66.52,
    "arc": 65.02,
    "hellaswag": 83.96,
    "mmlu": 63.67,
    "truthfulqa": 51.75,
    "winogrande": 78.85,
    "gsm8k": 55.88,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "81ce4a9354d3b73276a0fa96b95d384f66d2de3d",
    "model_name_for_query": "openaccess-ai-collective/dpopenhermes-alpha-v0",
    "link": "https://huggingface.co/openaccess-ai-collective/dpopenhermes-alpha-v0",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\u2b55",
    "model": "LLaMA-2-Wizard-70B-QLoRA",
    "average": 66.47,
    "arc": 67.58,
    "hellaswag": 87.52,
    "mmlu": 69.11,
    "truthfulqa": 61.79,
    "winogrande": 82.32,
    "gsm8k": 30.48,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 70.0,
    "likes": 2.0,
    "still_on_hub": false,
    "revision": "4bff676fe29f56d31961794c062aebc36312446e",
    "model_name_for_query": "v2ray/LLaMA-2-Wizard-70B-QLoRA",
    "link": "https://huggingface.co/v2ray/LLaMA-2-Wizard-70B-QLoRA",
    "author": "v2ray"
  },
  {
    "T": "\ud83d\udd36",
    "model": "A13",
    "average": 66.45,
    "arc": 61.09,
    "hellaswag": 81.7,
    "mmlu": 69.62,
    "truthfulqa": 53.25,
    "winogrande": 80.35,
    "gsm8k": 52.69,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "gpl",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "c9b20b6f34269c27e56759888c5d42bd045e6da7",
    "model_name_for_query": "AA051610/A13",
    "link": "https://huggingface.co/AA051610/A13",
    "author": "AA051610"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Math-OpenHermes-2.5-Mistral-7B",
    "average": 66.42,
    "arc": 63.05,
    "hellaswag": 83.07,
    "mmlu": 63.21,
    "truthfulqa": 50.91,
    "winogrande": 77.19,
    "gsm8k": 61.11,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "db052d375f389aa264bacac47aeb07538698122d",
    "model_name_for_query": "simonveitner/Math-OpenHermes-2.5-Mistral-7B",
    "link": "https://huggingface.co/simonveitner/Math-OpenHermes-2.5-Mistral-7B",
    "author": "simonveitner"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Instruct_Llama70B_Dolly15k",
    "average": 66.42,
    "arc": 68.34,
    "hellaswag": 87.21,
    "mmlu": 69.52,
    "truthfulqa": 46.46,
    "winogrande": 84.29,
    "gsm8k": 42.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 68.72,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "45444ac60488594e0700e6c7313ff444b4468240",
    "model_name_for_query": "Brillibits/Instruct_Llama70B_Dolly15k",
    "link": "https://huggingface.co/Brillibits/Instruct_Llama70B_Dolly15k",
    "author": "Brillibits"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "openhermes-2_5-dpo-no-robots",
    "average": 66.4,
    "arc": 64.93,
    "hellaswag": 84.3,
    "mmlu": 63.86,
    "truthfulqa": 52.12,
    "winogrande": 77.9,
    "gsm8k": 55.27,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bee345f7da9816e459846b6bc3dbea6c69850855",
    "model_name_for_query": "openaccess-ai-collective/openhermes-2_5-dpo-no-robots",
    "link": "https://huggingface.co/openaccess-ai-collective/openhermes-2_5-dpo-no-robots",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "qCammel70",
    "average": 66.31,
    "arc": 68.34,
    "hellaswag": 87.87,
    "mmlu": 70.18,
    "truthfulqa": 57.47,
    "winogrande": 84.29,
    "gsm8k": 29.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "cf1e917e42fd1e56ee1edef7ee1a98cbe705c18c",
    "model_name_for_query": "augtoma/qCammel70",
    "link": "https://huggingface.co/augtoma/qCammel70",
    "author": "augtoma"
  },
  {
    "T": "\ud83d\udd36",
    "model": "qCammel-70",
    "average": 66.31,
    "arc": 68.34,
    "hellaswag": 87.87,
    "mmlu": 70.18,
    "truthfulqa": 57.47,
    "winogrande": 84.29,
    "gsm8k": 29.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "cf1e917e42fd1e56ee1edef7ee1a98cbe705c18c",
    "model_name_for_query": "augtoma/qCammel-70",
    "link": "https://huggingface.co/augtoma/qCammel-70",
    "author": "augtoma"
  },
  {
    "T": "\ud83d\udd36",
    "model": "qCammel-70v1",
    "average": 66.31,
    "arc": 68.34,
    "hellaswag": 87.87,
    "mmlu": 70.18,
    "truthfulqa": 57.47,
    "winogrande": 84.29,
    "gsm8k": 29.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "cf1e917e42fd1e56ee1edef7ee1a98cbe705c18c",
    "model_name_for_query": "augtoma/qCammel-70v1",
    "link": "https://huggingface.co/augtoma/qCammel-70v1",
    "author": "augtoma"
  },
  {
    "T": "\ud83d\udd36",
    "model": "qCammel-70-x",
    "average": 66.31,
    "arc": 68.34,
    "hellaswag": 87.87,
    "mmlu": 70.18,
    "truthfulqa": 57.47,
    "winogrande": 84.29,
    "gsm8k": 29.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "cf1e917e42fd1e56ee1edef7ee1a98cbe705c18c",
    "model_name_for_query": "augtoma/qCammel-70-x",
    "link": "https://huggingface.co/augtoma/qCammel-70-x",
    "author": "augtoma"
  },
  {
    "T": "\ud83d\udd36",
    "model": "qCammel-70x",
    "average": 66.31,
    "arc": 68.34,
    "hellaswag": 87.87,
    "mmlu": 70.18,
    "truthfulqa": 57.47,
    "winogrande": 84.29,
    "gsm8k": 29.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "cf1e917e42fd1e56ee1edef7ee1a98cbe705c18c",
    "model_name_for_query": "augtoma/qCammel-70x",
    "link": "https://huggingface.co/augtoma/qCammel-70x",
    "author": "augtoma"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Platypus2-70B",
    "average": 66.28,
    "arc": 70.65,
    "hellaswag": 87.15,
    "mmlu": 70.08,
    "truthfulqa": 52.37,
    "winogrande": 84.37,
    "gsm8k": 33.06,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 68.72,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "16b6583ad58313331f86be18e531ab03f1857695",
    "model_name_for_query": "garage-bAInd/Platypus2-70B",
    "link": "https://huggingface.co/garage-bAInd/Platypus2-70B",
    "author": "garage-bAInd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mythospice-limarp-70b",
    "average": 66.27,
    "arc": 69.2,
    "hellaswag": 87.46,
    "mmlu": 70.14,
    "truthfulqa": 55.86,
    "winogrande": 82.72,
    "gsm8k": 32.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "agpl-3.0",
    "params": 68.72,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ff29fed2a33fc050fd20d0e25b5b23c4a101b074",
    "model_name_for_query": "Doctor-Shotgun/mythospice-limarp-70b",
    "link": "https://huggingface.co/Doctor-Shotgun/mythospice-limarp-70b",
    "author": "Doctor-Shotgun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Xwin-LM-70B-V0.1",
    "average": 66.2,
    "arc": 70.22,
    "hellaswag": 87.25,
    "mmlu": 69.77,
    "truthfulqa": 59.86,
    "winogrande": 82.87,
    "gsm8k": 27.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 159.0,
    "still_on_hub": true,
    "revision": "d6c803a180e3d46c371f8d3cb3848b861596ccbc",
    "model_name_for_query": "Xwin-LM/Xwin-LM-70B-V0.1",
    "link": "https://huggingface.co/Xwin-LM/Xwin-LM-70B-V0.1",
    "author": "Xwin-LM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mythospice-70b",
    "average": 66.17,
    "arc": 69.28,
    "hellaswag": 87.53,
    "mmlu": 70.1,
    "truthfulqa": 56.76,
    "winogrande": 83.27,
    "gsm8k": 30.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b00992c26604c9cd496bc41472a05e4c01cd2008",
    "model_name_for_query": "Doctor-Shotgun/mythospice-70b",
    "link": "https://huggingface.co/Doctor-Shotgun/mythospice-70b",
    "author": "Doctor-Shotgun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-70b-fb16-orca-chat-10k",
    "average": 66.16,
    "arc": 68.09,
    "hellaswag": 87.07,
    "mmlu": 69.21,
    "truthfulqa": 61.56,
    "winogrande": 84.14,
    "gsm8k": 26.91,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 68.98,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "697aaeb8eb9905c9b25bebb736d1905444c774a6",
    "model_name_for_query": "quantumaikr/llama-2-70b-fb16-orca-chat-10k",
    "link": "https://huggingface.co/quantumaikr/llama-2-70b-fb16-orca-chat-10k",
    "author": "quantumaikr"
  },
  {
    "T": "\u2b55",
    "model": "where-llambo-7b",
    "average": 66.08,
    "arc": 58.45,
    "hellaswag": 82.06,
    "mmlu": 62.61,
    "truthfulqa": 49.61,
    "winogrande": 78.53,
    "gsm8k": 65.2,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "554d9c7bab7ea6deabef0266aef17aa98f758543",
    "model_name_for_query": "amazingvince/where-llambo-7b",
    "link": "https://huggingface.co/amazingvince/where-llambo-7b",
    "author": "amazingvince"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-70b-Guanaco-QLoRA-fp16",
    "average": 66.05,
    "arc": 68.26,
    "hellaswag": 88.32,
    "mmlu": 70.23,
    "truthfulqa": 55.69,
    "winogrande": 83.98,
    "gsm8k": 29.8,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 53.0,
    "still_on_hub": true,
    "revision": "54b0e39d5e9aee7b323f50b0a26db15295c3d5c9",
    "model_name_for_query": "TheBloke/llama-2-70b-Guanaco-QLoRA-fp16",
    "link": "https://huggingface.co/TheBloke/llama-2-70b-Guanaco-QLoRA-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "SOLAR-10.7B-v1.0",
    "average": 66.04,
    "arc": 61.95,
    "hellaswag": 84.6,
    "mmlu": 65.48,
    "truthfulqa": 45.04,
    "winogrande": 83.66,
    "gsm8k": 55.5,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6e2783822f35c376ea96852fe479faa6a8bf09cb",
    "model_name_for_query": "upstage/SOLAR-10.7B-v1.0",
    "link": "https://huggingface.co/upstage/SOLAR-10.7B-v1.0",
    "author": "upstage"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pic_7B_mistral_Full_v0.1",
    "average": 66.0,
    "arc": 63.91,
    "hellaswag": 83.7,
    "mmlu": 63.3,
    "truthfulqa": 54.51,
    "winogrande": 77.9,
    "gsm8k": 52.69,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "64f7a800327466b76697c1f81d88b008274c8861",
    "model_name_for_query": "TokenBender/pic_7B_mistral_Full_v0.1",
    "link": "https://huggingface.co/TokenBender/pic_7B_mistral_Full_v0.1",
    "author": "TokenBender"
  },
  {
    "T": "\ud83d\udd36",
    "model": "medllama-2-70b-qlora-1.1",
    "average": 65.99,
    "arc": 69.03,
    "hellaswag": 87.17,
    "mmlu": 71.04,
    "truthfulqa": 52.41,
    "winogrande": 84.21,
    "gsm8k": 32.07,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 70.0,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "d55e05e9d67418c639933c85a5b9d17c6f531a92",
    "model_name_for_query": "s1ghhh/medllama-2-70b-qlora-1.1",
    "link": "https://huggingface.co/s1ghhh/medllama-2-70b-qlora-1.1",
    "author": "s1ghhh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_51",
    "average": 65.96,
    "arc": 68.43,
    "hellaswag": 86.71,
    "mmlu": 69.31,
    "truthfulqa": 57.18,
    "winogrande": 81.77,
    "gsm8k": 32.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "9542702011bf4d282f4b0f0bd79229f5822b6313",
    "model_name_for_query": "psmathur/model_51",
    "link": "https://huggingface.co/psmathur/model_51",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "14B-DPO-alpha",
    "average": 65.91,
    "arc": 58.11,
    "hellaswag": 79.38,
    "mmlu": 66.62,
    "truthfulqa": 54.15,
    "winogrande": 74.51,
    "gsm8k": 62.7,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "wtfpl",
    "params": 14.0,
    "likes": 64.0,
    "still_on_hub": false,
    "revision": "34bc2dd73ae5f8738e5bcaaa5591427675f7801f",
    "model_name_for_query": "CausalLM/14B-DPO-alpha",
    "link": "https://huggingface.co/CausalLM/14B-DPO-alpha",
    "author": "CausalLM"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Qwen-14B",
    "average": 65.86,
    "arc": 58.28,
    "hellaswag": 83.99,
    "mmlu": 67.7,
    "truthfulqa": 49.43,
    "winogrande": 76.8,
    "gsm8k": 58.98,
    "model_type": "pretrained",
    "architecture": "QWenLMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 14.17,
    "likes": 162.0,
    "still_on_hub": true,
    "revision": "5eda9482e32a8ea7ed2dc47178f3b491eb207939",
    "model_name_for_query": "Qwen/Qwen-14B",
    "link": "https://huggingface.co/Qwen/Qwen-14B",
    "author": "Qwen"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-falcon-180b-v13-preview0",
    "average": 65.85,
    "arc": 65.1,
    "hellaswag": 86.19,
    "mmlu": 64.6,
    "truthfulqa": 54.97,
    "winogrande": 82.64,
    "gsm8k": 41.62,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 178.64,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7d7b93ffd67d1b0c39f3503050dbbcc951948120",
    "model_name_for_query": "OpenBuddy/openbuddy-falcon-180b-v13-preview0",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-falcon-180b-v13-preview0",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-7B-v2.03-128k",
    "average": 65.83,
    "arc": 64.68,
    "hellaswag": 84.56,
    "mmlu": 63.02,
    "truthfulqa": 51.16,
    "winogrande": 81.06,
    "gsm8k": 50.49,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "22bb3c15b2770dfe91e239573b6c35b475a43cbe",
    "model_name_for_query": "perlthoughts/Chupacabra-7B-v2.03-128k",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.03-128k",
    "author": "perlthoughts"
  },
  {
    "T": "?",
    "model": "Mixtral-8x7B-v0.1",
    "average": 65.81,
    "arc": 64.33,
    "hellaswag": 85.7,
    "mmlu": 70.17,
    "truthfulqa": 47.62,
    "winogrande": 80.19,
    "gsm8k": 46.85,
    "model_type": "",
    "architecture": "MixtralForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c2b2ae2f1f9532c7c50045bc57d643f46acf8d30",
    "model_name_for_query": "mistralai/Mixtral-8x7B-v0.1",
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-v0.1",
    "author": "mistralai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-Mistral-7B",
    "average": 65.78,
    "arc": 60.67,
    "hellaswag": 82.58,
    "mmlu": 61.95,
    "truthfulqa": 44.89,
    "winogrande": 75.77,
    "gsm8k": 68.84,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "016a7bb03bfcd953860357e1a16d5b333b887d26",
    "model_name_for_query": "meta-math/MetaMath-Mistral-7B",
    "link": "https://huggingface.co/meta-math/MetaMath-Mistral-7B",
    "author": "meta-math"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_420",
    "average": 65.76,
    "arc": 70.14,
    "hellaswag": 87.73,
    "mmlu": 70.35,
    "truthfulqa": 54.0,
    "winogrande": 83.74,
    "gsm8k": 28.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "13c7b5f403c0f2af9bf7fce2d4a32deb9054c083",
    "model_name_for_query": "psmathur/model_420",
    "link": "https://huggingface.co/psmathur/model_420",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-70b-dolphin-peft",
    "average": 65.72,
    "arc": 69.62,
    "hellaswag": 86.82,
    "mmlu": 69.18,
    "truthfulqa": 57.43,
    "winogrande": 83.9,
    "gsm8k": 27.37,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 70.0,
    "likes": 12.0,
    "still_on_hub": false,
    "revision": "a1190dee60b5854e80d340958dc3cc956bc56f68",
    "model_name_for_query": "dfurman/llama-2-70b-dolphin-peft",
    "link": "https://huggingface.co/dfurman/llama-2-70b-dolphin-peft",
    "author": "dfurman"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-Instruct-v0.2",
    "average": 65.71,
    "arc": 63.14,
    "hellaswag": 84.88,
    "mmlu": 60.78,
    "truthfulqa": 68.26,
    "winogrande": 77.19,
    "gsm8k": 40.03,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "c72e5d1908b1e2929ec8fc4c8820e9706af1f80f",
    "model_name_for_query": "mistralai/Mistral-7B-Instruct-v0.2",
    "link": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2",
    "author": "mistralai"
  },
  {
    "T": "?",
    "model": "Mixtral-8x7B-v0.1-GPTQ",
    "average": 65.7,
    "arc": 65.19,
    "hellaswag": 84.72,
    "mmlu": 69.43,
    "truthfulqa": 45.43,
    "winogrande": 81.14,
    "gsm8k": 48.29,
    "model_type": "",
    "architecture": "MixtralForCausalLM",
    "precision": "GPTQ",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7d1eb57b65f823458e27509cd0aac7172f54a260",
    "model_name_for_query": "TheBloke/Mixtral-8x7B-v0.1-GPTQ",
    "link": "https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLaMA-2-Jannie-70B-QLoRA",
    "average": 65.6,
    "arc": 68.94,
    "hellaswag": 86.9,
    "mmlu": 69.37,
    "truthfulqa": 53.67,
    "winogrande": 82.95,
    "gsm8k": 31.77,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 70.0,
    "likes": 14.0,
    "still_on_hub": false,
    "revision": "e552ddca841a2b86e36bbe5f99840afedfdbcd14",
    "model_name_for_query": "v2ray/LLaMA-2-Jannie-70B-QLoRA",
    "link": "https://huggingface.co/v2ray/LLaMA-2-Jannie-70B-QLoRA",
    "author": "v2ray"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Camel-Platypus2-70B",
    "average": 65.59,
    "arc": 71.08,
    "hellaswag": 87.6,
    "mmlu": 70.04,
    "truthfulqa": 58.09,
    "winogrande": 83.82,
    "gsm8k": 22.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 68.72,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "b9f8de09ab860ee8ba570db7227c5444020ea056",
    "model_name_for_query": "garage-bAInd/Camel-Platypus2-70B",
    "link": "https://huggingface.co/garage-bAInd/Camel-Platypus2-70B",
    "author": "garage-bAInd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Yee-34B-200K-Chat",
    "average": 65.56,
    "arc": 65.61,
    "hellaswag": 84.33,
    "mmlu": 74.91,
    "truthfulqa": 53.88,
    "winogrande": 79.79,
    "gsm8k": 34.8,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "gpl-3.0",
    "params": 34.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "94bc30449e41628f59dd965cb7d9a8eb53ce9a45",
    "model_name_for_query": "JosephusCheung/Yee-34B-200K-Chat",
    "link": "https://huggingface.co/JosephusCheung/Yee-34B-200K-Chat",
    "author": "JosephusCheung"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-11b-v3-2",
    "average": 65.52,
    "arc": 66.64,
    "hellaswag": 82.12,
    "mmlu": 62.37,
    "truthfulqa": 60.22,
    "winogrande": 79.64,
    "gsm8k": 42.15,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8821b441a4a07ec7c45e1c13bead93e99ad2f099",
    "model_name_for_query": "NurtureAI/neural-chat-11b-v3-2",
    "link": "https://huggingface.co/NurtureAI/neural-chat-11b-v3-2",
    "author": "NurtureAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_42_70b",
    "average": 65.51,
    "arc": 68.26,
    "hellaswag": 87.65,
    "mmlu": 70.0,
    "truthfulqa": 48.76,
    "winogrande": 83.66,
    "gsm8k": 34.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "ca3789cd6b683e97dcd6a5f0367f90a63d7a4e7b",
    "model_name_for_query": "psmathur/model_42_70b",
    "link": "https://huggingface.co/psmathur/model_42_70b",
    "author": "psmathur"
  },
  {
    "T": "\u2b55",
    "model": "Lima_Unchained_70b",
    "average": 65.51,
    "arc": 68.26,
    "hellaswag": 87.65,
    "mmlu": 70.0,
    "truthfulqa": 48.76,
    "winogrande": 83.66,
    "gsm8k": 34.72,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "7dadf059a03bdfec2eb4f4a47666545875c68e49",
    "model_name_for_query": "pankajmathur/Lima_Unchained_70b",
    "link": "https://huggingface.co/pankajmathur/Lima_Unchained_70b",
    "author": "pankajmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-70b-oasst-1-200",
    "average": 65.5,
    "arc": 67.66,
    "hellaswag": 87.24,
    "mmlu": 69.95,
    "truthfulqa": 51.28,
    "winogrande": 84.14,
    "gsm8k": 32.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 68.72,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "153b209007e688d713cd670c9972f2827c597b45",
    "model_name_for_query": "jordiclive/Llama-2-70b-oasst-1-200",
    "link": "https://huggingface.co/jordiclive/Llama-2-70b-oasst-1-200",
    "author": "jordiclive"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bagel-7b-v0.1",
    "average": 65.49,
    "arc": 63.91,
    "hellaswag": 83.14,
    "mmlu": 64.56,
    "truthfulqa": 52.65,
    "winogrande": 80.58,
    "gsm8k": 48.07,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "10ac045905d13da0e2be8e647cfe3e5ac8444894",
    "model_name_for_query": "jondurbin/bagel-7b-v0.1",
    "link": "https://huggingface.co/jondurbin/bagel-7b-v0.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fiction.live-Kimiko-V2-70B-fp16",
    "average": 65.48,
    "arc": 67.66,
    "hellaswag": 87.65,
    "mmlu": 69.82,
    "truthfulqa": 49.28,
    "winogrande": 83.9,
    "gsm8k": 34.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "6b0c2cb654133cad2d4920e7da2e3f6cb1c4f7fd",
    "model_name_for_query": "TheBloke/fiction.live-Kimiko-V2-70B-fp16",
    "link": "https://huggingface.co/TheBloke/fiction.live-Kimiko-V2-70B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "falcon-180B",
    "average": 65.46,
    "arc": 69.2,
    "hellaswag": 88.89,
    "mmlu": 69.59,
    "truthfulqa": 45.16,
    "winogrande": 86.74,
    "gsm8k": 33.21,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "4bit",
    "license": "unknown",
    "params": 179.52,
    "likes": 830.0,
    "still_on_hub": false,
    "revision": "71a1a70b629e9963f7b4601e82f3f9079d48011e",
    "model_name_for_query": "tiiuae/falcon-180B",
    "link": "https://huggingface.co/tiiuae/falcon-180B",
    "author": "tiiuae"
  },
  {
    "T": "\u2b55",
    "model": "Metis-0.3",
    "average": 65.44,
    "arc": 62.71,
    "hellaswag": 84.8,
    "mmlu": 60.92,
    "truthfulqa": 67.56,
    "winogrande": 77.27,
    "gsm8k": 39.35,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d5b89820d04640d217aa3c174fa1d1ad5553419a",
    "model_name_for_query": "Mihaiii/Metis-0.3",
    "link": "https://huggingface.co/Mihaiii/Metis-0.3",
    "author": "Mihaiii"
  },
  {
    "T": "\u2b55",
    "model": "Camel-Platypus2-70B",
    "average": 65.39,
    "arc": 70.14,
    "hellaswag": 87.71,
    "mmlu": 69.83,
    "truthfulqa": 57.77,
    "winogrande": 82.95,
    "gsm8k": 23.96,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "cc-by-nc-4.0",
    "params": 68.72,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "6f958a1063fe1e6075f6e379fae621ff5a1d98c6",
    "model_name_for_query": "garage-bAInd/Camel-Platypus2-70B",
    "link": "https://huggingface.co/garage-bAInd/Camel-Platypus2-70B",
    "author": "garage-bAInd"
  },
  {
    "T": "\u2b55",
    "model": "lemur-70b-chat-v1",
    "average": 65.38,
    "arc": 66.98,
    "hellaswag": 85.73,
    "mmlu": 65.99,
    "truthfulqa": 56.58,
    "winogrande": 81.69,
    "gsm8k": 35.33,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 68.72,
    "likes": 46.0,
    "still_on_hub": true,
    "revision": "33da87ba6d90662c6a00535bd628e5b39b3afd3b",
    "model_name_for_query": "OpenLemur/lemur-70b-chat-v1",
    "link": "https://huggingface.co/OpenLemur/lemur-70b-chat-v1",
    "author": "OpenLemur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-7B-v2.03",
    "average": 65.34,
    "arc": 63.82,
    "hellaswag": 84.73,
    "mmlu": 63.05,
    "truthfulqa": 48.53,
    "winogrande": 80.9,
    "gsm8k": 51.02,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "73641ebe6ba450a83f6e80ed919fba48cc5f2837",
    "model_name_for_query": "perlthoughts/Chupacabra-7B-v2.03",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.03",
    "author": "perlthoughts"
  },
  {
    "T": "\u2b55",
    "model": "Yi-34B-Chat",
    "average": 65.32,
    "arc": 65.44,
    "hellaswag": 84.16,
    "mmlu": 74.9,
    "truthfulqa": 55.37,
    "winogrande": 80.11,
    "gsm8k": 31.92,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 34.39,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "a99ec35331cbfc9da596af7d4538fe2efecff03c",
    "model_name_for_query": "01-ai/Yi-34B-Chat",
    "link": "https://huggingface.co/01-ai/Yi-34B-Chat",
    "author": "01-ai"
  },
  {
    "T": "?",
    "model": "llama2-70B-qlora-gpt4",
    "average": 65.29,
    "arc": 70.31,
    "hellaswag": 86.39,
    "mmlu": 69.29,
    "truthfulqa": 54.02,
    "winogrande": 82.87,
    "gsm8k": 28.89,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "08115ee077953e9c01c6a40f5086def3ecf9f5f0",
    "model_name_for_query": "liuxiang886/llama2-70B-qlora-gpt4",
    "link": "https://huggingface.co/liuxiang886/llama2-70B-qlora-gpt4",
    "author": "liuxiang886"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Writing_Partner_Mistral_7B",
    "average": 65.29,
    "arc": 64.59,
    "hellaswag": 84.59,
    "mmlu": 62.55,
    "truthfulqa": 48.55,
    "winogrande": 76.87,
    "gsm8k": 54.59,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "d71b744e4d7432301d891409a05710bf2e4fa4c3",
    "model_name_for_query": "FPHam/Writing_Partner_Mistral_7B",
    "link": "https://huggingface.co/FPHam/Writing_Partner_Mistral_7B",
    "author": "FPHam"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MadMix-v0.1",
    "average": 65.26,
    "arc": 64.93,
    "hellaswag": 84.37,
    "mmlu": 64.37,
    "truthfulqa": 51.05,
    "winogrande": 77.19,
    "gsm8k": 49.66,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "71773ca4ca1fd76a00bd695a52b96b43b8fd78ff",
    "model_name_for_query": "Fredithefish/MadMix-v0.1",
    "link": "https://huggingface.co/Fredithefish/MadMix-v0.1",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "MathHermes-2.5-Mistral-7B",
    "average": 65.24,
    "arc": 64.76,
    "hellaswag": 84.19,
    "mmlu": 63.59,
    "truthfulqa": 51.95,
    "winogrande": 77.66,
    "gsm8k": 49.28,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2a6ee2674304f91d1dcc772695deded76d4c32bd",
    "model_name_for_query": "simonveitner/MathHermes-2.5-Mistral-7B",
    "link": "https://huggingface.co/simonveitner/MathHermes-2.5-Mistral-7B",
    "author": "simonveitner"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-70b-fb16-korean",
    "average": 65.23,
    "arc": 67.15,
    "hellaswag": 86.78,
    "mmlu": 69.29,
    "truthfulqa": 56.5,
    "winogrande": 82.64,
    "gsm8k": 29.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.98,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "fd57855006c15c4121feccab1cbeee8107de5b5a",
    "model_name_for_query": "quantumaikr/llama-2-70b-fb16-korean",
    "link": "https://huggingface.co/quantumaikr/llama-2-70b-fb16-korean",
    "author": "quantumaikr"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrca-Zephyr-7B",
    "average": 64.97,
    "arc": 64.08,
    "hellaswag": 83.82,
    "mmlu": 62.46,
    "truthfulqa": 54.31,
    "winogrande": 78.93,
    "gsm8k": 46.25,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "2a2c7d287a46243cccf3ff6628375d0d190394ac",
    "model_name_for_query": "Weyaxi/OpenOrca-Zephyr-7B",
    "link": "https://huggingface.co/Weyaxi/OpenOrca-Zephyr-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-70b-gpt4-1.4.1",
    "average": 64.97,
    "arc": 70.39,
    "hellaswag": 87.82,
    "mmlu": 70.31,
    "truthfulqa": 55.2,
    "winogrande": 83.58,
    "gsm8k": 22.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 46.0,
    "still_on_hub": true,
    "revision": "ea98153fa721ed7110c77e73388e3b6f3996f2bb",
    "model_name_for_query": "jondurbin/airoboros-l2-70b-gpt4-1.4.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-1.4.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolphin-2.2.1-mistral-7b",
    "average": 64.93,
    "arc": 63.31,
    "hellaswag": 83.76,
    "mmlu": 63.17,
    "truthfulqa": 53.11,
    "winogrande": 78.14,
    "gsm8k": 48.07,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 105.0,
    "still_on_hub": true,
    "revision": "001b48e9aebffb395c698af47b6b48364cc3cbe8",
    "model_name_for_query": "ehartford/dolphin-2.2.1-mistral-7b",
    "link": "https://huggingface.co/ehartford/dolphin-2.2.1-mistral-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Puffin-70B",
    "average": 64.91,
    "arc": 67.41,
    "hellaswag": 87.37,
    "mmlu": 69.77,
    "truthfulqa": 46.77,
    "winogrande": 83.9,
    "gsm8k": 34.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": ["mit"],
    "params": 68.72,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "129e0af93d04b1b9cc85ea48bbb300f1ccb44210",
    "model_name_for_query": "NousResearch/Nous-Puffin-70B",
    "link": "https://huggingface.co/NousResearch/Nous-Puffin-70B",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_70b_chat_uncensored",
    "average": 64.88,
    "arc": 68.43,
    "hellaswag": 86.77,
    "mmlu": 68.76,
    "truthfulqa": 52.5,
    "winogrande": 82.56,
    "gsm8k": 30.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 37.0,
    "still_on_hub": true,
    "revision": "34b23982a9a996adc8f45c4c2eac7245c4e251b3",
    "model_name_for_query": "jarradh/llama2_70b_chat_uncensored",
    "link": "https://huggingface.co/jarradh/llama2_70b_chat_uncensored",
    "author": "jarradh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-70B-LoRA-assemble-v2",
    "average": 64.73,
    "arc": 71.84,
    "hellaswag": 86.89,
    "mmlu": 69.37,
    "truthfulqa": 64.79,
    "winogrande": 81.22,
    "gsm8k": 14.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "7feeb5b665ab1ecdfd9cc4fe45fadb86b7b91b5b",
    "model_name_for_query": "oh-yeontaek/llama-2-70B-LoRA-assemble-v2",
    "link": "https://huggingface.co/oh-yeontaek/llama-2-70B-LoRA-assemble-v2",
    "author": "oh-yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-mistral-7b-dare-0.85",
    "average": 64.69,
    "arc": 63.57,
    "hellaswag": 84.82,
    "mmlu": 64.29,
    "truthfulqa": 50.66,
    "winogrande": 79.24,
    "gsm8k": 45.56,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b19e60f64b3be7f41658958658658bc12038c68f",
    "model_name_for_query": "uukuguy/speechless-mistral-7b-dare-0.85",
    "link": "https://huggingface.co/uukuguy/speechless-mistral-7b-dare-0.85",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Euryale-L2-70B",
    "average": 64.66,
    "arc": 68.94,
    "hellaswag": 87.07,
    "mmlu": 68.84,
    "truthfulqa": 54.49,
    "winogrande": 82.08,
    "gsm8k": 26.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 68.72,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "6589310a57ce5d9d6877f353f3d00cda8fa9101c",
    "model_name_for_query": "Sao10K/Euryale-L2-70B",
    "link": "https://huggingface.co/Sao10K/Euryale-L2-70B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "PiVoT-0.1-early",
    "average": 64.58,
    "arc": 62.46,
    "hellaswag": 82.97,
    "mmlu": 61.02,
    "truthfulqa": 62.89,
    "winogrande": 73.72,
    "gsm8k": 44.43,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-sa-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6eeae58a1a292a1d7f989952a07aead6d5da3c69",
    "model_name_for_query": "maywell/PiVoT-0.1-early",
    "link": "https://huggingface.co/maywell/PiVoT-0.1-early",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-70b-gpt4-m2.0",
    "average": 64.56,
    "arc": 70.05,
    "hellaswag": 87.83,
    "mmlu": 70.67,
    "truthfulqa": 49.79,
    "winogrande": 83.58,
    "gsm8k": 25.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "1cccd0b60a988bf6ddc4e2688895837845afa076",
    "model_name_for_query": "jondurbin/airoboros-l2-70b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-70B-fp16",
    "average": 64.52,
    "arc": 67.32,
    "hellaswag": 87.33,
    "mmlu": 69.83,
    "truthfulqa": 44.92,
    "winogrande": 83.74,
    "gsm8k": 33.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.98,
    "likes": 40.0,
    "still_on_hub": true,
    "revision": "b25061ef1b440e970d15d4ac99bc42937cd442a2",
    "model_name_for_query": "TheBloke/Llama-2-70B-fp16",
    "link": "https://huggingface.co/TheBloke/Llama-2-70B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-65b-instruct",
    "average": 64.51,
    "arc": 68.86,
    "hellaswag": 86.43,
    "mmlu": 64.77,
    "truthfulqa": 59.7,
    "winogrande": 81.06,
    "gsm8k": 26.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 65.02,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "b95668861dfb7b0abca44ccdbef2db49b2dd8917",
    "model_name_for_query": "upstage/llama-65b-instruct",
    "link": "https://huggingface.co/upstage/llama-65b-instruct",
    "author": "upstage"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SauerkrautLM-7b-HerO",
    "average": 64.49,
    "arc": 63.23,
    "hellaswag": 83.52,
    "mmlu": 63.3,
    "truthfulqa": 49.22,
    "winogrande": 78.37,
    "gsm8k": 49.28,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "0aeb810af28e2910a92b929c21b931a5c06073de",
    "model_name_for_query": "VAGOsolutions/SauerkrautLM-7b-HerO",
    "link": "https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO",
    "author": "VAGOsolutions"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama-65b-v8-bf16",
    "average": 64.47,
    "arc": 62.8,
    "hellaswag": 83.6,
    "mmlu": 62.01,
    "truthfulqa": 55.09,
    "winogrande": 79.95,
    "gsm8k": 43.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 65.07,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "445b77821fac8e6cfb77d0399fb827400b5bb71e",
    "model_name_for_query": "OpenBuddy/openbuddy-llama-65b-v8-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama-65b-v8-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-70b-oasst-sft-v10",
    "average": 64.47,
    "arc": 67.06,
    "hellaswag": 86.38,
    "mmlu": 67.7,
    "truthfulqa": 56.45,
    "winogrande": 82.0,
    "gsm8k": 27.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 68.72,
    "likes": 64.0,
    "still_on_hub": true,
    "revision": "e68a8a2888097def3c7f4fe5d443866a18d05c6c",
    "model_name_for_query": "OpenAssistant/llama2-70b-oasst-sft-v10",
    "link": "https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Starling-LM-11B-alpha-v1",
    "average": 64.44,
    "arc": 62.2,
    "hellaswag": 83.24,
    "mmlu": 64.03,
    "truthfulqa": 45.7,
    "winogrande": 80.51,
    "gsm8k": 50.95,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "b2b3b9fc069a8b5d8be82f68f0f578a6f23e9e5f",
    "model_name_for_query": "NurtureAI/Starling-LM-11B-alpha-v1",
    "link": "https://huggingface.co/NurtureAI/Starling-LM-11B-alpha-v1",
    "author": "NurtureAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-7B-Symbolic",
    "average": 64.44,
    "arc": 63.14,
    "hellaswag": 82.73,
    "mmlu": 62.62,
    "truthfulqa": 48.82,
    "winogrande": 75.85,
    "gsm8k": 53.45,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "23eb76553aa37cd48c1f2d8a314d78fd3ead53f6",
    "model_name_for_query": "hedronstone/OpenHermes-7B-Symbolic",
    "link": "https://huggingface.co/hedronstone/OpenHermes-7B-Symbolic",
    "author": "hedronstone"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-7B-Reasoner",
    "average": 64.44,
    "arc": 63.14,
    "hellaswag": 82.73,
    "mmlu": 62.62,
    "truthfulqa": 48.82,
    "winogrande": 75.85,
    "gsm8k": 53.45,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d26f2defbf9f40a65dbb2ead08c79cd61096ed08",
    "model_name_for_query": "hedronstone/OpenHermes-7B-Reasoner",
    "link": "https://huggingface.co/hedronstone/OpenHermes-7B-Reasoner",
    "author": "hedronstone"
  },
  {
    "T": "\ud83d\udd36",
    "model": "medilora-mistral-7b",
    "average": 64.41,
    "arc": 61.69,
    "hellaswag": 83.13,
    "mmlu": 62.22,
    "truthfulqa": 49.91,
    "winogrande": 77.66,
    "gsm8k": 51.86,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "b6512d2a2202e685da461ff876a1ffb707034c97",
    "model_name_for_query": "Medilora/medilora-mistral-7b",
    "link": "https://huggingface.co/Medilora/medilora-mistral-7b",
    "author": "Medilora"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chronos-70b-v2",
    "average": 64.41,
    "arc": 68.09,
    "hellaswag": 86.5,
    "mmlu": 68.28,
    "truthfulqa": 53.7,
    "winogrande": 81.22,
    "gsm8k": 28.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 68.72,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "373af41ca0b2855972b8d471fd63e72b63e4c9fc",
    "model_name_for_query": "elinas/chronos-70b-v2",
    "link": "https://huggingface.co/elinas/chronos-70b-v2",
    "author": "elinas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-dpo-v1",
    "average": 64.39,
    "arc": 63.48,
    "hellaswag": 83.59,
    "mmlu": 63.35,
    "truthfulqa": 50.49,
    "winogrande": 79.32,
    "gsm8k": 46.1,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "3c677a659bffbccbd8cf5ea75d198541ea2ec990",
    "model_name_for_query": "xxyyy123/Mistral-dpo-v1",
    "link": "https://huggingface.co/xxyyy123/Mistral-dpo-v1",
    "author": "xxyyy123"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "v1olet_merged_dpo_7B_v4",
    "average": 64.3,
    "arc": 66.98,
    "hellaswag": 84.09,
    "mmlu": 59.02,
    "truthfulqa": 59.43,
    "winogrande": 81.06,
    "gsm8k": 35.25,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aa1b6363990ed2f180b2a22986cecc3afa4d12c8",
    "model_name_for_query": "v1olet/v1olet_merged_dpo_7B_v4",
    "link": "https://huggingface.co/v1olet/v1olet_merged_dpo_7B_v4",
    "author": "v1olet"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "PiVoT-10.7B-Mistral-v0.2",
    "average": 64.25,
    "arc": 63.31,
    "hellaswag": 81.68,
    "mmlu": 59.86,
    "truthfulqa": 58.23,
    "winogrande": 80.03,
    "gsm8k": 42.38,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-sa-4.0",
    "params": 10.73,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "a496457d0743b6030ffbb96dad2dc6a62d143943",
    "model_name_for_query": "maywell/PiVoT-10.7B-Mistral-v0.2",
    "link": "https://huggingface.co/maywell/PiVoT-10.7B-Mistral-v0.2",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_420_preview",
    "average": 64.22,
    "arc": 67.06,
    "hellaswag": 87.26,
    "mmlu": 69.85,
    "truthfulqa": 44.57,
    "winogrande": 83.35,
    "gsm8k": 33.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5095384f1b7bb6e23a987f95589e66e21ae854ef",
    "model_name_for_query": "psmathur/model_420_preview",
    "link": "https://huggingface.co/psmathur/model_420_preview",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-70b-gpt4-2.0",
    "average": 64.14,
    "arc": 68.52,
    "hellaswag": 87.89,
    "mmlu": 70.41,
    "truthfulqa": 49.79,
    "winogrande": 83.5,
    "gsm8k": 24.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.72,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "f16526d9bb814dc10adc911f94e8c7a520beb5b6",
    "model_name_for_query": "jondurbin/airoboros-l2-70b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-65b-hf",
    "average": 63.99,
    "arc": 63.31,
    "hellaswag": 86.09,
    "mmlu": 63.84,
    "truthfulqa": 43.43,
    "winogrande": 82.48,
    "gsm8k": 44.81,
    "model_type": "fine-tuned",
    "architecture": "LLaMAForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.0,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "7a7b897ab10b3d82d1e7e6fbcd2159d70b4586cf",
    "model_name_for_query": "Enoch/llama-65b-hf",
    "link": "https://huggingface.co/Enoch/llama-65b-hf",
    "author": "Enoch"
  },
  {
    "T": "?",
    "model": "UltraLM-65b",
    "average": 63.82,
    "arc": 67.06,
    "hellaswag": 84.98,
    "mmlu": 63.48,
    "truthfulqa": 53.51,
    "winogrande": 81.14,
    "gsm8k": 32.75,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 65.02,
    "likes": 6.0,
    "still_on_hub": false,
    "revision": "",
    "model_name_for_query": "openbmb/UltraLM-65b",
    "link": "https://huggingface.co/openbmb/UltraLM-65b",
    "author": "openbmb"
  },
  {
    "T": "\ud83d\udd36",
    "model": "14B",
    "average": 63.81,
    "arc": 56.66,
    "hellaswag": 79.08,
    "mmlu": 65.86,
    "truthfulqa": 47.75,
    "winogrande": 74.9,
    "gsm8k": 58.61,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "wtfpl",
    "params": 14.0,
    "likes": 220.0,
    "still_on_hub": false,
    "revision": "2576a37434e2e03804c841d36c669c8a34c729de",
    "model_name_for_query": "CausalLM/14B",
    "link": "https://huggingface.co/CausalLM/14B",
    "author": "CausalLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "medilora-qwen-14b",
    "average": 63.81,
    "arc": 56.66,
    "hellaswag": 79.08,
    "mmlu": 65.86,
    "truthfulqa": 47.75,
    "winogrande": 74.9,
    "gsm8k": 58.61,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "mit",
    "params": 14.17,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "0649cf49b7a879fe837567a346a3ebbbac77614a",
    "model_name_for_query": "Medilora/medilora-qwen-14b",
    "link": "https://huggingface.co/Medilora/medilora-qwen-14b",
    "author": "Medilora"
  },
  {
    "T": "\u2b55",
    "model": "CausalLM-Platypus-14B",
    "average": 63.8,
    "arc": 56.91,
    "hellaswag": 80.06,
    "mmlu": 64.98,
    "truthfulqa": 47.57,
    "winogrande": 76.01,
    "gsm8k": 57.24,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 14.17,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1659d3cdbb8bb8dba902ab2874f4fa886980fc70",
    "model_name_for_query": "KnutJaegersberg/CausalLM-Platypus-14B",
    "link": "https://huggingface.co/KnutJaegersberg/CausalLM-Platypus-14B",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "tigerbot-70b-base",
    "average": 63.71,
    "arc": 62.46,
    "hellaswag": 83.61,
    "mmlu": 65.49,
    "truthfulqa": 52.76,
    "winogrande": 80.19,
    "gsm8k": 37.76,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 68.95,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "8af85526293eb8625375f3f7a1bab69825176e48",
    "model_name_for_query": "TigerResearch/tigerbot-70b-base",
    "link": "https://huggingface.co/TigerResearch/tigerbot-70b-base",
    "author": "TigerResearch"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Starling-LM-11B-alpha",
    "average": 63.66,
    "arc": 62.97,
    "hellaswag": 84.85,
    "mmlu": 63.83,
    "truthfulqa": 54.52,
    "winogrande": 77.82,
    "gsm8k": 37.98,
    "model_type": "pretrained",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-nd-4.0",
    "params": 11.39,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "16086688b70e4f54e1ba4f54a1a847c30b987a74",
    "model_name_for_query": "Delcos/Starling-LM-11B-alpha",
    "link": "https://huggingface.co/Delcos/Starling-LM-11B-alpha",
    "author": "Delcos"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt4-alpaca-lora_mlp-65B-HF",
    "average": 63.66,
    "arc": 65.02,
    "hellaswag": 86.13,
    "mmlu": 62.73,
    "truthfulqa": 59.16,
    "winogrande": 80.66,
    "gsm8k": 28.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.02,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "664ff8e3e1d446971a16a6c9018ab24de7664684",
    "model_name_for_query": "TheBloke/gpt4-alpaca-lora_mlp-65B-HF",
    "link": "https://huggingface.co/TheBloke/gpt4-alpaca-lora_mlp-65B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "openinstruct-mistral-7b",
    "average": 63.64,
    "arc": 59.73,
    "hellaswag": 82.77,
    "mmlu": 60.55,
    "truthfulqa": 48.76,
    "winogrande": 79.56,
    "gsm8k": 50.49,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "54f379bf7676ffd09b48b0ff607b7ae6c0a6f688",
    "model_name_for_query": "monology/openinstruct-mistral-7b",
    "link": "https://huggingface.co/monology/openinstruct-mistral-7b",
    "author": "monology"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-code-mistral-7b-v1.0",
    "average": 63.6,
    "arc": 61.18,
    "hellaswag": 83.77,
    "mmlu": 63.4,
    "truthfulqa": 47.9,
    "winogrande": 78.37,
    "gsm8k": 47.01,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "43dea8e97d05f2e4358415b9a95a1b327c1f5804",
    "model_name_for_query": "uukuguy/speechless-code-mistral-7b-v1.0",
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-7b-v1.0",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "higgs-llama-vicuna-ep25-70b",
    "average": 63.6,
    "arc": 62.29,
    "hellaswag": 86.07,
    "mmlu": 64.25,
    "truthfulqa": 53.75,
    "winogrande": 80.66,
    "gsm8k": 34.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 68.72,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "1da59e150f1d0bae67f66400738a01d408a8c45d",
    "model_name_for_query": "luffycodes/higgs-llama-vicuna-ep25-70b",
    "link": "https://huggingface.co/luffycodes/higgs-llama-vicuna-ep25-70b",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Falkor-16b",
    "average": 63.52,
    "arc": 65.96,
    "hellaswag": 82.62,
    "mmlu": 63.58,
    "truthfulqa": 62.77,
    "winogrande": 77.9,
    "gsm8k": 28.28,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 14.22,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2365c7af9eb60bfa946b566dadd6802befa122e8",
    "model_name_for_query": "perlthoughts/Falkor-16b",
    "link": "https://huggingface.co/perlthoughts/Falkor-16b",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "notus-7b-v1",
    "average": 63.49,
    "arc": 64.59,
    "hellaswag": 84.83,
    "mmlu": 63.04,
    "truthfulqa": 54.35,
    "winogrande": 79.56,
    "gsm8k": 34.57,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "f23f4cf6cb76402c76e932ead01109191af72a60",
    "model_name_for_query": "argilla/notus-7b-v1",
    "link": "https://huggingface.co/argilla/notus-7b-v1",
    "author": "argilla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral7B_adaptor_v1",
    "average": 63.42,
    "arc": 62.97,
    "hellaswag": 83.81,
    "mmlu": 63.56,
    "truthfulqa": 49.77,
    "winogrande": 79.16,
    "gsm8k": 41.24,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "23e800094570c22fbaa4279ef7e7f27315ac61af",
    "model_name_for_query": "xxyyy123/Mistral7B_adaptor_v1",
    "link": "https://huggingface.co/xxyyy123/Mistral7B_adaptor_v1",
    "author": "xxyyy123"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-16B-v2.01",
    "average": 63.42,
    "arc": 65.36,
    "hellaswag": 82.92,
    "mmlu": 63.27,
    "truthfulqa": 64.53,
    "winogrande": 79.08,
    "gsm8k": 25.32,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 14.22,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3b723559b550a34e489cc41ec5414e00531ec2ae",
    "model_name_for_query": "perlthoughts/Chupacabra-16B-v2.01",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-16B-v2.01",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "tora-70b-v1.0",
    "average": 63.39,
    "arc": 67.75,
    "hellaswag": 85.83,
    "mmlu": 69.22,
    "truthfulqa": 51.79,
    "winogrande": 81.93,
    "gsm8k": 23.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "e95fd7daf017e7c414ec07ebef4ddf013c16f9a4",
    "model_name_for_query": "llm-agents/tora-70b-v1.0",
    "link": "https://huggingface.co/llm-agents/tora-70b-v1.0",
    "author": "llm-agents"
  },
  {
    "T": "\u2b55",
    "model": "Mini_Synatra_SFT",
    "average": 63.39,
    "arc": 62.46,
    "hellaswag": 83.44,
    "mmlu": 61.2,
    "truthfulqa": 53.67,
    "winogrande": 74.66,
    "gsm8k": 44.88,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fc042f671dc0c94b21a6107eda75a6f9c8d44f2d",
    "model_name_for_query": "maywell/Mini_Synatra_SFT",
    "link": "https://huggingface.co/maywell/Mini_Synatra_SFT",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
    "average": 63.37,
    "arc": 62.88,
    "hellaswag": 83.99,
    "mmlu": 62.89,
    "truthfulqa": 50.55,
    "winogrande": 79.72,
    "gsm8k": 40.18,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "2872cd97f88418d6b07082048b316ea5b996982d",
    "model_name_for_query": "xxyyy123/1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
    "link": "https://huggingface.co/xxyyy123/1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
    "author": "xxyyy123"
  },
  {
    "T": "\u2b55",
    "model": "DeciLM-7B-instruct",
    "average": 63.19,
    "arc": 61.01,
    "hellaswag": 82.37,
    "mmlu": 60.24,
    "truthfulqa": 49.75,
    "winogrande": 79.72,
    "gsm8k": 46.02,
    "model_type": "instruction-tuned",
    "architecture": "DeciLMForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.04,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "24a66a701c10e5d70397f9bfc1624447327a0a08",
    "model_name_for_query": "Deci/DeciLM-7B-instruct",
    "link": "https://huggingface.co/Deci/DeciLM-7B-instruct",
    "author": "Deci"
  },
  {
    "T": "\u2b55",
    "model": "Yi-34B-Chat",
    "average": 63.17,
    "arc": 65.1,
    "hellaswag": 84.08,
    "mmlu": 74.87,
    "truthfulqa": 55.41,
    "winogrande": 79.79,
    "gsm8k": 19.79,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.39,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "a99ec35331cbfc9da596af7d4538fe2efecff03c",
    "model_name_for_query": "01-ai/Yi-34B-Chat",
    "link": "https://huggingface.co/01-ai/Yi-34B-Chat",
    "author": "01-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "testllm-c2",
    "average": 63.13,
    "arc": 60.58,
    "hellaswag": 81.91,
    "mmlu": 61.2,
    "truthfulqa": 49.87,
    "winogrande": 77.82,
    "gsm8k": 47.38,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b87c798bc27522824451dfccf5eae50edbd4263b",
    "model_name_for_query": "Kiddyz/testllm-c2",
    "link": "https://huggingface.co/Kiddyz/testllm-c2",
    "author": "Kiddyz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-falcon-180b-v12-preview0",
    "average": 63.06,
    "arc": 62.29,
    "hellaswag": 83.8,
    "mmlu": 55.92,
    "truthfulqa": 53.05,
    "winogrande": 82.08,
    "gsm8k": 41.24,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 178.64,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4f1aeb136860ee3216f23faec0c598014e5c40a6",
    "model_name_for_query": "OpenBuddy/openbuddy-falcon-180b-v12-preview0",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-falcon-180b-v12-preview0",
    "author": "OpenBuddy"
  },
  {
    "T": "?",
    "model": "LLaMA_2_13B_SFT_v1",
    "average": 63.04,
    "arc": 64.51,
    "hellaswag": 83.38,
    "mmlu": 58.6,
    "truthfulqa": 53.2,
    "winogrande": 78.53,
    "gsm8k": 40.03,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "31421b19a3f5fe2eff4871c86d3a94d5723b6fd2",
    "model_name_for_query": "adonlee/LLaMA_2_13B_SFT_v1",
    "link": "https://huggingface.co/adonlee/LLaMA_2_13B_SFT_v1",
    "author": "adonlee"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Airoboros-L2-70B-2.1-GPTQ",
    "average": 63.04,
    "arc": 70.39,
    "hellaswag": 86.54,
    "mmlu": 68.89,
    "truthfulqa": 55.55,
    "winogrande": 81.61,
    "gsm8k": 15.24,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "llama2",
    "params": 72.82,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "23ed580cb77ebaee49ea11eb4538fd3ab3795b76",
    "model_name_for_query": "TheBloke/Airoboros-L2-70B-2.1-GPTQ",
    "link": "https://huggingface.co/TheBloke/Airoboros-L2-70B-2.1-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "blossom-v3-mistral-7b",
    "average": 62.95,
    "arc": 60.49,
    "hellaswag": 81.9,
    "mmlu": 61.35,
    "truthfulqa": 50.31,
    "winogrande": 76.95,
    "gsm8k": 46.7,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ec6e84a662c801e248d3bb3a19529155de02bda0",
    "model_name_for_query": "Azure99/blossom-v3-mistral-7b",
    "link": "https://huggingface.co/Azure99/blossom-v3-mistral-7b",
    "author": "Azure99"
  },
  {
    "T": "\u2b55",
    "model": "CollectiveCognition-v1.1-Mistral-7B",
    "average": 62.92,
    "arc": 62.12,
    "hellaswag": 84.17,
    "mmlu": 62.35,
    "truthfulqa": 57.62,
    "winogrande": 75.37,
    "gsm8k": 35.86,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 45.0,
    "still_on_hub": true,
    "revision": "5f57f70ec99450c70da2540e94dd7fd67be4b23c",
    "model_name_for_query": "teknium/CollectiveCognition-v1.1-Mistral-7B",
    "link": "https://huggingface.co/teknium/CollectiveCognition-v1.1-Mistral-7B",
    "author": "teknium"
  },
  {
    "T": "\u2b55",
    "model": "MelangeA-70b",
    "average": 62.82,
    "arc": 71.25,
    "hellaswag": 87.3,
    "mmlu": 70.56,
    "truthfulqa": 60.61,
    "winogrande": 81.53,
    "gsm8k": 5.69,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.98,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d48cf79d1ead50154b1e70120779ae91bc5fafb4",
    "model_name_for_query": "chargoddard/MelangeA-70b",
    "link": "https://huggingface.co/chargoddard/MelangeA-70b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-65b",
    "average": 62.79,
    "arc": 63.48,
    "hellaswag": 86.09,
    "mmlu": 63.93,
    "truthfulqa": 43.43,
    "winogrande": 82.56,
    "gsm8k": 37.23,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.29,
    "likes": 64.0,
    "still_on_hub": true,
    "revision": "49707c5313d34d1c5a846e29cf2a2a650c22c8ee",
    "model_name_for_query": "huggyllama/llama-65b",
    "link": "https://huggingface.co/huggyllama/llama-65b",
    "author": "huggyllama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-1-dare-0.85",
    "average": 62.74,
    "arc": 61.95,
    "hellaswag": 83.84,
    "mmlu": 64.43,
    "truthfulqa": 44.9,
    "winogrande": 79.16,
    "gsm8k": 42.15,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "3c15d3e2a7790e45501e105daed5eb88b665ceef",
    "model_name_for_query": "uukuguy/neural-chat-7b-v3-1-dare-0.85",
    "link": "https://huggingface.co/uukuguy/neural-chat-7b-v3-1-dare-0.85",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ARIA-70B-V3",
    "average": 62.73,
    "arc": 63.91,
    "hellaswag": 86.21,
    "mmlu": 64.75,
    "truthfulqa": 51.32,
    "winogrande": 82.08,
    "gsm8k": 28.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 68.98,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6e7fdcd20626786dd744ea86c664a3c088ced39f",
    "model_name_for_query": "Faradaylab/ARIA-70B-V3",
    "link": "https://huggingface.co/Faradaylab/ARIA-70B-V3",
    "author": "Faradaylab"
  },
  {
    "T": "\u2b55",
    "model": "SG-Raccoon-Yi-200k-2.0",
    "average": 62.72,
    "arc": 62.54,
    "hellaswag": 80.26,
    "mmlu": 73.29,
    "truthfulqa": 53.21,
    "winogrande": 76.32,
    "gsm8k": 30.71,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 55.59,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "986706415fcb2118f35626dbc12e054457ec9ad3",
    "model_name_for_query": "mlinmg/SG-Raccoon-Yi-200k-2.0",
    "link": "https://huggingface.co/mlinmg/SG-Raccoon-Yi-200k-2.0",
    "author": "mlinmg"
  },
  {
    "T": "?",
    "model": "MadMix-v0.2",
    "average": 62.72,
    "arc": 64.85,
    "hellaswag": 83.54,
    "mmlu": 64.02,
    "truthfulqa": 55.79,
    "winogrande": 77.35,
    "gsm8k": 30.78,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "69a3c98c23938a9370c62ae43894eb7723de97dc",
    "model_name_for_query": "Fredithefish/MadMix-v0.2",
    "link": "https://huggingface.co/Fredithefish/MadMix-v0.2",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "guanaco-65B-HF",
    "average": 62.67,
    "arc": 65.44,
    "hellaswag": 86.47,
    "mmlu": 62.92,
    "truthfulqa": 52.81,
    "winogrande": 82.4,
    "gsm8k": 26.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.02,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "7f83ae526f8b83705ca8434535da8fd8c692f9d0",
    "model_name_for_query": "TheBloke/guanaco-65B-HF",
    "link": "https://huggingface.co/TheBloke/guanaco-65B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-XS-v1-3-yarn-128K",
    "average": 62.66,
    "arc": 61.09,
    "hellaswag": 82.95,
    "mmlu": 62.15,
    "truthfulqa": 50.13,
    "winogrande": 74.43,
    "gsm8k": 45.19,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "0f5977a5d2fa791359dc92eb1574b6112e709cad",
    "model_name_for_query": "migtissera/Tess-XS-v1-3-yarn-128K",
    "link": "https://huggingface.co/migtissera/Tess-XS-v1-3-yarn-128K",
    "author": "migtissera"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-70b-IA3-guanaco",
    "average": 62.61,
    "arc": 68.52,
    "hellaswag": 85.67,
    "mmlu": 67.03,
    "truthfulqa": 43.47,
    "winogrande": 82.24,
    "gsm8k": 28.73,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.72,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e3230df22d065b6699096494d1151fa337dde9e8",
    "model_name_for_query": "yeontaek/llama-2-70b-IA3-guanaco",
    "link": "https://huggingface.co/yeontaek/llama-2-70b-IA3-guanaco",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-70b-gpt4-2.0",
    "average": 62.6,
    "arc": 68.6,
    "hellaswag": 87.53,
    "mmlu": 69.37,
    "truthfulqa": 48.52,
    "winogrande": 83.9,
    "gsm8k": 17.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "other",
    "params": 68.72,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "f16526d9bb814dc10adc911f94e8c7a520beb5b6",
    "model_name_for_query": "jondurbin/airoboros-l2-70b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "VicUnlocked-alpaca-65B-QLoRA-fp16",
    "average": 62.58,
    "arc": 65.61,
    "hellaswag": 85.15,
    "mmlu": 63.13,
    "truthfulqa": 52.47,
    "winogrande": 81.29,
    "gsm8k": 27.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.02,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "6cdacfda96970aa144e316b108ab9bc17c99a573",
    "model_name_for_query": "TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16",
    "link": "https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "blossom-v3_1-mistral-7b",
    "average": 62.53,
    "arc": 60.49,
    "hellaswag": 81.71,
    "mmlu": 61.0,
    "truthfulqa": 49.51,
    "winogrande": 75.53,
    "gsm8k": 46.93,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d84e28c169a93933829e10f314f1e3e674df9843",
    "model_name_for_query": "Azure99/blossom-v3_1-mistral-7b",
    "link": "https://huggingface.co/Azure99/blossom-v3_1-mistral-7b",
    "author": "Azure99"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-XS-v1-3-yarn-128K",
    "average": 62.49,
    "arc": 61.6,
    "hellaswag": 82.96,
    "mmlu": 62.1,
    "truthfulqa": 50.2,
    "winogrande": 74.74,
    "gsm8k": 43.37,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "72d393d13f1bd26442e59993c57840b91ff6f6fc",
    "model_name_for_query": "migtissera/Tess-XS-v1-3-yarn-128K",
    "link": "https://huggingface.co/migtissera/Tess-XS-v1-3-yarn-128K",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ShiningValiantXS",
    "average": 62.48,
    "arc": 64.42,
    "hellaswag": 83.58,
    "mmlu": 60.37,
    "truthfulqa": 55.0,
    "winogrande": 76.8,
    "gsm8k": 34.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "8c1f86bd2e646408eed2ed3a2634b38ea4e5c599",
    "model_name_for_query": "ValiantLabs/ShiningValiantXS",
    "link": "https://huggingface.co/ValiantLabs/ShiningValiantXS",
    "author": "ValiantLabs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Kant-Test-0.1-Mistral-7B",
    "average": 62.42,
    "arc": 62.37,
    "hellaswag": 82.84,
    "mmlu": 63.38,
    "truthfulqa": 49.62,
    "winogrande": 78.3,
    "gsm8k": 37.98,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5989100fa82aaab0db2f8ed3e37a446126050ef9",
    "model_name_for_query": "Zardos/Kant-Test-0.1-Mistral-7B",
    "link": "https://huggingface.co/Zardos/Kant-Test-0.1-Mistral-7B",
    "author": "Zardos"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Llama-2-70b-chat-hf",
    "average": 62.4,
    "arc": 64.59,
    "hellaswag": 85.88,
    "mmlu": 63.91,
    "truthfulqa": 52.8,
    "winogrande": 80.51,
    "gsm8k": 26.69,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 68.98,
    "likes": 1453.0,
    "still_on_hub": false,
    "revision": "7f54101c0fbb67a8143ca23eb8bd09b71f269c74",
    "model_name_for_query": "meta-llama/Llama-2-70b-chat-hf",
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf",
    "author": "meta-llama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ARIA-70B-French",
    "average": 62.37,
    "arc": 64.51,
    "hellaswag": 85.87,
    "mmlu": 63.88,
    "truthfulqa": 52.8,
    "winogrande": 80.51,
    "gsm8k": 26.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d8580d360c51e71fddd27897445e2aa9d1888585",
    "model_name_for_query": "willyninja30/ARIA-70B-French",
    "link": "https://huggingface.co/willyninja30/ARIA-70B-French",
    "author": "willyninja30"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-1.2",
    "average": 62.36,
    "arc": 65.87,
    "hellaswag": 86.08,
    "mmlu": 63.37,
    "truthfulqa": 52.72,
    "winogrande": 79.56,
    "gsm8k": 26.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "50ab86e198e1c82ec81aefc628f23501c101d390",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-1.2",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.2",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-7b-alpha-dare-0.85",
    "average": 62.35,
    "arc": 61.18,
    "hellaswag": 83.67,
    "mmlu": 64.3,
    "truthfulqa": 44.41,
    "winogrande": 78.45,
    "gsm8k": 42.08,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "afe35301593b4ce2e7b5d1696066724ef1f802eb",
    "model_name_for_query": "uukuguy/zephyr-7b-alpha-dare-0.85",
    "link": "https://huggingface.co/uukuguy/zephyr-7b-alpha-dare-0.85",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca2-13B-selfmerge-39B",
    "average": 62.24,
    "arc": 60.84,
    "hellaswag": 79.84,
    "mmlu": 60.32,
    "truthfulqa": 56.38,
    "winogrande": 76.87,
    "gsm8k": 39.2,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "ms-pl",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7a9e6775716a3947d0e40842b5d61753bc0551ac",
    "model_name_for_query": "vmajor/Orca2-13B-selfmerge-39B",
    "link": "https://huggingface.co/vmajor/Orca2-13B-selfmerge-39B",
    "author": "vmajor"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca2-13B-selfmerge-26B",
    "average": 62.24,
    "arc": 60.84,
    "hellaswag": 79.84,
    "mmlu": 60.32,
    "truthfulqa": 56.38,
    "winogrande": 76.87,
    "gsm8k": 39.2,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "ms-pl",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "46cdde5be7e3c48ada1bd3143ad593eecfb641e7",
    "model_name_for_query": "vmajor/Orca2-13B-selfmerge-26B",
    "link": "https://huggingface.co/vmajor/Orca2-13B-selfmerge-26B",
    "author": "vmajor"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-7B-v1.4",
    "average": 62.19,
    "arc": 60.41,
    "hellaswag": 82.87,
    "mmlu": 60.98,
    "truthfulqa": 51.88,
    "winogrande": 74.82,
    "gsm8k": 42.15,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "53a5249ee9e5b2327de81f09c26a4577dea9260b",
    "model_name_for_query": "migtissera/Tess-7B-v1.4",
    "link": "https://huggingface.co/migtissera/Tess-7B-v1.4",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca-2-13b-f16",
    "average": 62.14,
    "arc": 60.67,
    "hellaswag": 79.81,
    "mmlu": 60.37,
    "truthfulqa": 56.41,
    "winogrande": 76.64,
    "gsm8k": 38.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b29c52ea0757c460e83592e55ea89e016cef3549",
    "model_name_for_query": "uukuguy/Orca-2-13b-f16",
    "link": "https://huggingface.co/uukuguy/Orca-2-13b-f16",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lemur-70b-v1",
    "average": 62.07,
    "arc": 64.33,
    "hellaswag": 85.72,
    "mmlu": 65.85,
    "truthfulqa": 44.78,
    "winogrande": 83.03,
    "gsm8k": 28.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 31.0,
    "still_on_hub": true,
    "revision": "74432ae16ef50207fe17fb88b2f1c1d32ef3b481",
    "model_name_for_query": "OpenLemur/lemur-70b-v1",
    "link": "https://huggingface.co/OpenLemur/lemur-70b-v1",
    "author": "OpenLemur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
    "average": 62.06,
    "arc": 61.69,
    "hellaswag": 83.85,
    "mmlu": 64.43,
    "truthfulqa": 43.13,
    "winogrande": 78.93,
    "gsm8k": 40.33,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "7a3def1c382793d2b12741896302c31a471b6d1d",
    "model_name_for_query": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
    "link": "https://huggingface.co/uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
    "author": "uukuguy"
  },
  {
    "T": "?",
    "model": "Alpaca-elina-65b",
    "average": 62.03,
    "arc": 65.27,
    "hellaswag": 85.75,
    "mmlu": 63.42,
    "truthfulqa": 47.32,
    "winogrande": 81.37,
    "gsm8k": 29.04,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 65.02,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "51ce30a69b3c3363c8cfcd6395bf1df974ba2977",
    "model_name_for_query": "Aeala/Alpaca-elina-65b",
    "link": "https://huggingface.co/Aeala/Alpaca-elina-65b",
    "author": "Aeala"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-200K-Q",
    "average": 62.0,
    "arc": 63.91,
    "hellaswag": 83.52,
    "mmlu": 75.19,
    "truthfulqa": 44.21,
    "winogrande": 81.06,
    "gsm8k": 24.11,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0f58c270f8f3b82523799dcfd7080b857850bd77",
    "model_name_for_query": "kyujinpy/PlatYi-34B-200K-Q",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-200K-Q",
    "author": "kyujinpy"
  },
  {
    "T": "\u2b55",
    "model": "Iambe-20b-DARE-v2",
    "average": 61.99,
    "arc": 62.8,
    "hellaswag": 84.53,
    "mmlu": 60.45,
    "truthfulqa": 53.85,
    "winogrande": 77.03,
    "gsm8k": 33.28,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 19.99,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "02bd8edd30a5ddd1eede94c19a6ae160842a2f9f",
    "model_name_for_query": "athirdpath/Iambe-20b-DARE-v2",
    "link": "https://huggingface.co/athirdpath/Iambe-20b-DARE-v2",
    "author": "athirdpath"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-beta-math",
    "average": 61.99,
    "arc": 56.66,
    "hellaswag": 81.26,
    "mmlu": 57.24,
    "truthfulqa": 44.83,
    "winogrande": 75.53,
    "gsm8k": 56.41,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.0,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "dd3d070a104d8b36ba98d14a485d88fa95aaab63",
    "model_name_for_query": "abhishek/zephyr-beta-math",
    "link": "https://huggingface.co/abhishek/zephyr-beta-math",
    "author": "abhishek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-7B-v3.0",
    "average": 61.99,
    "arc": 62.46,
    "hellaswag": 83.79,
    "mmlu": 63.9,
    "truthfulqa": 43.85,
    "winogrande": 77.9,
    "gsm8k": 40.03,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "93c2e8b8055b42779f2b68059ebe38af6f2789c4",
    "model_name_for_query": "migtissera/Synthia-7B-v3.0",
    "link": "https://huggingface.co/migtissera/Synthia-7B-v3.0",
    "author": "migtissera"
  },
  {
    "T": "\u2b55",
    "model": "MelangeC-70b",
    "average": 61.96,
    "arc": 71.67,
    "hellaswag": 87.6,
    "mmlu": 70.37,
    "truthfulqa": 58.13,
    "winogrande": 83.98,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 68.98,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e54a2b924dec135f3fa2373933ab8485178cde1b",
    "model_name_for_query": "chargoddard/MelangeC-70b",
    "link": "https://huggingface.co/chargoddard/MelangeC-70b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ARIA-70B-V2",
    "average": 61.93,
    "arc": 62.12,
    "hellaswag": 85.68,
    "mmlu": 63.49,
    "truthfulqa": 49.8,
    "winogrande": 81.69,
    "gsm8k": 28.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "2bf026af438d522268533484a85a3e54178e7809",
    "model_name_for_query": "Faradaylab/ARIA-70B-V2",
    "link": "https://huggingface.co/Faradaylab/ARIA-70B-V2",
    "author": "Faradaylab"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MythoMist-7b",
    "average": 61.67,
    "arc": 65.87,
    "hellaswag": 83.55,
    "mmlu": 62.32,
    "truthfulqa": 59.98,
    "winogrande": 78.06,
    "gsm8k": 20.24,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3b6c71416d191ab161fd3043117304a10df99716",
    "model_name_for_query": "Gryphe/MythoMist-7b",
    "link": "https://huggingface.co/Gryphe/MythoMist-7b",
    "author": "Gryphe"
  },
  {
    "T": "?",
    "model": "mistral-7b-finetuned-orca-dpo-v2",
    "average": 61.59,
    "arc": 66.21,
    "hellaswag": 83.64,
    "mmlu": 62.37,
    "truthfulqa": 59.65,
    "winogrande": 78.14,
    "gsm8k": 19.56,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a5c1daaec60a480e8c81b265135583034054be2b",
    "model_name_for_query": "lvkaokao/mistral-7b-finetuned-orca-dpo-v2",
    "link": "https://huggingface.co/lvkaokao/mistral-7b-finetuned-orca-dpo-v2",
    "author": "lvkaokao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-1",
    "average": 61.59,
    "arc": 66.21,
    "hellaswag": 83.64,
    "mmlu": 62.37,
    "truthfulqa": 59.65,
    "winogrande": 78.14,
    "gsm8k": 19.56,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "3995e9a13d54ce95f0ad55de2eaa92e2dc580174",
    "model_name_for_query": "Intel/neural-chat-7b-v3-1",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "author": "Intel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-1",
    "average": 61.59,
    "arc": 65.7,
    "hellaswag": 83.54,
    "mmlu": 62.12,
    "truthfulqa": 59.48,
    "winogrande": 78.61,
    "gsm8k": 20.09,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "8bit",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "af2489cde09e9d2c175622f651875e83824c4b10",
    "model_name_for_query": "Intel/neural-chat-7b-v3-1",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "author": "Intel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "NSFW_DPO_Noromaid-7b",
    "average": 61.59,
    "arc": 62.63,
    "hellaswag": 84.5,
    "mmlu": 63.34,
    "truthfulqa": 44.99,
    "winogrande": 78.22,
    "gsm8k": 35.86,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "51b4408a40736e18f69d932cb403811558428378",
    "model_name_for_query": "athirdpath/NSFW_DPO_Noromaid-7b",
    "link": "https://huggingface.co/athirdpath/NSFW_DPO_Noromaid-7b",
    "author": "athirdpath"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-7b-beta",
    "average": 61.59,
    "arc": 62.46,
    "hellaswag": 84.35,
    "mmlu": 60.7,
    "truthfulqa": 57.83,
    "winogrande": 77.11,
    "gsm8k": 27.07,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "8bit",
    "license": "mit",
    "params": 7.24,
    "likes": 976.0,
    "still_on_hub": true,
    "revision": "0f17b36adfbe7d86ea1c591a9efeeae17b313f48",
    "model_name_for_query": "HuggingFaceH4/zephyr-7b-beta",
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "author": "HuggingFaceH4"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "DeciLM-7B",
    "average": 61.55,
    "arc": 59.39,
    "hellaswag": 82.51,
    "mmlu": 59.76,
    "truthfulqa": 40.33,
    "winogrande": 79.95,
    "gsm8k": 47.38,
    "model_type": "pretrained",
    "architecture": "DeciLMForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.04,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "b943e32a12bc21df2b8b3c50525c6646acd442bb",
    "model_name_for_query": "Deci/DeciLM-7B",
    "link": "https://huggingface.co/Deci/DeciLM-7B",
    "author": "Deci"
  },
  {
    "T": "\u2b55",
    "model": "zephyr-7b-dpo-full-beta-0.2",
    "average": 61.55,
    "arc": 61.77,
    "hellaswag": 84.04,
    "mmlu": 61.79,
    "truthfulqa": 54.72,
    "winogrande": 76.95,
    "gsm8k": 30.02,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "727b63fc1ca6a592072159a7185c22f74cd38480",
    "model_name_for_query": "tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "link": "https://huggingface.co/tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "author": "tianlinliu0121"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-1",
    "average": 61.54,
    "arc": 66.3,
    "hellaswag": 83.6,
    "mmlu": 62.44,
    "truthfulqa": 59.54,
    "winogrande": 77.98,
    "gsm8k": 19.41,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "3995e9a13d54ce95f0ad55de2eaa92e2dc580174",
    "model_name_for_query": "Intel/neural-chat-7b-v3-1",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "author": "Intel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-2.5-Mistral-7B",
    "average": 61.52,
    "arc": 64.93,
    "hellaswag": 84.18,
    "mmlu": 63.64,
    "truthfulqa": 52.24,
    "winogrande": 78.06,
    "gsm8k": 26.08,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 125.0,
    "still_on_hub": true,
    "revision": "2a54cad766bc90828354db5c4199795aecfd0df1",
    "model_name_for_query": "teknium/OpenHermes-2.5-Mistral-7B",
    "link": "https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B",
    "author": "teknium"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Noromaid-7b-v0.1.1",
    "average": 61.49,
    "arc": 62.2,
    "hellaswag": 84.28,
    "mmlu": 63.44,
    "truthfulqa": 44.3,
    "winogrande": 77.9,
    "gsm8k": 36.85,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "349a2eb5c61e3e13c2b39d15c7b94f5c31ab6bd5",
    "model_name_for_query": "NeverSleep/Noromaid-7b-v0.1.1",
    "link": "https://huggingface.co/NeverSleep/Noromaid-7b-v0.1.1",
    "author": "NeverSleep"
  },
  {
    "T": "\ud83d\udd36",
    "model": "robin-65b-v2-fp16",
    "average": 61.48,
    "arc": 61.95,
    "hellaswag": 84.6,
    "mmlu": 62.51,
    "truthfulqa": 52.31,
    "winogrande": 80.51,
    "gsm8k": 26.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.02,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "40edb31ba93045d673735361bc98f56125bbc77b",
    "model_name_for_query": "TheBloke/robin-65b-v2-fp16",
    "link": "https://huggingface.co/TheBloke/robin-65b-v2-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-2.5-Mistral-7B",
    "average": 61.45,
    "arc": 64.93,
    "hellaswag": 84.3,
    "mmlu": 63.82,
    "truthfulqa": 52.31,
    "winogrande": 77.9,
    "gsm8k": 25.47,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 115.0,
    "still_on_hub": true,
    "revision": "2a54cad766bc90828354db5c4199795aecfd0df1",
    "model_name_for_query": "teknium/OpenHermes-2.5-Mistral-7B",
    "link": "https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B",
    "author": "teknium"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-llama2-13b",
    "average": 61.36,
    "arc": 62.03,
    "hellaswag": 81.82,
    "mmlu": 58.69,
    "truthfulqa": 55.66,
    "winogrande": 76.01,
    "gsm8k": 33.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "c6362c4fc0dc03420e3c08454b2e7689e4e32d3a",
    "model_name_for_query": "uukuguy/speechless-llama2-13b",
    "link": "https://huggingface.co/uukuguy/speechless-llama2-13b",
    "author": "uukuguy"
  },
  {
    "T": "\u2b55",
    "model": "zephyr-7b-dpo-full-beta-0.2",
    "average": 61.36,
    "arc": 61.86,
    "hellaswag": 83.98,
    "mmlu": 61.85,
    "truthfulqa": 54.78,
    "winogrande": 76.95,
    "gsm8k": 28.73,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "727b63fc1ca6a592072159a7185c22f74cd38480",
    "model_name_for_query": "tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "link": "https://huggingface.co/tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "author": "tianlinliu0121"
  },
  {
    "T": "\ud83d\udd36",
    "model": "alpaca-lora-65B-HF",
    "average": 61.33,
    "arc": 64.85,
    "hellaswag": 85.59,
    "mmlu": 63.11,
    "truthfulqa": 45.15,
    "winogrande": 81.22,
    "gsm8k": 28.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.02,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "113b61b37a2862b950ada68620e57acafbcefe13",
    "model_name_for_query": "TheBloke/alpaca-lora-65B-HF",
    "link": "https://huggingface.co/TheBloke/alpaca-lora-65B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "phi-2",
    "average": 61.33,
    "arc": 61.09,
    "hellaswag": 75.11,
    "mmlu": 58.11,
    "truthfulqa": 44.47,
    "winogrande": 74.35,
    "gsm8k": 54.81,
    "model_type": "pretrained",
    "architecture": "PhiForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 2.78,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "d3186761bf5c4409f7679359284066c25ab668ee",
    "model_name_for_query": "microsoft/phi-2",
    "link": "https://huggingface.co/microsoft/phi-2",
    "author": "microsoft"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
    "average": 61.26,
    "arc": 60.58,
    "hellaswag": 83.34,
    "mmlu": 61.53,
    "truthfulqa": 48.21,
    "winogrande": 77.74,
    "gsm8k": 36.16,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "43abfcab8bf532a2601ed6e61e0c3614272b7df9",
    "model_name_for_query": "NickyNicky/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
    "link": "https://huggingface.co/NickyNicky/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
    "author": "NickyNicky"
  },
  {
    "T": "\u2b55",
    "model": "WizardLM-70B-V1.0",
    "average": 61.25,
    "arc": 65.44,
    "hellaswag": 84.41,
    "mmlu": 64.05,
    "truthfulqa": 54.81,
    "winogrande": 80.82,
    "gsm8k": 17.97,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 68.72,
    "likes": 112.0,
    "still_on_hub": true,
    "revision": "6dae38060d70b82dcfe787a612d04aaf0adf0738",
    "model_name_for_query": "WizardLM/WizardLM-70B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardLM-70B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_3.5",
    "average": 61.24,
    "arc": 63.91,
    "hellaswag": 84.79,
    "mmlu": 64.94,
    "truthfulqa": 46.38,
    "winogrande": 80.58,
    "gsm8k": 26.84,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 517.0,
    "still_on_hub": true,
    "revision": "5b874a33a91d63023055e6cb2d5d86afe883b4ec",
    "model_name_for_query": "openchat/openchat_3.5",
    "link": "https://huggingface.co/openchat/openchat_3.5",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Mini_DPO_test02",
    "average": 61.23,
    "arc": 59.73,
    "hellaswag": 83.89,
    "mmlu": 61.9,
    "truthfulqa": 48.47,
    "winogrande": 78.37,
    "gsm8k": 35.03,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "cd417467644c4178100083e342bad88a3f968be6",
    "model_name_for_query": "Minirecord/Mini_DPO_test02",
    "link": "https://huggingface.co/Minirecord/Mini_DPO_test02",
    "author": "Minirecord"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_3.5",
    "average": 61.22,
    "arc": 63.82,
    "hellaswag": 84.8,
    "mmlu": 64.98,
    "truthfulqa": 46.39,
    "winogrande": 80.74,
    "gsm8k": 26.61,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 517.0,
    "still_on_hub": true,
    "revision": "5b874a33a91d63023055e6cb2d5d86afe883b4ec",
    "model_name_for_query": "openchat/openchat_3.5",
    "link": "https://huggingface.co/openchat/openchat_3.5",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-2.0",
    "average": 61.2,
    "arc": 66.64,
    "hellaswag": 86.66,
    "mmlu": 63.18,
    "truthfulqa": 49.11,
    "winogrande": 80.74,
    "gsm8k": 20.85,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ea4bdd0221f77de9b0343cd8291cbd0fd6033ca8",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-65b",
    "average": 61.19,
    "arc": 63.48,
    "hellaswag": 86.09,
    "mmlu": 63.93,
    "truthfulqa": 43.43,
    "winogrande": 82.56,
    "gsm8k": 27.67,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "other",
    "params": 65.29,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "4ae2e56610e8b9b9a78472708390668e9096b4f9",
    "model_name_for_query": "huggingface/llama-65b",
    "link": "https://huggingface.co/huggingface/llama-65b",
    "author": "huggingface"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mistral-7b-slimorcaboros",
    "average": 61.18,
    "arc": 63.65,
    "hellaswag": 83.7,
    "mmlu": 63.46,
    "truthfulqa": 55.81,
    "winogrande": 77.03,
    "gsm8k": 23.43,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c06e1a6b6c0fe764117f9ec7611ce31e796e602a",
    "model_name_for_query": "openaccess-ai-collective/mistral-7b-slimorcaboros",
    "link": "https://huggingface.co/openaccess-ai-collective/mistral-7b-slimorcaboros",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "jackalope-7b",
    "average": 61.16,
    "arc": 63.4,
    "hellaswag": 83.29,
    "mmlu": 63.5,
    "truthfulqa": 50.06,
    "winogrande": 78.06,
    "gsm8k": 28.66,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "5ba23522319a51d0af23b336a6a83c72ae3780e7",
    "model_name_for_query": "openaccess-ai-collective/jackalope-7b",
    "link": "https://huggingface.co/openaccess-ai-collective/jackalope-7b",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\u2b55",
    "model": "mistral-7b-ft-h4-no_robots_instructions",
    "average": 61.16,
    "arc": 60.92,
    "hellaswag": 83.17,
    "mmlu": 63.37,
    "truthfulqa": 43.63,
    "winogrande": 78.85,
    "gsm8k": 37.0,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "785446da9a53ceae48795069bf7ccaf46a91a5ba",
    "model_name_for_query": "mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "link": "https://huggingface.co/mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "author": "mrm8488"
  },
  {
    "T": "\u2b55",
    "model": "mistral-7b-ft-h4-no_robots_instructions",
    "average": 61.16,
    "arc": 60.92,
    "hellaswag": 83.24,
    "mmlu": 63.74,
    "truthfulqa": 43.64,
    "winogrande": 78.69,
    "gsm8k": 36.69,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "785446da9a53ceae48795069bf7ccaf46a91a5ba",
    "model_name_for_query": "mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "link": "https://huggingface.co/mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "author": "mrm8488"
  },
  {
    "T": "\u2b55",
    "model": "PlatYi-34B-Llama-Q-v3",
    "average": 61.15,
    "arc": 64.33,
    "hellaswag": 84.88,
    "mmlu": 74.98,
    "truthfulqa": 51.8,
    "winogrande": 84.21,
    "gsm8k": 6.67,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 34.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2d04b9e3a6c86a718c33e0686c0b5f4e46feb364",
    "model_name_for_query": "kyujinpy/PlatYi-34B-Llama-Q-v3",
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q-v3",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-2.0",
    "average": 61.14,
    "arc": 66.81,
    "hellaswag": 86.66,
    "mmlu": 63.41,
    "truthfulqa": 49.17,
    "winogrande": 80.27,
    "gsm8k": 20.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ea4bdd0221f77de9b0343cd8291cbd0fd6033ca8",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "dolphin-2.1-mistral-7b",
    "average": 61.12,
    "arc": 64.42,
    "hellaswag": 84.92,
    "mmlu": 63.32,
    "truthfulqa": 55.56,
    "winogrande": 77.74,
    "gsm8k": 20.77,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 54.0,
    "still_on_hub": true,
    "revision": "aa5bd48c8b3040d1155a8fd59328df160aa63680",
    "model_name_for_query": "ehartford/dolphin-2.1-mistral-7b",
    "link": "https://huggingface.co/ehartford/dolphin-2.1-mistral-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Kant-Test-0.1-Mistral-7B",
    "average": 61.1,
    "arc": 61.77,
    "hellaswag": 82.89,
    "mmlu": 62.86,
    "truthfulqa": 49.4,
    "winogrande": 78.53,
    "gsm8k": 31.16,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5989100fa82aaab0db2f8ed3e37a446126050ef9",
    "model_name_for_query": "Zardos/Kant-Test-0.1-Mistral-7B",
    "link": "https://huggingface.co/Zardos/Kant-Test-0.1-Mistral-7B",
    "author": "Zardos"
  },
  {
    "T": "?",
    "model": "Dans-07YahooAnswers-7b",
    "average": 61.07,
    "arc": 61.52,
    "hellaswag": 83.69,
    "mmlu": 63.52,
    "truthfulqa": 41.84,
    "winogrande": 78.53,
    "gsm8k": 37.3,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "a9d5e333dd7752b689b97bc7e0cfbd530536a06e",
    "model_name_for_query": "Dans-DiscountModels/Dans-07YahooAnswers-7b",
    "link": "https://huggingface.co/Dans-DiscountModels/Dans-07YahooAnswers-7b",
    "author": "Dans-DiscountModels"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolphin-2.1-mistral-7b",
    "average": 61.0,
    "arc": 63.99,
    "hellaswag": 85.0,
    "mmlu": 63.44,
    "truthfulqa": 55.57,
    "winogrande": 77.9,
    "gsm8k": 20.09,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 54.0,
    "still_on_hub": true,
    "revision": "aa5bd48c8b3040d1155a8fd59328df160aa63680",
    "model_name_for_query": "ehartford/dolphin-2.1-mistral-7b",
    "link": "https://huggingface.co/ehartford/dolphin-2.1-mistral-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Mistral-7B-v0.1",
    "average": 60.97,
    "arc": 59.98,
    "hellaswag": 83.31,
    "mmlu": 64.16,
    "truthfulqa": 42.15,
    "winogrande": 78.37,
    "gsm8k": 37.83,
    "model_type": "pretrained",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 1173.0,
    "still_on_hub": true,
    "revision": "e836d8f71b5812f9fee65618453dc537c66bd82a",
    "model_name_for_query": "mistralai/Mistral-7B-v0.1",
    "link": "https://huggingface.co/mistralai/Mistral-7B-v0.1",
    "author": "mistralai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-30b-instruct-2048",
    "average": 60.91,
    "arc": 64.93,
    "hellaswag": 84.94,
    "mmlu": 61.9,
    "truthfulqa": 56.3,
    "winogrande": 79.56,
    "gsm8k": 17.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 102.0,
    "still_on_hub": true,
    "revision": "be44a37814a20e790063086703f570732597887a",
    "model_name_for_query": "upstage/llama-30b-instruct-2048",
    "link": "https://huggingface.co/upstage/llama-30b-instruct-2048",
    "author": "upstage"
  },
  {
    "T": "\ud83d\udd36",
    "model": "alpaca-lora-65b-en-pt-es-ca",
    "average": 60.89,
    "arc": 65.02,
    "hellaswag": 84.88,
    "mmlu": 62.19,
    "truthfulqa": 46.06,
    "winogrande": 80.51,
    "gsm8k": 26.69,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 65.0,
    "likes": 2.0,
    "still_on_hub": false,
    "revision": "aa5bd88bd132925cf2dd5c44eceafdb5ed5e5be4",
    "model_name_for_query": "HiTZ/alpaca-lora-65b-en-pt-es-ca",
    "link": "https://huggingface.co/HiTZ/alpaca-lora-65b-en-pt-es-ca",
    "author": "HiTZ"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SlimOpenOrca-Mistral-7B",
    "average": 60.84,
    "arc": 62.97,
    "hellaswag": 83.49,
    "mmlu": 62.3,
    "truthfulqa": 57.39,
    "winogrande": 77.43,
    "gsm8k": 21.46,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b0134a7512444dfbb60a2e2d81469a5bbbb18026",
    "model_name_for_query": "Weyaxi/SlimOpenOrca-Mistral-7B",
    "link": "https://huggingface.co/Weyaxi/SlimOpenOrca-Mistral-7B",
    "author": "Weyaxi"
  },
  {
    "T": "?",
    "model": "30B-Epsilon",
    "average": 60.8,
    "arc": 63.05,
    "hellaswag": 83.59,
    "mmlu": 56.89,
    "truthfulqa": 59.03,
    "winogrande": 77.66,
    "gsm8k": 24.56,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "6962638c2b0368ad496af6e20e46e3de97a7772b",
    "model_name_for_query": "CalderaAI/30B-Epsilon",
    "link": "https://huggingface.co/CalderaAI/30B-Epsilon",
    "author": "CalderaAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "average": 60.79,
    "arc": 64.33,
    "hellaswag": 84.4,
    "mmlu": 63.72,
    "truthfulqa": 52.52,
    "winogrande": 78.37,
    "gsm8k": 21.38,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.24,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "d4039b40e842df7f6b8de50532444c8944ea5791",
    "model_name_for_query": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "link": "https://huggingface.co/uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-m2.0",
    "average": 60.79,
    "arc": 65.02,
    "hellaswag": 86.35,
    "mmlu": 64.37,
    "truthfulqa": 46.66,
    "winogrande": 80.19,
    "gsm8k": 22.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fa081d52619b35d7016fb40ce855187d6a8e7e4c",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama-30b-v7.1-bf16",
    "average": 60.76,
    "arc": 62.37,
    "hellaswag": 82.29,
    "mmlu": 58.18,
    "truthfulqa": 52.6,
    "winogrande": 77.51,
    "gsm8k": 31.61,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.35,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "85f7ad9d6ff016312262a47d45ffd07dee54aab0",
    "model_name_for_query": "OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "link": "https://huggingface.co/OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "author": "OpenBuddyEA"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-mistral-six-in-one-7b",
    "average": 60.76,
    "arc": 62.97,
    "hellaswag": 84.6,
    "mmlu": 63.29,
    "truthfulqa": 57.77,
    "winogrande": 77.51,
    "gsm8k": 18.42,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "41e912e0f79094a80687f88ca5555f84aa9d307f",
    "model_name_for_query": "uukuguy/speechless-mistral-six-in-one-7b",
    "link": "https://huggingface.co/uukuguy/speechless-mistral-six-in-one-7b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT4-X-Alpasta-30b",
    "average": 60.76,
    "arc": 63.05,
    "hellaswag": 83.56,
    "mmlu": 57.71,
    "truthfulqa": 51.52,
    "winogrande": 78.22,
    "gsm8k": 30.48,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 64.0,
    "still_on_hub": true,
    "revision": "1a0d1d72a40946463fb4a9780207da19bfecc38b",
    "model_name_for_query": "MetaIX/GPT4-X-Alpasta-30b",
    "link": "https://huggingface.co/MetaIX/GPT4-X-Alpasta-30b",
    "author": "MetaIX"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "oasst-rlhf-2-llama-30b-7k-steps-hf",
    "average": 60.74,
    "arc": 61.35,
    "hellaswag": 83.8,
    "mmlu": 57.89,
    "truthfulqa": 51.18,
    "winogrande": 78.77,
    "gsm8k": 31.46,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "e04207847429af03c4780f5ac85c726536217981",
    "model_name_for_query": "Yhyu13/oasst-rlhf-2-llama-30b-7k-steps-hf",
    "link": "https://huggingface.co/Yhyu13/oasst-rlhf-2-llama-30b-7k-steps-hf",
    "author": "Yhyu13"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Venomia-m7",
    "average": 60.74,
    "arc": 63.14,
    "hellaswag": 84.0,
    "mmlu": 60.06,
    "truthfulqa": 49.08,
    "winogrande": 75.77,
    "gsm8k": 32.37,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "46d997c522776af0236b254bd4c5f071b39a06a0",
    "model_name_for_query": "Sao10K/Venomia-m7",
    "link": "https://huggingface.co/Sao10K/Venomia-m7",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama-30b-v7.1-bf16",
    "average": 60.71,
    "arc": 62.46,
    "hellaswag": 82.3,
    "mmlu": 58.15,
    "truthfulqa": 52.57,
    "winogrande": 77.82,
    "gsm8k": 30.93,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 32.35,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "85f7ad9d6ff016312262a47d45ffd07dee54aab0",
    "model_name_for_query": "OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "link": "https://huggingface.co/OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "author": "OpenBuddyEA"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-m2.0",
    "average": 60.68,
    "arc": 65.1,
    "hellaswag": 86.34,
    "mmlu": 64.32,
    "truthfulqa": 46.63,
    "winogrande": 80.11,
    "gsm8k": 21.61,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fa081d52619b35d7016fb40ce855187d6a8e7e4c",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-1.4-peft",
    "average": 60.67,
    "arc": 65.78,
    "hellaswag": 85.83,
    "mmlu": 62.27,
    "truthfulqa": 52.45,
    "winogrande": 79.64,
    "gsm8k": 18.04,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 65.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "85ae3b595c6b8415df87000c22bc14ea18c174f5",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-1.4-peft",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.4-peft",
    "author": "jondurbin"
  },
  {
    "T": "?",
    "model": "airoboros-65b-gpt4-1.4",
    "average": 60.67,
    "arc": 65.78,
    "hellaswag": 85.83,
    "mmlu": 62.27,
    "truthfulqa": 52.45,
    "winogrande": 79.64,
    "gsm8k": 18.04,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "ae256799615c16443f9c423c653ed9f60577e99e",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-1.4",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.4",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Zephyrus-L1-33B",
    "average": 60.61,
    "arc": 64.51,
    "hellaswag": 84.15,
    "mmlu": 57.37,
    "truthfulqa": 53.87,
    "winogrande": 80.19,
    "gsm8k": 23.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.53,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "679aae34440d576456b283070371b2a15dbb948b",
    "model_name_for_query": "Sao10K/Zephyrus-L1-33B",
    "link": "https://huggingface.co/Sao10K/Zephyrus-L1-33B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-1.4",
    "average": 60.59,
    "arc": 65.53,
    "hellaswag": 85.77,
    "mmlu": 61.95,
    "truthfulqa": 52.43,
    "winogrande": 79.79,
    "gsm8k": 18.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "ae256799615c16443f9c423c653ed9f60577e99e",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-1.4",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.4",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "Synatra-7B-v0.3-dpo",
    "average": 60.55,
    "arc": 62.8,
    "hellaswag": 82.58,
    "mmlu": 61.46,
    "truthfulqa": 56.46,
    "winogrande": 76.24,
    "gsm8k": 23.73,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 7.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "405a4f1e6513cd1b8de5eb4e003bb49cc86d1f8a",
    "model_name_for_query": "maywell/Synatra-7B-v0.3-dpo",
    "link": "https://huggingface.co/maywell/Synatra-7B-v0.3-dpo",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolphin-2.2.1-mistral-7b",
    "average": 60.54,
    "arc": 63.48,
    "hellaswag": 83.86,
    "mmlu": 63.28,
    "truthfulqa": 53.17,
    "winogrande": 78.37,
    "gsm8k": 21.08,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 84.0,
    "still_on_hub": true,
    "revision": "001b48e9aebffb395c698af47b6b48364cc3cbe8",
    "model_name_for_query": "ehartford/dolphin-2.2.1-mistral-7b",
    "link": "https://huggingface.co/ehartford/dolphin-2.2.1-mistral-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-11B-TestBench9",
    "average": 60.52,
    "arc": 64.08,
    "hellaswag": 84.24,
    "mmlu": 64.0,
    "truthfulqa": 56.19,
    "winogrande": 78.45,
    "gsm8k": 16.15,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4ff48527af8c3907129c06160c7f7b7b786a5a79",
    "model_name_for_query": "Undi95/Mistral-11B-TestBench9",
    "link": "https://huggingface.co/Undi95/Mistral-11B-TestBench9",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-70B-V1.0-GPTQ",
    "average": 60.5,
    "arc": 63.82,
    "hellaswag": 83.85,
    "mmlu": 63.68,
    "truthfulqa": 54.54,
    "winogrande": 78.61,
    "gsm8k": 18.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "llama2",
    "params": 72.82,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "c234d7c9c0fd26efb55757fdbfb604d549539fe0",
    "model_name_for_query": "TheBloke/WizardLM-70B-V1.0-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-70B-V1.0-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dolphin2.1-OpenOrca-7B",
    "average": 60.47,
    "arc": 63.91,
    "hellaswag": 84.26,
    "mmlu": 62.66,
    "truthfulqa": 53.84,
    "winogrande": 78.22,
    "gsm8k": 19.94,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "076c0f7de93307e8fb3ad3bd820fb5f73325ca70",
    "model_name_for_query": "Weyaxi/Dolphin2.1-OpenOrca-7B",
    "link": "https://huggingface.co/Weyaxi/Dolphin2.1-OpenOrca-7B",
    "author": "Weyaxi"
  },
  {
    "T": "?",
    "model": "oasst-sft-6-llama-33b-xor-MERGED-16bit",
    "average": 60.45,
    "arc": 61.52,
    "hellaswag": 83.5,
    "mmlu": 57.43,
    "truthfulqa": 50.7,
    "winogrande": 79.08,
    "gsm8k": 30.48,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "62f92ddab8b37eaeda15cf5ecb5605141a0525eb",
    "model_name_for_query": "TehVenom/oasst-sft-6-llama-33b-xor-MERGED-16bit",
    "link": "https://huggingface.co/TehVenom/oasst-sft-6-llama-33b-xor-MERGED-16bit",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT4-x-AlpacaDente-30b",
    "average": 60.43,
    "arc": 62.12,
    "hellaswag": 82.78,
    "mmlu": 56.19,
    "truthfulqa": 52.68,
    "winogrande": 78.69,
    "gsm8k": 30.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "ee76c821f861f0ab0276f9f429dd06565f1f2051",
    "model_name_for_query": "Aeala/GPT4-x-AlpacaDente-30b",
    "link": "https://huggingface.co/Aeala/GPT4-x-AlpacaDente-30b",
    "author": "Aeala"
  },
  {
    "T": "\u2b55",
    "model": "WizardMath-70B-V1.0",
    "average": 60.42,
    "arc": 68.17,
    "hellaswag": 86.49,
    "mmlu": 68.89,
    "truthfulqa": 52.69,
    "winogrande": 82.32,
    "gsm8k": 3.94,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 68.72,
    "likes": 95.0,
    "still_on_hub": true,
    "revision": "e85b43e53c5379e35393b970c66d76c2d1060381",
    "model_name_for_query": "WizardLM/WizardMath-70B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardMath-70B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\u2b55",
    "model": "WizardMath-70B-V1.0",
    "average": 60.41,
    "arc": 67.92,
    "hellaswag": 86.46,
    "mmlu": 68.92,
    "truthfulqa": 52.77,
    "winogrande": 82.32,
    "gsm8k": 4.09,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 68.72,
    "likes": 95.0,
    "still_on_hub": true,
    "revision": "e85b43e53c5379e35393b970c66d76c2d1060381",
    "model_name_for_query": "WizardLM/WizardMath-70B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardMath-70B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SlimOrca-13B",
    "average": 60.39,
    "arc": 60.15,
    "hellaswag": 81.4,
    "mmlu": 57.04,
    "truthfulqa": 49.37,
    "winogrande": 74.43,
    "gsm8k": 39.95,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 13.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "75427e93dc99a5e1d8b9aefa106ad36fc750b744",
    "model_name_for_query": "ajibawa-2023/SlimOrca-13B",
    "link": "https://huggingface.co/ajibawa-2023/SlimOrca-13B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-mistral-7b-dare-0.85",
    "average": 60.39,
    "arc": 63.31,
    "hellaswag": 84.93,
    "mmlu": 64.22,
    "truthfulqa": 50.68,
    "winogrande": 79.32,
    "gsm8k": 19.86,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5eefd1b560cd65aec2f689880476f909b46d306c",
    "model_name_for_query": "speechlessai/speechless-mistral-7b-dare-0.85",
    "link": "https://huggingface.co/speechlessai/speechless-mistral-7b-dare-0.85",
    "author": "speechlessai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dolphin2.1-OpenOrca-7B",
    "average": 60.38,
    "arc": 64.16,
    "hellaswag": 84.25,
    "mmlu": 62.7,
    "truthfulqa": 53.83,
    "winogrande": 77.66,
    "gsm8k": 19.71,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "076c0f7de93307e8fb3ad3bd820fb5f73325ca70",
    "model_name_for_query": "Weyaxi/Dolphin2.1-OpenOrca-7B",
    "link": "https://huggingface.co/Weyaxi/Dolphin2.1-OpenOrca-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-SlimOrca",
    "average": 60.37,
    "arc": 62.54,
    "hellaswag": 83.86,
    "mmlu": 62.77,
    "truthfulqa": 54.23,
    "winogrande": 77.43,
    "gsm8k": 21.38,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "a9744d8cf9ce4230678a891bcf8bba7cbc0aaece",
    "model_name_for_query": "Open-Orca/Mistral-7B-SlimOrca",
    "link": "https://huggingface.co/Open-Orca/Mistral-7B-SlimOrca",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_3.5",
    "average": 60.26,
    "arc": 62.46,
    "hellaswag": 83.96,
    "mmlu": 62.89,
    "truthfulqa": 45.43,
    "winogrande": 81.06,
    "gsm8k": 25.78,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "4bit",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 535.0,
    "still_on_hub": true,
    "revision": "5b874a33a91d63023055e6cb2d5d86afe883b4ec",
    "model_name_for_query": "openchat/openchat_3.5",
    "link": "https://huggingface.co/openchat/openchat_3.5",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SlimOpenOrca-Mistral-7B-v2",
    "average": 60.25,
    "arc": 62.88,
    "hellaswag": 83.41,
    "mmlu": 62.05,
    "truthfulqa": 56.65,
    "winogrande": 77.58,
    "gsm8k": 18.95,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7cd030ccdb169c2685fe028bb4380b91ad74920f",
    "model_name_for_query": "PulsarAI/SlimOpenOrca-Mistral-7B-v2",
    "link": "https://huggingface.co/PulsarAI/SlimOpenOrca-Mistral-7B-v2",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-11B-TestBench11",
    "average": 60.25,
    "arc": 64.42,
    "hellaswag": 83.93,
    "mmlu": 63.82,
    "truthfulqa": 56.68,
    "winogrande": 77.74,
    "gsm8k": 14.94,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "9aae2b156b24557bb98e515f3a90c7865529d2e9",
    "model_name_for_query": "Undi95/Mistral-11B-TestBench11",
    "link": "https://huggingface.co/Undi95/Mistral-11B-TestBench11",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wendigo-14b-alpha4",
    "average": 60.25,
    "arc": 59.3,
    "hellaswag": 79.65,
    "mmlu": 59.85,
    "truthfulqa": 54.98,
    "winogrande": 74.74,
    "gsm8k": 32.98,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 14.22,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ea3ecf4418cf3655cf5093a8feb045b47b92c331",
    "model_name_for_query": "MisterRid/wendigo-14b-alpha4",
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha4",
    "author": "MisterRid"
  },
  {
    "T": "\u2b55",
    "model": "smartyplats-7b-v2",
    "average": 60.24,
    "arc": 57.94,
    "hellaswag": 80.76,
    "mmlu": 58.16,
    "truthfulqa": 50.26,
    "winogrande": 75.53,
    "gsm8k": 38.82,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "99049eb184b9b3ef074043d6e626fe3db09f5a19",
    "model_name_for_query": "vihangd/smartyplats-7b-v2",
    "link": "https://huggingface.co/vihangd/smartyplats-7b-v2",
    "author": "vihangd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPlatty-30B",
    "average": 60.23,
    "arc": 65.78,
    "hellaswag": 84.79,
    "mmlu": 63.49,
    "truthfulqa": 52.45,
    "winogrande": 80.98,
    "gsm8k": 13.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "836cf4dcd60ebe2ff09415c72f809d94639e8d35",
    "model_name_for_query": "lilloukas/GPlatty-30B",
    "link": "https://huggingface.co/lilloukas/GPlatty-30B",
    "author": "lilloukas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "notus-7b-v1",
    "average": 60.22,
    "arc": 64.59,
    "hellaswag": 84.78,
    "mmlu": 63.03,
    "truthfulqa": 54.37,
    "winogrande": 79.4,
    "gsm8k": 15.16,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "89f594b32aea9bf5de0abe3877f20ff302549934",
    "model_name_for_query": "argilla/notus-7b-v1",
    "link": "https://huggingface.co/argilla/notus-7b-v1",
    "author": "argilla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-OpenOrca",
    "average": 60.17,
    "arc": 64.08,
    "hellaswag": 83.99,
    "mmlu": 62.24,
    "truthfulqa": 53.05,
    "winogrande": 77.74,
    "gsm8k": 19.94,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 314.0,
    "still_on_hub": true,
    "revision": "7233ac83317946d05c474b71cc1379f49eb74c14",
    "model_name_for_query": "Open-Orca/Mistral-7B-OpenOrca",
    "link": "https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-65b-gpt4-1.3",
    "average": 60.15,
    "arc": 66.13,
    "hellaswag": 85.99,
    "mmlu": 63.89,
    "truthfulqa": 51.32,
    "winogrande": 79.95,
    "gsm8k": 13.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 65.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4373e66135c6fb4a6063777c4270a34509e7e932",
    "model_name_for_query": "jondurbin/airoboros-65b-gpt4-1.3",
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.3",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wendigo-14b-alpha3",
    "average": 60.1,
    "arc": 59.39,
    "hellaswag": 79.51,
    "mmlu": 59.72,
    "truthfulqa": 55.12,
    "winogrande": 74.74,
    "gsm8k": 32.15,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 14.22,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "01c9ec549ddc830eaa6639e7e89b6337c51586e3",
    "model_name_for_query": "MisterRid/wendigo-14b-alpha3",
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha3",
    "author": "MisterRid"
  },
  {
    "T": "\u2b55",
    "model": "CollectiveCognition-v1-Mistral-7B",
    "average": 60.1,
    "arc": 62.37,
    "hellaswag": 85.5,
    "mmlu": 62.76,
    "truthfulqa": 54.48,
    "winogrande": 77.58,
    "gsm8k": 17.89,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "58777f0563610fa770c4fa252c0350de71d4ab9d",
    "model_name_for_query": "teknium/CollectiveCognition-v1-Mistral-7B",
    "link": "https://huggingface.co/teknium/CollectiveCognition-v1-Mistral-7B",
    "author": "teknium"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ccy0-2g7e-wqsa-0",
    "average": 60.07,
    "arc": 58.19,
    "hellaswag": 82.19,
    "mmlu": 59.59,
    "truthfulqa": 49.99,
    "winogrande": 78.22,
    "gsm8k": 32.22,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1cd1158f3104fa8ed8469e2b09d674b997e229b4",
    "model_name_for_query": "abhishek/ccy0-2g7e-wqsa-0",
    "link": "https://huggingface.co/abhishek/ccy0-2g7e-wqsa-0",
    "author": "abhishek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-30b-2048-instruct-PL-lora_unload",
    "average": 60.03,
    "arc": 63.82,
    "hellaswag": 84.7,
    "mmlu": 61.49,
    "truthfulqa": 52.49,
    "winogrande": 79.79,
    "gsm8k": 17.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b15f4310ea37fef99e4f16372a4b1f2342e27613",
    "model_name_for_query": "Aspik101/llama-30b-2048-instruct-PL-lora_unload",
    "link": "https://huggingface.co/Aspik101/llama-30b-2048-instruct-PL-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\u2b55",
    "model": "Metis-0.1",
    "average": 60.02,
    "arc": 60.15,
    "hellaswag": 82.85,
    "mmlu": 61.42,
    "truthfulqa": 45.24,
    "winogrande": 77.27,
    "gsm8k": 33.21,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ead51068b4208b37c37733109570b445d086551e",
    "model_name_for_query": "Mihaiii/Metis-0.1",
    "link": "https://huggingface.co/Mihaiii/Metis-0.1",
    "author": "Mihaiii"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Velara",
    "average": 60.01,
    "arc": 58.96,
    "hellaswag": 82.83,
    "mmlu": 59.45,
    "truthfulqa": 44.7,
    "winogrande": 73.8,
    "gsm8k": 40.33,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-nd-4.0",
    "params": 11.39,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0fad8e711563d3a5a4631500d6a1d6b87f10d396",
    "model_name_for_query": "Delcos/Velara",
    "link": "https://huggingface.co/Delcos/Velara",
    "author": "Delcos"
  },
  {
    "T": "?",
    "model": "WizardLM-33B-V1.0-Uncensored",
    "average": 59.99,
    "arc": 63.65,
    "hellaswag": 83.84,
    "mmlu": 59.36,
    "truthfulqa": 56.8,
    "winogrande": 77.66,
    "gsm8k": 18.65,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 44.0,
    "still_on_hub": true,
    "revision": "3eca9fdee0ce28d6a4a635a6f19d9a413caee3e7",
    "model_name_for_query": "ehartford/WizardLM-33B-V1.0-Uncensored",
    "link": "https://huggingface.co/ehartford/WizardLM-33B-V1.0-Uncensored",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "psyonic-cetacean-20B",
    "average": 59.97,
    "arc": 63.57,
    "hellaswag": 86.2,
    "mmlu": 59.66,
    "truthfulqa": 57.55,
    "winogrande": 78.14,
    "gsm8k": 14.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 19.99,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "298d2086a949d53af06096d229f64f4719261698",
    "model_name_for_query": "jebcarter/psyonic-cetacean-20B",
    "link": "https://huggingface.co/jebcarter/psyonic-cetacean-20B",
    "author": "jebcarter"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-1",
    "average": 59.9,
    "arc": 64.25,
    "hellaswag": 82.49,
    "mmlu": 60.79,
    "truthfulqa": 56.4,
    "winogrande": 77.35,
    "gsm8k": 18.12,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "4bit",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "3995e9a13d54ce95f0ad55de2eaa92e2dc580174",
    "model_name_for_query": "Intel/neural-chat-7b-v3-1",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "author": "Intel"
  },
  {
    "T": "\u2b55",
    "model": "samantha-1.2-mistral-7b",
    "average": 59.83,
    "arc": 64.08,
    "hellaswag": 85.08,
    "mmlu": 63.91,
    "truthfulqa": 50.4,
    "winogrande": 78.53,
    "gsm8k": 16.98,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "5574a021f55a446a756dcbc776f1765aefc280a1",
    "model_name_for_query": "ehartford/samantha-1.2-mistral-7b",
    "link": "https://huggingface.co/ehartford/samantha-1.2-mistral-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-30b-instruct-2048-PL-lora",
    "average": 59.82,
    "arc": 63.31,
    "hellaswag": 84.66,
    "mmlu": 61.66,
    "truthfulqa": 53.35,
    "winogrande": 79.08,
    "gsm8k": 16.83,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1a076bce564f03bd47951eecab628c541fb1a6ad",
    "model_name_for_query": "Aspik101/llama-30b-instruct-2048-PL-lora",
    "link": "https://huggingface.co/Aspik101/llama-30b-instruct-2048-PL-lora",
    "author": "Aspik101"
  },
  {
    "T": "\u2b55",
    "model": "WizardMath-70B-V1.0",
    "average": 59.81,
    "arc": 67.49,
    "hellaswag": 86.03,
    "mmlu": 68.44,
    "truthfulqa": 52.23,
    "winogrande": 81.77,
    "gsm8k": 2.88,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "llama2",
    "params": 68.72,
    "likes": 95.0,
    "still_on_hub": true,
    "revision": "97e5913edd2c593c3eef12070024674e7ee4e16c",
    "model_name_for_query": "WizardLM/WizardMath-70B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardMath-70B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mistral-7b-sft-beta",
    "average": 59.78,
    "arc": 57.42,
    "hellaswag": 82.23,
    "mmlu": 61.42,
    "truthfulqa": 43.58,
    "winogrande": 77.58,
    "gsm8k": 36.47,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.0,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "c985a04e76fb00d3c3f65214d0b02c5a751d2274",
    "model_name_for_query": "HuggingFaceH4/mistral-7b-sft-beta",
    "link": "https://huggingface.co/HuggingFaceH4/mistral-7b-sft-beta",
    "author": "HuggingFaceH4"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-70B-chat-GPTQ",
    "average": 59.75,
    "arc": 62.63,
    "hellaswag": 84.81,
    "mmlu": 62.74,
    "truthfulqa": 50.98,
    "winogrande": 78.69,
    "gsm8k": 18.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "llama2",
    "params": 72.82,
    "likes": 204.0,
    "still_on_hub": true,
    "revision": "054fbf6f65e7ab7691ec07ec9ad366acf2dd90bf",
    "model_name_for_query": "TheBloke/Llama-2-70B-chat-GPTQ",
    "link": "https://huggingface.co/TheBloke/Llama-2-70B-chat-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "Synatra-RP-Orca-2-7b-v0.1",
    "average": 59.65,
    "arc": 57.68,
    "hellaswag": 77.37,
    "mmlu": 56.1,
    "truthfulqa": 52.52,
    "winogrande": 74.59,
    "gsm8k": 39.65,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.74,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "da80bc823c407c28c464cc0547a8ed9e0ca82f79",
    "model_name_for_query": "maywell/Synatra-RP-Orca-2-7b-v0.1",
    "link": "https://huggingface.co/maywell/Synatra-RP-Orca-2-7b-v0.1",
    "author": "maywell"
  },
  {
    "T": "\u2b55",
    "model": "Orca-2-13B-no_robots",
    "average": 59.63,
    "arc": 59.13,
    "hellaswag": 79.57,
    "mmlu": 60.28,
    "truthfulqa": 51.17,
    "winogrande": 80.35,
    "gsm8k": 27.29,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "6f32722f7d24501036698cbca9c7a3e2336f071f",
    "model_name_for_query": "Locutusque/Orca-2-13B-no_robots",
    "link": "https://huggingface.co/Locutusque/Orca-2-13B-no_robots",
    "author": "Locutusque"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Yarn-Mistral-7b-64k",
    "average": 59.63,
    "arc": 59.9,
    "hellaswag": 82.51,
    "mmlu": 62.96,
    "truthfulqa": 41.86,
    "winogrande": 77.27,
    "gsm8k": 33.28,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "0273c624561fcecc8e8f4030492a9307aa60f945",
    "model_name_for_query": "NousResearch/Yarn-Mistral-7b-64k",
    "link": "https://huggingface.co/NousResearch/Yarn-Mistral-7b-64k",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SynthIA-7B-v1.5",
    "average": 59.59,
    "arc": 62.71,
    "hellaswag": 83.37,
    "mmlu": 63.48,
    "truthfulqa": 51.32,
    "winogrande": 79.24,
    "gsm8k": 17.44,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5a9912ef90a0efc1aaea327e5cf3e9554c8bd897",
    "model_name_for_query": "migtissera/SynthIA-7B-v1.5",
    "link": "https://huggingface.co/migtissera/SynthIA-7B-v1.5",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "internlm-20b",
    "average": 59.55,
    "arc": 60.49,
    "hellaswag": 82.13,
    "mmlu": 61.85,
    "truthfulqa": 52.61,
    "winogrande": 76.72,
    "gsm8k": 23.5,
    "model_type": "pretrained",
    "architecture": "InternLMForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.0,
    "likes": 47.0,
    "still_on_hub": true,
    "revision": "b8825fe3394608fe84f0f5eb6471454384fb83aa",
    "model_name_for_query": "internlm/internlm-20b",
    "link": "https://huggingface.co/internlm/internlm-20b",
    "author": "internlm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chupacabra-v3",
    "average": 59.52,
    "arc": 66.21,
    "hellaswag": 81.29,
    "mmlu": 59.36,
    "truthfulqa": 57.85,
    "winogrande": 77.43,
    "gsm8k": 15.01,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "1dfa5e16d4be646b496d657d86554482ad48b3c9",
    "model_name_for_query": "perlthoughts/Chupacabra-v3",
    "link": "https://huggingface.co/perlthoughts/Chupacabra-v3",
    "author": "perlthoughts"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-30B-fp16",
    "average": 59.51,
    "arc": 62.54,
    "hellaswag": 83.28,
    "mmlu": 59.03,
    "truthfulqa": 52.49,
    "winogrande": 77.51,
    "gsm8k": 22.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "465f87a243969963f25ae6cf8f8d2de6c0898bbe",
    "model_name_for_query": "TheBloke/WizardLM-30B-fp16",
    "link": "https://huggingface.co/TheBloke/WizardLM-30B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "?",
    "model": "gpt4-alpaca-lora-30b-HF",
    "average": 59.51,
    "arc": 64.85,
    "hellaswag": 85.72,
    "mmlu": 58.51,
    "truthfulqa": 52.24,
    "winogrande": 80.19,
    "gsm8k": 15.54,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "3c8007467a081dc72ae09b9d358416b056b38920",
    "model_name_for_query": "TheBloke/gpt4-alpaca-lora-30b-HF",
    "link": "https://huggingface.co/TheBloke/gpt4-alpaca-lora-30b-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-7b-alpha",
    "average": 59.5,
    "arc": 61.01,
    "hellaswag": 84.04,
    "mmlu": 61.39,
    "truthfulqa": 57.9,
    "winogrande": 78.61,
    "gsm8k": 14.03,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.11,
    "likes": 377.0,
    "still_on_hub": true,
    "revision": "2cd2cd16a6ab22585d643cf264fac73b18e7852a",
    "model_name_for_query": "HuggingFaceH4/zephyr-7b-alpha",
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha",
    "author": "HuggingFaceH4"
  },
  {
    "T": "\ud83d\udd36",
    "model": "HelpSteer-filtered-7B",
    "average": 59.49,
    "arc": 59.56,
    "hellaswag": 83.32,
    "mmlu": 63.52,
    "truthfulqa": 41.11,
    "winogrande": 76.01,
    "gsm8k": 33.43,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0f14404caa1b4609bb2f50714df973223f443e40",
    "model_name_for_query": "Weyaxi/HelpSteer-filtered-7B",
    "link": "https://huggingface.co/Weyaxi/HelpSteer-filtered-7B",
    "author": "Weyaxi"
  },
  {
    "T": "?",
    "model": "WizardLM-30B-V1.0",
    "average": 59.45,
    "arc": 62.54,
    "hellaswag": 83.27,
    "mmlu": 59.05,
    "truthfulqa": 52.49,
    "winogrande": 77.51,
    "gsm8k": 21.83,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 32.32,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "75318440dba949804d6263d368e1f29a94ea7c5f",
    "model_name_for_query": "LLMs/WizardLM-30B-V1.0",
    "link": "https://huggingface.co/LLMs/WizardLM-30B-V1.0",
    "author": "LLMs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Yarn-Mistral-7b-128k",
    "average": 59.42,
    "arc": 59.64,
    "hellaswag": 82.5,
    "mmlu": 63.02,
    "truthfulqa": 41.78,
    "winogrande": 76.95,
    "gsm8k": 32.6,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 462.0,
    "still_on_hub": true,
    "revision": "d09f1f8ed437d61c1aff94c1beabee554843dcdd",
    "model_name_for_query": "NousResearch/Yarn-Mistral-7b-128k",
    "link": "https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-XS-v1.1",
    "average": 59.39,
    "arc": 63.91,
    "hellaswag": 84.06,
    "mmlu": 63.07,
    "truthfulqa": 49.92,
    "winogrande": 79.16,
    "gsm8k": 16.22,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e8850e534a3a9f602f72201b09c7ef8f879c1c0b",
    "model_name_for_query": "migtissera/Tess-XS-v1.1",
    "link": "https://huggingface.co/migtissera/Tess-XS-v1.1",
    "author": "migtissera"
  },
  {
    "T": "?",
    "model": "grendel",
    "average": 59.36,
    "arc": 60.49,
    "hellaswag": 79.99,
    "mmlu": 58.98,
    "truthfulqa": 52.68,
    "winogrande": 75.3,
    "gsm8k": 28.73,
    "model_type": "",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9444ef27ab9cc263745f9b24ffd7e2da60d2283c",
    "model_name_for_query": "openaccess-ai-collective/grendel",
    "link": "https://huggingface.co/openaccess-ai-collective/grendel",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenAssistant-SFT-7-Llama-30B-HF",
    "average": 59.34,
    "arc": 60.58,
    "hellaswag": 82.17,
    "mmlu": 57.93,
    "truthfulqa": 46.94,
    "winogrande": 78.61,
    "gsm8k": 29.8,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "a7a2306b9a63de2c545f35b24735f4540baf5903",
    "model_name_for_query": "TheBloke/OpenAssistant-SFT-7-Llama-30B-HF",
    "link": "https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SynthIA-7B-v1.3",
    "average": 59.34,
    "arc": 62.12,
    "hellaswag": 83.45,
    "mmlu": 62.65,
    "truthfulqa": 51.37,
    "winogrande": 78.85,
    "gsm8k": 17.59,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 115.0,
    "still_on_hub": true,
    "revision": "8e6d0b18be876e0ebfff47d6c4f33d776f189971",
    "model_name_for_query": "migtissera/SynthIA-7B-v1.3",
    "link": "https://huggingface.co/migtissera/SynthIA-7B-v1.3",
    "author": "migtissera"
  },
  {
    "T": "?",
    "model": "fin-llama-33b-merged",
    "average": 59.33,
    "arc": 65.02,
    "hellaswag": 86.2,
    "mmlu": 58.73,
    "truthfulqa": 49.75,
    "winogrande": 80.03,
    "gsm8k": 16.22,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl",
    "params": 32.32,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "17114520801da7b9599fe7a9fdf238915713a59b",
    "model_name_for_query": "bavest/fin-llama-33b-merged",
    "link": "https://huggingface.co/bavest/fin-llama-33b-merged",
    "author": "bavest"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MysticFusion-13B",
    "average": 59.31,
    "arc": 61.35,
    "hellaswag": 84.43,
    "mmlu": 57.29,
    "truthfulqa": 51.98,
    "winogrande": 76.01,
    "gsm8k": 24.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "02255943c6eff59ef6bd17e1a43a37ce3751ff5e",
    "model_name_for_query": "Walmart-the-bag/MysticFusion-13B",
    "link": "https://huggingface.co/Walmart-the-bag/MysticFusion-13B",
    "author": "Walmart-the-bag"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SuperPlatty-30B",
    "average": 59.3,
    "arc": 65.78,
    "hellaswag": 83.95,
    "mmlu": 62.57,
    "truthfulqa": 53.52,
    "winogrande": 80.35,
    "gsm8k": 9.63,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "017e1c32bca060107337dbf26db2044a7caa56f2",
    "model_name_for_query": "ariellee/SuperPlatty-30B",
    "link": "https://huggingface.co/ariellee/SuperPlatty-30B",
    "author": "ariellee"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-claude-instruct",
    "average": 59.27,
    "arc": 63.23,
    "hellaswag": 84.99,
    "mmlu": 63.84,
    "truthfulqa": 47.47,
    "winogrande": 78.14,
    "gsm8k": 17.97,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "faff0de73681ad1f0500169ae18d7a5ff424eb7f",
    "model_name_for_query": "Norquinal/Mistral-7B-claude-instruct",
    "link": "https://huggingface.co/Norquinal/Mistral-7B-claude-instruct",
    "author": "Norquinal"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Venomia-1.1-m7",
    "average": 59.27,
    "arc": 58.45,
    "hellaswag": 83.04,
    "mmlu": 56.39,
    "truthfulqa": 47.21,
    "winogrande": 74.43,
    "gsm8k": 36.09,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "00dd78ef6ee386c860f9136b9ef703a4c141e7f3",
    "model_name_for_query": "Sao10K/Venomia-1.1-m7",
    "link": "https://huggingface.co/Sao10K/Venomia-1.1-m7",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "zephyrnotus-11b-alpha",
    "average": 59.26,
    "arc": 61.35,
    "hellaswag": 82.8,
    "mmlu": 60.67,
    "truthfulqa": 57.22,
    "winogrande": 76.4,
    "gsm8k": 17.13,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a6f74e800b6c77261a1d212bb3e6b2752cbedef9",
    "model_name_for_query": "mergedlm/zephyrnotus-11b-alpha",
    "link": "https://huggingface.co/mergedlm/zephyrnotus-11b-alpha",
    "author": "mergedlm"
  },
  {
    "T": "\u2b55",
    "model": "Synatra-7B-v0.3-RP",
    "average": 59.26,
    "arc": 62.2,
    "hellaswag": 82.29,
    "mmlu": 60.8,
    "truthfulqa": 52.64,
    "winogrande": 76.48,
    "gsm8k": 21.15,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "372f6e0ab2c20b93e0c42218f76a71a4f9bb282e",
    "model_name_for_query": "maywell/Synatra-7B-v0.3-RP",
    "link": "https://huggingface.co/maywell/Synatra-7B-v0.3-RP",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-7b-beta",
    "average": 59.23,
    "arc": 62.03,
    "hellaswag": 84.36,
    "mmlu": 61.07,
    "truthfulqa": 57.45,
    "winogrande": 77.74,
    "gsm8k": 12.74,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.24,
    "likes": 784.0,
    "still_on_hub": true,
    "revision": "8af01af3d4f9dc9b962447180d6d0f8c5315da86",
    "model_name_for_query": "HuggingFaceH4/zephyr-7b-beta",
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "author": "HuggingFaceH4"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
    "average": 59.22,
    "arc": 61.52,
    "hellaswag": 84.06,
    "mmlu": 60.23,
    "truthfulqa": 51.05,
    "winogrande": 80.82,
    "gsm8k": 17.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1114ff08ed15ef417502da58f0237d2f6650c9ce",
    "model_name_for_query": "gaodrew/gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
    "link": "https://huggingface.co/gaodrew/gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
    "author": "gaodrew"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Qwen-7B",
    "average": 59.19,
    "arc": 51.37,
    "hellaswag": 78.47,
    "mmlu": 59.84,
    "truthfulqa": 47.79,
    "winogrande": 72.69,
    "gsm8k": 44.96,
    "model_type": "pretrained",
    "architecture": "QWenLMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 7.72,
    "likes": 288.0,
    "still_on_hub": true,
    "revision": "c9bdb955021a80ae26fa6978891996dbe4951d8d",
    "model_name_for_query": "Qwen/Qwen-7B",
    "link": "https://huggingface.co/Qwen/Qwen-7B",
    "author": "Qwen"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigostral-7b-chat",
    "average": 59.18,
    "arc": 62.63,
    "hellaswag": 84.34,
    "mmlu": 63.53,
    "truthfulqa": 49.24,
    "winogrande": 78.61,
    "gsm8k": 16.76,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "969fbfc7a91f53c8562a2c48a3c24dd3745d5a97",
    "model_name_for_query": "bofenghuang/vigostral-7b-chat",
    "link": "https://huggingface.co/bofenghuang/vigostral-7b-chat",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "PiVoT-0.1-Evil-a",
    "average": 59.16,
    "arc": 59.64,
    "hellaswag": 81.48,
    "mmlu": 58.94,
    "truthfulqa": 39.23,
    "winogrande": 75.3,
    "gsm8k": 40.41,
    "model_type": "RL-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b6e20287ba4156f06b4288d4003acc677040527f",
    "model_name_for_query": "maywell/PiVoT-0.1-Evil-a",
    "link": "https://huggingface.co/maywell/PiVoT-0.1-Evil-a",
    "author": "maywell"
  },
  {
    "T": "\u2b55",
    "model": "Karen_TheEditor_V2_STRICT_Mistral_7B",
    "average": 59.13,
    "arc": 59.56,
    "hellaswag": 81.79,
    "mmlu": 59.56,
    "truthfulqa": 49.36,
    "winogrande": 74.35,
    "gsm8k": 30.17,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "0935960b2765aa23d7a63c49873361b09dd12f60",
    "model_name_for_query": "FPHam/Karen_TheEditor_V2_STRICT_Mistral_7B",
    "link": "https://huggingface.co/FPHam/Karen_TheEditor_V2_STRICT_Mistral_7B",
    "author": "FPHam"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-v0.1-PeanutButter-v0.0.0-7B",
    "average": 59.09,
    "arc": 62.2,
    "hellaswag": 84.1,
    "mmlu": 64.14,
    "truthfulqa": 46.94,
    "winogrande": 78.69,
    "gsm8k": 18.5,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9609a969ba6429b84e538d96afac55eb133a9983",
    "model_name_for_query": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.0-7B",
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.0-7B",
    "author": "PeanutJar"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-7b-beta",
    "average": 59.08,
    "arc": 62.03,
    "hellaswag": 84.53,
    "mmlu": 61.06,
    "truthfulqa": 57.44,
    "winogrande": 78.06,
    "gsm8k": 11.37,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 784.0,
    "still_on_hub": true,
    "revision": "8af01af3d4f9dc9b962447180d6d0f8c5315da86",
    "model_name_for_query": "HuggingFaceH4/zephyr-7b-beta",
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "author": "HuggingFaceH4"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_3.5-16k",
    "average": 59.03,
    "arc": 63.31,
    "hellaswag": 83.58,
    "mmlu": 61.9,
    "truthfulqa": 43.47,
    "winogrande": 80.11,
    "gsm8k": 21.83,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "e8d66e7fb2ebb918f468137ea5fa3dc13ddc69da",
    "model_name_for_query": "NurtureAI/openchat_3.5-16k",
    "link": "https://huggingface.co/NurtureAI/openchat_3.5-16k",
    "author": "NurtureAI"
  },
  {
    "T": "\u2b55",
    "model": "Platypus-30B",
    "average": 59.03,
    "arc": 64.59,
    "hellaswag": 84.26,
    "mmlu": 64.23,
    "truthfulqa": 45.35,
    "winogrande": 81.37,
    "gsm8k": 14.4,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "c5d21054f8dd71099696bd7790df07ac54990f29",
    "model_name_for_query": "garage-bAInd/Platypus-30B",
    "link": "https://huggingface.co/garage-bAInd/Platypus-30B",
    "author": "garage-bAInd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Platypus-30B",
    "average": 59.03,
    "arc": 64.59,
    "hellaswag": 84.24,
    "mmlu": 64.19,
    "truthfulqa": 45.35,
    "winogrande": 81.37,
    "gsm8k": 14.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "979ad39b58a8e4a9419b7bc7a0dc8419f3912e71",
    "model_name_for_query": "lilloukas/Platypus-30B",
    "link": "https://huggingface.co/lilloukas/Platypus-30B",
    "author": "lilloukas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_v3_13B-GPTQ",
    "average": 59.01,
    "arc": 61.95,
    "hellaswag": 81.56,
    "mmlu": 56.1,
    "truthfulqa": 49.22,
    "winogrande": 75.77,
    "gsm8k": 29.49,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "other",
    "params": 16.23,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "7b7a2dcd946f393e26215268c4c7e0699be2bbd8",
    "model_name_for_query": "TheBloke/orca_mini_v3_13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/orca_mini_v3_13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "zephyr-alpha-Nebula-v2-7B",
    "average": 59.01,
    "arc": 58.62,
    "hellaswag": 83.05,
    "mmlu": 56.68,
    "truthfulqa": 58.28,
    "winogrande": 73.56,
    "gsm8k": 23.88,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e8f1fd1acceda7fb662340f5afe312a7ef030374",
    "model_name_for_query": "Weyaxi/zephyr-alpha-Nebula-v2-7B",
    "link": "https://huggingface.co/Weyaxi/zephyr-alpha-Nebula-v2-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wizard-mistral-v0.1",
    "average": 59.01,
    "arc": 61.77,
    "hellaswag": 83.51,
    "mmlu": 63.99,
    "truthfulqa": 47.46,
    "winogrande": 78.3,
    "gsm8k": 19.03,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b66724f8195e7b76289f8f3f72a98392557c46ad",
    "model_name_for_query": "unaidedelf87777/wizard-mistral-v0.1",
    "link": "https://huggingface.co/unaidedelf87777/wizard-mistral-v0.1",
    "author": "unaidedelf87777"
  },
  {
    "T": "?",
    "model": "samantha-1.1-llama-33b",
    "average": 58.98,
    "arc": 67.83,
    "hellaswag": 85.55,
    "mmlu": 58.79,
    "truthfulqa": 61.19,
    "winogrande": 76.48,
    "gsm8k": 4.02,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "ad8892a17be1372f611203a4cf71560cc337e458",
    "model_name_for_query": "ehartford/samantha-1.1-llama-33b",
    "link": "https://huggingface.co/ehartford/samantha-1.1-llama-33b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tess-XS-v1.0",
    "average": 58.95,
    "arc": 61.43,
    "hellaswag": 83.82,
    "mmlu": 64.1,
    "truthfulqa": 47.12,
    "winogrande": 78.93,
    "gsm8k": 18.27,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a581ab1793366ff2d5f3c966ff0e7b8b1149d775",
    "model_name_for_query": "migtissera/Tess-XS-v1.0",
    "link": "https://huggingface.co/migtissera/Tess-XS-v1.0",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chronoboros-33B",
    "average": 58.92,
    "arc": 63.91,
    "hellaswag": 85.0,
    "mmlu": 59.44,
    "truthfulqa": 49.83,
    "winogrande": 80.35,
    "gsm8k": 15.01,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "a4deca117c5fa48f2cdc49ed2e2596046201d688",
    "model_name_for_query": "Henk717/chronoboros-33B",
    "link": "https://huggingface.co/Henk717/chronoboros-33B",
    "author": "Henk717"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-v0.1-Open-Platypus",
    "average": 58.92,
    "arc": 62.37,
    "hellaswag": 85.08,
    "mmlu": 63.79,
    "truthfulqa": 47.33,
    "winogrande": 77.66,
    "gsm8k": 17.29,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "aa2c84e89c4c8a10e0569e45021b59e6d1c08bda",
    "model_name_for_query": "akjindal53244/Mistral-7B-v0.1-Open-Platypus",
    "link": "https://huggingface.co/akjindal53244/Mistral-7B-v0.1-Open-Platypus",
    "author": "akjindal53244"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-30b-instruct",
    "average": 58.91,
    "arc": 62.46,
    "hellaswag": 86.23,
    "mmlu": 59.37,
    "truthfulqa": 52.78,
    "winogrande": 80.51,
    "gsm8k": 12.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "fea4312379557e8a1e8073965f560798de369edd",
    "model_name_for_query": "upstage/llama-30b-instruct",
    "link": "https://huggingface.co/upstage/llama-30b-instruct",
    "author": "upstage"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-OpenOrca-1k",
    "average": 58.9,
    "arc": 62.97,
    "hellaswag": 84.66,
    "mmlu": 62.2,
    "truthfulqa": 52.96,
    "winogrande": 78.61,
    "gsm8k": 11.98,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.11,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "ae9e37811a54ffe45f41a572c7e68363aa11b062",
    "model_name_for_query": "mncai/Mistral-7B-OpenOrca-1k",
    "link": "https://huggingface.co/mncai/Mistral-7B-OpenOrca-1k",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "manticore-30b-chat-pyg-alpha",
    "average": 58.86,
    "arc": 64.16,
    "hellaswag": 84.38,
    "mmlu": 57.49,
    "truthfulqa": 51.57,
    "winogrande": 79.48,
    "gsm8k": 16.07,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.53,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "0cff8e9718e57202171003d556d2e6630061879d",
    "model_name_for_query": "openaccess-ai-collective/manticore-30b-chat-pyg-alpha",
    "link": "https://huggingface.co/openaccess-ai-collective/manticore-30b-chat-pyg-alpha",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-code-mistral-7b-v1.0",
    "average": 58.85,
    "arc": 60.58,
    "hellaswag": 83.75,
    "mmlu": 62.98,
    "truthfulqa": 47.9,
    "winogrande": 78.69,
    "gsm8k": 19.18,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "753852b8cb52dc5f0411568e98c0cb445a7835dc",
    "model_name_for_query": "uukuguy/speechless-code-mistral-7b-v1.0",
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-7b-v1.0",
    "author": "uukuguy"
  },
  {
    "T": "\u2b55",
    "model": "mistral_7b_norobots",
    "average": 58.85,
    "arc": 58.96,
    "hellaswag": 80.57,
    "mmlu": 57.66,
    "truthfulqa": 41.91,
    "winogrande": 75.61,
    "gsm8k": 38.36,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "36dde2c5b08140d612042d1ae047dd7551b7e15b",
    "model_name_for_query": "qblocks/mistral_7b_norobots",
    "link": "https://huggingface.co/qblocks/mistral_7b_norobots",
    "author": "qblocks"
  },
  {
    "T": "?",
    "model": "airochronos-33B",
    "average": 58.84,
    "arc": 64.42,
    "hellaswag": 85.21,
    "mmlu": 59.79,
    "truthfulqa": 50.59,
    "winogrande": 79.32,
    "gsm8k": 13.72,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.53,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "06843c6693cc265dabb464c818a3d3713239721a",
    "model_name_for_query": "Henk717/airochronos-33B",
    "link": "https://huggingface.co/Henk717/airochronos-33B",
    "author": "Henk717"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-11B-SynthIAirOmniMix",
    "average": 58.84,
    "arc": 62.46,
    "hellaswag": 83.13,
    "mmlu": 63.47,
    "truthfulqa": 55.69,
    "winogrande": 76.4,
    "gsm8k": 11.9,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "19694dc88e74a018d54bac6070cf521dff6d4397",
    "model_name_for_query": "NeverSleep/Mistral-11B-SynthIAirOmniMix",
    "link": "https://huggingface.co/NeverSleep/Mistral-11B-SynthIAirOmniMix",
    "author": "NeverSleep"
  },
  {
    "T": "\u2b55",
    "model": "Nebula-v2-7B",
    "average": 58.82,
    "arc": 58.7,
    "hellaswag": 83.06,
    "mmlu": 57.61,
    "truthfulqa": 46.72,
    "winogrande": 75.14,
    "gsm8k": 31.69,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d2a5611f7d7c37bfa2270d1823bceef01c0be383",
    "model_name_for_query": "PulsarAI/Nebula-v2-7B",
    "link": "https://huggingface.co/PulsarAI/Nebula-v2-7B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "scarlett-33b",
    "average": 58.81,
    "arc": 67.75,
    "hellaswag": 85.48,
    "mmlu": 58.98,
    "truthfulqa": 61.05,
    "winogrande": 76.8,
    "gsm8k": 2.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 32.32,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "305eea72fb9fe2ac5929a62483ea51f152bcc060",
    "model_name_for_query": "ajibawa-2023/scarlett-33b",
    "link": "https://huggingface.co/ajibawa-2023/scarlett-33b",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama-30b",
    "average": 58.77,
    "arc": 64.25,
    "hellaswag": 83.64,
    "mmlu": 58.23,
    "truthfulqa": 53.2,
    "winogrande": 77.43,
    "gsm8k": 15.85,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7f035eabd1d0e7b38ace395847a623f475d90da8",
    "model_name_for_query": "YeungNLP/firefly-llama-30b",
    "link": "https://huggingface.co/YeungNLP/firefly-llama-30b",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airochronos-33B",
    "average": 58.75,
    "arc": 64.25,
    "hellaswag": 85.2,
    "mmlu": 59.83,
    "truthfulqa": 50.56,
    "winogrande": 79.08,
    "gsm8k": 13.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 32.53,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "06843c6693cc265dabb464c818a3d3713239721a",
    "model_name_for_query": "Henk717/airochronos-33B",
    "link": "https://huggingface.co/Henk717/airochronos-33B",
    "author": "Henk717"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-m-7b-3.1.2",
    "average": 58.75,
    "arc": 61.86,
    "hellaswag": 83.51,
    "mmlu": 61.91,
    "truthfulqa": 53.75,
    "winogrande": 77.58,
    "gsm8k": 13.87,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "e9a7f0271fa442d65bf6be87feeb3f4de2f5760e",
    "model_name_for_query": "jondurbin/airoboros-m-7b-3.1.2",
    "link": "https://huggingface.co/jondurbin/airoboros-m-7b-3.1.2",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dromedary-65b-lora-HF",
    "average": 58.73,
    "arc": 61.6,
    "hellaswag": 82.53,
    "mmlu": 63.08,
    "truthfulqa": 38.82,
    "winogrande": 78.93,
    "gsm8k": 27.45,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.02,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "3fa4546259d6bbd6b5d637484c325ab19181a73c",
    "model_name_for_query": "TheBloke/dromedary-65b-lora-HF",
    "link": "https://huggingface.co/TheBloke/dromedary-65b-lora-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-30b-supercot",
    "average": 58.73,
    "arc": 64.85,
    "hellaswag": 85.08,
    "mmlu": 56.56,
    "truthfulqa": 53.96,
    "winogrande": 80.03,
    "gsm8k": 11.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 124.0,
    "still_on_hub": true,
    "revision": "dc9d81f454d286ea040c5cd45b058aecaa51c13e",
    "model_name_for_query": "ausboss/llama-30b-supercot",
    "link": "https://huggingface.co/ausboss/llama-30b-supercot",
    "author": "ausboss"
  },
  {
    "T": "\ud83d\udd36",
    "model": "UltraLM-13b-v2.0",
    "average": 58.72,
    "arc": 62.63,
    "hellaswag": 81.49,
    "mmlu": 56.17,
    "truthfulqa": 49.48,
    "winogrande": 76.48,
    "gsm8k": 26.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "a452045c96ae62379a98ef0d85666616a66e78a6",
    "model_name_for_query": "openbmb/UltraLM-13b-v2.0",
    "link": "https://huggingface.co/openbmb/UltraLM-13b-v2.0",
    "author": "openbmb"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
    "average": 58.72,
    "arc": 61.01,
    "hellaswag": 84.31,
    "mmlu": 64.34,
    "truthfulqa": 44.87,
    "winogrande": 78.85,
    "gsm8k": 18.95,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7ecfa4c5b100565bf8cfdfa7442e9772d28a9a23",
    "model_name_for_query": "uukuguy/CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
    "link": "https://huggingface.co/uukuguy/CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT4-x-AlpacaDente2-30b",
    "average": 58.71,
    "arc": 60.58,
    "hellaswag": 81.81,
    "mmlu": 56.63,
    "truthfulqa": 48.38,
    "winogrande": 78.14,
    "gsm8k": 26.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 30.0,
    "still_on_hub": true,
    "revision": "9fe5a8dada738f44e7ee9293b2140ae0be021787",
    "model_name_for_query": "Aeala/GPT4-x-AlpacaDente2-30b",
    "link": "https://huggingface.co/Aeala/GPT4-x-AlpacaDente2-30b",
    "author": "Aeala"
  },
  {
    "T": "\u2b55",
    "model": "mistral-7b-platypus-fp16",
    "average": 58.71,
    "arc": 63.05,
    "hellaswag": 84.15,
    "mmlu": 64.11,
    "truthfulqa": 45.07,
    "winogrande": 78.53,
    "gsm8k": 17.36,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d836a261afa0871d3734a7dfd1a28dc23c173ea7",
    "model_name_for_query": "bhenrym14/mistral-7b-platypus-fp16",
    "link": "https://huggingface.co/bhenrym14/mistral-7b-platypus-fp16",
    "author": "bhenrym14"
  },
  {
    "T": "\u2b55",
    "model": "Dolphin-Nebula-7B",
    "average": 58.69,
    "arc": 55.2,
    "hellaswag": 78.57,
    "mmlu": 53.44,
    "truthfulqa": 57.97,
    "winogrande": 73.88,
    "gsm8k": 33.06,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c14b3545066e5ee5562c1724a037b41db95f1f0d",
    "model_name_for_query": "Weyaxi/Dolphin-Nebula-7B",
    "link": "https://huggingface.co/Weyaxi/Dolphin-Nebula-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-v0.1-PeanutButter-v0.0.2-7B",
    "average": 58.66,
    "arc": 61.77,
    "hellaswag": 84.11,
    "mmlu": 64.38,
    "truthfulqa": 45.92,
    "winogrande": 78.37,
    "gsm8k": 17.44,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f4d471d7a9447d0969a58d5b3146d50cfa3005b3",
    "model_name_for_query": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.2-7B",
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.2-7B",
    "author": "PeanutJar"
  },
  {
    "T": "?",
    "model": "Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA",
    "average": 58.65,
    "arc": 61.26,
    "hellaswag": 84.52,
    "mmlu": 63.63,
    "truthfulqa": 45.75,
    "winogrande": 78.61,
    "gsm8k": 18.12,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "56e805fbebffaf25e61df5a3d68b75cb604a6e1c",
    "model_name_for_query": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA",
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA",
    "author": "PeanutJar"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca-2-13b",
    "average": 58.64,
    "arc": 60.67,
    "hellaswag": 79.81,
    "mmlu": 60.37,
    "truthfulqa": 56.41,
    "winogrande": 76.64,
    "gsm8k": 17.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 13.0,
    "likes": 138.0,
    "still_on_hub": true,
    "revision": "2539ff53e6baa4cc603774ad5a2d646f4041ea4e",
    "model_name_for_query": "microsoft/Orca-2-13b",
    "link": "https://huggingface.co/microsoft/Orca-2-13b",
    "author": "microsoft"
  },
  {
    "T": "\ud83d\udd36",
    "model": "falcon-40b-openassistant-peft",
    "average": 58.63,
    "arc": 62.63,
    "hellaswag": 85.59,
    "mmlu": 57.77,
    "truthfulqa": 51.02,
    "winogrande": 81.45,
    "gsm8k": 13.34,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 40.0,
    "likes": 38.0,
    "still_on_hub": false,
    "revision": "3d5084b6fbcb9f9f36493d9fd1e3795b0b9860f0",
    "model_name_for_query": "dfurman/falcon-40b-openassistant-peft",
    "link": "https://huggingface.co/dfurman/falcon-40b-openassistant-peft",
    "author": "dfurman"
  },
  {
    "T": "\u2b55",
    "model": "SOLAR-Platypus-10.7B-v1",
    "average": 58.62,
    "arc": 61.69,
    "hellaswag": 84.23,
    "mmlu": 60.37,
    "truthfulqa": 51.58,
    "winogrande": 82.79,
    "gsm8k": 11.07,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e9314a1f1ca7f790491c177e7720fb14851ef603",
    "model_name_for_query": "kyujinpy/SOLAR-Platypus-10.7B-v1",
    "link": "https://huggingface.co/kyujinpy/SOLAR-Platypus-10.7B-v1",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "QuantumLM-70B-hf",
    "average": 58.61,
    "arc": 59.47,
    "hellaswag": 83.02,
    "mmlu": 62.25,
    "truthfulqa": 53.39,
    "winogrande": 78.77,
    "gsm8k": 14.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 68.98,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "e13dd23ae5e611e959b6c8d5bc47bf4fd37cd9d7",
    "model_name_for_query": "quantumaikr/QuantumLM-70B-hf",
    "link": "https://huggingface.co/quantumaikr/QuantumLM-70B-hf",
    "author": "quantumaikr"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mamba-gpt-7b-v1",
    "average": 58.61,
    "arc": 61.26,
    "hellaswag": 84.1,
    "mmlu": 63.46,
    "truthfulqa": 46.34,
    "winogrande": 79.16,
    "gsm8k": 17.36,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e64d658b397748e409d9633fd24fc5a6df429600",
    "model_name_for_query": "CobraMamba/mamba-gpt-7b-v1",
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-7b-v1",
    "author": "CobraMamba"
  },
  {
    "T": "\u2b55",
    "model": "koOpenChat-sft",
    "average": 58.61,
    "arc": 59.81,
    "hellaswag": 78.73,
    "mmlu": 61.32,
    "truthfulqa": 51.24,
    "winogrande": 76.4,
    "gsm8k": 24.18,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "47472b36e181694422564b130ee075ffa596537d",
    "model_name_for_query": "maywell/koOpenChat-sft",
    "link": "https://huggingface.co/maywell/koOpenChat-sft",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MegaMix-T1-13B",
    "average": 58.61,
    "arc": 61.35,
    "hellaswag": 83.44,
    "mmlu": 58.49,
    "truthfulqa": 48.19,
    "winogrande": 76.09,
    "gsm8k": 24.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "55d31300f8972b56320855bb40efb5e3d1e1a6fc",
    "model_name_for_query": "gradientputri/MegaMix-T1-13B",
    "link": "https://huggingface.co/gradientputri/MegaMix-T1-13B",
    "author": "gradientputri"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolphin-2.0-mistral-7b",
    "average": 58.58,
    "arc": 59.22,
    "hellaswag": 80.26,
    "mmlu": 56.9,
    "truthfulqa": 61.09,
    "winogrande": 75.37,
    "gsm8k": 18.65,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 58.0,
    "still_on_hub": true,
    "revision": "c673387016c622fd0a707426953c03957398bc37",
    "model_name_for_query": "ehartford/dolphin-2.0-mistral-7b",
    "link": "https://huggingface.co/ehartford/dolphin-2.0-mistral-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-neural-chat-frankenmerge11b",
    "average": 58.57,
    "arc": 61.52,
    "hellaswag": 84.09,
    "mmlu": 61.51,
    "truthfulqa": 60.63,
    "winogrande": 76.24,
    "gsm8k": 7.43,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.39,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "f915831e904e0dcda760873aa16a35daf5ac9e6d",
    "model_name_for_query": "S4sch/zephyr-neural-chat-frankenmerge11b",
    "link": "https://huggingface.co/S4sch/zephyr-neural-chat-frankenmerge11b",
    "author": "S4sch"
  },
  {
    "T": "?",
    "model": "vicuna-33b-v1.3",
    "average": 58.54,
    "arc": 62.12,
    "hellaswag": 83.0,
    "mmlu": 59.22,
    "truthfulqa": 56.16,
    "winogrande": 77.03,
    "gsm8k": 13.72,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 230.0,
    "still_on_hub": true,
    "revision": "ef8d6becf883fb3ce52e3706885f761819477ab4",
    "model_name_for_query": "lmsys/vicuna-33b-v1.3",
    "link": "https://huggingface.co/lmsys/vicuna-33b-v1.3",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MegaMix-A1-13B",
    "average": 58.52,
    "arc": 61.6,
    "hellaswag": 83.49,
    "mmlu": 58.26,
    "truthfulqa": 47.48,
    "winogrande": 76.16,
    "gsm8k": 24.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "14e0756c210bcf420fbf825e6b8087ee5c716e7f",
    "model_name_for_query": "gradientputri/MegaMix-A1-13B",
    "link": "https://huggingface.co/gradientputri/MegaMix-A1-13B",
    "author": "gradientputri"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MLewd-ReMM-L2-Chat-20B",
    "average": 58.49,
    "arc": 62.46,
    "hellaswag": 85.62,
    "mmlu": 59.13,
    "truthfulqa": 55.63,
    "winogrande": 77.19,
    "gsm8k": 10.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 19.99,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "cda06630a1d8173541431e5ce8bc17dcfaa37e5e",
    "model_name_for_query": "Undi95/MLewd-ReMM-L2-Chat-20B",
    "link": "https://huggingface.co/Undi95/MLewd-ReMM-L2-Chat-20B",
    "author": "Undi95"
  },
  {
    "T": "?",
    "model": "Wizard-Vicuna-30B-Uncensored-GPTQ",
    "average": 58.47,
    "arc": 61.09,
    "hellaswag": 82.4,
    "mmlu": 56.46,
    "truthfulqa": 49.9,
    "winogrande": 77.66,
    "gsm8k": 23.28,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 35.58,
    "likes": 380.0,
    "still_on_hub": true,
    "revision": "56a82ece7a9309189561a590e8f4d2fe0d4be92b",
    "model_name_for_query": "TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ",
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3",
    "average": 58.46,
    "arc": 67.15,
    "hellaswag": 83.29,
    "mmlu": 62.26,
    "truthfulqa": 58.77,
    "winogrande": 78.06,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "7a05c8a2151f7d32252d9ef5db10445c13ae1f20",
    "model_name_for_query": "Intel/neural-chat-7b-v3",
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3",
    "author": "Intel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-chat-AYB-13B",
    "average": 58.45,
    "arc": 63.4,
    "hellaswag": 84.79,
    "mmlu": 59.34,
    "truthfulqa": 55.62,
    "winogrande": 76.24,
    "gsm8k": 11.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "cc7ca1b8f906b9f62ace094540f4ff4124dd581a",
    "model_name_for_query": "posicube/Llama2-chat-AYB-13B",
    "link": "https://huggingface.co/posicube/Llama2-chat-AYB-13B",
    "author": "posicube"
  },
  {
    "T": "\ud83d\udd36",
    "model": "trurl-2-13b-pl-instruct_unload has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/213\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #213</a>",
    "average": 58.44,
    "arc": 59.9,
    "hellaswag": 79.99,
    "mmlu": 78.66,
    "truthfulqa": 45.56,
    "winogrande": 74.35,
    "gsm8k": 12.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "17f57642165e30a4025d6817bd47dcd80d0c5c4d",
    "model_name_for_query": "Aspik101/trurl-2-13b-pl-instruct_unload",
    "link": "https://huggingface.co/Aspik101/trurl-2-13b-pl-instruct_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "X-MythoChronos-13B",
    "average": 58.43,
    "arc": 59.73,
    "hellaswag": 83.39,
    "mmlu": 56.5,
    "truthfulqa": 53.55,
    "winogrande": 74.43,
    "gsm8k": 22.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "8d302741466512f0621a594fce6bf5b8125c8d4c",
    "model_name_for_query": "Undi95/X-MythoChronos-13B",
    "link": "https://huggingface.co/Undi95/X-MythoChronos-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "30B-Lazarus",
    "average": 58.4,
    "arc": 64.93,
    "hellaswag": 84.27,
    "mmlu": 56.47,
    "truthfulqa": 58.65,
    "winogrande": 78.37,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 116.0,
    "still_on_hub": true,
    "revision": "24da9e88f2b2b7946bc6fe9412d6728b9adc2c3d",
    "model_name_for_query": "CalderaAI/30B-Lazarus",
    "link": "https://huggingface.co/CalderaAI/30B-Lazarus",
    "author": "CalderaAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-PersonalityEngine-30b",
    "average": 58.39,
    "arc": 63.48,
    "hellaswag": 84.37,
    "mmlu": 58.99,
    "truthfulqa": 46.98,
    "winogrande": 80.98,
    "gsm8k": 15.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "1990b46a2e2ac1f6282d961bce691ceceafed514",
    "model_name_for_query": "PocketDoc/Dans-PersonalityEngine-30b",
    "link": "https://huggingface.co/PocketDoc/Dans-PersonalityEngine-30b",
    "author": "PocketDoc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SynthIA-7B-v1.3-dare-0.85",
    "average": 58.38,
    "arc": 61.01,
    "hellaswag": 83.5,
    "mmlu": 64.49,
    "truthfulqa": 43.77,
    "winogrande": 78.93,
    "gsm8k": 18.57,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "91381d0ac625dcde542428ed6cb35177b4260923",
    "model_name_for_query": "uukuguy/SynthIA-7B-v1.3-dare-0.85",
    "link": "https://huggingface.co/uukuguy/SynthIA-7B-v1.3-dare-0.85",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Uncensored-Frank-33B",
    "average": 58.38,
    "arc": 62.12,
    "hellaswag": 83.3,
    "mmlu": 57.57,
    "truthfulqa": 54.03,
    "winogrande": 76.56,
    "gsm8k": 16.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 32.32,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "1c1f4e9256ac2be145a9106863ee9f2e9d701e74",
    "model_name_for_query": "ajibawa-2023/Uncensored-Frank-33B",
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Frank-33B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-chat-AY-13B",
    "average": 58.34,
    "arc": 62.8,
    "hellaswag": 83.23,
    "mmlu": 60.01,
    "truthfulqa": 55.95,
    "winogrande": 75.93,
    "gsm8k": 12.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "66037b5ee553f7b878d796d2b2d5ada5734cc164",
    "model_name_for_query": "posicube/Llama-chat-AY-13B",
    "link": "https://huggingface.co/posicube/Llama-chat-AY-13B",
    "author": "posicube"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SynthIA-v1.3-Nebula-v2-7B",
    "average": 58.33,
    "arc": 59.39,
    "hellaswag": 82.77,
    "mmlu": 57.57,
    "truthfulqa": 50.62,
    "winogrande": 74.74,
    "gsm8k": 24.87,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c6030620e9d4390d54ec221a18ff3e530f4dcd84",
    "model_name_for_query": "Weyaxi/SynthIA-v1.3-Nebula-v2-7B",
    "link": "https://huggingface.co/Weyaxi/SynthIA-v1.3-Nebula-v2-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mamba-gpt-7b-v2",
    "average": 58.31,
    "arc": 61.95,
    "hellaswag": 83.83,
    "mmlu": 61.74,
    "truthfulqa": 46.63,
    "winogrande": 78.45,
    "gsm8k": 17.29,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6439444e2c0b61253d3e61ae04fe0436717acc2f",
    "model_name_for_query": "CobraMamba/mamba-gpt-7b-v2",
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-7b-v2",
    "author": "CobraMamba"
  },
  {
    "T": "\ud83d\udd36",
    "model": "30B-Lazarus-instruct-PL-lora_unload",
    "average": 58.29,
    "arc": 62.8,
    "hellaswag": 84.13,
    "mmlu": 56.87,
    "truthfulqa": 55.49,
    "winogrande": 79.08,
    "gsm8k": 11.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "eeb29b35ceb6dd5c532f1e4e1235f1cdd3f51f23",
    "model_name_for_query": "Aspik101/30B-Lazarus-instruct-PL-lora_unload",
    "link": "https://huggingface.co/Aspik101/30B-Lazarus-instruct-PL-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Vicuzard-30B-Uncensored",
    "average": 58.26,
    "arc": 62.97,
    "hellaswag": 83.68,
    "mmlu": 58.16,
    "truthfulqa": 52.27,
    "winogrande": 77.11,
    "gsm8k": 15.39,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "e2329c05a6e59660ba3cbcc01adf30a78f852594",
    "model_name_for_query": "concedo/Vicuzard-30B-Uncensored",
    "link": "https://huggingface.co/concedo/Vicuzard-30B-Uncensored",
    "author": "concedo"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
    "average": 58.24,
    "arc": 60.75,
    "hellaswag": 84.24,
    "mmlu": 63.66,
    "truthfulqa": 44.94,
    "winogrande": 78.69,
    "gsm8k": 17.13,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "2609363766acf308877a71aba352e60d7c044b49",
    "model_name_for_query": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
    "author": "PeanutJar"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-1.4",
    "average": 58.2,
    "arc": 64.42,
    "hellaswag": 85.13,
    "mmlu": 59.53,
    "truthfulqa": 50.47,
    "winogrande": 77.9,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "04e1e194247a95cc60ba3cd70d026bc94c1f1764",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-1.4",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.4",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "mistral-7b-platypus1k",
    "average": 58.19,
    "arc": 61.6,
    "hellaswag": 82.93,
    "mmlu": 63.16,
    "truthfulqa": 46.96,
    "winogrande": 78.14,
    "gsm8k": 16.38,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c34c4a249ecf0cc391beba142a1f9cb23154fcd1",
    "model_name_for_query": "lgaalves/mistral-7b-platypus1k",
    "link": "https://huggingface.co/lgaalves/mistral-7b-platypus1k",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udd36",
    "model": "sheep-duck-llama-2-13b",
    "average": 58.19,
    "arc": 63.14,
    "hellaswag": 84.52,
    "mmlu": 59.89,
    "truthfulqa": 55.48,
    "winogrande": 76.95,
    "gsm8k": 9.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "71edf22c49677d0239caf5f87d8139dd9cc79078",
    "model_name_for_query": "Riiid/sheep-duck-llama-2-13b",
    "link": "https://huggingface.co/Riiid/sheep-duck-llama-2-13b",
    "author": "Riiid"
  },
  {
    "T": "\u2b55",
    "model": "llama-33B-instructed",
    "average": 58.18,
    "arc": 64.59,
    "hellaswag": 86.17,
    "mmlu": 60.5,
    "truthfulqa": 44.12,
    "winogrande": 79.32,
    "gsm8k": 14.4,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7c40caaea4fe3264fd469dac428b0f9450e574a6",
    "model_name_for_query": "Secbone/llama-33B-instructed",
    "link": "https://huggingface.co/Secbone/llama-33B-instructed",
    "author": "Secbone"
  },
  {
    "T": "\ud83d\udd36",
    "model": "sitebunny-13b",
    "average": 58.17,
    "arc": 63.14,
    "hellaswag": 83.64,
    "mmlu": 59.91,
    "truthfulqa": 56.21,
    "winogrande": 76.72,
    "gsm8k": 9.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "67107327d09c2f9bf3e4b316d97767c97f5a0804",
    "model_name_for_query": "42MARU/sitebunny-13b",
    "link": "https://huggingface.co/42MARU/sitebunny-13b",
    "author": "42MARU"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-TotSirocco-7b",
    "average": 58.16,
    "arc": 62.2,
    "hellaswag": 84.28,
    "mmlu": 63.8,
    "truthfulqa": 46.04,
    "winogrande": 79.48,
    "gsm8k": 13.19,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 7.24,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "824e3a4738818142374721306ce85b83770de24b",
    "model_name_for_query": "PocketDoc/Dans-TotSirocco-7b",
    "link": "https://huggingface.co/PocketDoc/Dans-TotSirocco-7b",
    "author": "PocketDoc"
  },
  {
    "T": "\u2b55",
    "model": "llama-megamerge-dare-13b",
    "average": 58.15,
    "arc": 60.58,
    "hellaswag": 83.0,
    "mmlu": 54.91,
    "truthfulqa": 45.76,
    "winogrande": 76.16,
    "gsm8k": 28.51,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5529ddb255dbdabdd179bdc911f141c3f0d2fb3f",
    "model_name_for_query": "martyn/llama-megamerge-dare-13b",
    "link": "https://huggingface.co/martyn/llama-megamerge-dare-13b",
    "author": "martyn"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-TotSirocco-7b",
    "average": 58.15,
    "arc": 62.03,
    "hellaswag": 84.23,
    "mmlu": 64.19,
    "truthfulqa": 46.49,
    "winogrande": 78.69,
    "gsm8k": 13.27,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.24,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "824e3a4738818142374721306ce85b83770de24b",
    "model_name_for_query": "PocketDoc/Dans-TotSirocco-7b",
    "link": "https://huggingface.co/PocketDoc/Dans-TotSirocco-7b",
    "author": "PocketDoc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-OpenOrca-lora",
    "average": 58.14,
    "arc": 61.95,
    "hellaswag": 83.62,
    "mmlu": 64.16,
    "truthfulqa": 42.74,
    "winogrande": 79.08,
    "gsm8k": 17.29,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "605dc043063cb9589c06883d839122920ed1eca5",
    "model_name_for_query": "uukuguy/Mistral-7B-OpenOrca-lora",
    "link": "https://huggingface.co/uukuguy/Mistral-7B-OpenOrca-lora",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mistral-guanaco1k-ep2",
    "average": 58.13,
    "arc": 60.07,
    "hellaswag": 82.76,
    "mmlu": 61.5,
    "truthfulqa": 54.4,
    "winogrande": 78.06,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.11,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "9c9f31f213b69da7797c2c0630c17cf8f785fc13",
    "model_name_for_query": "caisarl76/mistral-guanaco1k-ep2",
    "link": "https://huggingface.co/caisarl76/mistral-guanaco1k-ep2",
    "author": "caisarl76"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-guanaco1k-ep2",
    "average": 58.13,
    "arc": 60.07,
    "hellaswag": 82.76,
    "mmlu": 61.5,
    "truthfulqa": 54.4,
    "winogrande": 78.06,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.11,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "9c9f31f213b69da7797c2c0630c17cf8f785fc13",
    "model_name_for_query": "caisarl76/Mistral-7B-guanaco1k-ep2",
    "link": "https://huggingface.co/caisarl76/Mistral-7B-guanaco1k-ep2",
    "author": "caisarl76"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-1.8-L2-13B",
    "average": 58.12,
    "arc": 63.48,
    "hellaswag": 84.12,
    "mmlu": 58.57,
    "truthfulqa": 52.86,
    "winogrande": 76.4,
    "gsm8k": 13.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "fe054ab749a69375285df40913a88bd40f1e2bf6",
    "model_name_for_query": "Sao10K/Stheno-1.8-L2-13B",
    "link": "https://huggingface.co/Sao10K/Stheno-1.8-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "2x-LoRA-Assemble-13B",
    "average": 58.1,
    "arc": 63.65,
    "hellaswag": 83.47,
    "mmlu": 59.82,
    "truthfulqa": 55.94,
    "winogrande": 76.48,
    "gsm8k": 9.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1aca45d37eade21eb381aaefc9245b58ec3b7b26",
    "model_name_for_query": "PulsarAI/2x-LoRA-Assemble-13B",
    "link": "https://huggingface.co/PulsarAI/2x-LoRA-Assemble-13B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
    "average": 58.09,
    "arc": 62.46,
    "hellaswag": 83.66,
    "mmlu": 57.82,
    "truthfulqa": 50.94,
    "winogrande": 78.37,
    "gsm8k": 15.31,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "652f03ac67b4293198d98b618e64285fb32a28e9",
    "model_name_for_query": "Aspik101/Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
    "link": "https://huggingface.co/Aspik101/Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-33b-instruct",
    "average": 58.08,
    "arc": 63.05,
    "hellaswag": 85.0,
    "mmlu": 58.32,
    "truthfulqa": 52.1,
    "winogrande": 78.85,
    "gsm8k": 11.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 32.32,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "9c2b558b888e0ef8b4a72e0771db72a06a5c8474",
    "model_name_for_query": "bofenghuang/vigogne-33b-instruct",
    "link": "https://huggingface.co/bofenghuang/vigogne-33b-instruct",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "falcon-40b",
    "average": 58.07,
    "arc": 61.86,
    "hellaswag": 85.28,
    "mmlu": 56.89,
    "truthfulqa": 41.65,
    "winogrande": 81.29,
    "gsm8k": 21.46,
    "model_type": "pretrained",
    "architecture": "RWForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 41.3,
    "likes": 1099.0,
    "still_on_hub": true,
    "revision": "3d7c5902f1dc9da830979a826cd96114b3ba4ec1",
    "model_name_for_query": "tiiuae/falcon-40b",
    "link": "https://huggingface.co/tiiuae/falcon-40b",
    "author": "tiiuae"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-openplatypus-1k",
    "average": 58.07,
    "arc": 60.15,
    "hellaswag": 84.25,
    "mmlu": 59.84,
    "truthfulqa": 49.86,
    "winogrande": 76.87,
    "gsm8k": 17.44,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dad401175da3782475a122008720ddc3338e2632",
    "model_name_for_query": "mncai/Mistral-7B-openplatypus-1k",
    "link": "https://huggingface.co/mncai/Mistral-7B-openplatypus-1k",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CAMEL-33B-Combined-Data",
    "average": 58.06,
    "arc": 62.97,
    "hellaswag": 83.83,
    "mmlu": 58.98,
    "truthfulqa": 50.21,
    "winogrande": 78.3,
    "gsm8k": 14.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "62c74e7531625c1383bbbdc7c8346a996e9d1e21",
    "model_name_for_query": "camel-ai/CAMEL-33B-Combined-Data",
    "link": "https://huggingface.co/camel-ai/CAMEL-33B-Combined-Data",
    "author": "camel-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "hippogriff-30b-chat",
    "average": 58.05,
    "arc": 64.51,
    "hellaswag": 85.2,
    "mmlu": 59.09,
    "truthfulqa": 48.42,
    "winogrande": 80.82,
    "gsm8k": 10.24,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "64c10edf5312cd13704925b07413882d9e94c7a0",
    "model_name_for_query": "openaccess-ai-collective/hippogriff-30b-chat",
    "link": "https://huggingface.co/openaccess-ai-collective/hippogriff-30b-chat",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-m-7b-3.1.2-dare-0.85",
    "average": 58.03,
    "arc": 61.09,
    "hellaswag": 83.57,
    "mmlu": 64.05,
    "truthfulqa": 43.64,
    "winogrande": 78.37,
    "gsm8k": 17.44,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b5bc02f4e1008bd3a72046a93ac2f4dd4bef02da",
    "model_name_for_query": "uukuguy/airoboros-m-7b-3.1.2-dare-0.85",
    "link": "https://huggingface.co/uukuguy/airoboros-m-7b-3.1.2-dare-0.85",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DaringFortitude",
    "average": 58.01,
    "arc": 63.48,
    "hellaswag": 83.56,
    "mmlu": 59.81,
    "truthfulqa": 55.96,
    "winogrande": 76.48,
    "gsm8k": 8.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "0c463888cd83b7acebd7b6fb961562e11402e47d",
    "model_name_for_query": "sequelbox/DaringFortitude",
    "link": "https://huggingface.co/sequelbox/DaringFortitude",
    "author": "sequelbox"
  },
  {
    "T": "\u2b55",
    "model": "Luban-Marcoroni-13B",
    "average": 57.98,
    "arc": 63.65,
    "hellaswag": 82.92,
    "mmlu": 58.7,
    "truthfulqa": 55.55,
    "winogrande": 77.03,
    "gsm8k": 10.01,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "bf152c36935acd67a9029c017f0c1ff2d7a92314",
    "model_name_for_query": "Weyaxi/Luban-Marcoroni-13B",
    "link": "https://huggingface.co/Weyaxi/Luban-Marcoroni-13B",
    "author": "Weyaxi"
  },
  {
    "T": "\u2b55",
    "model": "samantha-mistral-7b",
    "average": 57.96,
    "arc": 63.4,
    "hellaswag": 84.1,
    "mmlu": 61.36,
    "truthfulqa": 46.08,
    "winogrande": 76.8,
    "gsm8k": 16.0,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "7f9e40543fdff8c3e58eca0390c8a631829c1206",
    "model_name_for_query": "ehartford/samantha-mistral-7b",
    "link": "https://huggingface.co/ehartford/samantha-mistral-7b",
    "author": "ehartford"
  },
  {
    "T": "\u2b55",
    "model": "llama2-megamerge-dare-13b-v2",
    "average": 57.94,
    "arc": 59.39,
    "hellaswag": 80.93,
    "mmlu": 55.26,
    "truthfulqa": 47.27,
    "winogrande": 75.53,
    "gsm8k": 29.26,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d0ff28a0cb4a70b15f55a416fbae6979f4ae5775",
    "model_name_for_query": "martyn/llama2-megamerge-dare-13b-v2",
    "link": "https://huggingface.co/martyn/llama2-megamerge-dare-13b-v2",
    "author": "martyn"
  },
  {
    "T": "\u2b55",
    "model": "Luban-Marcoroni-13B-v3",
    "average": 57.94,
    "arc": 63.74,
    "hellaswag": 82.88,
    "mmlu": 58.64,
    "truthfulqa": 55.56,
    "winogrande": 76.87,
    "gsm8k": 9.93,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "9b68680ed8351ef8ef6948169e69a888af40002e",
    "model_name_for_query": "Weyaxi/Luban-Marcoroni-13B-v3",
    "link": "https://huggingface.co/Weyaxi/Luban-Marcoroni-13B-v3",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llamix2-Xwin-MoE-4x13B",
    "average": 57.93,
    "arc": 60.41,
    "hellaswag": 82.96,
    "mmlu": 56.24,
    "truthfulqa": 39.63,
    "winogrande": 75.14,
    "gsm8k": 33.21,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 38.5,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "220833f87c233684e8a4b0e03126ffcdffce5229",
    "model_name_for_query": "Undi95/Llamix2-Xwin-MoE-4x13B",
    "link": "https://huggingface.co/Undi95/Llamix2-Xwin-MoE-4x13B",
    "author": "Undi95"
  },
  {
    "T": "\u2b55",
    "model": "Luban-Marcoroni-13B-v2",
    "average": 57.92,
    "arc": 63.48,
    "hellaswag": 82.89,
    "mmlu": 58.72,
    "truthfulqa": 55.56,
    "winogrande": 76.95,
    "gsm8k": 9.93,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d7c704a08218dcc03963bc08e9113e281c056f53",
    "model_name_for_query": "Weyaxi/Luban-Marcoroni-13B-v2",
    "link": "https://huggingface.co/Weyaxi/Luban-Marcoroni-13B-v2",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-OpenOrca-Guanaco-accu16",
    "average": 57.91,
    "arc": 59.73,
    "hellaswag": 83.08,
    "mmlu": 61.29,
    "truthfulqa": 50.81,
    "winogrande": 76.56,
    "gsm8k": 16.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e83b8c1887c45473961a4ff36ae202ada1ca3d42",
    "model_name_for_query": "caisarl76/Mistral-7B-OpenOrca-Guanaco-accu16",
    "link": "https://huggingface.co/caisarl76/Mistral-7B-OpenOrca-Guanaco-accu16",
    "author": "caisarl76"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13B-LoRA-assemble",
    "average": 57.91,
    "arc": 63.57,
    "hellaswag": 83.51,
    "mmlu": 59.82,
    "truthfulqa": 55.96,
    "winogrande": 76.16,
    "gsm8k": 8.42,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "85bb49d333dba4a08b051418663d16853ce30cee",
    "model_name_for_query": "oh-yeontaek/llama-2-13B-LoRA-assemble",
    "link": "https://huggingface.co/oh-yeontaek/llama-2-13B-LoRA-assemble",
    "author": "oh-yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Enterredaas-33b",
    "average": 57.9,
    "arc": 60.92,
    "hellaswag": 84.18,
    "mmlu": 58.3,
    "truthfulqa": 49.02,
    "winogrande": 78.77,
    "gsm8k": 16.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d72dc1f05eaf1beb6373fd53fd22eb90f293a5c4",
    "model_name_for_query": "Aeala/Enterredaas-33b",
    "link": "https://huggingface.co/Aeala/Enterredaas-33b",
    "author": "Aeala"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Wizard-Vicuna-30B-Uncensored",
    "average": 57.89,
    "arc": 62.12,
    "hellaswag": 83.45,
    "mmlu": 58.24,
    "truthfulqa": 50.81,
    "winogrande": 78.45,
    "gsm8k": 14.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 72.0,
    "still_on_hub": true,
    "revision": "6374baef4cedd41f85c111b8eec3eb38ee24c4b9",
    "model_name_for_query": "ehartford/Wizard-Vicuna-30B-Uncensored",
    "link": "https://huggingface.co/ehartford/Wizard-Vicuna-30B-Uncensored",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Wizard-Vicuna-30B-Uncensored-fp16",
    "average": 57.89,
    "arc": 62.12,
    "hellaswag": 83.45,
    "mmlu": 58.24,
    "truthfulqa": 50.81,
    "winogrande": 78.45,
    "gsm8k": 14.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "c7b7cecb5a314fc66deebabcb67c230a3fbe84f7",
    "model_name_for_query": "TheBloke/Wizard-Vicuna-30B-Uncensored-fp16",
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-chat-AYT-13B",
    "average": 57.88,
    "arc": 63.31,
    "hellaswag": 83.53,
    "mmlu": 59.67,
    "truthfulqa": 55.8,
    "winogrande": 76.09,
    "gsm8k": 8.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.02,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "dd12dced8076a959c03b8b5c4a4266f234d6639a",
    "model_name_for_query": "posicube/Llama2-chat-AYT-13B",
    "link": "https://huggingface.co/posicube/Llama2-chat-AYT-13B",
    "author": "posicube"
  },
  {
    "T": "\ud83d\udd36",
    "model": "VicUnlocked-alpaca-30b",
    "average": 57.86,
    "arc": 61.86,
    "hellaswag": 83.79,
    "mmlu": 57.64,
    "truthfulqa": 51.03,
    "winogrande": 78.22,
    "gsm8k": 14.63,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "c63d117d1ec5794766dd6dc5e1469769df8aba1d",
    "model_name_for_query": "Aeala/VicUnlocked-alpaca-30b",
    "link": "https://huggingface.co/Aeala/VicUnlocked-alpaca-30b",
    "author": "Aeala"
  },
  {
    "T": "\u2b55",
    "model": "Chat-AYB-Nova-13B",
    "average": 57.84,
    "arc": 62.97,
    "hellaswag": 84.28,
    "mmlu": 58.58,
    "truthfulqa": 51.28,
    "winogrande": 77.58,
    "gsm8k": 12.36,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "942af4d59533af09cf9ba13d1e369b8e871a0a4b",
    "model_name_for_query": "PulsarAI/Chat-AYB-Nova-13B",
    "link": "https://huggingface.co/PulsarAI/Chat-AYB-Nova-13B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mistral_7b_2epoch_norobots",
    "average": 57.84,
    "arc": 61.01,
    "hellaswag": 83.37,
    "mmlu": 63.96,
    "truthfulqa": 42.62,
    "winogrande": 79.08,
    "gsm8k": 16.98,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "624be22cfde6797a100230ec9dc1421f52eb0aa2",
    "model_name_for_query": "souvik0306/mistral_7b_2epoch_norobots",
    "link": "https://huggingface.co/souvik0306/mistral_7b_2epoch_norobots",
    "author": "souvik0306"
  },
  {
    "T": "?",
    "model": "Stheno-v2-Delta-fp16",
    "average": 57.81,
    "arc": 62.46,
    "hellaswag": 83.45,
    "mmlu": 59.04,
    "truthfulqa": 55.25,
    "winogrande": 73.88,
    "gsm8k": 12.81,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3979769be8d92aa2dd0c7aebf385635863f16dd9",
    "model_name_for_query": "Sao10K/Stheno-v2-Delta-fp16",
    "link": "https://huggingface.co/Sao10K/Stheno-v2-Delta-fp16",
    "author": "Sao10K"
  },
  {
    "T": "?",
    "model": "Stheno-V2-Delta-fp16",
    "average": 57.81,
    "arc": 62.46,
    "hellaswag": 83.45,
    "mmlu": 59.04,
    "truthfulqa": 55.25,
    "winogrande": 73.88,
    "gsm8k": 12.81,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3979769be8d92aa2dd0c7aebf385635863f16dd9",
    "model_name_for_query": "Sao10K/Stheno-V2-Delta-fp16",
    "link": "https://huggingface.co/Sao10K/Stheno-V2-Delta-fp16",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "ChatAYT-Lora-Assamble-Marcoroni",
    "average": 57.76,
    "arc": 62.46,
    "hellaswag": 83.05,
    "mmlu": 58.72,
    "truthfulqa": 56.12,
    "winogrande": 77.35,
    "gsm8k": 8.87,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "51c9b600023cd26c4eb3754b9a89c60dde959ccc",
    "model_name_for_query": "Weyaxi/ChatAYT-Lora-Assamble-Marcoroni",
    "link": "https://huggingface.co/Weyaxi/ChatAYT-Lora-Assamble-Marcoroni",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama2-13b-v8.1-fp16",
    "average": 57.76,
    "arc": 55.97,
    "hellaswag": 79.79,
    "mmlu": 54.95,
    "truthfulqa": 51.16,
    "winogrande": 74.35,
    "gsm8k": 30.33,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.88,
    "likes": 62.0,
    "still_on_hub": true,
    "revision": "b51c6b29abdf7c420cb5e5f4f309ff83179c7bb8",
    "model_name_for_query": "OpenBuddy/openbuddy-llama2-13b-v8.1-fp16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v8.1-fp16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrcaxOpenChat-Preview2-13B",
    "average": 57.76,
    "arc": 62.37,
    "hellaswag": 82.96,
    "mmlu": 58.68,
    "truthfulqa": 51.23,
    "winogrande": 77.19,
    "gsm8k": 14.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 94.0,
    "still_on_hub": true,
    "revision": "26d1bc5c54c1f60a5de0b1ed4d0b16f285aee230",
    "model_name_for_query": "Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "link": "https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MLewd-L2-Chat-13B",
    "average": 57.75,
    "arc": 62.03,
    "hellaswag": 84.19,
    "mmlu": 58.75,
    "truthfulqa": 52.84,
    "winogrande": 77.43,
    "gsm8k": 11.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "6c66622a99c1bc73498aa6a15a59da825d875310",
    "model_name_for_query": "Undi95/MLewd-L2-Chat-13B",
    "link": "https://huggingface.co/Undi95/MLewd-L2-Chat-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pwen-14B-Chat-20_30",
    "average": 57.74,
    "arc": 56.14,
    "hellaswag": 79.78,
    "mmlu": 60.01,
    "truthfulqa": 47.02,
    "winogrande": 76.48,
    "gsm8k": 26.99,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 14.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "e878e1f1f7b533c32beb8e06ebcf0cfa23f3fe9b",
    "model_name_for_query": "JosephusCheung/Pwen-14B-Chat-20_30",
    "link": "https://huggingface.co/JosephusCheung/Pwen-14B-Chat-20_30",
    "author": "JosephusCheung"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Luban-13B",
    "average": 57.73,
    "arc": 63.05,
    "hellaswag": 82.8,
    "mmlu": 58.73,
    "truthfulqa": 55.53,
    "winogrande": 76.56,
    "gsm8k": 9.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "01b0f2046083dd8d9d8f9e626d78d83eaa1d57dd",
    "model_name_for_query": "ai-business/Luban-13B",
    "link": "https://huggingface.co/ai-business/Luban-13B",
    "author": "ai-business"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-1.2",
    "average": 57.69,
    "arc": 64.42,
    "hellaswag": 84.93,
    "mmlu": 60.35,
    "truthfulqa": 49.18,
    "winogrande": 77.51,
    "gsm8k": 9.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "b3254a827fb1dfe0d4e428bf5ab1c3a2bac82d68",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-1.2",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.2",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Alpacino30b",
    "average": 57.67,
    "arc": 62.71,
    "hellaswag": 85.04,
    "mmlu": 58.48,
    "truthfulqa": 44.23,
    "winogrande": 79.79,
    "gsm8k": 15.77,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 67.0,
    "still_on_hub": true,
    "revision": "300bc5f3dc129a3d17adf059394e381eff7fbd55",
    "model_name_for_query": "digitous/Alpacino30b",
    "link": "https://huggingface.co/digitous/Alpacino30b",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "magpie-13b",
    "average": 57.64,
    "arc": 63.31,
    "hellaswag": 84.25,
    "mmlu": 58.15,
    "truthfulqa": 49.15,
    "winogrande": 76.48,
    "gsm8k": 14.48,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "a58124cdc9f39ccd59d4290a8bdfda93ff3690dc",
    "model_name_for_query": "boomerchan/magpie-13b",
    "link": "https://huggingface.co/boomerchan/magpie-13b",
    "author": "boomerchan"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mistral-7b-v0.1-layla-v2",
    "average": 57.6,
    "arc": 56.31,
    "hellaswag": 79.76,
    "mmlu": 50.81,
    "truthfulqa": 51.57,
    "winogrande": 75.77,
    "gsm8k": 31.39,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "0f444610d26724271cd6dfb168667a405a2a3e6c",
    "model_name_for_query": "l3utterfly/mistral-7b-v0.1-layla-v2",
    "link": "https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v2",
    "author": "l3utterfly"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca-2-13B-GPTQ",
    "average": 57.6,
    "arc": 59.81,
    "hellaswag": 79.12,
    "mmlu": 59.35,
    "truthfulqa": 55.14,
    "winogrande": 76.64,
    "gsm8k": 15.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "other",
    "params": 16.24,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "2fc627e11b197c7d563eeea9c4338c2adc8e2c93",
    "model_name_for_query": "TheBloke/Orca-2-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/Orca-2-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MelloGPT",
    "average": 57.59,
    "arc": 53.84,
    "hellaswag": 76.12,
    "mmlu": 55.99,
    "truthfulqa": 55.61,
    "winogrande": 73.88,
    "gsm8k": 30.1,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aedecb296e2cdcb3da95a345a794ea26f071c419",
    "model_name_for_query": "steve-cse/MelloGPT",
    "link": "https://huggingface.co/steve-cse/MelloGPT",
    "author": "steve-cse"
  },
  {
    "T": "?",
    "model": "mistral-7b-v0.1-layla-v1",
    "average": 57.56,
    "arc": 60.15,
    "hellaswag": 83.25,
    "mmlu": 60.31,
    "truthfulqa": 48.9,
    "winogrande": 75.93,
    "gsm8k": 16.83,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5f06add6aa1d51d78288dbdcbd1abfd5f0ed0c84",
    "model_name_for_query": "l3utterfly/mistral-7b-v0.1-layla-v1",
    "link": "https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v1",
    "author": "l3utterfly"
  },
  {
    "T": "?",
    "model": "tulu-30B-fp16",
    "average": 57.53,
    "arc": 59.98,
    "hellaswag": 83.4,
    "mmlu": 56.1,
    "truthfulqa": 45.14,
    "winogrande": 80.82,
    "gsm8k": 19.71,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "37c3655676c37662f60c68dacfce3f0e861be846",
    "model_name_for_query": "TheBloke/tulu-30B-fp16",
    "link": "https://huggingface.co/TheBloke/tulu-30B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "average": 57.52,
    "arc": 59.64,
    "hellaswag": 82.7,
    "mmlu": 58.3,
    "truthfulqa": 56.0,
    "winogrande": 75.37,
    "gsm8k": 13.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 24.0,
    "still_on_hub": true,
    "revision": "4410d8a20871927e9fe981c01bc8314b451b2fcd",
    "model_name_for_query": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "link": "https://huggingface.co/uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-1.3",
    "average": 57.49,
    "arc": 63.82,
    "hellaswag": 85.09,
    "mmlu": 58.94,
    "truthfulqa": 45.33,
    "winogrande": 79.01,
    "gsm8k": 12.74,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "f94e5249d2b998933466d42e08fa9551e3238205",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-1.3",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.3",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Unholy-v1-12L-13B",
    "average": 57.47,
    "arc": 63.57,
    "hellaswag": 83.75,
    "mmlu": 58.08,
    "truthfulqa": 51.09,
    "winogrande": 77.27,
    "gsm8k": 11.07,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "ee25c078f08b0812d82597afa3f5e877c19a5c83",
    "model_name_for_query": "Undi95/Unholy-v1-12L-13B",
    "link": "https://huggingface.co/Undi95/Unholy-v1-12L-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-AdventurousWinds-7b",
    "average": 57.46,
    "arc": 61.01,
    "hellaswag": 83.47,
    "mmlu": 63.69,
    "truthfulqa": 42.65,
    "winogrande": 78.22,
    "gsm8k": 15.69,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.24,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "ddc7e4fcbbb5c666a3fe1bbe4a47b4477151b699",
    "model_name_for_query": "PocketDoc/Dans-AdventurousWinds-7b",
    "link": "https://huggingface.co/PocketDoc/Dans-AdventurousWinds-7b",
    "author": "PocketDoc"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-33b-gpt4-1.3",
    "average": 57.43,
    "arc": 63.91,
    "hellaswag": 85.04,
    "mmlu": 58.53,
    "truthfulqa": 45.36,
    "winogrande": 78.69,
    "gsm8k": 13.04,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "f94e5249d2b998933466d42e08fa9551e3238205",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-1.3",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.3",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MXLewd-L2-20B",
    "average": 57.43,
    "arc": 63.23,
    "hellaswag": 85.33,
    "mmlu": 57.36,
    "truthfulqa": 51.65,
    "winogrande": 76.09,
    "gsm8k": 10.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 19.99,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "ac279478abd9ddb8d1f5adcc548be0287b963adf",
    "model_name_for_query": "Undi95/MXLewd-L2-20B",
    "link": "https://huggingface.co/Undi95/MXLewd-L2-20B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-llama2-luban-orca-platypus-13b",
    "average": 57.42,
    "arc": 62.54,
    "hellaswag": 82.76,
    "mmlu": 59.23,
    "truthfulqa": 54.66,
    "winogrande": 77.11,
    "gsm8k": 8.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "908cfb670611875b52045c4bab81cff53f0279a7",
    "model_name_for_query": "uukuguy/speechless-llama2-luban-orca-platypus-13b",
    "link": "https://huggingface.co/uukuguy/speechless-llama2-luban-orca-platypus-13b",
    "author": "uukuguy"
  },
  {
    "T": "\u2b55",
    "model": "chinese-alpaca-2-13b",
    "average": 57.41,
    "arc": 58.7,
    "hellaswag": 79.76,
    "mmlu": 55.12,
    "truthfulqa": 50.22,
    "winogrande": 75.61,
    "gsm8k": 25.02,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 74.0,
    "still_on_hub": true,
    "revision": "3b2e3895ff83c8892ab20fb8f98754d947879186",
    "model_name_for_query": "hfl/chinese-alpaca-2-13b",
    "link": "https://huggingface.co/hfl/chinese-alpaca-2-13b",
    "author": "hfl"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistralic-7B-1",
    "average": 57.4,
    "arc": 60.84,
    "hellaswag": 82.29,
    "mmlu": 60.8,
    "truthfulqa": 52.38,
    "winogrande": 77.03,
    "gsm8k": 11.07,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.11,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "ebf138de4fb7a57f0d187ad0ab43abd6b35bfb62",
    "model_name_for_query": "SkunkworksAI/Mistralic-7B-1",
    "link": "https://huggingface.co/SkunkworksAI/Mistralic-7B-1",
    "author": "SkunkworksAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-polyglot-13b",
    "average": 57.36,
    "arc": 59.81,
    "hellaswag": 81.27,
    "mmlu": 55.04,
    "truthfulqa": 48.71,
    "winogrande": 76.72,
    "gsm8k": 22.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7a08a96118aa86e0405a5f980d7e40dadf86e1be",
    "model_name_for_query": "chargoddard/llama-polyglot-13b",
    "link": "https://huggingface.co/chargoddard/llama-polyglot-13b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "digital-socrates-13b",
    "average": 57.34,
    "arc": 58.36,
    "hellaswag": 80.14,
    "mmlu": 57.01,
    "truthfulqa": 44.47,
    "winogrande": 74.59,
    "gsm8k": 29.49,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c738ee4bb61e67eebb9d196c440dcb2d99e5f906",
    "model_name_for_query": "allenai/digital-socrates-13b",
    "link": "https://huggingface.co/allenai/digital-socrates-13b",
    "author": "allenai"
  },
  {
    "T": "?",
    "model": "VicUnlocked-30B-LoRA-HF",
    "average": 57.33,
    "arc": 59.73,
    "hellaswag": 84.02,
    "mmlu": 57.81,
    "truthfulqa": 48.54,
    "winogrande": 79.48,
    "gsm8k": 14.4,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "3259cb3c2a10cfb429fb51c4a76fffa049f4c44d",
    "model_name_for_query": "TheBloke/VicUnlocked-30B-LoRA-HF",
    "link": "https://huggingface.co/TheBloke/VicUnlocked-30B-LoRA-HF",
    "author": "TheBloke"
  },
  {
    "T": "?",
    "model": "airoboros-33b-gpt4",
    "average": 57.32,
    "arc": 63.74,
    "hellaswag": 84.87,
    "mmlu": 58.54,
    "truthfulqa": 47.06,
    "winogrande": 77.03,
    "gsm8k": 12.66,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "5b6bd680b1c008e52521dc8c663dbc87820da3d0",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BrainDerp2",
    "average": 57.32,
    "arc": 60.92,
    "hellaswag": 81.94,
    "mmlu": 58.9,
    "truthfulqa": 57.19,
    "winogrande": 75.93,
    "gsm8k": 9.02,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "948ee7af94a8b092807df4becfc0a8c1cd042878",
    "model_name_for_query": "Sao10K/BrainDerp2",
    "link": "https://huggingface.co/Sao10K/BrainDerp2",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
    "average": 57.31,
    "arc": 62.37,
    "hellaswag": 82.99,
    "mmlu": 59.38,
    "truthfulqa": 52.2,
    "winogrande": 75.77,
    "gsm8k": 11.14,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "39ae03b77b4f1d453b02468ce6bb4ddeb6526b77",
    "model_name_for_query": "TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLaMA_2_13B_SFT_v0",
    "average": 57.31,
    "arc": 62.03,
    "hellaswag": 83.8,
    "mmlu": 58.39,
    "truthfulqa": 49.92,
    "winogrande": 77.27,
    "gsm8k": 12.43,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a6790d83337578f38d2bcd51038a779eaa8d0fac",
    "model_name_for_query": "adonlee/LLaMA_2_13B_SFT_v0",
    "link": "https://huggingface.co/adonlee/LLaMA_2_13B_SFT_v0",
    "author": "adonlee"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLlama-34b-Instruct-hf",
    "average": 57.29,
    "arc": 54.27,
    "hellaswag": 76.92,
    "mmlu": 55.54,
    "truthfulqa": 44.44,
    "winogrande": 74.59,
    "gsm8k": 37.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 33.74,
    "likes": 215.0,
    "still_on_hub": true,
    "revision": "bf5e5060fa30f33149efe84bbcc682001a00ab94",
    "model_name_for_query": "codellama/CodeLlama-34b-Instruct-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf",
    "author": "codellama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrca-Platypus2-13B",
    "average": 57.28,
    "arc": 62.8,
    "hellaswag": 83.15,
    "mmlu": 59.39,
    "truthfulqa": 53.08,
    "winogrande": 76.24,
    "gsm8k": 9.02,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 204.0,
    "still_on_hub": true,
    "revision": "e7a40134f7eb687c6ab66d445dc7251257f8d391",
    "model_name_for_query": "Open-Orca/OpenOrca-Platypus2-13B",
    "link": "https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B",
    "author": "Open-Orca"
  },
  {
    "T": "\u2b55",
    "model": "2x-LoRA-Assemble-Nova-13B",
    "average": 57.26,
    "arc": 62.63,
    "hellaswag": 83.24,
    "mmlu": 58.64,
    "truthfulqa": 51.88,
    "winogrande": 76.95,
    "gsm8k": 10.24,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2a344b91b28ce4d0bd48b9b5a6cc87b71123eab5",
    "model_name_for_query": "PulsarAI/2x-LoRA-Assemble-Nova-13B",
    "link": "https://huggingface.co/PulsarAI/2x-LoRA-Assemble-Nova-13B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MLewd-ReMM-L2-Chat-20B-Inverted",
    "average": 57.25,
    "arc": 61.69,
    "hellaswag": 85.32,
    "mmlu": 58.0,
    "truthfulqa": 53.77,
    "winogrande": 75.61,
    "gsm8k": 9.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 19.99,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b5b501b4d23ec7ab24b827f79e48b2c67e548ddb",
    "model_name_for_query": "Undi95/MLewd-ReMM-L2-Chat-20B-Inverted",
    "link": "https://huggingface.co/Undi95/MLewd-ReMM-L2-Chat-20B-Inverted",
    "author": "Undi95"
  },
  {
    "T": "\u2b55",
    "model": "Giraffe-13b-32k-v3",
    "average": 57.24,
    "arc": 59.04,
    "hellaswag": 79.59,
    "mmlu": 55.01,
    "truthfulqa": 46.68,
    "winogrande": 76.95,
    "gsm8k": 26.16,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "bbc483fc0a3b88740fd6e04a7fd0c7d98b85cd1d",
    "model_name_for_query": "abacusai/Giraffe-13b-32k-v3",
    "link": "https://huggingface.co/abacusai/Giraffe-13b-32k-v3",
    "author": "abacusai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_v3_13b",
    "average": 57.24,
    "arc": 63.14,
    "hellaswag": 82.35,
    "mmlu": 56.52,
    "truthfulqa": 51.81,
    "winogrande": 76.48,
    "gsm8k": 13.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 27.0,
    "still_on_hub": true,
    "revision": "99904e4119575f2c1606ca1e31d288f38a9f20b5",
    "model_name_for_query": "psmathur/orca_mini_v3_13b",
    "link": "https://huggingface.co/psmathur/orca_mini_v3_13b",
    "author": "psmathur"
  },
  {
    "T": "\u2b55",
    "model": "orca_mini_v3_13b",
    "average": 57.24,
    "arc": 63.14,
    "hellaswag": 82.35,
    "mmlu": 56.52,
    "truthfulqa": 51.81,
    "winogrande": 76.48,
    "gsm8k": 13.12,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 27.0,
    "still_on_hub": true,
    "revision": "72eec98f68d240a71d3da8a266917b6e754ae831",
    "model_name_for_query": "pankajmathur/orca_mini_v3_13b",
    "link": "https://huggingface.co/pankajmathur/orca_mini_v3_13b",
    "author": "pankajmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MLewd-Chat-v2-13B",
    "average": 57.23,
    "arc": 61.86,
    "hellaswag": 83.81,
    "mmlu": 57.0,
    "truthfulqa": 54.51,
    "winogrande": 75.77,
    "gsm8k": 10.46,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "f6181961a6a2f9ca534e1a8907b4a4459be6b6bd",
    "model_name_for_query": "Undi95/MLewd-Chat-v2-13B",
    "link": "https://huggingface.co/Undi95/MLewd-Chat-v2-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Athena-v4",
    "average": 57.23,
    "arc": 62.54,
    "hellaswag": 84.19,
    "mmlu": 57.33,
    "truthfulqa": 50.87,
    "winogrande": 76.48,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "dde640538a44a08f6f456a2b7634e31a5d7a1245",
    "model_name_for_query": "IkariDev/Athena-v4",
    "link": "https://huggingface.co/IkariDev/Athena-v4",
    "author": "IkariDev"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-llama2-hermes-orca-platypus-13b",
    "average": 57.17,
    "arc": 60.92,
    "hellaswag": 83.5,
    "mmlu": 59.39,
    "truthfulqa": 54.29,
    "winogrande": 75.22,
    "gsm8k": 9.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f227ad33b16726b099e35e5dc47f4db1f22665a7",
    "model_name_for_query": "uukuguy/speechless-llama2-hermes-orca-platypus-13b",
    "link": "https://huggingface.co/uukuguy/speechless-llama2-hermes-orca-platypus-13b",
    "author": "uukuguy"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-33b-2.1",
    "average": 57.16,
    "arc": 63.65,
    "hellaswag": 84.97,
    "mmlu": 57.37,
    "truthfulqa": 52.17,
    "winogrande": 78.22,
    "gsm8k": 6.6,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "12ccd0e6c9ef12c7d3c2eab8266cd32c0b2f7683",
    "model_name_for_query": "jondurbin/airoboros-33b-2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-m2.0",
    "average": 57.16,
    "arc": 64.68,
    "hellaswag": 84.95,
    "mmlu": 57.77,
    "truthfulqa": 47.44,
    "winogrande": 77.74,
    "gsm8k": 10.39,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "57bd88e24d603dc4bbe4016ed0871db7c0e529d5",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BrainDerp3",
    "average": 57.13,
    "arc": 60.92,
    "hellaswag": 82.1,
    "mmlu": 58.91,
    "truthfulqa": 57.18,
    "winogrande": 75.61,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "0b575b9245406cca92942ce2ababb5b868109bed",
    "model_name_for_query": "Sao10K/BrainDerp3",
    "link": "https://huggingface.co/Sao10K/BrainDerp3",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CalliopeDS-v2-L2-13B",
    "average": 57.12,
    "arc": 62.8,
    "hellaswag": 84.14,
    "mmlu": 56.14,
    "truthfulqa": 51.06,
    "winogrande": 76.01,
    "gsm8k": 12.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e63d24870c840d47e82b029e7f405baa10ad9ea4",
    "model_name_for_query": "Doctor-Shotgun/CalliopeDS-v2-L2-13B",
    "link": "https://huggingface.co/Doctor-Shotgun/CalliopeDS-v2-L2-13B",
    "author": "Doctor-Shotgun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MegaMix-S1-13B",
    "average": 57.12,
    "arc": 62.46,
    "hellaswag": 83.65,
    "mmlu": 57.88,
    "truthfulqa": 44.52,
    "winogrande": 75.85,
    "gsm8k": 18.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "afca2c9488cf8738faec4db6721f6a4c755a5d81",
    "model_name_for_query": "gradientputri/MegaMix-S1-13B",
    "link": "https://huggingface.co/gradientputri/MegaMix-S1-13B",
    "author": "gradientputri"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BrainDerp",
    "average": 57.11,
    "arc": 60.75,
    "hellaswag": 82.1,
    "mmlu": 58.81,
    "truthfulqa": 56.9,
    "winogrande": 75.85,
    "gsm8k": 8.26,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ba21a7ed5458b3fa2b05ce6aab431acd1f857516",
    "model_name_for_query": "Sao10K/BrainDerp",
    "link": "https://huggingface.co/Sao10K/BrainDerp",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ReMM-v2.2-L2-13B",
    "average": 57.1,
    "arc": 61.26,
    "hellaswag": 84.16,
    "mmlu": 56.22,
    "truthfulqa": 51.35,
    "winogrande": 75.61,
    "gsm8k": 14.03,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d55031fbcd41d749bc0c0ffbcd85636718d373b6",
    "model_name_for_query": "Undi95/ReMM-v2.2-L2-13B",
    "link": "https://huggingface.co/Undi95/ReMM-v2.2-L2-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Athena-v3",
    "average": 57.09,
    "arc": 61.69,
    "hellaswag": 84.34,
    "mmlu": 57.87,
    "truthfulqa": 51.26,
    "winogrande": 75.77,
    "gsm8k": 11.6,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "5e4024b6694bb13f1a81ce4277ac9141f0b226df",
    "model_name_for_query": "IkariDev/Athena-v3",
    "link": "https://huggingface.co/IkariDev/Athena-v3",
    "author": "IkariDev"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-33b-coder",
    "average": 57.07,
    "arc": 60.41,
    "hellaswag": 83.27,
    "mmlu": 57.17,
    "truthfulqa": 51.79,
    "winogrande": 76.87,
    "gsm8k": 12.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 32.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "67f6e669d7a15c1104a1478057f3752a503e83c0",
    "model_name_for_query": "FelixChao/vicuna-33b-coder",
    "link": "https://huggingface.co/FelixChao/vicuna-33b-coder",
    "author": "FelixChao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Emerhyst-20B",
    "average": 57.07,
    "arc": 61.69,
    "hellaswag": 84.98,
    "mmlu": 56.98,
    "truthfulqa": 54.16,
    "winogrande": 76.09,
    "gsm8k": 8.49,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 19.99,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "e4c23af4f5dd88cb27d245e2bfc3b81db652632c",
    "model_name_for_query": "Undi95/Emerhyst-20B",
    "link": "https://huggingface.co/Undi95/Emerhyst-20B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-orca-v1",
    "average": 57.05,
    "arc": 62.03,
    "hellaswag": 82.27,
    "mmlu": 57.71,
    "truthfulqa": 49.61,
    "winogrande": 76.87,
    "gsm8k": 13.8,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "e77ec90f432bdffa210a0e4310d117e5d1c662df",
    "model_name_for_query": "circulus/Llama-2-13b-orca-v1",
    "link": "https://huggingface.co/circulus/Llama-2-13b-orca-v1",
    "author": "circulus"
  },
  {
    "T": "\ud83d\udd36",
    "model": "StableBeluga-13B",
    "average": 57.05,
    "arc": 62.03,
    "hellaswag": 82.27,
    "mmlu": 57.71,
    "truthfulqa": 49.61,
    "winogrande": 76.87,
    "gsm8k": 13.8,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 107.0,
    "still_on_hub": true,
    "revision": "1d6eef4cc2b73f39600a568803ad8183f2da4514",
    "model_name_for_query": "stabilityai/StableBeluga-13B",
    "link": "https://huggingface.co/stabilityai/StableBeluga-13B",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-m2.0",
    "average": 57.03,
    "arc": 63.4,
    "hellaswag": 85.19,
    "mmlu": 57.46,
    "truthfulqa": 48.15,
    "winogrande": 78.37,
    "gsm8k": 9.63,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "84a89dee5bf3447079f115a3ef4d58ef8f924798",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zephyr-beta-Nebula-v2-7B",
    "average": 57.03,
    "arc": 56.57,
    "hellaswag": 82.53,
    "mmlu": 56.4,
    "truthfulqa": 58.68,
    "winogrande": 70.48,
    "gsm8k": 17.51,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "226caedb50a12730232c1f8fe9c96b6dcf818ba7",
    "model_name_for_query": "Weyaxi/zephyr-beta-Nebula-v2-7B",
    "link": "https://huggingface.co/Weyaxi/zephyr-beta-Nebula-v2-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-2.0",
    "average": 57.02,
    "arc": 63.91,
    "hellaswag": 85.67,
    "mmlu": 57.95,
    "truthfulqa": 45.54,
    "winogrande": 77.98,
    "gsm8k": 11.07,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "a4e1b721add286900c5a6f529c3d7a3e0049b2e0",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wendigo-14b-alpha2",
    "average": 57.02,
    "arc": 56.66,
    "hellaswag": 77.19,
    "mmlu": 58.0,
    "truthfulqa": 53.71,
    "winogrande": 73.64,
    "gsm8k": 22.9,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 14.22,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f8332eddcb7f8ab2b5195486d4b508c4628992f6",
    "model_name_for_query": "MisterRid/wendigo-14b-alpha2",
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha2",
    "author": "MisterRid"
  },
  {
    "T": "\ud83d\udd36",
    "model": "synapsellm-7b-mistral-v0.3-preview",
    "average": 57.01,
    "arc": 53.84,
    "hellaswag": 74.86,
    "mmlu": 54.81,
    "truthfulqa": 55.03,
    "winogrande": 74.59,
    "gsm8k": 28.96,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4e509275c5e51bee6e82c2c15082a6cc50d87b5b",
    "model_name_for_query": "WebraftAI/synapsellm-7b-mistral-v0.3-preview",
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.3-preview",
    "author": "WebraftAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wendigo-14b-alpha1",
    "average": 57.01,
    "arc": 56.48,
    "hellaswag": 77.2,
    "mmlu": 57.83,
    "truthfulqa": 53.76,
    "winogrande": 73.01,
    "gsm8k": 23.81,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 14.22,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0024ee75d8ed5d9373ff42df72c21f3217ba9d2e",
    "model_name_for_query": "MisterRid/wendigo-14b-alpha1",
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha1",
    "author": "MisterRid"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-2.0",
    "average": 57.01,
    "arc": 63.82,
    "hellaswag": 85.65,
    "mmlu": 58.44,
    "truthfulqa": 45.57,
    "winogrande": 77.9,
    "gsm8k": 10.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "ddc598f492f5098a8e308f51a82834f98f29a4ce",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "YuLan-Chat-2-13b-fp16",
    "average": 57.01,
    "arc": 59.04,
    "hellaswag": 80.66,
    "mmlu": 56.72,
    "truthfulqa": 52.18,
    "winogrande": 79.64,
    "gsm8k": 13.8,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.95,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "2d439187efd6edd91a0c0146f08dff52d92aa7bc",
    "model_name_for_query": "yulan-team/YuLan-Chat-2-13b-fp16",
    "link": "https://huggingface.co/yulan-team/YuLan-Chat-2-13b-fp16",
    "author": "yulan-team"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ReMM-v2-L2-13B",
    "average": 56.99,
    "arc": 61.95,
    "hellaswag": 84.0,
    "mmlu": 56.14,
    "truthfulqa": 50.81,
    "winogrande": 75.85,
    "gsm8k": 13.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "bc42c77f88482c37c72c85c66135e99972bbca1b",
    "model_name_for_query": "Undi95/ReMM-v2-L2-13B",
    "link": "https://huggingface.co/Undi95/ReMM-v2-L2-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrca-Platypus2-13B-GPTQ",
    "average": 56.98,
    "arc": 62.54,
    "hellaswag": 82.67,
    "mmlu": 58.56,
    "truthfulqa": 51.93,
    "winogrande": 76.8,
    "gsm8k": 9.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "cc-by-nc-4.0",
    "params": 16.24,
    "likes": 49.0,
    "still_on_hub": true,
    "revision": "0fa9a56066656fbc94e3ec088bc900fd1d4d38e8",
    "model_name_for_query": "TheBloke/OpenOrca-Platypus2-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/OpenOrca-Platypus2-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "GenAI-Nova-13B",
    "average": 56.98,
    "arc": 62.29,
    "hellaswag": 83.27,
    "mmlu": 59.47,
    "truthfulqa": 51.79,
    "winogrande": 77.35,
    "gsm8k": 7.73,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0ce62a64ca53cd5feb18f523a96dd3be86e6513d",
    "model_name_for_query": "PulsarAI/GenAI-Nova-13B",
    "link": "https://huggingface.co/PulsarAI/GenAI-Nova-13B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-m2.0",
    "average": 56.97,
    "arc": 63.14,
    "hellaswag": 85.19,
    "mmlu": 57.28,
    "truthfulqa": 48.07,
    "winogrande": 78.45,
    "gsm8k": 9.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "96af3dc6c9f2248d964cf14cef6e5f2e5894583a",
    "model_name_for_query": "jondurbin/airoboros-33b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "?",
    "model": "llama-30b",
    "average": 56.96,
    "arc": 61.43,
    "hellaswag": 84.73,
    "mmlu": 58.45,
    "truthfulqa": 42.27,
    "winogrande": 80.03,
    "gsm8k": 14.86,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.53,
    "likes": 37.0,
    "still_on_hub": true,
    "revision": "2b1edcdb3c7ced7bce6c1aa75c94545777c3118b",
    "model_name_for_query": "huggyllama/llama-30b",
    "link": "https://huggingface.co/huggyllama/llama-30b",
    "author": "huggyllama"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-30b",
    "average": 56.94,
    "arc": 61.26,
    "hellaswag": 84.73,
    "mmlu": 58.47,
    "truthfulqa": 42.27,
    "winogrande": 80.03,
    "gsm8k": 14.86,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "other",
    "params": 32.53,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "13c77caa472bfa79d4f3f0ec82cbdc9dd88e5d22",
    "model_name_for_query": "huggingface/llama-30b",
    "link": "https://huggingface.co/huggingface/llama-30b",
    "author": "huggingface"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-30B-hf-openassitant",
    "average": 56.94,
    "arc": 61.26,
    "hellaswag": 84.73,
    "mmlu": 58.47,
    "truthfulqa": 42.27,
    "winogrande": 80.03,
    "gsm8k": 14.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 32.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "fba493af11a73cf5a2ee7857dd7aecb98c659dc4",
    "model_name_for_query": "Yhyu13/llama-30B-hf-openassitant",
    "link": "https://huggingface.co/Yhyu13/llama-30B-hf-openassitant",
    "author": "Yhyu13"
  },
  {
    "T": "\ud83d\udd36",
    "model": "UndiMix-v4-13B",
    "average": 56.93,
    "arc": 61.95,
    "hellaswag": 83.88,
    "mmlu": 56.9,
    "truthfulqa": 48.96,
    "winogrande": 76.16,
    "gsm8k": 13.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "6dd97c74cfe1d22432d5c993814e230f333ba401",
    "model_name_for_query": "Undi95/UndiMix-v4-13B",
    "link": "https://huggingface.co/Undi95/UndiMix-v4-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-megacode2_min100",
    "average": 56.92,
    "arc": 60.58,
    "hellaswag": 81.26,
    "mmlu": 57.92,
    "truthfulqa": 48.89,
    "winogrande": 76.95,
    "gsm8k": 15.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b38d1b53c358a0313c69bcceebe97628327ada82",
    "model_name_for_query": "andreaskoepf/llama2-13b-megacode2_min100",
    "link": "https://huggingface.co/andreaskoepf/llama2-13b-megacode2_min100",
    "author": "andreaskoepf"
  },
  {
    "T": "\u2b55",
    "model": "LosslessMegaCoder-llama2-13b-mini",
    "average": 56.92,
    "arc": 60.58,
    "hellaswag": 81.26,
    "mmlu": 57.92,
    "truthfulqa": 48.89,
    "winogrande": 76.95,
    "gsm8k": 15.92,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "1f5609ffd40bc3af2dcbc5c88e9312d47a73c4b4",
    "model_name_for_query": "rombodawg/LosslessMegaCoder-llama2-13b-mini",
    "link": "https://huggingface.co/rombodawg/LosslessMegaCoder-llama2-13b-mini",
    "author": "rombodawg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-orca-v1",
    "average": 56.91,
    "arc": 62.2,
    "hellaswag": 82.32,
    "mmlu": 57.67,
    "truthfulqa": 49.6,
    "winogrande": 76.8,
    "gsm8k": 12.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "e77ec90f432bdffa210a0e4310d117e5d1c662df",
    "model_name_for_query": "circulus/Llama-2-13b-orca-v1",
    "link": "https://huggingface.co/circulus/Llama-2-13b-orca-v1",
    "author": "circulus"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Emerald-13B",
    "average": 56.89,
    "arc": 62.29,
    "hellaswag": 83.69,
    "mmlu": 55.7,
    "truthfulqa": 50.94,
    "winogrande": 75.93,
    "gsm8k": 12.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7696299463d8ec402a4e1eb001f3a447f1c5552",
    "model_name_for_query": "Undi95/Emerald-13B",
    "link": "https://huggingface.co/Undi95/Emerald-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ReMM-Mistral-13B",
    "average": 56.89,
    "arc": 62.2,
    "hellaswag": 83.82,
    "mmlu": 55.43,
    "truthfulqa": 53.32,
    "winogrande": 74.51,
    "gsm8k": 12.05,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": false,
    "revision": "a5ef9385d9430a81778183d71b58eb2b869d6a7e",
    "model_name_for_query": "Undi95/ReMM-Mistral-13B",
    "link": "https://huggingface.co/Undi95/ReMM-Mistral-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrcaxOpenChat-Preview2-13B-GPTQ",
    "average": 56.84,
    "arc": 61.26,
    "hellaswag": 82.14,
    "mmlu": 57.85,
    "truthfulqa": 50.22,
    "winogrande": 77.11,
    "gsm8k": 12.43,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "llama2",
    "params": 16.24,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "ec9eb4f471b5bb6a7e5e505369628586c0c72252",
    "model_name_for_query": "TheBloke/OpenOrcaxOpenChat-Preview2-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/OpenOrcaxOpenChat-Preview2-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "alpaca-cleaned-llama-30b-bf16",
    "average": 56.82,
    "arc": 61.77,
    "hellaswag": 85.06,
    "mmlu": 57.52,
    "truthfulqa": 51.49,
    "winogrande": 77.35,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "2424b6346e9e8fd749b9a6734f5d7125b5926daf",
    "model_name_for_query": "dsvv-cair/alpaca-cleaned-llama-30b-bf16",
    "link": "https://huggingface.co/dsvv-cair/alpaca-cleaned-llama-30b-bf16",
    "author": "dsvv-cair"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca-2-13b-SFT_v5",
    "average": 56.77,
    "arc": 59.22,
    "hellaswag": 80.09,
    "mmlu": 60.19,
    "truthfulqa": 51.84,
    "winogrande": 80.9,
    "gsm8k": 8.42,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "3c1b86e1a4e89119e373198ff018838988cc74d0",
    "model_name_for_query": "Locutusque/Orca-2-13b-SFT_v5",
    "link": "https://huggingface.co/Locutusque/Orca-2-13b-SFT_v5",
    "author": "Locutusque"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-6B-200K",
    "average": 56.76,
    "arc": 53.75,
    "hellaswag": 75.57,
    "mmlu": 64.65,
    "truthfulqa": 41.56,
    "winogrande": 73.64,
    "gsm8k": 31.39,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 6.06,
    "likes": 108.0,
    "still_on_hub": true,
    "revision": "6cb672ed8441c35d043dd3cda448466daa3b38b1",
    "model_name_for_query": "01-ai/Yi-6B-200K",
    "link": "https://huggingface.co/01-ai/Yi-6B-200K",
    "author": "01-ai"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2xOpenOrca-13B-IA3-v3",
    "average": 56.74,
    "arc": 62.54,
    "hellaswag": 82.1,
    "mmlu": 58.67,
    "truthfulqa": 46.96,
    "winogrande": 77.82,
    "gsm8k": 12.36,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "17493c1f2e4620a44d7947edad0386d338e805ce",
    "model_name_for_query": "yeontaek/Platypus2xOpenOrca-13B-IA3-v3",
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3-v3",
    "author": "yeontaek"
  },
  {
    "T": "\u2b55",
    "model": "Orca-Nova-13B",
    "average": 56.72,
    "arc": 62.37,
    "hellaswag": 82.47,
    "mmlu": 57.44,
    "truthfulqa": 45.97,
    "winogrande": 77.58,
    "gsm8k": 14.48,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5a6c3686749ecb76971a915403da8c07a98078a6",
    "model_name_for_query": "TFLai/Orca-Nova-13B",
    "link": "https://huggingface.co/TFLai/Orca-Nova-13B",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ReMM-v2.1-L2-13B",
    "average": 56.71,
    "arc": 61.43,
    "hellaswag": 83.92,
    "mmlu": 55.95,
    "truthfulqa": 50.3,
    "winogrande": 75.93,
    "gsm8k": 12.74,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e6b5ac97f74355cb281a621261debe5720fb4da2",
    "model_name_for_query": "Undi95/ReMM-v2.1-L2-13B",
    "link": "https://huggingface.co/Undi95/ReMM-v2.1-L2-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrcaxOpenChat-Preview2-13B",
    "average": 56.7,
    "arc": 62.71,
    "hellaswag": 81.99,
    "mmlu": 57.51,
    "truthfulqa": 47.45,
    "winogrande": 76.8,
    "gsm8k": 13.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 94.0,
    "still_on_hub": true,
    "revision": "26d1bc5c54c1f60a5de0b1ed4d0b16f285aee230",
    "model_name_for_query": "Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "link": "https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-6B-200K",
    "average": 56.69,
    "arc": 53.58,
    "hellaswag": 75.58,
    "mmlu": 64.65,
    "truthfulqa": 41.74,
    "winogrande": 74.27,
    "gsm8k": 30.33,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.06,
    "likes": 116.0,
    "still_on_hub": true,
    "revision": "6cb672ed8441c35d043dd3cda448466daa3b38b1",
    "model_name_for_query": "01-ai/Yi-6B-200K",
    "link": "https://huggingface.co/01-ai/Yi-6B-200K",
    "author": "01-ai"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2xOpenOrca-13B-IA3",
    "average": 56.65,
    "arc": 62.12,
    "hellaswag": 82.1,
    "mmlu": 58.84,
    "truthfulqa": 47.88,
    "winogrande": 77.11,
    "gsm8k": 11.83,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5ca46029dd22c007d4dc1706f6284a32be4546c2",
    "model_name_for_query": "yeontaek/Platypus2xOpenOrca-13B-IA3",
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3",
    "author": "yeontaek"
  },
  {
    "T": "\u2b55",
    "model": "storytime-13b",
    "average": 56.64,
    "arc": 62.03,
    "hellaswag": 83.96,
    "mmlu": 57.48,
    "truthfulqa": 52.5,
    "winogrande": 75.53,
    "gsm8k": 8.34,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "233568319a636b6a7b02a4def2c51d08a3e0fbfc",
    "model_name_for_query": "chargoddard/storytime-13b",
    "link": "https://huggingface.co/chargoddard/storytime-13b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "unraveled-7b-a1",
    "average": 56.63,
    "arc": 59.81,
    "hellaswag": 82.8,
    "mmlu": 63.39,
    "truthfulqa": 42.23,
    "winogrande": 77.19,
    "gsm8k": 14.33,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fac05775fa8121b58cda8031b7001323bd43983d",
    "model_name_for_query": "ZoidBB/unraveled-7b-a1",
    "link": "https://huggingface.co/ZoidBB/unraveled-7b-a1",
    "author": "ZoidBB"
  },
  {
    "T": "\u2b55",
    "model": "duplicitous-slurpbeast-13b",
    "average": 56.62,
    "arc": 62.12,
    "hellaswag": 83.92,
    "mmlu": 57.53,
    "truthfulqa": 52.33,
    "winogrande": 75.06,
    "gsm8k": 8.79,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "88dc61b7afebf2220ca42898e1286c59961ed440",
    "model_name_for_query": "chargoddard/duplicitous-slurpbeast-13b",
    "link": "https://huggingface.co/chargoddard/duplicitous-slurpbeast-13b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Amethyst-13B-Mistral",
    "average": 56.62,
    "arc": 62.63,
    "hellaswag": 83.17,
    "mmlu": 55.91,
    "truthfulqa": 52.43,
    "winogrande": 74.74,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": false,
    "revision": "4328809e568f01e3f0a05764e3bb58e901310415",
    "model_name_for_query": "Undi95/Amethyst-13B-Mistral",
    "link": "https://huggingface.co/Undi95/Amethyst-13B-Mistral",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Amethyst-13B",
    "average": 56.62,
    "arc": 62.63,
    "hellaswag": 83.17,
    "mmlu": 55.91,
    "truthfulqa": 52.43,
    "winogrande": 74.74,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d4a85b1006f0b9439e64f0e7400533a7b867c24d",
    "model_name_for_query": "Undi95/Amethyst-13B",
    "link": "https://huggingface.co/Undi95/Amethyst-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BELLE-Llama2-13B-chat-0.4M",
    "average": 56.62,
    "arc": 60.67,
    "hellaswag": 82.31,
    "mmlu": 55.94,
    "truthfulqa": 50.85,
    "winogrande": 75.53,
    "gsm8k": 14.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 27.0,
    "still_on_hub": true,
    "revision": "1776feacbf1052cff02eb3d7531a854555d3f6dc",
    "model_name_for_query": "BELLE-2/BELLE-Llama2-13B-chat-0.4M",
    "link": "https://huggingface.co/BELLE-2/BELLE-Llama2-13B-chat-0.4M",
    "author": "BELLE-2"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Clover3-17B",
    "average": 56.61,
    "arc": 59.9,
    "hellaswag": 81.18,
    "mmlu": 60.47,
    "truthfulqa": 40.72,
    "winogrande": 78.61,
    "gsm8k": 18.8,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 16.84,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "428f6f58869426baae2c49442b207a15bc2da3cc",
    "model_name_for_query": "Undi95/Clover3-17B",
    "link": "https://huggingface.co/Undi95/Clover3-17B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chronos-33b",
    "average": 56.59,
    "arc": 62.2,
    "hellaswag": 83.48,
    "mmlu": 55.87,
    "truthfulqa": 46.67,
    "winogrande": 78.3,
    "gsm8k": 13.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 23.0,
    "still_on_hub": true,
    "revision": "3c11f81d9180618f13777276b1eb0eb70ab99cf0",
    "model_name_for_query": "elinas/chronos-33b",
    "link": "https://huggingface.co/elinas/chronos-33b",
    "author": "elinas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LlongOrca-13B-16k",
    "average": 56.59,
    "arc": 62.46,
    "hellaswag": 82.75,
    "mmlu": 55.54,
    "truthfulqa": 50.11,
    "winogrande": 76.4,
    "gsm8k": 12.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "8ea1fb205553cadbc90069d80a7e58281b6281c3",
    "model_name_for_query": "Open-Orca/LlongOrca-13B-16k",
    "link": "https://huggingface.co/Open-Orca/LlongOrca-13B-16k",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-megacode2-oasst",
    "average": 56.59,
    "arc": 60.67,
    "hellaswag": 81.93,
    "mmlu": 57.38,
    "truthfulqa": 47.85,
    "winogrande": 76.16,
    "gsm8k": 15.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "2c45ecf161da2ff2aa984900f2e4d2b7a7311ab8",
    "model_name_for_query": "OpenAssistant/llama2-13b-megacode2-oasst",
    "link": "https://huggingface.co/OpenAssistant/llama2-13b-megacode2-oasst",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Slerpeno",
    "average": 56.59,
    "arc": 61.69,
    "hellaswag": 84.1,
    "mmlu": 56.77,
    "truthfulqa": 48.05,
    "winogrande": 76.4,
    "gsm8k": 12.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-4.0",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "7ff32abd17851a769a031659e91e660f219be363",
    "model_name_for_query": "Brouz/Slerpeno",
    "link": "https://huggingface.co/Brouz/Slerpeno",
    "author": "Brouz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "NyakuraV2.1-m7",
    "average": 56.57,
    "arc": 58.62,
    "hellaswag": 81.89,
    "mmlu": 58.46,
    "truthfulqa": 45.01,
    "winogrande": 72.77,
    "gsm8k": 22.67,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0a1cd69beed347cd80a290ce5b568c03264ec595",
    "model_name_for_query": "Sao10K/NyakuraV2.1-m7",
    "link": "https://huggingface.co/Sao10K/NyakuraV2.1-m7",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "duplicitous-mammal-13b",
    "average": 56.57,
    "arc": 61.69,
    "hellaswag": 83.79,
    "mmlu": 57.5,
    "truthfulqa": 52.27,
    "winogrande": 75.06,
    "gsm8k": 9.1,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a05d0562b8da2ac2e76aa65984e8063249bc85c8",
    "model_name_for_query": "chargoddard/duplicitous-mammal-13b",
    "link": "https://huggingface.co/chargoddard/duplicitous-mammal-13b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenRP-13B",
    "average": 56.57,
    "arc": 62.12,
    "hellaswag": 82.6,
    "mmlu": 57.5,
    "truthfulqa": 48.29,
    "winogrande": 76.01,
    "gsm8k": 12.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "d11815287c51ef51485fb003f8f72773cf6f19a4",
    "model_name_for_query": "Undi95/OpenRP-13B",
    "link": "https://huggingface.co/Undi95/OpenRP-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MM-ReMM-L2-20B",
    "average": 56.55,
    "arc": 60.84,
    "hellaswag": 85.18,
    "mmlu": 56.45,
    "truthfulqa": 53.33,
    "winogrande": 75.77,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 19.99,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "37869800c15fb37d017ea83bb50fec6d6141f6ba",
    "model_name_for_query": "Undi95/MM-ReMM-L2-20B",
    "link": "https://huggingface.co/Undi95/MM-ReMM-L2-20B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BerrySauce-L2-13b",
    "average": 56.55,
    "arc": 62.29,
    "hellaswag": 83.78,
    "mmlu": 57.1,
    "truthfulqa": 48.3,
    "winogrande": 76.09,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c8788874b78c84bc5593586d16fbd8ae7b5b2991",
    "model_name_for_query": "sauce1337/BerrySauce-L2-13b",
    "link": "https://huggingface.co/sauce1337/BerrySauce-L2-13b",
    "author": "sauce1337"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MLewdBoros-L2-13B",
    "average": 56.51,
    "arc": 62.54,
    "hellaswag": 83.9,
    "mmlu": 56.57,
    "truthfulqa": 48.14,
    "winogrande": 76.95,
    "gsm8k": 10.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "a3033ac5825662f1c66418d7543648dc76980185",
    "model_name_for_query": "Undi95/MLewdBoros-L2-13B",
    "link": "https://huggingface.co/Undi95/MLewdBoros-L2-13B",
    "author": "Undi95"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2xOpenOrca-13B-IA3-v4",
    "average": 56.49,
    "arc": 61.43,
    "hellaswag": 81.84,
    "mmlu": 59.02,
    "truthfulqa": 48.64,
    "winogrande": 77.19,
    "gsm8k": 10.84,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3aa9abe9cb2e5c699f80935e04fbb351cdfbf21b",
    "model_name_for_query": "yeontaek/Platypus2xOpenOrca-13B-IA3-v4",
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3-v4",
    "author": "yeontaek"
  },
  {
    "T": "\u2b55",
    "model": "EnsembleV5-Nova-13B",
    "average": 56.49,
    "arc": 62.71,
    "hellaswag": 82.55,
    "mmlu": 56.79,
    "truthfulqa": 49.86,
    "winogrande": 76.24,
    "gsm8k": 10.77,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7ba38d309709d35149b4a18f94096875885035ae",
    "model_name_for_query": "TFLai/EnsembleV5-Nova-13B",
    "link": "https://huggingface.co/TFLai/EnsembleV5-Nova-13B",
    "author": "TFLai"
  },
  {
    "T": "\u2b55",
    "model": "EnsembleV5-Nova-13B",
    "average": 56.49,
    "arc": 62.71,
    "hellaswag": 82.55,
    "mmlu": 56.79,
    "truthfulqa": 49.86,
    "winogrande": 76.24,
    "gsm8k": 10.77,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3e25556187ba576082a85c270d2d4b4ea6ea9f6f",
    "model_name_for_query": "PulsarAI/EnsembleV5-Nova-13B",
    "link": "https://huggingface.co/PulsarAI/EnsembleV5-Nova-13B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mythalion-13b",
    "average": 56.48,
    "arc": 61.26,
    "hellaswag": 83.81,
    "mmlu": 56.53,
    "truthfulqa": 46.56,
    "winogrande": 77.43,
    "gsm8k": 13.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 58.0,
    "still_on_hub": true,
    "revision": "24916f62b8243a7e4646ea53eeb45d890cbd308f",
    "model_name_for_query": "PygmalionAI/mythalion-13b",
    "link": "https://huggingface.co/PygmalionAI/mythalion-13b",
    "author": "PygmalionAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-code-mistral-7b-v2.0",
    "average": 56.47,
    "arc": 52.47,
    "hellaswag": 75.61,
    "mmlu": 51.31,
    "truthfulqa": 52.05,
    "winogrande": 71.43,
    "gsm8k": 35.94,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8371b49e786758da62de015daa006c0e58b7ce82",
    "model_name_for_query": "uukuguy/speechless-code-mistral-7b-v2.0",
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-7b-v2.0",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-30B-Uncensored",
    "average": 56.46,
    "arc": 60.24,
    "hellaswag": 82.93,
    "mmlu": 56.8,
    "truthfulqa": 51.57,
    "winogrande": 74.35,
    "gsm8k": 12.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 118.0,
    "still_on_hub": true,
    "revision": "761783745fcb97831ad8035d3cbd5de484aca3ce",
    "model_name_for_query": "ehartford/WizardLM-30B-Uncensored",
    "link": "https://huggingface.co/ehartford/WizardLM-30B-Uncensored",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SciPhi-Self-RAG-Mistral-7B-32k",
    "average": 56.46,
    "arc": 57.34,
    "hellaswag": 80.44,
    "mmlu": 60.81,
    "truthfulqa": 45.63,
    "winogrande": 74.82,
    "gsm8k": 19.71,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.0,
    "likes": 38.0,
    "still_on_hub": true,
    "revision": "640192e2ba5898f87c407a9f771fc270f7628dee",
    "model_name_for_query": "SciPhi/SciPhi-Self-RAG-Mistral-7B-32k",
    "link": "https://huggingface.co/SciPhi/SciPhi-Self-RAG-Mistral-7B-32k",
    "author": "SciPhi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pygmalion-2-13b-SuperCOT",
    "average": 56.46,
    "arc": 63.23,
    "hellaswag": 83.68,
    "mmlu": 54.9,
    "truthfulqa": 53.14,
    "winogrande": 77.51,
    "gsm8k": 6.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "763b3fd5afc3e7fb6c7c8768d40f06901c8d5913",
    "model_name_for_query": "royallab/Pygmalion-2-13b-SuperCOT",
    "link": "https://huggingface.co/royallab/Pygmalion-2-13b-SuperCOT",
    "author": "royallab"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-Inverted-L2-13B",
    "average": 56.44,
    "arc": 59.3,
    "hellaswag": 82.9,
    "mmlu": 56.45,
    "truthfulqa": 52.04,
    "winogrande": 74.74,
    "gsm8k": 13.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "efaf592c95ae8e769e0d56d36ba4ed23e3bf4059",
    "model_name_for_query": "Sao10K/Stheno-Inverted-L2-13B",
    "link": "https://huggingface.co/Sao10K/Stheno-Inverted-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "Nova-13B",
    "average": 56.44,
    "arc": 62.71,
    "hellaswag": 82.57,
    "mmlu": 57.98,
    "truthfulqa": 51.34,
    "winogrande": 77.27,
    "gsm8k": 6.75,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "ae1145f9fa846ab8d39d8b7da888287ef917efb5",
    "model_name_for_query": "TFLai/Nova-13B",
    "link": "https://huggingface.co/TFLai/Nova-13B",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-L2-13B",
    "average": 56.43,
    "arc": 61.01,
    "hellaswag": 83.95,
    "mmlu": 56.33,
    "truthfulqa": 50.18,
    "winogrande": 75.14,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "c4e7b771e30fdbfd6bd2e66a6928024bd5692bbd",
    "model_name_for_query": "Sao10K/Stheno-L2-13B",
    "link": "https://huggingface.co/Sao10K/Stheno-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mythical-Destroyer-L2-13B",
    "average": 56.39,
    "arc": 58.7,
    "hellaswag": 82.0,
    "mmlu": 57.66,
    "truthfulqa": 56.35,
    "winogrande": 74.66,
    "gsm8k": 8.95,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "7c87376b201b1c30c4e12c0b7bc2f28f017ce7bc",
    "model_name_for_query": "Sao10K/Mythical-Destroyer-L2-13B",
    "link": "https://huggingface.co/Sao10K/Mythical-Destroyer-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_7b_merge_orcafamily",
    "average": 56.38,
    "arc": 56.91,
    "hellaswag": 81.17,
    "mmlu": 51.49,
    "truthfulqa": 49.68,
    "winogrande": 75.93,
    "gsm8k": 23.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fb65f697de632f2f3fef57fc3cd12fb5e4913a89",
    "model_name_for_query": "yeen214/llama2_7b_merge_orcafamily",
    "link": "https://huggingface.co/yeen214/llama2_7b_merge_orcafamily",
    "author": "yeen214"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-AdventurousWinds-Mk2-7b",
    "average": 56.38,
    "arc": 58.19,
    "hellaswag": 83.48,
    "mmlu": 61.8,
    "truthfulqa": 43.56,
    "winogrande": 76.32,
    "gsm8k": 14.94,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "cfcc969a7e97275b2298253f1eabf4575e5a3768",
    "model_name_for_query": "PocketDoc/Dans-AdventurousWinds-Mk2-7b",
    "link": "https://huggingface.co/PocketDoc/Dans-AdventurousWinds-Mk2-7b",
    "author": "PocketDoc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MLewd-v2.4-13B",
    "average": 56.37,
    "arc": 61.69,
    "hellaswag": 83.83,
    "mmlu": 55.1,
    "truthfulqa": 53.34,
    "winogrande": 74.51,
    "gsm8k": 9.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "6f6ec6024ee054020e49fd96f149919692848f0b",
    "model_name_for_query": "Undi95/MLewd-v2.4-13B",
    "link": "https://huggingface.co/Undi95/MLewd-v2.4-13B",
    "author": "Undi95"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-l2-13b-2.2.1",
    "average": 56.36,
    "arc": 60.92,
    "hellaswag": 83.77,
    "mmlu": 56.47,
    "truthfulqa": 49.42,
    "winogrande": 76.01,
    "gsm8k": 11.6,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "9b2dbc1f6f17a162228799df6e9449c903ddf04d",
    "model_name_for_query": "jondurbin/airoboros-l2-13b-2.2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-2.2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_v3.1",
    "average": 56.36,
    "arc": 59.81,
    "hellaswag": 82.8,
    "mmlu": 56.76,
    "truthfulqa": 44.45,
    "winogrande": 76.24,
    "gsm8k": 18.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "a95be7130d32da99bcd484f6f436b2dd49341110",
    "model_name_for_query": "openchat/openchat_v3.1",
    "link": "https://huggingface.co/openchat/openchat_v3.1",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CalliopeDS-L2-13B",
    "average": 56.34,
    "arc": 60.49,
    "hellaswag": 83.38,
    "mmlu": 55.8,
    "truthfulqa": 51.32,
    "winogrande": 77.03,
    "gsm8k": 10.01,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "agpl-3.0",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "b373eda586a6527e62382eda5480204652a82499",
    "model_name_for_query": "Doctor-Shotgun/CalliopeDS-L2-13B",
    "link": "https://huggingface.co/Doctor-Shotgun/CalliopeDS-L2-13B",
    "author": "Doctor-Shotgun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLAMA-13B-test-finetuning",
    "average": 56.34,
    "arc": 58.02,
    "hellaswag": 82.36,
    "mmlu": 54.27,
    "truthfulqa": 44.14,
    "winogrande": 76.72,
    "gsm8k": 22.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5bd0eb026b12c59fd198f307c0c17188af69744c",
    "model_name_for_query": "iGenius-AI-Team/LLAMA-13B-test-finetuning",
    "link": "https://huggingface.co/iGenius-AI-Team/LLAMA-13B-test-finetuning",
    "author": "iGenius-AI-Team"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MythoMix-L2-13b",
    "average": 56.31,
    "arc": 61.09,
    "hellaswag": 83.86,
    "mmlu": 55.42,
    "truthfulqa": 52.08,
    "winogrande": 75.45,
    "gsm8k": 9.93,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "eca790fb9394c9c61be27ef709080b3b92783a45",
    "model_name_for_query": "Gryphe/MythoMix-L2-13b",
    "link": "https://huggingface.co/Gryphe/MythoMix-L2-13b",
    "author": "Gryphe"
  },
  {
    "T": "\u2b55",
    "model": "mistral-7b_open_platypus",
    "average": 56.29,
    "arc": 55.8,
    "hellaswag": 82.13,
    "mmlu": 59.76,
    "truthfulqa": 48.87,
    "winogrande": 78.61,
    "gsm8k": 12.59,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b9a60b9ad0fe06bd314ffe99d543f1df6ecd10da",
    "model_name_for_query": "lgaalves/mistral-7b_open_platypus",
    "link": "https://huggingface.co/lgaalves/mistral-7b_open_platypus",
    "author": "lgaalves"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2xOpenOrca-13B-IA3-v2.1",
    "average": 56.29,
    "arc": 62.29,
    "hellaswag": 82.09,
    "mmlu": 57.91,
    "truthfulqa": 47.03,
    "winogrande": 77.43,
    "gsm8k": 10.99,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "31e1e3235515717a151915131bc970be188d964e",
    "model_name_for_query": "yeontaek/Platypus2xOpenOrca-13B-IA3-v2.1",
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3-v2.1",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Uncensored-Jordan-13B",
    "average": 56.27,
    "arc": 57.42,
    "hellaswag": 82.7,
    "mmlu": 55.75,
    "truthfulqa": 50.51,
    "winogrande": 76.16,
    "gsm8k": 15.09,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 13.0,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "c56a396342133bbd75ab3f79622c85cb55be49a4",
    "model_name_for_query": "ajibawa-2023/Uncensored-Jordan-13B",
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Jordan-13B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-code-mistral-orca-7b-v1.0",
    "average": 56.24,
    "arc": 59.64,
    "hellaswag": 82.25,
    "mmlu": 61.33,
    "truthfulqa": 48.45,
    "winogrande": 77.51,
    "gsm8k": 8.26,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "f7db67fe6c82657b35d0ffcf8b7ff1568d979482",
    "model_name_for_query": "uukuguy/speechless-code-mistral-orca-7b-v1.0",
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-orca-7b-v1.0",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "StableBeluga-13B-instruct-PL-lora_unload",
    "average": 56.24,
    "arc": 60.92,
    "hellaswag": 82.13,
    "mmlu": 56.99,
    "truthfulqa": 48.64,
    "winogrande": 76.56,
    "gsm8k": 12.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6e1a6e1f91f6ac97b643be1bd24be6096e2e7dd3",
    "model_name_for_query": "Aspik101/StableBeluga-13B-instruct-PL-lora_unload",
    "link": "https://huggingface.co/Aspik101/StableBeluga-13B-instruct-PL-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MythoLogic-L2-13b",
    "average": 56.19,
    "arc": 61.01,
    "hellaswag": 83.93,
    "mmlu": 55.7,
    "truthfulqa": 48.64,
    "winogrande": 76.09,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "665948fc79acc2bcce3e9e7d2b0689ca43ae62d4",
    "model_name_for_query": "Gryphe/MythoLogic-L2-13b",
    "link": "https://huggingface.co/Gryphe/MythoLogic-L2-13b",
    "author": "Gryphe"
  },
  {
    "T": "\u2b55",
    "model": "Synatra-11B-Testbench",
    "average": 56.17,
    "arc": 57.34,
    "hellaswag": 78.66,
    "mmlu": 55.56,
    "truthfulqa": 51.97,
    "winogrande": 75.77,
    "gsm8k": 17.74,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 11.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9399ea6c2a1d955e31d6b4d68b2b86115aea0e59",
    "model_name_for_query": "maywell/Synatra-11B-Testbench",
    "link": "https://huggingface.co/maywell/Synatra-11B-Testbench",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-1.2-L2-13B",
    "average": 56.15,
    "arc": 60.75,
    "hellaswag": 83.67,
    "mmlu": 56.27,
    "truthfulqa": 50.32,
    "winogrande": 74.98,
    "gsm8k": 10.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e76f35fe771ef142d6629092bd4a93301fd6cd4a",
    "model_name_for_query": "Sao10K/Stheno-1.2-L2-13B",
    "link": "https://huggingface.co/Sao10K/Stheno-1.2-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "SpeechlessV1-Nova-13B",
    "average": 56.14,
    "arc": 61.77,
    "hellaswag": 82.68,
    "mmlu": 57.75,
    "truthfulqa": 51.44,
    "winogrande": 77.43,
    "gsm8k": 5.76,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fbe6f0e32b5ecf9d75510d0b11a286466f46d79e",
    "model_name_for_query": "TFLai/SpeechlessV1-Nova-13B",
    "link": "https://huggingface.co/TFLai/SpeechlessV1-Nova-13B",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "NewHope_HF_not_official",
    "average": 56.11,
    "arc": 61.09,
    "hellaswag": 84.03,
    "mmlu": 55.73,
    "truthfulqa": 44.96,
    "winogrande": 74.98,
    "gsm8k": 15.85,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f587f4a31de6818f4200d9cdc7f116ca8ba1cdc2",
    "model_name_for_query": "WhoTookMyAmogusNickname/NewHope_HF_not_official",
    "link": "https://huggingface.co/WhoTookMyAmogusNickname/NewHope_HF_not_official",
    "author": "WhoTookMyAmogusNickname"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chronos-hermes-13b-v2",
    "average": 56.1,
    "arc": 60.32,
    "hellaswag": 83.21,
    "mmlu": 55.05,
    "truthfulqa": 50.91,
    "winogrande": 75.37,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "2f0e2cb734685a6ce0736a9f3e909a795d7592cc",
    "model_name_for_query": "Austism/chronos-hermes-13b-v2",
    "link": "https://huggingface.co/Austism/chronos-hermes-13b-v2",
    "author": "Austism"
  },
  {
    "T": "\u2b55",
    "model": "Nebula-7B",
    "average": 56.1,
    "arc": 59.3,
    "hellaswag": 83.46,
    "mmlu": 57.0,
    "truthfulqa": 45.56,
    "winogrande": 76.4,
    "gsm8k": 14.86,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "569f848698a468fb03d37033c67f3734bbaec127",
    "model_name_for_query": "PulsarAI/Nebula-7B",
    "link": "https://huggingface.co/PulsarAI/Nebula-7B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "prometheus-13b-v1.0",
    "average": 56.09,
    "arc": 53.24,
    "hellaswag": 80.75,
    "mmlu": 51.49,
    "truthfulqa": 45.66,
    "winogrande": 73.72,
    "gsm8k": 31.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 29.0,
    "still_on_hub": true,
    "revision": "9088377314f91af4b48940e09a0c76d0878f5020",
    "model_name_for_query": "kaist-ai/prometheus-13b-v1.0",
    "link": "https://huggingface.co/kaist-ai/prometheus-13b-v1.0",
    "author": "kaist-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "qCammel-13",
    "average": 56.05,
    "arc": 60.84,
    "hellaswag": 83.66,
    "mmlu": 56.73,
    "truthfulqa": 47.54,
    "winogrande": 76.16,
    "gsm8k": 11.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "af473e64f6a4fa02a7e24ee7679eea9505eb179d",
    "model_name_for_query": "augtoma/qCammel-13",
    "link": "https://huggingface.co/augtoma/qCammel-13",
    "author": "augtoma"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Huginn-13b-v1.2",
    "average": 56.03,
    "arc": 60.92,
    "hellaswag": 83.56,
    "mmlu": 55.33,
    "truthfulqa": 51.97,
    "winogrande": 75.22,
    "gsm8k": 9.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "cb3562e7aae05a95fe61610b7b8f4957d3529ce7",
    "model_name_for_query": "The-Face-Of-Goonery/Huginn-13b-v1.2",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-v1.2",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ReMM-SLERP-L2-13B",
    "average": 56.03,
    "arc": 60.92,
    "hellaswag": 83.56,
    "mmlu": 55.33,
    "truthfulqa": 51.97,
    "winogrande": 75.22,
    "gsm8k": 9.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "27baccf242bc1dc34fc39661a40bbf867cbea8b5",
    "model_name_for_query": "Undi95/ReMM-SLERP-L2-13B",
    "link": "https://huggingface.co/Undi95/ReMM-SLERP-L2-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "carl-33b",
    "average": 56.03,
    "arc": 64.59,
    "hellaswag": 85.27,
    "mmlu": 58.38,
    "truthfulqa": 45.32,
    "winogrande": 76.24,
    "gsm8k": 6.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 32.32,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "5f80b372b493d901cab4490b4f23c71499023615",
    "model_name_for_query": "ajibawa-2023/carl-33b",
    "link": "https://huggingface.co/ajibawa-2023/carl-33b",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "synapsellm-7b-mistral-v0.5-preview",
    "average": 56.03,
    "arc": 52.73,
    "hellaswag": 76.51,
    "mmlu": 54.67,
    "truthfulqa": 55.16,
    "winogrande": 74.35,
    "gsm8k": 22.74,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d1b4d9a4657d145ce7cda431ed46076c1518af55",
    "model_name_for_query": "WebraftAI/synapsellm-7b-mistral-v0.5-preview",
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.5-preview",
    "author": "WebraftAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neural-chat-7b-v3-1-Nebula-v2-7B",
    "average": 56.01,
    "arc": 61.77,
    "hellaswag": 80.21,
    "mmlu": 59.07,
    "truthfulqa": 58.56,
    "winogrande": 71.82,
    "gsm8k": 4.62,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "0b98e4ca35764da09cabcaaebbdac1f827629219",
    "model_name_for_query": "Weyaxi/neural-chat-7b-v3-1-Nebula-v2-7B",
    "link": "https://huggingface.co/Weyaxi/neural-chat-7b-v3-1-Nebula-v2-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MythoMax-L2-13b",
    "average": 56.0,
    "arc": 60.92,
    "hellaswag": 83.56,
    "mmlu": 55.33,
    "truthfulqa": 51.97,
    "winogrande": 75.22,
    "gsm8k": 9.02,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 119.0,
    "still_on_hub": true,
    "revision": "faa4ef8c87dbb00d447904ceb048d49b6a463d07",
    "model_name_for_query": "Gryphe/MythoMax-L2-13b",
    "link": "https://huggingface.co/Gryphe/MythoMax-L2-13b",
    "author": "Gryphe"
  },
  {
    "T": "\u2b55",
    "model": "huginnv1.2",
    "average": 55.98,
    "arc": 62.37,
    "hellaswag": 84.28,
    "mmlu": 57.02,
    "truthfulqa": 47.81,
    "winogrande": 75.22,
    "gsm8k": 9.17,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "aed4ddc951c657993939fa5b87a4088550569a3b",
    "model_name_for_query": "The-Face-Of-Goonery/huginnv1.2",
    "link": "https://huggingface.co/The-Face-Of-Goonery/huginnv1.2",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Hermes-Llama2-13b",
    "average": 55.97,
    "arc": 61.52,
    "hellaswag": 83.29,
    "mmlu": 55.11,
    "truthfulqa": 50.38,
    "winogrande": 75.45,
    "gsm8k": 10.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": ["mit"],
    "params": 12.85,
    "likes": 221.0,
    "still_on_hub": true,
    "revision": "8f95aa9cd207db7b24179fc779c2b8973e71bee2",
    "model_name_for_query": "NousResearch/Nous-Hermes-Llama2-13b",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Samantha-1.11-13b",
    "average": 55.97,
    "arc": 60.84,
    "hellaswag": 82.99,
    "mmlu": 55.96,
    "truthfulqa": 47.72,
    "winogrande": 76.01,
    "gsm8k": 12.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "e355ead3a939f471fe2586201156fb972fad0f4b",
    "model_name_for_query": "ehartford/Samantha-1.11-13b",
    "link": "https://huggingface.co/ehartford/Samantha-1.11-13b",
    "author": "ehartford"
  },
  {
    "T": "\u2b55",
    "model": "Walter-SOLAR-11B",
    "average": 55.95,
    "arc": 60.41,
    "hellaswag": 84.86,
    "mmlu": 64.99,
    "truthfulqa": 44.88,
    "winogrande": 79.56,
    "gsm8k": 0.99,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e7bbf8ba7572aced748c7fc7368dc024e2df7df0",
    "model_name_for_query": "KnutJaegersberg/Walter-SOLAR-11B",
    "link": "https://huggingface.co/KnutJaegersberg/Walter-SOLAR-11B",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Hermes-13B-Code",
    "average": 55.93,
    "arc": 61.18,
    "hellaswag": 83.21,
    "mmlu": 55.13,
    "truthfulqa": 50.56,
    "winogrande": 75.14,
    "gsm8k": 10.39,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "5a45cb2a6442581ce32cc19c561c49cec1db4ebb",
    "model_name_for_query": "Undi95/Nous-Hermes-13B-Code",
    "link": "https://huggingface.co/Undi95/Nous-Hermes-13B-Code",
    "author": "Undi95"
  },
  {
    "T": "\u2b55",
    "model": "Chat-AYB-Platypus2-13B",
    "average": 55.93,
    "arc": 60.49,
    "hellaswag": 84.03,
    "mmlu": 57.83,
    "truthfulqa": 54.52,
    "winogrande": 75.77,
    "gsm8k": 2.96,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5a54eb9d5a66df4720ec52422f5627ccd94d5fd6",
    "model_name_for_query": "PulsarAI/Chat-AYB-Platypus2-13B",
    "link": "https://huggingface.co/PulsarAI/Chat-AYB-Platypus2-13B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "synapsellm-7b-mistral-v0.4-preview2",
    "average": 55.93,
    "arc": 52.99,
    "hellaswag": 74.54,
    "mmlu": 54.6,
    "truthfulqa": 53.79,
    "winogrande": 73.95,
    "gsm8k": 25.7,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "59e4ad04a24b656401fab0e8f20de387aaa95512",
    "model_name_for_query": "WebraftAI/synapsellm-7b-mistral-v0.4-preview2",
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.4-preview2",
    "author": "WebraftAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "synapsellm-7b-mistral-v0.5-preview2",
    "average": 55.93,
    "arc": 52.22,
    "hellaswag": 75.54,
    "mmlu": 51.64,
    "truthfulqa": 55.47,
    "winogrande": 73.09,
    "gsm8k": 27.6,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b6378fa3b7d39f946d3ce1e0b854622c2866cf7e",
    "model_name_for_query": "WebraftAI/synapsellm-7b-mistral-v0.5-preview2",
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.5-preview2",
    "author": "WebraftAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "AppleSauce-L2-13b",
    "average": 55.91,
    "arc": 61.01,
    "hellaswag": 83.61,
    "mmlu": 57.07,
    "truthfulqa": 47.81,
    "winogrande": 75.93,
    "gsm8k": 10.01,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ba253c52eb85e24987c81e5d36b5a9a00e276ce7",
    "model_name_for_query": "sauce1337/AppleSauce-L2-13b",
    "link": "https://huggingface.co/sauce1337/AppleSauce-L2-13b",
    "author": "sauce1337"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-13B-v1.2",
    "average": 55.9,
    "arc": 61.26,
    "hellaswag": 82.93,
    "mmlu": 56.47,
    "truthfulqa": 47.27,
    "winogrande": 76.48,
    "gsm8k": 10.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "60d4937ac3c4dcb84c40bbf7265c5cc7f5f3d4f9",
    "model_name_for_query": "migtissera/Synthia-13B-v1.2",
    "link": "https://huggingface.co/migtissera/Synthia-13B-v1.2",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama2-34b-v11.1-bf16",
    "average": 55.88,
    "arc": 50.0,
    "hellaswag": 71.19,
    "mmlu": 55.71,
    "truthfulqa": 53.01,
    "winogrande": 70.8,
    "gsm8k": 34.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 33.53,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "21ac0d26c0097e5ac5b4a757493574b156da7731",
    "model_name_for_query": "openBuddy/openbuddy-llama2-34b-v11.1-bf16",
    "link": "https://huggingface.co/openBuddy/openbuddy-llama2-34b-v11.1-bf16",
    "author": "openBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-codellama2-34b-v11.1-bf16",
    "average": 55.88,
    "arc": 50.0,
    "hellaswag": 71.19,
    "mmlu": 55.71,
    "truthfulqa": 53.01,
    "winogrande": 70.8,
    "gsm8k": 34.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 33.53,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "1b361b3634bf59913b47c9dad1b138e99833472b",
    "model_name_for_query": "OpenBuddy/openbuddy-codellama2-34b-v11.1-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-codellama2-34b-v11.1-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama2-13b-v1.2",
    "average": 55.87,
    "arc": 60.67,
    "hellaswag": 80.46,
    "mmlu": 56.51,
    "truthfulqa": 51.03,
    "winogrande": 74.82,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "97279d20a8c7e2d0576c9ff4b2e15a421c40d58a",
    "model_name_for_query": "YeungNLP/firefly-llama2-13b-v1.2",
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b-v1.2",
    "author": "YeungNLP"
  },
  {
    "T": "\u2b55",
    "model": "Synatra-V0.1-7B-Instruct",
    "average": 55.86,
    "arc": 55.29,
    "hellaswag": 76.63,
    "mmlu": 55.29,
    "truthfulqa": 55.76,
    "winogrande": 72.77,
    "gsm8k": 19.41,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.11,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "7ee3416f31a3c7e8d5ab4295ac1b641075f36345",
    "model_name_for_query": "maywell/Synatra-V0.1-7B-Instruct",
    "link": "https://huggingface.co/maywell/Synatra-V0.1-7B-Instruct",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synatra-V0.1-7B",
    "average": 55.86,
    "arc": 55.29,
    "hellaswag": 76.63,
    "mmlu": 55.29,
    "truthfulqa": 55.76,
    "winogrande": 72.77,
    "gsm8k": 19.41,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.11,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "7ee3416f31a3c7e8d5ab4295ac1b641075f36345",
    "model_name_for_query": "maywell/Synatra-V0.1-7B",
    "link": "https://huggingface.co/maywell/Synatra-V0.1-7B",
    "author": "maywell"
  },
  {
    "T": "\ud83d\udd36",
    "model": "7B-DPO-alpha",
    "average": 55.84,
    "arc": 50.85,
    "hellaswag": 73.0,
    "mmlu": 63.39,
    "truthfulqa": 57.58,
    "winogrande": 67.56,
    "gsm8k": 22.67,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "wtfpl",
    "params": 7.0,
    "likes": 46.0,
    "still_on_hub": false,
    "revision": "36501a519950fb80c2e7df77e12c9110dca580f4",
    "model_name_for_query": "CausalLM/7B-DPO-alpha",
    "link": "https://huggingface.co/CausalLM/7B-DPO-alpha",
    "author": "CausalLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-7B-Instruct-v0.2-DARE",
    "average": 55.84,
    "arc": 61.95,
    "hellaswag": 75.62,
    "mmlu": 49.99,
    "truthfulqa": 54.36,
    "winogrande": 74.98,
    "gsm8k": 18.12,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "98731ddd2dd52fd1b2c69c4cb95bbb1ac03ce496",
    "model_name_for_query": "janhq/Mistral-7B-Instruct-v0.2-DARE",
    "link": "https://huggingface.co/janhq/Mistral-7B-Instruct-v0.2-DARE",
    "author": "janhq"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Barcenas-13b",
    "average": 55.83,
    "arc": 61.26,
    "hellaswag": 82.13,
    "mmlu": 56.25,
    "truthfulqa": 46.67,
    "winogrande": 76.32,
    "gsm8k": 12.36,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fa988ba73f67ad0c8e7fa8f408106ea040070258",
    "model_name_for_query": "Danielbrdz/Barcenas-13b",
    "link": "https://huggingface.co/Danielbrdz/Barcenas-13b",
    "author": "Danielbrdz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Metamath-reproduce-7b",
    "average": 55.81,
    "arc": 47.18,
    "hellaswag": 73.65,
    "mmlu": 42.94,
    "truthfulqa": 41.58,
    "winogrande": 71.35,
    "gsm8k": 58.15,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9955b88b535863a36ee9d9a255260bbc2cdab47b",
    "model_name_for_query": "feidfoe/Metamath-reproduce-7b",
    "link": "https://huggingface.co/feidfoe/Metamath-reproduce-7b",
    "author": "feidfoe"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-OpenOrca_5w",
    "average": 55.8,
    "arc": 61.01,
    "hellaswag": 82.82,
    "mmlu": 56.09,
    "truthfulqa": 44.87,
    "winogrande": 77.74,
    "gsm8k": 12.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0ddd810c9150492d7318656acac44849651edbf2",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-OpenOrca_5w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-OpenOrca_5w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "?",
    "model": "neu-sai-it1",
    "average": 55.78,
    "arc": 61.26,
    "hellaswag": 81.39,
    "mmlu": 60.17,
    "truthfulqa": 51.49,
    "winogrande": 77.51,
    "gsm8k": 2.88,
    "model_type": "",
    "architecture": "?",
    "precision": "4bit",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "c78cd605142d20c62c78b2c7456fe61d49d990a6",
    "model_name_for_query": "CoruNethron/neu-sai-it1",
    "link": "https://huggingface.co/CoruNethron/neu-sai-it1",
    "author": "CoruNethron"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Hermes-Llama2-13b",
    "average": 55.75,
    "arc": 61.26,
    "hellaswag": 83.26,
    "mmlu": 55.04,
    "truthfulqa": 50.41,
    "winogrande": 75.37,
    "gsm8k": 9.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": ["mit"],
    "params": 12.85,
    "likes": 221.0,
    "still_on_hub": true,
    "revision": "8f95aa9cd207db7b24179fc779c2b8973e71bee2",
    "model_name_for_query": "NousResearch/Nous-Hermes-Llama2-13b",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stable-Platypus2-13B",
    "average": 55.75,
    "arc": 62.71,
    "hellaswag": 82.29,
    "mmlu": 58.3,
    "truthfulqa": 52.52,
    "winogrande": 76.87,
    "gsm8k": 1.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 12.85,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "0e54aa49c24617e30a23a20c0c5da61419b9fe68",
    "model_name_for_query": "garage-bAInd/Stable-Platypus2-13B",
    "link": "https://huggingface.co/garage-bAInd/Stable-Platypus2-13B",
    "author": "garage-bAInd"
  },
  {
    "T": "\u2b55",
    "model": "llama2-13B-sharegpt4-orca-openplatypus-8w",
    "average": 55.75,
    "arc": 62.8,
    "hellaswag": 84.04,
    "mmlu": 55.13,
    "truthfulqa": 45.66,
    "winogrande": 75.14,
    "gsm8k": 11.75,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ad086aacf0176911133b6cccfb34364afce9de5a",
    "model_name_for_query": "lu-vae/llama2-13B-sharegpt4-orca-openplatypus-8w",
    "link": "https://huggingface.co/lu-vae/llama2-13B-sharegpt4-orca-openplatypus-8w",
    "author": "lu-vae"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CollectiveCognition-v1.1-Nebula-7B",
    "average": 55.72,
    "arc": 58.11,
    "hellaswag": 82.39,
    "mmlu": 57.03,
    "truthfulqa": 53.53,
    "winogrande": 73.72,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c41d373a2d49b79236d6c4d0dfc4086e709c07eb",
    "model_name_for_query": "PulsarAI/CollectiveCognition-v1.1-Nebula-7B",
    "link": "https://huggingface.co/PulsarAI/CollectiveCognition-v1.1-Nebula-7B",
    "author": "PulsarAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_v3.1",
    "average": 55.71,
    "arc": 60.15,
    "hellaswag": 82.84,
    "mmlu": 56.84,
    "truthfulqa": 44.38,
    "winogrande": 76.24,
    "gsm8k": 13.8,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "cc708183e430234b8718c08d9f90474569eabeac",
    "model_name_for_query": "openchat/openchat_v3.1",
    "link": "https://huggingface.co/openchat/openchat_v3.1",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-1.1-L2-13B",
    "average": 55.71,
    "arc": 60.75,
    "hellaswag": 83.64,
    "mmlu": 56.39,
    "truthfulqa": 50.3,
    "winogrande": 75.22,
    "gsm8k": 7.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0f45a9f834dd216ce25ffa606b3b1ef2c99e7acd",
    "model_name_for_query": "Sao10K/Stheno-1.1-L2-13B",
    "link": "https://huggingface.co/Sao10K/Stheno-1.1-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "llama2-13b-sharegpt4-test",
    "average": 55.69,
    "arc": 58.02,
    "hellaswag": 82.65,
    "mmlu": 55.99,
    "truthfulqa": 48.27,
    "winogrande": 76.09,
    "gsm8k": 13.12,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2be36a2dab4ed0f97727a1508367f53d59950818",
    "model_name_for_query": "lu-vae/llama2-13b-sharegpt4-test",
    "link": "https://huggingface.co/lu-vae/llama2-13b-sharegpt4-test",
    "author": "lu-vae"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Llama-2-13b-hf",
    "average": 55.69,
    "arc": 59.39,
    "hellaswag": 82.13,
    "mmlu": 55.77,
    "truthfulqa": 37.38,
    "winogrande": 76.64,
    "gsm8k": 22.82,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 389.0,
    "still_on_hub": false,
    "revision": "7da18fb10421c3ae2a1eb92815bad75e84816e35",
    "model_name_for_query": "meta-llama/Llama-2-13b-hf",
    "link": "https://huggingface.co/meta-llama/Llama-2-13b-hf",
    "author": "meta-llama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_v3.2",
    "average": 55.68,
    "arc": 59.64,
    "hellaswag": 82.68,
    "mmlu": 56.68,
    "truthfulqa": 44.49,
    "winogrande": 76.95,
    "gsm8k": 13.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "65320bf6dbe0cb4682d45a9e55dbc876502f8b66",
    "model_name_for_query": "openchat/openchat_v3.2",
    "link": "https://huggingface.co/openchat/openchat_v3.2",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama2-13b",
    "average": 55.68,
    "arc": 59.13,
    "hellaswag": 81.99,
    "mmlu": 55.49,
    "truthfulqa": 51.57,
    "winogrande": 74.66,
    "gsm8k": 11.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "6e918dc8beb1e764def5938fdb8e3f64ba40a456",
    "model_name_for_query": "YeungNLP/firefly-llama2-13b",
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-hermes-coig-lite-13b",
    "average": 55.65,
    "arc": 59.47,
    "hellaswag": 82.28,
    "mmlu": 55.18,
    "truthfulqa": 47.6,
    "winogrande": 78.61,
    "gsm8k": 10.77,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": ["mit"],
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2ee11d9c7acaefb723796227e2ad099b165f0dd9",
    "model_name_for_query": "uukuguy/speechless-hermes-coig-lite-13b",
    "link": "https://huggingface.co/uukuguy/speechless-hermes-coig-lite-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "U-Amethyst-20B",
    "average": 55.65,
    "arc": 62.2,
    "hellaswag": 83.11,
    "mmlu": 55.88,
    "truthfulqa": 53.2,
    "winogrande": 74.19,
    "gsm8k": 5.31,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 19.99,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "c0cbe0b3c88041bb6beef27dbe85146af8dddec9",
    "model_name_for_query": "Undi95/U-Amethyst-20B",
    "link": "https://huggingface.co/Undi95/U-Amethyst-20B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ennodata-13b-8bit-raw-15epoch",
    "average": 55.65,
    "arc": 61.6,
    "hellaswag": 82.2,
    "mmlu": 57.55,
    "truthfulqa": 53.58,
    "winogrande": 77.51,
    "gsm8k": 1.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ee2ceaae9cb806bc30df84ba4d598fdf32e53b17",
    "model_name_for_query": "Enno-Ai/ennodata-13b-8bit-raw-15epoch",
    "link": "https://huggingface.co/Enno-Ai/ennodata-13b-8bit-raw-15epoch",
    "author": "Enno-Ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Uncensored-Frank-13B",
    "average": 55.64,
    "arc": 61.6,
    "hellaswag": 82.62,
    "mmlu": 54.55,
    "truthfulqa": 48.34,
    "winogrande": 74.74,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "73a27445e5e5a72857626e551c70542ec607f60c",
    "model_name_for_query": "ajibawa-2023/Uncensored-Frank-13B",
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Frank-13B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nova-13B-50-step",
    "average": 55.61,
    "arc": 61.6,
    "hellaswag": 82.31,
    "mmlu": 57.27,
    "truthfulqa": 51.53,
    "winogrande": 76.56,
    "gsm8k": 4.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1a827ccb7f00157b3cc9ce538d61a6ba8d5a65db",
    "model_name_for_query": "TFLai/Nova-13B-50-step",
    "link": "https://huggingface.co/TFLai/Nova-13B-50-step",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ANIMA-Phi-Neptune-Mistral-7B-v4",
    "average": 55.61,
    "arc": 55.46,
    "hellaswag": 77.63,
    "mmlu": 53.12,
    "truthfulqa": 59.01,
    "winogrande": 73.48,
    "gsm8k": 14.94,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.11,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "a8e18f970f7ca994740177d6c228adee9e17aba9",
    "model_name_for_query": "Severian/ANIMA-Phi-Neptune-Mistral-7B-v4",
    "link": "https://huggingface.co/Severian/ANIMA-Phi-Neptune-Mistral-7B-v4",
    "author": "Severian"
  },
  {
    "T": "\u2b55",
    "model": "Stable-Platypus2-13B-QLoRA-0.80-epoch",
    "average": 55.56,
    "arc": 62.29,
    "hellaswag": 82.46,
    "mmlu": 57.09,
    "truthfulqa": 51.41,
    "winogrande": 76.56,
    "gsm8k": 3.56,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0c15b8540335b3e21a976a5fc5c33b47927fea6c",
    "model_name_for_query": "TFLai/Stable-Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Stable-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ANIMA-Phi-Neptune-Mistral-7B",
    "average": 55.54,
    "arc": 55.97,
    "hellaswag": 76.22,
    "mmlu": 52.89,
    "truthfulqa": 59.76,
    "winogrande": 73.48,
    "gsm8k": 14.94,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 7.11,
    "likes": 10.0,
    "still_on_hub": false,
    "revision": "e8e9a4804c842b84def9e9aaae38236d4754f277",
    "model_name_for_query": "Severian/ANIMA-Phi-Neptune-Mistral-7B",
    "link": "https://huggingface.co/Severian/ANIMA-Phi-Neptune-Mistral-7B",
    "author": "Severian"
  },
  {
    "T": "\ud83d\udd36",
    "model": "internlm-20b-chat",
    "average": 55.53,
    "arc": 55.38,
    "hellaswag": 78.58,
    "mmlu": 58.53,
    "truthfulqa": 43.22,
    "winogrande": 78.77,
    "gsm8k": 18.73,
    "model_type": "fine-tuned",
    "architecture": "InternLMForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.0,
    "likes": 114.0,
    "still_on_hub": true,
    "revision": "79946225fa7a215e0ebcf4440a9cce88e475deaa",
    "model_name_for_query": "internlm/internlm-20b-chat",
    "link": "https://huggingface.co/internlm/internlm-20b-chat",
    "author": "internlm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-dolphin_5w",
    "average": 55.53,
    "arc": 60.67,
    "hellaswag": 82.69,
    "mmlu": 56.23,
    "truthfulqa": 44.41,
    "winogrande": 77.35,
    "gsm8k": 11.83,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0ec406128968b41a9b7a5f18c358f7638d696b56",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-dolphin_5w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-dolphin_5w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-hermes-coig-lite-13b",
    "average": 55.51,
    "arc": 59.56,
    "hellaswag": 82.26,
    "mmlu": 55.3,
    "truthfulqa": 47.56,
    "winogrande": 78.53,
    "gsm8k": 9.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": ["mit"],
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2ee11d9c7acaefb723796227e2ad099b165f0dd9",
    "model_name_for_query": "uukuguy/speechless-hermes-coig-lite-13b",
    "link": "https://huggingface.co/uukuguy/speechless-hermes-coig-lite-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-Inverted-1.2-L2-13B",
    "average": 55.5,
    "arc": 59.39,
    "hellaswag": 83.01,
    "mmlu": 55.77,
    "truthfulqa": 51.22,
    "winogrande": 74.66,
    "gsm8k": 8.95,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8d2e9087093eef1c9173e167beb40b9d034a4655",
    "model_name_for_query": "Sao10K/Stheno-Inverted-1.2-L2-13B",
    "link": "https://huggingface.co/Sao10K/Stheno-Inverted-1.2-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airolima-chronos-grad-l2-13B",
    "average": 55.5,
    "arc": 59.56,
    "hellaswag": 83.5,
    "mmlu": 55.78,
    "truthfulqa": 44.67,
    "winogrande": 75.85,
    "gsm8k": 13.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "d2ad57b2b50361485b2b04e59a989161599cb08b",
    "model_name_for_query": "kingbri/airolima-chronos-grad-l2-13B",
    "link": "https://huggingface.co/kingbri/airolima-chronos-grad-l2-13B",
    "author": "kingbri"
  },
  {
    "T": "\ud83d\udd36",
    "model": "UndiMix-v1-13b",
    "average": 55.5,
    "arc": 59.47,
    "hellaswag": 82.45,
    "mmlu": 55.83,
    "truthfulqa": 49.78,
    "winogrande": 75.45,
    "gsm8k": 10.01,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fd311f52648825d6988d2f945918468ceb32289f",
    "model_name_for_query": "Undi95/UndiMix-v1-13b",
    "link": "https://huggingface.co/Undi95/UndiMix-v1-13b",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chronolima-airo-grad-l2-13B",
    "average": 55.5,
    "arc": 59.56,
    "hellaswag": 83.47,
    "mmlu": 55.8,
    "truthfulqa": 44.58,
    "winogrande": 75.61,
    "gsm8k": 13.95,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "agpl-3.0",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "9195bd6ea775daf347a275e190665e10bf1fb54b",
    "model_name_for_query": "kingbri/chronolima-airo-grad-l2-13B",
    "link": "https://huggingface.co/kingbri/chronolima-airo-grad-l2-13B",
    "author": "kingbri"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_v3.2",
    "average": 55.49,
    "arc": 59.47,
    "hellaswag": 82.6,
    "mmlu": 56.82,
    "truthfulqa": 44.51,
    "winogrande": 76.09,
    "gsm8k": 13.42,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "bc771c901529dedbf04864d0b81452f62301f882",
    "model_name_for_query": "openchat/openchat_v3.2",
    "link": "https://huggingface.co/openchat/openchat_v3.2",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-v1.5",
    "average": 55.41,
    "arc": 57.08,
    "hellaswag": 81.24,
    "mmlu": 56.67,
    "truthfulqa": 51.51,
    "winogrande": 74.66,
    "gsm8k": 11.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 100.0,
    "still_on_hub": true,
    "revision": "3deb0106f72a3a433f0c6ea0cb978bdf14bcd3a6",
    "model_name_for_query": "lmsys/vicuna-13b-v1.5",
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.5",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "model_007_13b_v2",
    "average": 55.41,
    "arc": 61.95,
    "hellaswag": 82.48,
    "mmlu": 57.32,
    "truthfulqa": 53.5,
    "winogrande": 75.85,
    "gsm8k": 1.36,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "1c959d4b5d5b8683b051f07475bb5c1ab24c8bb0",
    "model_name_for_query": "psmathur/model_007_13b_v2",
    "link": "https://huggingface.co/psmathur/model_007_13b_v2",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_13b_instructed_version2",
    "average": 55.41,
    "arc": 60.07,
    "hellaswag": 84.05,
    "mmlu": 55.61,
    "truthfulqa": 46.12,
    "winogrande": 75.61,
    "gsm8k": 10.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ea321257d81e0f41c985f5155297b7fbd6ac375a",
    "model_name_for_query": "Expert68/llama2_13b_instructed_version2",
    "link": "https://huggingface.co/Expert68/llama2_13b_instructed_version2",
    "author": "Expert68"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-13B",
    "average": 55.41,
    "arc": 59.98,
    "hellaswag": 81.86,
    "mmlu": 56.11,
    "truthfulqa": 47.41,
    "winogrande": 76.09,
    "gsm8k": 10.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "fbb23bc41438b016f1df1e9180c6c350a03557ea",
    "model_name_for_query": "migtissera/Synthia-13B",
    "link": "https://huggingface.co/migtissera/Synthia-13B",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ennodata-raw-pankajmathur-13b-peft",
    "average": 55.4,
    "arc": 61.95,
    "hellaswag": 82.21,
    "mmlu": 57.44,
    "truthfulqa": 53.57,
    "winogrande": 75.93,
    "gsm8k": 1.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "206553873db96a6730d36477837335dbbcc906fc",
    "model_name_for_query": "Enno-Ai/ennodata-raw-pankajmathur-13b-peft",
    "link": "https://huggingface.co/Enno-Ai/ennodata-raw-pankajmathur-13b-peft",
    "author": "Enno-Ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
    "average": 55.4,
    "arc": 59.13,
    "hellaswag": 80.64,
    "mmlu": 56.12,
    "truthfulqa": 51.29,
    "winogrande": 74.66,
    "gsm8k": 10.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "848ef91ab46a72260542283918a971347c6bfa93",
    "model_name_for_query": "luffycodes/nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
    "link": "https://huggingface.co/luffycodes/nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-orca-platypus-coig-lite-2k-0.6e-13b",
    "average": 55.4,
    "arc": 59.9,
    "hellaswag": 80.76,
    "mmlu": 58.34,
    "truthfulqa": 47.97,
    "winogrande": 77.9,
    "gsm8k": 7.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "65214c9923d55795ecd6e7f9e0fcee5ba5f26929",
    "model_name_for_query": "uukuguy/speechless-orca-platypus-coig-lite-2k-0.6e-13b",
    "link": "https://huggingface.co/uukuguy/speechless-orca-platypus-coig-lite-2k-0.6e-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-30b-chat",
    "average": 55.38,
    "arc": 58.7,
    "hellaswag": 82.54,
    "mmlu": 51.16,
    "truthfulqa": 52.42,
    "winogrande": 75.3,
    "gsm8k": 12.13,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 29.96,
    "likes": 183.0,
    "still_on_hub": true,
    "revision": "54f33278a04aa4e612bca482b82f801ab658e890",
    "model_name_for_query": "mosaicml/mpt-30b-chat",
    "link": "https://huggingface.co/mosaicml/mpt-30b-chat",
    "author": "mosaicml"
  },
  {
    "T": "\u2b55",
    "model": "minotaur-llama2-13b-qlora",
    "average": 55.37,
    "arc": 60.07,
    "hellaswag": 82.42,
    "mmlu": 55.87,
    "truthfulqa": 45.57,
    "winogrande": 76.24,
    "gsm8k": 12.05,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.0,
    "likes": 2.0,
    "still_on_hub": false,
    "revision": "22c83f7d68e547fb0b59acfa01c60b108c59fe55",
    "model_name_for_query": "ehartford/minotaur-llama2-13b-qlora",
    "link": "https://huggingface.co/ehartford/minotaur-llama2-13b-qlora",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gaodrew-gorgonzola-13b has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/215\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #215</a>",
    "average": 55.35,
    "arc": 53.84,
    "hellaswag": 78.86,
    "mmlu": 71.54,
    "truthfulqa": 42.58,
    "winogrande": 75.3,
    "gsm8k": 10.01,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a53fbe358d4cb546916847d861ccfaf7c724a103",
    "model_name_for_query": "gaodrew/gaodrew-gorgonzola-13b",
    "link": "https://huggingface.co/gaodrew/gaodrew-gorgonzola-13b",
    "author": "gaodrew"
  },
  {
    "T": "\u2b55",
    "model": "Luban-Platypus2-13B-QLora-0.80-epoch",
    "average": 55.34,
    "arc": 60.24,
    "hellaswag": 82.22,
    "mmlu": 58.03,
    "truthfulqa": 55.26,
    "winogrande": 75.37,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "15a99bc147cf9b744cbab7a7c8c5f232cd0c8d10",
    "model_name_for_query": "TFLai/Luban-Platypus2-13B-QLora-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Luban-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "SthenoWriter-L2-13B",
    "average": 55.33,
    "arc": 62.29,
    "hellaswag": 83.28,
    "mmlu": 56.14,
    "truthfulqa": 44.72,
    "winogrande": 74.35,
    "gsm8k": 11.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a6d9e26ab765eb170cc0aa428ee5e25b08524657",
    "model_name_for_query": "Sao10K/SthenoWriter-L2-13B",
    "link": "https://huggingface.co/Sao10K/SthenoWriter-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "?",
    "model": "chinese-alpaca-33b-merged",
    "average": 55.33,
    "arc": 59.3,
    "hellaswag": 78.43,
    "mmlu": 57.69,
    "truthfulqa": 52.45,
    "winogrande": 76.09,
    "gsm8k": 8.04,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.44,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "fc2535104c0b48afc42575f9fe10bbcbb7612ec3",
    "model_name_for_query": "minlik/chinese-alpaca-33b-merged",
    "link": "https://huggingface.co/minlik/chinese-alpaca-33b-merged",
    "author": "minlik"
  },
  {
    "T": "\u2b55",
    "model": "2x-LoRA-Assemble-Platypus2-13B",
    "average": 55.33,
    "arc": 60.58,
    "hellaswag": 82.56,
    "mmlu": 58.25,
    "truthfulqa": 54.77,
    "winogrande": 74.9,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f147bf8428c174d1dc0332da626d4b039690ceab",
    "model_name_for_query": "PulsarAI/2x-LoRA-Assemble-Platypus2-13B",
    "link": "https://huggingface.co/PulsarAI/2x-LoRA-Assemble-Platypus2-13B",
    "author": "PulsarAI"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13b-Guanaco-QLoRA",
    "average": 55.31,
    "arc": 61.09,
    "hellaswag": 82.99,
    "mmlu": 55.47,
    "truthfulqa": 44.12,
    "winogrande": 77.19,
    "gsm8k": 10.99,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "67e68284234538d3851d5c0c334383daffec57a2",
    "model_name_for_query": "yeontaek/llama-2-13b-Guanaco-QLoRA",
    "link": "https://huggingface.co/yeontaek/llama-2-13b-Guanaco-QLoRA",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Xwin-LM-13B-V0.1",
    "average": 55.29,
    "arc": 62.54,
    "hellaswag": 82.8,
    "mmlu": 56.53,
    "truthfulqa": 45.96,
    "winogrande": 74.27,
    "gsm8k": 9.63,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 57.0,
    "still_on_hub": true,
    "revision": "32938856dc3d713dcba706aded7c82791b6ff647",
    "model_name_for_query": "Xwin-LM/Xwin-LM-13B-V0.1",
    "link": "https://huggingface.co/Xwin-LM/Xwin-LM-13B-V0.1",
    "author": "Xwin-LM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-OpenOrca_20w",
    "average": 55.28,
    "arc": 59.9,
    "hellaswag": 82.51,
    "mmlu": 56.3,
    "truthfulqa": 43.14,
    "winogrande": 77.19,
    "gsm8k": 12.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f01882672e89b164f76093cf3bd26cfc6ecf72ed",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-OpenOrca_20w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-OpenOrca_20w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama2-13b-v11.1-bf16",
    "average": 55.28,
    "arc": 51.79,
    "hellaswag": 76.23,
    "mmlu": 56.13,
    "truthfulqa": 49.7,
    "winogrande": 73.48,
    "gsm8k": 24.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.88,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "76fb7d00836eb2f1d9c9605d8881d73b782cf324",
    "model_name_for_query": "OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chronos-13b-v2",
    "average": 55.25,
    "arc": 58.7,
    "hellaswag": 82.52,
    "mmlu": 53.39,
    "truthfulqa": 50.55,
    "winogrande": 75.06,
    "gsm8k": 11.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "e5d411138e72370c5613dfea0f66ded99f6e62f9",
    "model_name_for_query": "elinas/chronos-13b-v2",
    "link": "https://huggingface.co/elinas/chronos-13b-v2",
    "author": "elinas"
  },
  {
    "T": "\u2b55",
    "model": "SOLAR-Platypus-10.7B-v2",
    "average": 55.25,
    "arc": 59.39,
    "hellaswag": 83.57,
    "mmlu": 59.93,
    "truthfulqa": 43.15,
    "winogrande": 81.45,
    "gsm8k": 4.02,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 10.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "39a8673aa6d98a994661200e87cbd4069b8b6aa8",
    "model_name_for_query": "kyujinpy/SOLAR-Platypus-10.7B-v2",
    "link": "https://huggingface.co/kyujinpy/SOLAR-Platypus-10.7B-v2",
    "author": "kyujinpy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CreativityEngine",
    "average": 55.25,
    "arc": 59.3,
    "hellaswag": 82.42,
    "mmlu": 53.55,
    "truthfulqa": 52.46,
    "winogrande": 74.19,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7870cc50b82b5cbebfa9935b6d73a9d20170299a",
    "model_name_for_query": "Undi95/CreativityEngine",
    "link": "https://huggingface.co/Undi95/CreativityEngine",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-13b-sharegpt4",
    "average": 55.25,
    "arc": 61.77,
    "hellaswag": 84.53,
    "mmlu": 55.21,
    "truthfulqa": 45.94,
    "winogrande": 75.22,
    "gsm8k": 8.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "294c40349bf0c5377f71d92e7539bf5de3176a74",
    "model_name_for_query": "beaugogh/Llama2-13b-sharegpt4",
    "link": "https://huggingface.co/beaugogh/Llama2-13b-sharegpt4",
    "author": "beaugogh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenHermes-13B",
    "average": 55.24,
    "arc": 59.81,
    "hellaswag": 82.24,
    "mmlu": 56.35,
    "truthfulqa": 46.01,
    "winogrande": 75.45,
    "gsm8k": 11.6,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "f09d0fe655ad57cce9179b7b40ea6f81e07db18c",
    "model_name_for_query": "teknium/OpenHermes-13B",
    "link": "https://huggingface.co/teknium/OpenHermes-13B",
    "author": "teknium"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-v1.5-PL-lora_unload",
    "average": 55.24,
    "arc": 56.91,
    "hellaswag": 81.22,
    "mmlu": 56.06,
    "truthfulqa": 49.76,
    "winogrande": 75.22,
    "gsm8k": 12.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5c8aeb722e11d1c7258abd45f9f2840f57976c28",
    "model_name_for_query": "Aspik101/vicuna-13b-v1.5-PL-lora_unload",
    "link": "https://huggingface.co/Aspik101/vicuna-13b-v1.5-PL-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-Chinese-chat",
    "average": 55.22,
    "arc": 60.58,
    "hellaswag": 82.19,
    "mmlu": 55.45,
    "truthfulqa": 45.11,
    "winogrande": 76.64,
    "gsm8k": 11.37,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 13.0,
    "likes": 37.0,
    "still_on_hub": false,
    "revision": "31103acf93479d5c3865fb9b51dcb38e10d8b801",
    "model_name_for_query": "shareAI/llama2-13b-Chinese-chat",
    "link": "https://huggingface.co/shareAI/llama2-13b-Chinese-chat",
    "author": "shareAI"
  },
  {
    "T": "\u2b55",
    "model": "OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
    "average": 55.22,
    "arc": 60.84,
    "hellaswag": 82.56,
    "mmlu": 56.42,
    "truthfulqa": 53.32,
    "winogrande": 75.93,
    "gsm8k": 2.27,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1f81c0439f60d848e3cbc7f06fcd58b5161a8557",
    "model_name_for_query": "TFLai/OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\u2b55",
    "model": "Chronorctypus-Limarobormes-13b",
    "average": 55.22,
    "arc": 59.9,
    "hellaswag": 82.75,
    "mmlu": 58.45,
    "truthfulqa": 51.9,
    "winogrande": 74.43,
    "gsm8k": 3.87,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "75c1bf5f4b40cf61873ff6487ccd3efc4f684330",
    "model_name_for_query": "chargoddard/Chronorctypus-Limarobormes-13b",
    "link": "https://huggingface.co/chargoddard/Chronorctypus-Limarobormes-13b",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-13b-3.0",
    "average": 55.21,
    "arc": 59.81,
    "hellaswag": 83.71,
    "mmlu": 54.86,
    "truthfulqa": 47.79,
    "winogrande": 76.16,
    "gsm8k": 8.95,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "2fcef275782b2c1061cf671d889aea652d13236c",
    "model_name_for_query": "jondurbin/airoboros-l2-13b-3.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-3.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mythical-Destroyer-V2-L2-13B",
    "average": 55.2,
    "arc": 59.3,
    "hellaswag": 82.66,
    "mmlu": 57.39,
    "truthfulqa": 57.09,
    "winogrande": 74.74,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "cbc8b2e4a3beafc311b9e61f8fa9f7526a77c360",
    "model_name_for_query": "Sao10K/Mythical-Destroyer-V2-L2-13B",
    "link": "https://huggingface.co/Sao10K/Mythical-Destroyer-V2-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "minotaur-13b-fixed",
    "average": 55.19,
    "arc": 59.04,
    "hellaswag": 81.66,
    "mmlu": 50.1,
    "truthfulqa": 50.36,
    "winogrande": 76.87,
    "gsm8k": 13.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "5dac6f7559dba1c6fb59fee18c3e713cc3c83db7",
    "model_name_for_query": "openaccess-ai-collective/minotaur-13b-fixed",
    "link": "https://huggingface.co/openaccess-ai-collective/minotaur-13b-fixed",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\u2b55",
    "model": "zephyr_7b_norobots",
    "average": 55.16,
    "arc": 56.48,
    "hellaswag": 79.64,
    "mmlu": 55.52,
    "truthfulqa": 44.6,
    "winogrande": 74.11,
    "gsm8k": 20.62,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "312485e3c11a5cace45ad04dcf87a89df6e69571",
    "model_name_for_query": "qblocks/zephyr_7b_norobots",
    "link": "https://huggingface.co/qblocks/zephyr_7b_norobots",
    "author": "qblocks"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2xOpenOrca-13B-LoRa",
    "average": 55.15,
    "arc": 60.75,
    "hellaswag": 82.09,
    "mmlu": 58.77,
    "truthfulqa": 45.15,
    "winogrande": 77.03,
    "gsm8k": 7.13,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8b2f5d65c03d415b7c43530def622e133e1ef014",
    "model_name_for_query": "yeontaek/Platypus2xOpenOrca-13B-LoRa",
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-LoRa",
    "author": "yeontaek"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-c34b-2.2.1",
    "average": 55.15,
    "arc": 54.69,
    "hellaswag": 76.84,
    "mmlu": 55.43,
    "truthfulqa": 51.36,
    "winogrande": 72.53,
    "gsm8k": 20.02,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 33.48,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "79d9761af231fecbfaf6066d6d405a0f8c04f4ba",
    "model_name_for_query": "jondurbin/airoboros-c34b-2.2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-c34b-2.2.1",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13B-Instruct-v0.2",
    "average": 55.14,
    "arc": 60.58,
    "hellaswag": 81.96,
    "mmlu": 55.46,
    "truthfulqa": 45.71,
    "winogrande": 77.82,
    "gsm8k": 9.33,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.0,
    "likes": 10.0,
    "still_on_hub": false,
    "revision": "ac4b0962df8430f0b31c76a3d97a61134114c87e",
    "model_name_for_query": "dfurman/Llama-2-13B-Instruct-v0.2",
    "link": "https://huggingface.co/dfurman/Llama-2-13B-Instruct-v0.2",
    "author": "dfurman"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-1.0-Uncensored-Llama2-13b",
    "average": 55.14,
    "arc": 55.72,
    "hellaswag": 80.34,
    "mmlu": 55.4,
    "truthfulqa": 51.44,
    "winogrande": 74.66,
    "gsm8k": 13.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "134cea14627fd875f6f277cad92f988024855478",
    "model_name_for_query": "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "link": "https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-2-13b-instruct",
    "average": 55.14,
    "arc": 61.18,
    "hellaswag": 83.25,
    "mmlu": 55.92,
    "truthfulqa": 51.08,
    "winogrande": 77.35,
    "gsm8k": 2.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "ac1f326ea75a28197c4b8e7c015071e8eef64485",
    "model_name_for_query": "bofenghuang/vigogne-2-13b-instruct",
    "link": "https://huggingface.co/bofenghuang/vigogne-2-13b-instruct",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "13B-Legerdemain-L2",
    "average": 55.13,
    "arc": 61.26,
    "hellaswag": 83.26,
    "mmlu": 56.0,
    "truthfulqa": 41.99,
    "winogrande": 75.22,
    "gsm8k": 13.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "d6624ce1bcc6b50c86b86e879a8c9822218b84d2",
    "model_name_for_query": "CalderaAI/13B-Legerdemain-L2",
    "link": "https://huggingface.co/CalderaAI/13B-Legerdemain-L2",
    "author": "CalderaAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-2-13b",
    "average": 55.12,
    "arc": 60.32,
    "hellaswag": 82.37,
    "mmlu": 56.02,
    "truthfulqa": 42.22,
    "winogrande": 78.06,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 29.0,
    "still_on_hub": true,
    "revision": "3cdc103995ccd5fc7fd2cb5f51f71b510466f5fc",
    "model_name_for_query": "PygmalionAI/pygmalion-2-13b",
    "link": "https://huggingface.co/PygmalionAI/pygmalion-2-13b",
    "author": "PygmalionAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PuddleJumper-13b",
    "average": 55.11,
    "arc": 58.7,
    "hellaswag": 81.18,
    "mmlu": 58.25,
    "truthfulqa": 56.44,
    "winogrande": 72.77,
    "gsm8k": 3.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "f3a8a475ff0c6ae37ac8ae0690980be11cac731a",
    "model_name_for_query": "totally-not-an-llm/PuddleJumper-13b",
    "link": "https://huggingface.co/totally-not-an-llm/PuddleJumper-13b",
    "author": "totally-not-an-llm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-1.0-Uncensored-Llama2-13b",
    "average": 55.1,
    "arc": 55.8,
    "hellaswag": 80.41,
    "mmlu": 55.59,
    "truthfulqa": 51.42,
    "winogrande": 74.11,
    "gsm8k": 13.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "134cea14627fd875f6f277cad92f988024855478",
    "model_name_for_query": "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "link": "https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-FINETUNE4",
    "average": 55.09,
    "arc": 58.7,
    "hellaswag": 81.93,
    "mmlu": 57.21,
    "truthfulqa": 43.26,
    "winogrande": 76.95,
    "gsm8k": 12.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "939d06081210fa943c60210a47583f43b60901ad",
    "model_name_for_query": "wei123602/Llama-2-13b-FINETUNE4",
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4",
    "author": "wei123602"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-orca-8k-3319",
    "average": 55.09,
    "arc": 60.75,
    "hellaswag": 81.91,
    "mmlu": 57.06,
    "truthfulqa": 42.64,
    "winogrande": 77.19,
    "gsm8k": 10.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 115.0,
    "still_on_hub": true,
    "revision": "160f58ec85ef25ad935eb583f14c7e8c7f7e7839",
    "model_name_for_query": "OpenAssistant/llama2-13b-orca-8k-3319",
    "link": "https://huggingface.co/OpenAssistant/llama2-13b-orca-8k-3319",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-llama2-dolphin-orca-platypus-13b",
    "average": 55.09,
    "arc": 59.64,
    "hellaswag": 82.65,
    "mmlu": 57.9,
    "truthfulqa": 43.44,
    "winogrande": 77.19,
    "gsm8k": 9.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fd23b7d052eb7c18ecd2acc1be77c66b7b8d6dad",
    "model_name_for_query": "speechlessai/speechless-llama2-dolphin-orca-platypus-13b",
    "link": "https://huggingface.co/speechlessai/speechless-llama2-dolphin-orca-platypus-13b",
    "author": "speechlessai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-Chinese-13b-Chat",
    "average": 55.07,
    "arc": 55.97,
    "hellaswag": 82.05,
    "mmlu": 54.74,
    "truthfulqa": 48.9,
    "winogrande": 76.16,
    "gsm8k": 12.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 206.0,
    "still_on_hub": true,
    "revision": "cb69cda10a72bc9736b1c10181ac41f28b69ff9b",
    "model_name_for_query": "FlagAlpha/Llama2-Chinese-13b-Chat",
    "link": "https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat",
    "author": "FlagAlpha"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-chat-german",
    "average": 55.07,
    "arc": 57.85,
    "hellaswag": 81.66,
    "mmlu": 54.45,
    "truthfulqa": 46.32,
    "winogrande": 76.48,
    "gsm8k": 13.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 46.0,
    "still_on_hub": true,
    "revision": "d72667bd92fd6f76835466d302563d213e0b1ee1",
    "model_name_for_query": "jphme/Llama-2-13b-chat-german",
    "link": "https://huggingface.co/jphme/Llama-2-13b-chat-german",
    "author": "jphme"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-dolphin_20w",
    "average": 55.06,
    "arc": 59.56,
    "hellaswag": 82.55,
    "mmlu": 55.89,
    "truthfulqa": 42.67,
    "winogrande": 77.27,
    "gsm8k": 12.43,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c75073d7545a4d222f40dc519021c55a81850d75",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-dolphin_20w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-dolphin_20w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Python-Code-33B",
    "average": 55.06,
    "arc": 56.31,
    "hellaswag": 81.01,
    "mmlu": 54.22,
    "truthfulqa": 44.39,
    "winogrande": 75.22,
    "gsm8k": 19.18,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-nd-4.0",
    "params": 33.0,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "cf9a561b57145748455fd3e193d2b0e4ae0a0fce",
    "model_name_for_query": "ajibawa-2023/Python-Code-33B",
    "link": "https://huggingface.co/ajibawa-2023/Python-Code-33B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GodziLLa-30B",
    "average": 55.05,
    "arc": 61.52,
    "hellaswag": 82.13,
    "mmlu": 54.21,
    "truthfulqa": 55.91,
    "winogrande": 76.16,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 32.32,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "aa9912a2ac60abeac28b4566731cd903dcc582ac",
    "model_name_for_query": "MayaPH/GodziLLa-30B",
    "link": "https://huggingface.co/MayaPH/GodziLLa-30B",
    "author": "MayaPH"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-V1.1",
    "average": 55.05,
    "arc": 60.24,
    "hellaswag": 81.39,
    "mmlu": 50.92,
    "truthfulqa": 54.56,
    "winogrande": 75.06,
    "gsm8k": 8.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 69.0,
    "still_on_hub": true,
    "revision": "badd80f8a6f46fb15310fedf6d4db54959854897",
    "model_name_for_query": "WizardLM/WizardLM-13B-V1.1",
    "link": "https://huggingface.co/WizardLM/WizardLM-13B-V1.1",
    "author": "WizardLM"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-16b-nastychat",
    "average": 55.04,
    "arc": 57.42,
    "hellaswag": 80.59,
    "mmlu": 55.99,
    "truthfulqa": 53.45,
    "winogrande": 74.66,
    "gsm8k": 8.11,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 16.19,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "6fb7f82d486b3eee53d750f83cc7eae434349809",
    "model_name_for_query": "chargoddard/llama-2-16b-nastychat",
    "link": "https://huggingface.co/chargoddard/llama-2-16b-nastychat",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "shisa-7b-v1",
    "average": 55.01,
    "arc": 56.14,
    "hellaswag": 78.63,
    "mmlu": 23.12,
    "truthfulqa": 52.49,
    "winogrande": 78.06,
    "gsm8k": 41.62,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.96,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "131c2f3bf4955d1e2b6762380132bdd8688c0646",
    "model_name_for_query": "augmxnt/shisa-7b-v1",
    "link": "https://huggingface.co/augmxnt/shisa-7b-v1",
    "author": "augmxnt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dulia-13b-8k-alpha",
    "average": 55.0,
    "arc": 60.67,
    "hellaswag": 82.0,
    "mmlu": 56.87,
    "truthfulqa": 42.59,
    "winogrande": 77.19,
    "gsm8k": 10.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c3bcafd7f6133a7e7c069f8765a99fe84989d926",
    "model_name_for_query": "duliadotio/dulia-13b-8k-alpha",
    "link": "https://huggingface.co/duliadotio/dulia-13b-8k-alpha",
    "author": "duliadotio"
  },
  {
    "T": "\u2b55",
    "model": "Redmond-Puffin-13B-instruct-PL-lora_unload",
    "average": 55.0,
    "arc": 60.92,
    "hellaswag": 82.43,
    "mmlu": 55.61,
    "truthfulqa": 44.26,
    "winogrande": 75.69,
    "gsm8k": 11.07,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b933009635299bca32c694336aa2007d756a2dda",
    "model_name_for_query": "Aspik101/Redmond-Puffin-13B-instruct-PL-lora_unload",
    "link": "https://huggingface.co/Aspik101/Redmond-Puffin-13B-instruct-PL-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_v3.2_super",
    "average": 54.99,
    "arc": 59.81,
    "hellaswag": 82.5,
    "mmlu": 55.9,
    "truthfulqa": 42.3,
    "winogrande": 75.93,
    "gsm8k": 13.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 24.0,
    "still_on_hub": true,
    "revision": "aab7ce4d48b31a295a0116b61569d8e87a09bb7a",
    "model_name_for_query": "openchat/openchat_v3.2_super",
    "link": "https://huggingface.co/openchat/openchat_v3.2_super",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chinese-alpaca-2-13b",
    "average": 54.99,
    "arc": 58.7,
    "hellaswag": 79.74,
    "mmlu": 55.1,
    "truthfulqa": 50.22,
    "winogrande": 75.69,
    "gsm8k": 10.46,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.97,
    "likes": 64.0,
    "still_on_hub": true,
    "revision": "576094cbf4988baf88b3bb66678be1db70bd720a",
    "model_name_for_query": "ziqingyang/chinese-alpaca-2-13b",
    "link": "https://huggingface.co/ziqingyang/chinese-alpaca-2-13b",
    "author": "ziqingyang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Asimov-7B-v1",
    "average": 54.98,
    "arc": 59.04,
    "hellaswag": 80.04,
    "mmlu": 56.35,
    "truthfulqa": 51.15,
    "winogrande": 73.95,
    "gsm8k": 9.33,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "4bit",
    "license": "mit",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0b33ad0a6dde60156ee6008ff47f7cfa6cd27937",
    "model_name_for_query": "prithivida/Asimov-7B-v1",
    "link": "https://huggingface.co/prithivida/Asimov-7B-v1",
    "author": "prithivida"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-v1.5-16k",
    "average": 54.97,
    "arc": 56.74,
    "hellaswag": 80.37,
    "mmlu": 55.28,
    "truthfulqa": 51.96,
    "winogrande": 72.38,
    "gsm8k": 13.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 167.0,
    "still_on_hub": true,
    "revision": "277697af19d4b267626ebc9f4e078d19a9a0fddf",
    "model_name_for_query": "lmsys/vicuna-13b-v1.5-16k",
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.5-16k",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-V1.0",
    "average": 54.97,
    "arc": 57.25,
    "hellaswag": 80.88,
    "mmlu": 52.92,
    "truthfulqa": 50.55,
    "winogrande": 74.11,
    "gsm8k": 14.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "f802ea7c01e2da27b0f7091c70d3ecfd8fc042b9",
    "model_name_for_query": "LLMs/WizardLM-13B-V1.0",
    "link": "https://huggingface.co/LLMs/WizardLM-13B-V1.0",
    "author": "LLMs"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-Instruct-v0.1",
    "average": 54.96,
    "arc": 54.52,
    "hellaswag": 75.63,
    "mmlu": 55.38,
    "truthfulqa": 56.28,
    "winogrande": 73.72,
    "gsm8k": 14.25,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 698.0,
    "still_on_hub": true,
    "revision": "7961f5aa9b736bf8e364b2e6f201190f97a27931",
    "model_name_for_query": "mistralai/Mistral-7B-Instruct-v0.1",
    "link": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1",
    "author": "mistralai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "synapsellm-7b-mistral-v0.4-preview3",
    "average": 54.94,
    "arc": 51.28,
    "hellaswag": 74.83,
    "mmlu": 52.93,
    "truthfulqa": 52.35,
    "winogrande": 73.48,
    "gsm8k": 24.79,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "67c0d0fe71c620f0be410a06f58b928f89218639",
    "model_name_for_query": "WebraftAI/synapsellm-7b-mistral-v0.4-preview3",
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.4-preview3",
    "author": "WebraftAI"
  },
  {
    "T": "\u2b55",
    "model": "Sydney_Overthinker_13b_HF",
    "average": 54.94,
    "arc": 58.96,
    "hellaswag": 80.85,
    "mmlu": 51.28,
    "truthfulqa": 45.7,
    "winogrande": 73.95,
    "gsm8k": 18.88,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c4d2617fb452a55ac3a39c64128a98874595adb1",
    "model_name_for_query": "FPHam/Sydney_Overthinker_13b_HF",
    "link": "https://huggingface.co/FPHam/Sydney_Overthinker_13b_HF",
    "author": "FPHam"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wizardLM-13B-1.0-fp16",
    "average": 54.93,
    "arc": 57.25,
    "hellaswag": 80.88,
    "mmlu": 52.9,
    "truthfulqa": 50.55,
    "winogrande": 74.11,
    "gsm8k": 13.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "b79733805e98e668ff9a459975c259881b1b8014",
    "model_name_for_query": "TheBloke/wizardLM-13B-1.0-fp16",
    "link": "https://huggingface.co/TheBloke/wizardLM-13B-1.0-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-AEZAKMI-v1",
    "average": 54.92,
    "arc": 58.87,
    "hellaswag": 82.01,
    "mmlu": 58.72,
    "truthfulqa": 53.54,
    "winogrande": 75.69,
    "gsm8k": 0.68,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fec4e695e5af743bb49d1976de83fa695be5f105",
    "model_name_for_query": "adamo1139/Mistral-7B-AEZAKMI-v1",
    "link": "https://huggingface.co/adamo1139/Mistral-7B-AEZAKMI-v1",
    "author": "adamo1139"
  },
  {
    "T": "?",
    "model": "13B-Chimera",
    "average": 54.92,
    "arc": 57.59,
    "hellaswag": 81.5,
    "mmlu": 49.86,
    "truthfulqa": 52.59,
    "winogrande": 77.27,
    "gsm8k": 10.69,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "85cfe8e6db2bee804873cfdb48955696cc5b0689",
    "model_name_for_query": "digitous/13B-Chimera",
    "link": "https://huggingface.co/digitous/13B-Chimera",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Llama-2-13b-chat-hf",
    "average": 54.91,
    "arc": 59.04,
    "hellaswag": 81.94,
    "mmlu": 54.64,
    "truthfulqa": 44.12,
    "winogrande": 74.51,
    "gsm8k": 15.24,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 617.0,
    "still_on_hub": false,
    "revision": "f848cf15ab9a51ae5735ab28120a9a0773eeb541",
    "model_name_for_query": "meta-llama/Llama-2-13b-chat-hf",
    "link": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf",
    "author": "meta-llama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Morningstar-13b-hf",
    "average": 54.91,
    "arc": 59.04,
    "hellaswag": 81.93,
    "mmlu": 54.63,
    "truthfulqa": 44.12,
    "winogrande": 74.51,
    "gsm8k": 15.24,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2605b5b3b0ecba906ac26d39aab40f33c2ec81c9",
    "model_name_for_query": "NewstaR/Morningstar-13b-hf",
    "link": "https://huggingface.co/NewstaR/Morningstar-13b-hf",
    "author": "NewstaR"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeUp-Llama-2-13b-chat-hf",
    "average": 54.91,
    "arc": 59.04,
    "hellaswag": 81.93,
    "mmlu": 54.63,
    "truthfulqa": 44.12,
    "winogrande": 74.51,
    "gsm8k": 15.24,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail++",
    "params": 12.85,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "d4af0b233a5b6a214e96582e103396e99dcf5f95",
    "model_name_for_query": "deepse/CodeUp-Llama-2-13b-chat-hf",
    "link": "https://huggingface.co/deepse/CodeUp-Llama-2-13b-chat-hf",
    "author": "deepse"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Kimiko-v2-13B-fp16",
    "average": 54.91,
    "arc": 61.01,
    "hellaswag": 83.32,
    "mmlu": 55.17,
    "truthfulqa": 40.65,
    "winogrande": 76.8,
    "gsm8k": 12.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "0fed305667508e50330e71a2d43e9cee5ea73783",
    "model_name_for_query": "TheBloke/Kimiko-v2-13B-fp16",
    "link": "https://huggingface.co/TheBloke/Kimiko-v2-13B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Huginn-13b-FP16",
    "average": 54.89,
    "arc": 60.58,
    "hellaswag": 82.53,
    "mmlu": 53.71,
    "truthfulqa": 54.46,
    "winogrande": 73.72,
    "gsm8k": 4.32,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "69615d9a8e1547f2407afd3380868a99f780e008",
    "model_name_for_query": "The-Face-Of-Goonery/Huginn-13b-FP16",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-FP16",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Platypus2-13B",
    "average": 54.89,
    "arc": 61.26,
    "hellaswag": 82.56,
    "mmlu": 56.7,
    "truthfulqa": 44.86,
    "winogrande": 76.87,
    "gsm8k": 7.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 12.85,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "b5e926e3d6c03e83c7983e87eb71098b5e80a62e",
    "model_name_for_query": "garage-bAInd/Platypus2-13B",
    "link": "https://huggingface.co/garage-bAInd/Platypus2-13B",
    "author": "garage-bAInd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
    "average": 54.88,
    "arc": 58.53,
    "hellaswag": 82.27,
    "mmlu": 55.9,
    "truthfulqa": 40.26,
    "winogrande": 76.95,
    "gsm8k": 15.39,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fdc145fe1b47cdda483535c018e35a5ab249a552",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LewdEngine",
    "average": 54.88,
    "arc": 60.49,
    "hellaswag": 83.08,
    "mmlu": 54.84,
    "truthfulqa": 43.63,
    "winogrande": 74.9,
    "gsm8k": 12.36,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6e918ff9f563552af4ad66f4308f6d040e24af4b",
    "model_name_for_query": "Undi95/LewdEngine",
    "link": "https://huggingface.co/Undi95/LewdEngine",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-guanaco-fp16",
    "average": 54.86,
    "arc": 60.92,
    "hellaswag": 83.18,
    "mmlu": 54.58,
    "truthfulqa": 44.0,
    "winogrande": 74.9,
    "gsm8k": 11.6,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "feb7ef47ceca6aec9548264a39622b63fdcb853c",
    "model_name_for_query": "Mikael110/llama-2-13b-guanaco-fp16",
    "link": "https://huggingface.co/Mikael110/llama-2-13b-guanaco-fp16",
    "author": "Mikael110"
  },
  {
    "T": "\ud83d\udd36",
    "model": "manticore-13b",
    "average": 54.86,
    "arc": 58.7,
    "hellaswag": 81.63,
    "mmlu": 50.84,
    "truthfulqa": 49.17,
    "winogrande": 76.64,
    "gsm8k": 12.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 108.0,
    "still_on_hub": true,
    "revision": "aed786b0200251c9962ac200c50f7e367f264b46",
    "model_name_for_query": "openaccess-ai-collective/manticore-13b",
    "link": "https://huggingface.co/openaccess-ai-collective/manticore-13b",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Redmond-Puffin-13B",
    "average": 54.86,
    "arc": 60.41,
    "hellaswag": 83.2,
    "mmlu": 55.36,
    "truthfulqa": 42.12,
    "winogrande": 76.64,
    "gsm8k": 11.45,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": ["mit"],
    "params": 12.85,
    "likes": 99.0,
    "still_on_hub": true,
    "revision": "12af25fa7ea02c4fc636952ea8b9dc9cf48e35be",
    "model_name_for_query": "NousResearch/Redmond-Puffin-13B",
    "link": "https://huggingface.co/NousResearch/Redmond-Puffin-13B",
    "author": "NousResearch"
  },
  {
    "T": "\u2b55",
    "model": "OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
    "average": 54.86,
    "arc": 59.81,
    "hellaswag": 82.69,
    "mmlu": 56.96,
    "truthfulqa": 52.92,
    "winogrande": 74.43,
    "gsm8k": 2.35,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5427ceec420f943a0b011a4d96f3efc292306933",
    "model_name_for_query": "TFLai/OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
    "link": "https://huggingface.co/TFLai/OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "7B",
    "average": 54.86,
    "arc": 50.0,
    "hellaswag": 74.58,
    "mmlu": 61.79,
    "truthfulqa": 50.13,
    "winogrande": 69.69,
    "gsm8k": 22.97,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "wtfpl",
    "params": 7.0,
    "likes": 103.0,
    "still_on_hub": false,
    "revision": "3f4f76e2d94308ea6b0edc3de83f18c213a8fde5",
    "model_name_for_query": "CausalLM/7B",
    "link": "https://huggingface.co/CausalLM/7B",
    "author": "CausalLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Code-13B",
    "average": 54.81,
    "arc": 57.34,
    "hellaswag": 83.28,
    "mmlu": 53.17,
    "truthfulqa": 42.46,
    "winogrande": 73.56,
    "gsm8k": 19.03,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "91f5a6d5cdf93aeb86dd8965e195d51522957fc6",
    "model_name_for_query": "ajibawa-2023/Code-13B",
    "link": "https://huggingface.co/ajibawa-2023/Code-13B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Samantha-1.11-CodeLlama-34b",
    "average": 54.8,
    "arc": 56.57,
    "hellaswag": 75.47,
    "mmlu": 53.51,
    "truthfulqa": 50.46,
    "winogrande": 73.48,
    "gsm8k": 19.33,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 41.0,
    "still_on_hub": true,
    "revision": "3fd110de9282e52f56f999bf1da1a76425f00e29",
    "model_name_for_query": "ehartford/Samantha-1.11-CodeLlama-34b",
    "link": "https://huggingface.co/ehartford/Samantha-1.11-CodeLlama-34b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-13b-FINETUNE3",
    "average": 54.79,
    "arc": 59.3,
    "hellaswag": 81.53,
    "mmlu": 57.46,
    "truthfulqa": 41.63,
    "winogrande": 76.72,
    "gsm8k": 12.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bacd035db122dafaf86bf52bb9ca8c613070cc58",
    "model_name_for_query": "wei123602/llama-13b-FINETUNE3",
    "link": "https://huggingface.co/wei123602/llama-13b-FINETUNE3",
    "author": "wei123602"
  },
  {
    "T": "\u2b55",
    "model": "Ensemble5-Platypus2-13B-QLora-0.80-epoch",
    "average": 54.76,
    "arc": 59.73,
    "hellaswag": 82.66,
    "mmlu": 56.94,
    "truthfulqa": 52.92,
    "winogrande": 74.43,
    "gsm8k": 1.9,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2af03c3287c60c4ba2fb6afa86c26cf722ab001d",
    "model_name_for_query": "TFLai/Ensemble5-Platypus2-13B-QLora-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Ensemble5-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-V1.2",
    "average": 54.76,
    "arc": 59.04,
    "hellaswag": 82.21,
    "mmlu": 54.64,
    "truthfulqa": 47.27,
    "winogrande": 71.9,
    "gsm8k": 13.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 157.0,
    "still_on_hub": true,
    "revision": "6760d0c07ffdc2405295ed7a29437cf4dc414bac",
    "model_name_for_query": "WizardLM/WizardLM-13B-V1.2",
    "link": "https://huggingface.co/WizardLM/WizardLM-13B-V1.2",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Redmond-Puffin-13B",
    "average": 54.74,
    "arc": 60.49,
    "hellaswag": 83.21,
    "mmlu": 54.95,
    "truthfulqa": 42.08,
    "winogrande": 76.48,
    "gsm8k": 11.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": ["mit"],
    "params": 12.85,
    "likes": 99.0,
    "still_on_hub": true,
    "revision": "12af25fa7ea02c4fc636952ea8b9dc9cf48e35be",
    "model_name_for_query": "NousResearch/Redmond-Puffin-13B",
    "link": "https://huggingface.co/NousResearch/Redmond-Puffin-13B",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chronos-Beluga-v2-13bfp16",
    "average": 54.74,
    "arc": 60.75,
    "hellaswag": 81.94,
    "mmlu": 54.08,
    "truthfulqa": 53.23,
    "winogrande": 73.8,
    "gsm8k": 4.62,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "6d50e6681bc26c9bc0c8377c26c438e295ee0c2f",
    "model_name_for_query": "The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\u2b55",
    "model": "TekniumAiroboros-Nebula-7B",
    "average": 54.74,
    "arc": 57.17,
    "hellaswag": 81.72,
    "mmlu": 55.25,
    "truthfulqa": 51.64,
    "winogrande": 73.24,
    "gsm8k": 9.4,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ef964d514cc25a600b0de78fc469d1acbec34591",
    "model_name_for_query": "Weyaxi/TekniumAiroboros-Nebula-7B",
    "link": "https://huggingface.co/Weyaxi/TekniumAiroboros-Nebula-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\u2b55",
    "model": "MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
    "average": 54.74,
    "arc": 60.32,
    "hellaswag": 83.72,
    "mmlu": 55.74,
    "truthfulqa": 52.18,
    "winogrande": 75.53,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3d91f63d82abd598d5b80d24d74feb6b00b7d80f",
    "model_name_for_query": "TFLai/MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\u2b55",
    "model": "13B-Thorns-l2",
    "average": 54.72,
    "arc": 62.88,
    "hellaswag": 83.57,
    "mmlu": 56.95,
    "truthfulqa": 49.52,
    "winogrande": 74.51,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "adc5e7befcc3d0a26f46198fdda4a098a2742fe6",
    "model_name_for_query": "CalderaAI/13B-Thorns-l2",
    "link": "https://huggingface.co/CalderaAI/13B-Thorns-l2",
    "author": "CalderaAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Medusa-13b",
    "average": 54.72,
    "arc": 58.19,
    "hellaswag": 81.35,
    "mmlu": 57.39,
    "truthfulqa": 51.24,
    "winogrande": 73.32,
    "gsm8k": 6.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "be755c9eef8233ca59e0178db75de878f5859222",
    "model_name_for_query": "Sao10K/Medusa-13b",
    "link": "https://huggingface.co/Sao10K/Medusa-13b",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "Giraffe-beta-13b-32k",
    "average": 54.69,
    "arc": 55.63,
    "hellaswag": 80.42,
    "mmlu": 53.61,
    "truthfulqa": 42.58,
    "winogrande": 74.59,
    "gsm8k": 21.3,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "259f3fe9ebbff7532498f44286f253d56699da6f",
    "model_name_for_query": "abacusai/Giraffe-beta-13b-32k",
    "link": "https://huggingface.co/abacusai/Giraffe-beta-13b-32k",
    "author": "abacusai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLaMA2-13B-Psyfighter2",
    "average": 54.66,
    "arc": 60.07,
    "hellaswag": 84.02,
    "mmlu": 55.07,
    "truthfulqa": 53.0,
    "winogrande": 74.35,
    "gsm8k": 1.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cc51a4e64b0821feda101dc04737486b4ff60735",
    "model_name_for_query": "KoboldAI/LLaMA2-13B-Psyfighter2",
    "link": "https://huggingface.co/KoboldAI/LLaMA2-13B-Psyfighter2",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-34b-v1.9",
    "average": 54.64,
    "arc": 54.27,
    "hellaswag": 75.2,
    "mmlu": 56.12,
    "truthfulqa": 43.92,
    "winogrande": 73.56,
    "gsm8k": 24.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 33.48,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "68aad9f8452b2abf7d5415d48c09bd55d5b7ca05",
    "model_name_for_query": "uukuguy/speechless-codellama-34b-v1.9",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-34b-v1.9",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
    "average": 54.64,
    "arc": 57.25,
    "hellaswag": 81.73,
    "mmlu": 55.72,
    "truthfulqa": 41.53,
    "winogrande": 77.58,
    "gsm8k": 14.03,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "209da26cff560ab34064f277190ab63f8c970b93",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13B-instructed",
    "average": 54.63,
    "arc": 59.39,
    "hellaswag": 83.88,
    "mmlu": 55.57,
    "truthfulqa": 46.89,
    "winogrande": 74.03,
    "gsm8k": 8.04,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e676fbd9015beacfba5d71426beace7605200477",
    "model_name_for_query": "Secbone/llama-2-13B-instructed",
    "link": "https://huggingface.co/Secbone/llama-2-13B-instructed",
    "author": "Secbone"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
    "average": 54.63,
    "arc": 58.7,
    "hellaswag": 81.66,
    "mmlu": 53.87,
    "truthfulqa": 43.02,
    "winogrande": 76.72,
    "gsm8k": 13.8,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "33fd8a46a711ab8c45698dae9601678dfd7b3d33",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "UltraLM-13B-fp16",
    "average": 54.62,
    "arc": 57.59,
    "hellaswag": 80.2,
    "mmlu": 51.85,
    "truthfulqa": 51.56,
    "winogrande": 75.85,
    "gsm8k": 10.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "734f5641f6c548474517d1536c46024517f120e0",
    "model_name_for_query": "TheBloke/UltraLM-13B-fp16",
    "link": "https://huggingface.co/TheBloke/UltraLM-13B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chat-Stheno-L2-13B",
    "average": 54.61,
    "arc": 58.45,
    "hellaswag": 80.96,
    "mmlu": 54.8,
    "truthfulqa": 43.31,
    "winogrande": 75.37,
    "gsm8k": 14.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "20419fdd5b4bdcbbf075223c33b396958c48a6cf",
    "model_name_for_query": "Sao10K/Chat-Stheno-L2-13B",
    "link": "https://huggingface.co/Sao10K/Chat-Stheno-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
    "average": 54.61,
    "arc": 60.41,
    "hellaswag": 82.58,
    "mmlu": 55.86,
    "truthfulqa": 43.61,
    "winogrande": 76.72,
    "gsm8k": 8.49,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "891be2d8f205baa04c8a92f6ab1225f0d0c3e5bd",
    "model_name_for_query": "dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
    "author": "dhmeltzer"
  },
  {
    "T": "\u2b55",
    "model": "Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
    "average": 54.6,
    "arc": 59.9,
    "hellaswag": 83.29,
    "mmlu": 56.69,
    "truthfulqa": 51.08,
    "winogrande": 75.22,
    "gsm8k": 1.44,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6e49d3d205e7f2e15c01ace0901da8931bbaab3b",
    "model_name_for_query": "TFLai/Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\u2b55",
    "model": "Samantha-Nebula-7B",
    "average": 54.58,
    "arc": 57.0,
    "hellaswag": 82.25,
    "mmlu": 54.21,
    "truthfulqa": 49.58,
    "winogrande": 73.09,
    "gsm8k": 11.37,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a7d4b8a1683e33dd3c60064d7dd9d5c35691323f",
    "model_name_for_query": "Weyaxi/Samantha-Nebula-7B",
    "link": "https://huggingface.co/Weyaxi/Samantha-Nebula-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrca-Platypus2-13B-thera-1250",
    "average": 54.56,
    "arc": 59.22,
    "hellaswag": 81.02,
    "mmlu": 57.04,
    "truthfulqa": 48.43,
    "winogrande": 73.09,
    "gsm8k": 8.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b1c2ebcda387211732e87911e39edca503502a33",
    "model_name_for_query": "gaodrew/OpenOrca-Platypus2-13B-thera-1250",
    "link": "https://huggingface.co/gaodrew/OpenOrca-Platypus2-13B-thera-1250",
    "author": "gaodrew"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca-2-7b",
    "average": 54.55,
    "arc": 54.1,
    "hellaswag": 76.19,
    "mmlu": 56.37,
    "truthfulqa": 52.45,
    "winogrande": 73.48,
    "gsm8k": 14.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 7.0,
    "likes": 49.0,
    "still_on_hub": true,
    "revision": "60e31e6bdcf582ad103b807cb74b73ee1d2c4b17",
    "model_name_for_query": "microsoft/Orca-2-7b",
    "link": "https://huggingface.co/microsoft/Orca-2-7b",
    "author": "microsoft"
  },
  {
    "T": "\u2b55",
    "model": "LLaMA2-13B-Holomax",
    "average": 54.52,
    "arc": 60.49,
    "hellaswag": 82.86,
    "mmlu": 54.67,
    "truthfulqa": 42.97,
    "winogrande": 74.66,
    "gsm8k": 11.45,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 13.02,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "2c4fddeb097636d6462b7628a8e053ad3ff4678c",
    "model_name_for_query": "KoboldAI/LLaMA2-13B-Holomax",
    "link": "https://huggingface.co/KoboldAI/LLaMA2-13B-Holomax",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLaMA2-13B-Tiefighter",
    "average": 54.51,
    "arc": 59.9,
    "hellaswag": 84.0,
    "mmlu": 54.98,
    "truthfulqa": 53.02,
    "winogrande": 74.51,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.0,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "0d193a4562d6836724485cb7df6e58ca846bbfeb",
    "model_name_for_query": "KoboldAI/LLaMA2-13B-Tiefighter",
    "link": "https://huggingface.co/KoboldAI/LLaMA2-13B-Tiefighter",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt4-alpaca-lora-13b-decapoda-1024",
    "average": 54.51,
    "arc": 59.39,
    "hellaswag": 81.87,
    "mmlu": 47.75,
    "truthfulqa": 52.59,
    "winogrande": 77.35,
    "gsm8k": 8.11,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 3.0,
    "still_on_hub": false,
    "revision": "7aedafea409de07a997d70a84e30242c7b86877c",
    "model_name_for_query": "chansung/gpt4-alpaca-lora-13b-decapoda-1024",
    "link": "https://huggingface.co/chansung/gpt4-alpaca-lora-13b-decapoda-1024",
    "author": "chansung"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
    "average": 54.5,
    "arc": 59.22,
    "hellaswag": 81.52,
    "mmlu": 54.94,
    "truthfulqa": 42.83,
    "winogrande": 76.87,
    "gsm8k": 11.6,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a759c4fae8dc5fcd264bf58b89b9fd13d06784ae",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2-13B-LoRa",
    "average": 54.48,
    "arc": 60.67,
    "hellaswag": 82.5,
    "mmlu": 56.34,
    "truthfulqa": 43.91,
    "winogrande": 75.93,
    "gsm8k": 7.51,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1450c541cf9e378e81862fabeb234b8e0a2bdf5a",
    "model_name_for_query": "yeontaek/Platypus2-13B-LoRa",
    "link": "https://huggingface.co/yeontaek/Platypus2-13B-LoRa",
    "author": "yeontaek"
  },
  {
    "T": "\u2b55",
    "model": "Limarp-Platypus2-13B-QLoRA-0.80-epoch",
    "average": 54.46,
    "arc": 60.49,
    "hellaswag": 82.76,
    "mmlu": 56.52,
    "truthfulqa": 44.14,
    "winogrande": 76.8,
    "gsm8k": 6.07,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0a8560232ff73ca3c3f8e217b4517fa6c4f55558",
    "model_name_for_query": "TFLai/Limarp-Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Limarp-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-FINETUNE4_TEST2",
    "average": 54.46,
    "arc": 58.45,
    "hellaswag": 81.7,
    "mmlu": 56.61,
    "truthfulqa": 40.19,
    "winogrande": 76.64,
    "gsm8k": 13.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e312c4c59cab9d130c33288c92aad7c0cb5331d5",
    "model_name_for_query": "wei123602/Llama-2-13b-FINETUNE4_TEST2",
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_TEST2",
    "author": "wei123602"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airophin-13b-pntk-16k-fp16",
    "average": 54.44,
    "arc": 61.18,
    "hellaswag": 82.86,
    "mmlu": 55.19,
    "truthfulqa": 43.2,
    "winogrande": 76.16,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "6b5418b69e8270df659eacb192f469e7c3af70b3",
    "model_name_for_query": "bhenrym14/airophin-13b-pntk-16k-fp16",
    "link": "https://huggingface.co/bhenrym14/airophin-13b-pntk-16k-fp16",
    "author": "bhenrym14"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
    "average": 54.4,
    "arc": 57.51,
    "hellaswag": 82.49,
    "mmlu": 54.83,
    "truthfulqa": 43.81,
    "winogrande": 77.27,
    "gsm8k": 10.46,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f65029ea8f030731ace568e40bab33a7097a13de",
    "model_name_for_query": "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
    "link": "https://huggingface.co/NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
    "author": "NekoPunchBBB"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE1_17w-r16",
    "average": 54.37,
    "arc": 57.25,
    "hellaswag": 82.27,
    "mmlu": 56.16,
    "truthfulqa": 39.75,
    "winogrande": 77.43,
    "gsm8k": 13.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5da5c92f3cf85a62c1be90a0bb2ae8dffce64a7d",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r16",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r16",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
    "average": 54.35,
    "arc": 59.73,
    "hellaswag": 81.06,
    "mmlu": 54.53,
    "truthfulqa": 38.64,
    "winogrande": 78.14,
    "gsm8k": 14.03,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aeeded8db9eea97e2e6a2e19a006ce1acd110a82",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
    "author": "CHIH-HUNG"
  },
  {
    "T": "?",
    "model": "orca_mini_v3_7B-GPTQ",
    "average": 54.35,
    "arc": 54.52,
    "hellaswag": 78.53,
    "mmlu": 51.85,
    "truthfulqa": 51.2,
    "winogrande": 74.66,
    "gsm8k": 15.31,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "other",
    "params": 9.05,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "4f06a6151128861d5bb256275620f7eadcab3238",
    "model_name_for_query": "TheBloke/orca_mini_v3_7B-GPTQ",
    "link": "https://huggingface.co/TheBloke/orca_mini_v3_7B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-hf-instruct-pl-lora_unload",
    "average": 54.34,
    "arc": 59.47,
    "hellaswag": 82.16,
    "mmlu": 54.83,
    "truthfulqa": 41.45,
    "winogrande": 76.24,
    "gsm8k": 11.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4ef2c736641c2983996c4662bf481782a9de5055",
    "model_name_for_query": "Lajonbot/Llama-2-13b-hf-instruct-pl-lora_unload",
    "link": "https://huggingface.co/Lajonbot/Llama-2-13b-hf-instruct-pl-lora_unload",
    "author": "Lajonbot"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-13b-instruct",
    "average": 54.34,
    "arc": 57.94,
    "hellaswag": 81.32,
    "mmlu": 47.62,
    "truthfulqa": 50.23,
    "winogrande": 77.11,
    "gsm8k": 11.83,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 12.85,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "a13e08a36c355d64fae59f28162e5fa542a8d235",
    "model_name_for_query": "bofenghuang/vigogne-13b-instruct",
    "link": "https://huggingface.co/bofenghuang/vigogne-13b-instruct",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-op-v4",
    "average": 54.34,
    "arc": 61.52,
    "hellaswag": 79.21,
    "mmlu": 57.01,
    "truthfulqa": 42.72,
    "winogrande": 75.93,
    "gsm8k": 9.63,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "6cd644049de2b944beaefcc6aa34965c00e08529",
    "model_name_for_query": "anhnv125/llama-op-v4",
    "link": "https://huggingface.co/anhnv125/llama-op-v4",
    "author": "anhnv125"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
    "average": 54.32,
    "arc": 58.7,
    "hellaswag": 81.89,
    "mmlu": 56.08,
    "truthfulqa": 38.95,
    "winogrande": 77.35,
    "gsm8k": 12.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4c3a4cb54c0487666bd58589b50f90c22de80969",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Camel-Platypus2-13B",
    "average": 54.32,
    "arc": 60.75,
    "hellaswag": 83.61,
    "mmlu": 56.51,
    "truthfulqa": 49.6,
    "winogrande": 75.37,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "0480a52799cb8e8de73bb41994df8b6b793937c7",
    "model_name_for_query": "garage-bAInd/Camel-Platypus2-13B",
    "link": "https://huggingface.co/garage-bAInd/Camel-Platypus2-13B",
    "author": "garage-bAInd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-Open-Platypus_2.5w",
    "average": 54.32,
    "arc": 59.56,
    "hellaswag": 82.46,
    "mmlu": 56.06,
    "truthfulqa": 42.45,
    "winogrande": 76.8,
    "gsm8k": 8.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bc55678af8226e1323305f743a4882da31994e0c",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-Open-Platypus_2.5w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-Open-Platypus_2.5w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "?",
    "model": "Alpagasus-2-13b-QLoRA-merged",
    "average": 54.31,
    "arc": 61.09,
    "hellaswag": 82.46,
    "mmlu": 55.27,
    "truthfulqa": 38.53,
    "winogrande": 77.35,
    "gsm8k": 11.14,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dacbafa40716a2d87e593240cc5c1dc883b5066a",
    "model_name_for_query": "StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "link": "https://huggingface.co/StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "author": "StudentLLM"
  },
  {
    "T": "?",
    "model": "WizardLM-13B-V1.1-GPTQ",
    "average": 54.28,
    "arc": 58.53,
    "hellaswag": 80.66,
    "mmlu": 49.59,
    "truthfulqa": 54.35,
    "winogrande": 74.43,
    "gsm8k": 8.11,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "9df807ac64034bc6e7387326689d6e39656ce5e0",
    "model_name_for_query": "TheBloke/WizardLM-13B-V1.1-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-13B-V1.1-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wizard-mega-13b",
    "average": 54.27,
    "arc": 57.34,
    "hellaswag": 81.09,
    "mmlu": 50.59,
    "truthfulqa": 50.22,
    "winogrande": 76.32,
    "gsm8k": 10.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 103.0,
    "still_on_hub": true,
    "revision": "76e90314541be6cfa2b55208831c99f1351c1a33",
    "model_name_for_query": "openaccess-ai-collective/wizard-mega-13b",
    "link": "https://huggingface.co/openaccess-ai-collective/wizard-mega-13b",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-v1.3",
    "average": 54.27,
    "arc": 54.61,
    "hellaswag": 80.41,
    "mmlu": 52.88,
    "truthfulqa": 52.14,
    "winogrande": 74.82,
    "gsm8k": 10.77,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 160.0,
    "still_on_hub": true,
    "revision": "7900eeb715a49affee9e6390f824e62eea3f3fb1",
    "model_name_for_query": "lmsys/vicuna-13b-v1.3",
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.3",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-code-alpaca",
    "average": 54.25,
    "arc": 60.84,
    "hellaswag": 82.14,
    "mmlu": 55.93,
    "truthfulqa": 38.27,
    "winogrande": 76.4,
    "gsm8k": 11.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "aa1d543fe3391fe9f0e6143ef785fffe9c871225",
    "model_name_for_query": "layoric/llama-2-13b-code-alpaca",
    "link": "https://huggingface.co/layoric/llama-2-13b-code-alpaca",
    "author": "layoric"
  },
  {
    "T": "\ud83d\udd36",
    "model": "13B-HyperMantis",
    "average": 54.25,
    "arc": 58.53,
    "hellaswag": 82.2,
    "mmlu": 50.61,
    "truthfulqa": 47.5,
    "winogrande": 76.24,
    "gsm8k": 10.39,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "aa828ef92c363a5577ffd7d29e678277b9d2eb3c",
    "model_name_for_query": "digitous/13B-HyperMantis",
    "link": "https://huggingface.co/digitous/13B-HyperMantis",
    "author": "digitous"
  },
  {
    "T": "\u2b55",
    "model": "EverythingLM-13b-V3-peft",
    "average": 54.24,
    "arc": 58.36,
    "hellaswag": 81.03,
    "mmlu": 54.7,
    "truthfulqa": 52.98,
    "winogrande": 72.85,
    "gsm8k": 5.53,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "7a2eed5038addcf4fa3b8dd358b45eb96134e749",
    "model_name_for_query": "totally-not-an-llm/EverythingLM-13b-V3-peft",
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-V3-peft",
    "author": "totally-not-an-llm"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2-13B-IA3",
    "average": 54.23,
    "arc": 61.09,
    "hellaswag": 82.65,
    "mmlu": 56.32,
    "truthfulqa": 38.35,
    "winogrande": 75.69,
    "gsm8k": 11.3,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b738c64d536df02f5c137a94bc7a32a4c486012b",
    "model_name_for_query": "yeontaek/Platypus2-13B-IA3",
    "link": "https://huggingface.co/yeontaek/Platypus2-13B-IA3",
    "author": "yeontaek"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13b-hf-platypus",
    "average": 54.22,
    "arc": 58.87,
    "hellaswag": 82.14,
    "mmlu": 54.98,
    "truthfulqa": 42.84,
    "winogrande": 77.11,
    "gsm8k": 9.4,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "39e07f6213a64d79cf31e9c0773dea6224f7f021",
    "model_name_for_query": "lgaalves/llama-2-13b-hf-platypus",
    "link": "https://huggingface.co/lgaalves/llama-2-13b-hf-platypus",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-hf_Open-Platypus",
    "average": 54.22,
    "arc": 58.87,
    "hellaswag": 82.14,
    "mmlu": 54.98,
    "truthfulqa": 42.84,
    "winogrande": 77.11,
    "gsm8k": 9.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c318a24121bd69509f395e17a9636093213ece21",
    "model_name_for_query": "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus",
    "link": "https://huggingface.co/NekoPunchBBB/Llama-2-13b-hf_Open-Platypus",
    "author": "NekoPunchBBB"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Free_Sydney_13b_HF",
    "average": 54.22,
    "arc": 59.39,
    "hellaswag": 81.4,
    "mmlu": 53.73,
    "truthfulqa": 45.63,
    "winogrande": 76.01,
    "gsm8k": 9.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "5474ecbccd1f2a2cda9f77a157993f55c97377ed",
    "model_name_for_query": "FPHam/Free_Sydney_13b_HF",
    "link": "https://huggingface.co/FPHam/Free_Sydney_13b_HF",
    "author": "FPHam"
  },
  {
    "T": "\ud83d\udd36",
    "model": "genz-13b-v2",
    "average": 54.2,
    "arc": 55.97,
    "hellaswag": 79.98,
    "mmlu": 54.3,
    "truthfulqa": 48.09,
    "winogrande": 74.59,
    "gsm8k": 12.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "98e0e2086df11b9f80e1571110540a657e52c2e8",
    "model_name_for_query": "budecosystem/genz-13b-v2",
    "link": "https://huggingface.co/budecosystem/genz-13b-v2",
    "author": "budecosystem"
  },
  {
    "T": "\u2b55",
    "model": "Alpagasus-2-13b-QLoRA-merged",
    "average": 54.2,
    "arc": 60.84,
    "hellaswag": 82.43,
    "mmlu": 55.55,
    "truthfulqa": 38.65,
    "winogrande": 76.87,
    "gsm8k": 10.84,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "e324e828c8d68aa8510f50dfab133388a44fd821",
    "model_name_for_query": "StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "link": "https://huggingface.co/StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "author": "StudentLLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-math1.2",
    "average": 54.19,
    "arc": 56.91,
    "hellaswag": 80.71,
    "mmlu": 53.21,
    "truthfulqa": 48.25,
    "winogrande": 74.74,
    "gsm8k": 11.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b05b4c22893e950e8e33acb67087a9acc8f0ab97",
    "model_name_for_query": "FelixChao/llama2-13b-math1.2",
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.2",
    "author": "FelixChao"
  },
  {
    "T": "\u2b55",
    "model": "PuddleJumper-13b-V2",
    "average": 54.19,
    "arc": 57.0,
    "hellaswag": 81.06,
    "mmlu": 58.3,
    "truthfulqa": 52.66,
    "winogrande": 72.45,
    "gsm8k": 3.64,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "1fe9494e334a32ba73dc2926f58246450850c534",
    "model_name_for_query": "totally-not-an-llm/PuddleJumper-13b-V2",
    "link": "https://huggingface.co/totally-not-an-llm/PuddleJumper-13b-V2",
    "author": "totally-not-an-llm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-math1.1",
    "average": 54.18,
    "arc": 57.25,
    "hellaswag": 80.74,
    "mmlu": 53.56,
    "truthfulqa": 48.43,
    "winogrande": 74.43,
    "gsm8k": 10.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3c4d83d3525e54a493ff510443fdcca44bf63b59",
    "model_name_for_query": "FelixChao/llama2-13b-math1.1",
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.1",
    "author": "FelixChao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE1_17w-r4",
    "average": 54.18,
    "arc": 56.74,
    "hellaswag": 82.27,
    "mmlu": 56.18,
    "truthfulqa": 39.65,
    "winogrande": 77.03,
    "gsm8k": 13.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7e0046627fabb0f23ace4b71f279d459ec4a0ff1",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r4",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r4",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
    "average": 54.16,
    "arc": 59.13,
    "hellaswag": 82.13,
    "mmlu": 54.98,
    "truthfulqa": 44.23,
    "winogrande": 76.4,
    "gsm8k": 8.11,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aad13bce3b243721e52e9cda479f1102dda99f12",
    "model_name_for_query": "dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Metharme-13b-Merged",
    "average": 54.15,
    "arc": 59.9,
    "hellaswag": 81.12,
    "mmlu": 47.18,
    "truthfulqa": 51.18,
    "winogrande": 76.8,
    "gsm8k": 8.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "90c02cc338afcdd890a948af06432674743363ad",
    "model_name_for_query": "TehVenom/Metharme-13b-Merged",
    "link": "https://huggingface.co/TehVenom/Metharme-13b-Merged",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-math1.1",
    "average": 54.14,
    "arc": 56.83,
    "hellaswag": 80.69,
    "mmlu": 53.43,
    "truthfulqa": 48.48,
    "winogrande": 74.74,
    "gsm8k": 10.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3c4d83d3525e54a493ff510443fdcca44bf63b59",
    "model_name_for_query": "FelixChao/llama2-13b-math1.1",
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.1",
    "author": "FelixChao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Wizard-Vicuna-13B-Uncensored-HF",
    "average": 54.14,
    "arc": 58.96,
    "hellaswag": 81.95,
    "mmlu": 47.92,
    "truthfulqa": 51.69,
    "winogrande": 75.69,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 197.0,
    "still_on_hub": true,
    "revision": "fff9ac7f0e2e7b340f2301f5f089d989fc03be67",
    "model_name_for_query": "TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Wizard-Vicuna-13B-Uncensored",
    "average": 54.14,
    "arc": 58.96,
    "hellaswag": 81.95,
    "mmlu": 47.92,
    "truthfulqa": 51.69,
    "winogrande": 75.69,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 218.0,
    "still_on_hub": true,
    "revision": "95bfd1640a54e76b3e857c2462fd3a77eca0b275",
    "model_name_for_query": "ehartford/Wizard-Vicuna-13B-Uncensored",
    "link": "https://huggingface.co/ehartford/Wizard-Vicuna-13B-Uncensored",
    "author": "ehartford"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
    "average": 54.14,
    "arc": 59.98,
    "hellaswag": 82.43,
    "mmlu": 55.41,
    "truthfulqa": 39.9,
    "winogrande": 76.56,
    "gsm8k": 10.54,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "6a0a2b6672c7b36c714a66c4a836e0b50c6cb5e6",
    "model_name_for_query": "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-orca-platypus-coig-lite-4k-0.5e-13b",
    "average": 54.13,
    "arc": 58.02,
    "hellaswag": 80.15,
    "mmlu": 57.26,
    "truthfulqa": 48.04,
    "winogrande": 75.45,
    "gsm8k": 5.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "081d1da5cfa2f6ad43abdf4fb5e41f8ec5846224",
    "model_name_for_query": "uukuguy/speechless-orca-platypus-coig-lite-4k-0.5e-13b",
    "link": "https://huggingface.co/uukuguy/speechless-orca-platypus-coig-lite-4k-0.5e-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "manticore-13b-chat-pyg",
    "average": 54.13,
    "arc": 58.53,
    "hellaswag": 81.96,
    "mmlu": 48.76,
    "truthfulqa": 48.76,
    "winogrande": 77.19,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 24.0,
    "still_on_hub": true,
    "revision": "f9ef65a3cf50e3c09ccb443f99225148e08517aa",
    "model_name_for_query": "openaccess-ai-collective/manticore-13b-chat-pyg",
    "link": "https://huggingface.co/openaccess-ai-collective/manticore-13b-chat-pyg",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "13B-BlueMethod",
    "average": 54.12,
    "arc": 59.64,
    "hellaswag": 82.07,
    "mmlu": 50.34,
    "truthfulqa": 47.74,
    "winogrande": 77.11,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "315aa0924dd42840b8cced581c9db1240f9bae1d",
    "model_name_for_query": "CalderaAI/13B-BlueMethod",
    "link": "https://huggingface.co/CalderaAI/13B-BlueMethod",
    "author": "CalderaAI"
  },
  {
    "T": "\u2b55",
    "model": "chinese-alpaca-2-13b-16k",
    "average": 54.12,
    "arc": 55.03,
    "hellaswag": 77.41,
    "mmlu": 51.28,
    "truthfulqa": 46.5,
    "winogrande": 73.4,
    "gsm8k": 21.08,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 24.0,
    "still_on_hub": true,
    "revision": "ba4536aed022c49bda60e1b56a0dbefc2ea6a30a",
    "model_name_for_query": "hfl/chinese-alpaca-2-13b-16k",
    "link": "https://huggingface.co/hfl/chinese-alpaca-2-13b-16k",
    "author": "hfl"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
    "average": 54.12,
    "arc": 57.17,
    "hellaswag": 82.26,
    "mmlu": 55.89,
    "truthfulqa": 39.93,
    "winogrande": 76.56,
    "gsm8k": 12.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aafcbc02289238952a6e16e059db395da65ba987",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Athena-v1",
    "average": 54.11,
    "arc": 60.07,
    "hellaswag": 82.64,
    "mmlu": 55.61,
    "truthfulqa": 46.58,
    "winogrande": 74.82,
    "gsm8k": 4.93,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "8f96e561c8c795e383ca0faeb1696fa1e33e87de",
    "model_name_for_query": "IkariDev/Athena-v1",
    "link": "https://huggingface.co/IkariDev/Athena-v1",
    "author": "IkariDev"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-platypus-llama2-chat-13B-hf",
    "average": 54.11,
    "arc": 62.97,
    "hellaswag": 82.75,
    "mmlu": 56.86,
    "truthfulqa": 42.93,
    "winogrande": 76.32,
    "gsm8k": 2.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e35bb473156d74c8b5ad23a5e9df815891e8139a",
    "model_name_for_query": "chickencaesar/llama2-platypus-llama2-chat-13B-hf",
    "link": "https://huggingface.co/chickencaesar/llama2-platypus-llama2-chat-13B-hf",
    "author": "chickencaesar"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Guanaco-13B-Uncensored",
    "average": 54.1,
    "arc": 59.56,
    "hellaswag": 82.7,
    "mmlu": 53.65,
    "truthfulqa": 43.26,
    "winogrande": 76.32,
    "gsm8k": 9.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "cf315234979f5924ad73399bcdcdf51b05a1fc98",
    "model_name_for_query": "Fredithefish/Guanaco-13B-Uncensored",
    "link": "https://huggingface.co/Fredithefish/Guanaco-13B-Uncensored",
    "author": "Fredithefish"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13b-Beluga-QLoRA",
    "average": 54.09,
    "arc": 59.22,
    "hellaswag": 81.92,
    "mmlu": 56.67,
    "truthfulqa": 48.23,
    "winogrande": 77.19,
    "gsm8k": 1.29,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c0d3c0a5d4e9001ea933c6b71ca3adc99d1f71a2",
    "model_name_for_query": "yeontaek/llama-2-13b-Beluga-QLoRA",
    "link": "https://huggingface.co/yeontaek/llama-2-13b-Beluga-QLoRA",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-6B",
    "average": 54.08,
    "arc": 55.55,
    "hellaswag": 76.57,
    "mmlu": 64.11,
    "truthfulqa": 41.96,
    "winogrande": 74.19,
    "gsm8k": 12.13,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.06,
    "likes": 287.0,
    "still_on_hub": true,
    "revision": "e00f7cbde45745a22625ac85c6ad5d5b9f27098d",
    "model_name_for_query": "01-ai/Yi-6B",
    "link": "https://huggingface.co/01-ai/Yi-6B",
    "author": "01-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
    "average": 54.08,
    "arc": 59.3,
    "hellaswag": 81.2,
    "mmlu": 55.58,
    "truthfulqa": 38.13,
    "winogrande": 76.8,
    "gsm8k": 13.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "71224344025dbfada6821c6a89cade1d8358dad1",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "StableBeluga1-Delta",
    "average": 54.08,
    "arc": 68.17,
    "hellaswag": 85.88,
    "mmlu": 64.83,
    "truthfulqa": 55.81,
    "winogrande": 49.8,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 65.29,
    "likes": 54.0,
    "still_on_hub": false,
    "revision": "40a78d91d43ad9aef6663ff15ddc15be9922bce5",
    "model_name_for_query": "stabilityai/StableBeluga1-Delta",
    "link": "https://huggingface.co/stabilityai/StableBeluga1-Delta",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airophin-v2-13b-PI-8k-fp16",
    "average": 54.07,
    "arc": 60.58,
    "hellaswag": 82.96,
    "mmlu": 56.75,
    "truthfulqa": 40.14,
    "winogrande": 76.64,
    "gsm8k": 7.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "26b7edfd282af223d86d5e539451357bb114247b",
    "model_name_for_query": "bhenrym14/airophin-v2-13b-PI-8k-fp16",
    "link": "https://huggingface.co/bhenrym14/airophin-v2-13b-PI-8k-fp16",
    "author": "bhenrym14"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
    "average": 54.06,
    "arc": 57.68,
    "hellaswag": 81.91,
    "mmlu": 54.95,
    "truthfulqa": 41.31,
    "winogrande": 76.48,
    "gsm8k": 12.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f76f93dad8408523e69c59abbb96ce6b1b9b9f69",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ReMM-L2-13B-PIPPA",
    "average": 54.06,
    "arc": 59.73,
    "hellaswag": 83.12,
    "mmlu": 54.1,
    "truthfulqa": 49.94,
    "winogrande": 74.51,
    "gsm8k": 2.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "79e711178c6881496ae1f5635b08bc193f370709",
    "model_name_for_query": "Undi95/ReMM-L2-13B-PIPPA",
    "link": "https://huggingface.co/Undi95/ReMM-L2-13B-PIPPA",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ReMM-L2-13B",
    "average": 54.06,
    "arc": 59.73,
    "hellaswag": 83.1,
    "mmlu": 54.11,
    "truthfulqa": 49.94,
    "winogrande": 74.51,
    "gsm8k": 2.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "c4710577003a23ca8e9040d16dfb8f3e9bc5d636",
    "model_name_for_query": "Undi95/ReMM-L2-13B",
    "link": "https://huggingface.co/Undi95/ReMM-L2-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-math1.2",
    "average": 54.05,
    "arc": 57.08,
    "hellaswag": 80.61,
    "mmlu": 53.05,
    "truthfulqa": 48.3,
    "winogrande": 74.27,
    "gsm8k": 10.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b05b4c22893e950e8e33acb67087a9acc8f0ab97",
    "model_name_for_query": "FelixChao/llama2-13b-math1.2",
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.2",
    "author": "FelixChao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-FINETUNE4_compare8k2",
    "average": 54.05,
    "arc": 58.28,
    "hellaswag": 81.39,
    "mmlu": 56.87,
    "truthfulqa": 39.86,
    "winogrande": 76.01,
    "gsm8k": 11.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fe1b604097aad9408ce63fa7ffc9c320cdd06e4f",
    "model_name_for_query": "wei123602/Llama-2-13b-FINETUNE4_compare8k2",
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_compare8k2",
    "author": "wei123602"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13B-HF",
    "average": 54.05,
    "arc": 58.28,
    "hellaswag": 81.05,
    "mmlu": 50.03,
    "truthfulqa": 51.57,
    "winogrande": 76.24,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "9219b61a0e8bc880e4cd0f8bebc48a97ee0950c7",
    "model_name_for_query": "TheBloke/airoboros-13B-HF",
    "link": "https://huggingface.co/TheBloke/airoboros-13B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Hermes-13b",
    "average": 54.04,
    "arc": 56.57,
    "hellaswag": 82.11,
    "mmlu": 50.44,
    "truthfulqa": 51.5,
    "winogrande": 75.3,
    "gsm8k": 8.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl",
    "params": 12.85,
    "likes": 388.0,
    "still_on_hub": true,
    "revision": "24e8c03148ffd1f3e469744dfc24ad2ad82848f8",
    "model_name_for_query": "NousResearch/Nous-Hermes-13b",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-13b",
    "author": "NousResearch"
  },
  {
    "T": "\u2b55",
    "model": "Huginn-13b-V4",
    "average": 54.04,
    "arc": 60.67,
    "hellaswag": 82.34,
    "mmlu": 52.32,
    "truthfulqa": 50.62,
    "winogrande": 73.64,
    "gsm8k": 4.62,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6186feee849e0c2b7e62d4cbdc4cdc48260ac684",
    "model_name_for_query": "The-Face-Of-Goonery/Huginn-13b-V4",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-V4",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\u2b55",
    "model": "Huginn-13b-v4.5",
    "average": 54.04,
    "arc": 60.67,
    "hellaswag": 82.34,
    "mmlu": 52.32,
    "truthfulqa": 50.62,
    "winogrande": 73.64,
    "gsm8k": 4.62,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "f3be56d8bf71a8d3905974b1e5fcba7336b02159",
    "model_name_for_query": "The-Face-Of-Goonery/Huginn-13b-v4.5",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-v4.5",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\u2b55",
    "model": "Huginn-v3-13b",
    "average": 54.04,
    "arc": 60.67,
    "hellaswag": 82.34,
    "mmlu": 52.32,
    "truthfulqa": 50.62,
    "winogrande": 73.64,
    "gsm8k": 4.62,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "6c2faf828c5380d28c51fcb4d3d0f1a420fb9a9a",
    "model_name_for_query": "The-Face-Of-Goonery/Huginn-v3-13b",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-v3-13b",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13b",
    "average": 54.02,
    "arc": 58.28,
    "hellaswag": 81.05,
    "mmlu": 50.03,
    "truthfulqa": 51.57,
    "winogrande": 76.24,
    "gsm8k": 6.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 93.0,
    "still_on_hub": true,
    "revision": "44830f9e1559f318f5dad875bab40d1d1beddbfc",
    "model_name_for_query": "jondurbin/airoboros-13b",
    "link": "https://huggingface.co/jondurbin/airoboros-13b",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-6B",
    "average": 54.02,
    "arc": 55.55,
    "hellaswag": 76.42,
    "mmlu": 63.85,
    "truthfulqa": 41.86,
    "winogrande": 73.8,
    "gsm8k": 12.66,
    "model_type": "pretrained",
    "architecture": "YiForCausalLM",
    "precision": "bfloat16",
    "license": "custom",
    "params": 6.0,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "d8029c814d8faa68e1aef2e488f668a3af5d1a8a",
    "model_name_for_query": "01-ai/Yi-6B",
    "link": "https://huggingface.co/01-ai/Yi-6B",
    "author": "01-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-13b-pretrained",
    "average": 54.02,
    "arc": 56.31,
    "hellaswag": 79.32,
    "mmlu": 47.03,
    "truthfulqa": 48.42,
    "winogrande": 76.95,
    "gsm8k": 16.07,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c28cc0cf5a1a1bf4de96b23d06b02129dca85eb9",
    "model_name_for_query": "dvruette/llama-13b-pretrained",
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
    "average": 54.02,
    "arc": 57.17,
    "hellaswag": 82.15,
    "mmlu": 54.88,
    "truthfulqa": 40.23,
    "winogrande": 76.32,
    "gsm8k": 13.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "86adab5c098c9338e098a8e5b0188b0aa39b2478",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch",
    "average": 54.01,
    "arc": 57.34,
    "hellaswag": 81.24,
    "mmlu": 55.64,
    "truthfulqa": 55.98,
    "winogrande": 73.88,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ada55b32fe8ed55b7691d997ad2e86f232c91aad",
    "model_name_for_query": "TFLai/MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch",
    "link": "https://huggingface.co/TFLai/MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "based-30b",
    "average": 54.0,
    "arc": 63.91,
    "hellaswag": 85.67,
    "mmlu": 58.28,
    "truthfulqa": 35.7,
    "winogrande": 80.11,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 32.32,
    "likes": 39.0,
    "still_on_hub": true,
    "revision": "5818a6344f48dc5a324589b57cb288a9d54c0b79",
    "model_name_for_query": "ehartford/based-30b",
    "link": "https://huggingface.co/ehartford/based-30b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-orca-platypus-coig-lite-4k-0.6e-13b",
    "average": 53.99,
    "arc": 58.79,
    "hellaswag": 79.93,
    "mmlu": 56.77,
    "truthfulqa": 48.29,
    "winogrande": 75.93,
    "gsm8k": 4.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6bf4cf6211489bdbea70585a4a5c0f39deefb4e5",
    "model_name_for_query": "uukuguy/speechless-orca-platypus-coig-lite-4k-0.6e-13b",
    "link": "https://huggingface.co/uukuguy/speechless-orca-platypus-coig-lite-4k-0.6e-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
    "average": 53.99,
    "arc": 56.06,
    "hellaswag": 81.89,
    "mmlu": 55.04,
    "truthfulqa": 40.12,
    "winogrande": 76.56,
    "gsm8k": 14.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f907fffbb08698040325b3f2e47200a1b48b3ed9",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt4-alpaca-lora-13B-HF",
    "average": 53.98,
    "arc": 59.56,
    "hellaswag": 82.09,
    "mmlu": 47.48,
    "truthfulqa": 48.96,
    "winogrande": 76.72,
    "gsm8k": 9.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "49678a2dd15fb4e1f1b99616ccc1ffd269912833",
    "model_name_for_query": "TheBloke/gpt4-alpaca-lora-13B-HF",
    "link": "https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "webMistral-7B",
    "average": 53.97,
    "arc": 59.04,
    "hellaswag": 80.89,
    "mmlu": 59.0,
    "truthfulqa": 39.71,
    "winogrande": 76.32,
    "gsm8k": 8.87,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "0b221c617df3d2f883cfd925f646ebd93de23037",
    "model_name_for_query": "KnutJaegersberg/webMistral-7B",
    "link": "https://huggingface.co/KnutJaegersberg/webMistral-7B",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\u2b55",
    "model": "WizardMath-13B-V1.0",
    "average": 53.97,
    "arc": 60.07,
    "hellaswag": 82.01,
    "mmlu": 54.8,
    "truthfulqa": 42.7,
    "winogrande": 71.9,
    "gsm8k": 12.36,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "209316bea6eab73d8b18fca2a730b1dff3dcf999",
    "model_name_for_query": "WizardLM/WizardMath-13B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardMath-13B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "minotaur-13b",
    "average": 53.97,
    "arc": 56.4,
    "hellaswag": 79.13,
    "mmlu": 49.61,
    "truthfulqa": 49.62,
    "winogrande": 76.56,
    "gsm8k": 12.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "b5ae4519d4c8f4559a0aa80b6efe2008413ece01",
    "model_name_for_query": "openaccess-ai-collective/minotaur-13b",
    "link": "https://huggingface.co/openaccess-ai-collective/minotaur-13b",
    "author": "openaccess-ai-collective"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_v2_w",
    "average": 53.96,
    "arc": 57.34,
    "hellaswag": 81.23,
    "mmlu": 50.17,
    "truthfulqa": 50.7,
    "winogrande": 75.93,
    "gsm8k": 8.42,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 29.0,
    "still_on_hub": true,
    "revision": "0eb53946b8fac30606dc72541f2fc073cb6a0e12",
    "model_name_for_query": "openchat/openchat_v2_w",
    "link": "https://huggingface.co/openchat/openchat_v2_w",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_v2",
    "average": 53.96,
    "arc": 57.17,
    "hellaswag": 81.14,
    "mmlu": 50.58,
    "truthfulqa": 49.54,
    "winogrande": 76.24,
    "gsm8k": 9.1,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "bd2a0968964c0f2dfae8f5a8950b43e35142f830",
    "model_name_for_query": "openchat/openchat_v2",
    "link": "https://huggingface.co/openchat/openchat_v2",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-FINETUNE4_TEST3",
    "average": 53.95,
    "arc": 59.04,
    "hellaswag": 81.65,
    "mmlu": 56.37,
    "truthfulqa": 39.98,
    "winogrande": 75.45,
    "gsm8k": 11.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e81b5d4550224711929fdea4effdd990cc0c7404",
    "model_name_for_query": "wei123602/Llama-2-13b-FINETUNE4_TEST3",
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_TEST3",
    "author": "wei123602"
  },
  {
    "T": "\u2b55",
    "model": "Platypus-Nebula-v2-7B",
    "average": 53.95,
    "arc": 55.38,
    "hellaswag": 83.02,
    "mmlu": 56.07,
    "truthfulqa": 46.94,
    "winogrande": 72.22,
    "gsm8k": 10.08,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2d95180bae03c0b268dff44a1f9806fc295adc09",
    "model_name_for_query": "Weyaxi/Platypus-Nebula-v2-7B",
    "link": "https://huggingface.co/Weyaxi/Platypus-Nebula-v2-7B",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
    "average": 53.95,
    "arc": 57.42,
    "hellaswag": 82.42,
    "mmlu": 55.57,
    "truthfulqa": 39.19,
    "winogrande": 77.03,
    "gsm8k": 12.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "469c6674ad2190b639d6f5ce6bfecc1463825dfb",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
    "average": 53.94,
    "arc": 58.36,
    "hellaswag": 82.33,
    "mmlu": 56.14,
    "truthfulqa": 39.51,
    "winogrande": 76.4,
    "gsm8k": 10.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d824054153586d58139b7c3527ba211f33a81382",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "trurl-2-13b-academic",
    "average": 53.94,
    "arc": 57.94,
    "hellaswag": 79.55,
    "mmlu": 55.2,
    "truthfulqa": 43.46,
    "winogrande": 76.56,
    "gsm8k": 10.92,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2e95049edf02368bbd4b4f6ffb50bc8821e919bb",
    "model_name_for_query": "Voicelab/trurl-2-13b-academic",
    "link": "https://huggingface.co/Voicelab/trurl-2-13b-academic",
    "author": "Voicelab"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pwen-7B-Chat-20_30",
    "average": 53.93,
    "arc": 51.45,
    "hellaswag": 73.99,
    "mmlu": 62.08,
    "truthfulqa": 47.01,
    "winogrande": 68.43,
    "gsm8k": 20.62,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "e6c38a7d2f4ba7b867fff421c08c02ba1908224e",
    "model_name_for_query": "JosephusCheung/Pwen-7B-Chat-20_30",
    "link": "https://huggingface.co/JosephusCheung/Pwen-7B-Chat-20_30",
    "author": "JosephusCheung"
  },
  {
    "T": "\u2b55",
    "model": "Ferret-7B",
    "average": 53.93,
    "arc": 62.29,
    "hellaswag": 81.31,
    "mmlu": 60.27,
    "truthfulqa": 40.01,
    "winogrande": 77.66,
    "gsm8k": 2.05,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b1ef5adff5ceb06d2d9808bccf5e06705f9e19dc",
    "model_name_for_query": "euclaise/Ferret-7B",
    "link": "https://huggingface.co/euclaise/Ferret-7B",
    "author": "euclaise"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13b-chat-platypus",
    "average": 53.92,
    "arc": 53.84,
    "hellaswag": 80.67,
    "mmlu": 54.44,
    "truthfulqa": 46.23,
    "winogrande": 76.01,
    "gsm8k": 12.36,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "828aa1020fc7d394fe8ee2c596e3211df7656eac",
    "model_name_for_query": "lgaalves/llama-2-13b-chat-platypus",
    "link": "https://huggingface.co/lgaalves/llama-2-13b-chat-platypus",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "average": 53.92,
    "arc": 60.58,
    "hellaswag": 82.97,
    "mmlu": 52.1,
    "truthfulqa": 46.1,
    "winogrande": 73.64,
    "gsm8k": 8.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.53,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "24ebae726954e4c1f24a8b2cbe0ca863012a7338",
    "model_name_for_query": "bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "link": "https://huggingface.co/bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "author": "bhenrym14"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-huangyt_Fintune_1_17w",
    "average": 53.91,
    "arc": 59.47,
    "hellaswag": 81.0,
    "mmlu": 54.31,
    "truthfulqa": 38.17,
    "winogrande": 77.27,
    "gsm8k": 13.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b499f140dc69506035dcb8212c66fcedff933d29",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MythoBoros-13b",
    "average": 53.9,
    "arc": 58.19,
    "hellaswag": 81.75,
    "mmlu": 50.13,
    "truthfulqa": 48.93,
    "winogrande": 75.77,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "67695d15e6610bc8055fbcde82f298e48ad2d374",
    "model_name_for_query": "Gryphe/MythoBoros-13b",
    "link": "https://huggingface.co/Gryphe/MythoBoros-13b",
    "author": "Gryphe"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13b-QLoRA",
    "average": 53.87,
    "arc": 58.02,
    "hellaswag": 82.33,
    "mmlu": 55.8,
    "truthfulqa": 46.23,
    "winogrande": 77.58,
    "gsm8k": 3.26,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d1a41d83c6bcc14378ee4859d65ef77a261d39d7",
    "model_name_for_query": "yeontaek/llama-2-13b-QLoRA",
    "link": "https://huggingface.co/yeontaek/llama-2-13b-QLoRA",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13b-gpt4-1.4-fp16",
    "average": 53.87,
    "arc": 59.64,
    "hellaswag": 83.22,
    "mmlu": 47.56,
    "truthfulqa": 48.82,
    "winogrande": 76.24,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "037e369be06a8a0eef87f2cddfd3469670483f29",
    "model_name_for_query": "jondurbin/airoboros-13b-gpt4-1.4-fp16",
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.4-fp16",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13b-gpt4-1.4",
    "average": 53.87,
    "arc": 59.64,
    "hellaswag": 83.22,
    "mmlu": 47.56,
    "truthfulqa": 48.82,
    "winogrande": 76.24,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "d0d2687ed2b4a63a644ed6c5b3f6401844718659",
    "model_name_for_query": "jondurbin/airoboros-13b-gpt4-1.4",
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.4",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "Ferret-7B",
    "average": 53.87,
    "arc": 62.29,
    "hellaswag": 81.33,
    "mmlu": 60.09,
    "truthfulqa": 39.94,
    "winogrande": 77.51,
    "gsm8k": 2.05,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e96b5245ef97999f143a2c9f9739e5cf52ec0d64",
    "model_name_for_query": "euclaise/Ferret-7B",
    "link": "https://huggingface.co/euclaise/Ferret-7B",
    "author": "euclaise"
  },
  {
    "T": "\u2b55",
    "model": "Ferret_7B",
    "average": 53.87,
    "arc": 62.29,
    "hellaswag": 81.33,
    "mmlu": 60.09,
    "truthfulqa": 39.94,
    "winogrande": 77.51,
    "gsm8k": 2.05,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c1e1e2743ffa7b9369aebac751b04f7e8740f80d",
    "model_name_for_query": "euclaise/Ferret_7B",
    "link": "https://huggingface.co/euclaise/Ferret_7B",
    "author": "euclaise"
  },
  {
    "T": "?",
    "model": "llama2-13b-ft-openllm-leaderboard-v1",
    "average": 53.86,
    "arc": 59.64,
    "hellaswag": 83.14,
    "mmlu": 60.93,
    "truthfulqa": 40.72,
    "winogrande": 77.35,
    "gsm8k": 1.36,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "70404059013c74b0641ed69d293b3d1ad708cd1e",
    "model_name_for_query": "zyh3826/llama2-13b-ft-openllm-leaderboard-v1",
    "link": "https://huggingface.co/zyh3826/llama2-13b-ft-openllm-leaderboard-v1",
    "author": "zyh3826"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
    "average": 53.86,
    "arc": 55.38,
    "hellaswag": 81.92,
    "mmlu": 55.28,
    "truthfulqa": 40.76,
    "winogrande": 76.09,
    "gsm8k": 13.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2ca747d779feaa99c475b8015c9b4a50aea41cd2",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-V1.2-PL-lora_unload",
    "average": 53.86,
    "arc": 58.53,
    "hellaswag": 81.1,
    "mmlu": 55.15,
    "truthfulqa": 46.18,
    "winogrande": 71.03,
    "gsm8k": 11.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5f14e6f5ea67fd2840791c46b3e00846cbdb32cf",
    "model_name_for_query": "Lajonbot/WizardLM-13B-V1.2-PL-lora_unload",
    "link": "https://huggingface.co/Lajonbot/WizardLM-13B-V1.2-PL-lora_unload",
    "author": "Lajonbot"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MythoLogic-13b",
    "average": 53.85,
    "arc": 58.45,
    "hellaswag": 81.56,
    "mmlu": 49.36,
    "truthfulqa": 49.47,
    "winogrande": 75.61,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "d89d925ad1eeaee465c4de3e5c74240a5a40b585",
    "model_name_for_query": "Gryphe/MythoLogic-13b",
    "link": "https://huggingface.co/Gryphe/MythoLogic-13b",
    "author": "Gryphe"
  },
  {
    "T": "\u2b55",
    "model": "platypus-2-22b-relora",
    "average": 53.83,
    "arc": 57.68,
    "hellaswag": 82.44,
    "mmlu": 55.33,
    "truthfulqa": 43.61,
    "winogrande": 77.35,
    "gsm8k": 6.6,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 21.83,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "15bca3e9b25cc2f280fec21686ef3bc445217503",
    "model_name_for_query": "chargoddard/platypus-2-22b-relora",
    "link": "https://huggingface.co/chargoddard/platypus-2-22b-relora",
    "author": "chargoddard"
  },
  {
    "T": "\u2b55",
    "model": "Libra-19B",
    "average": 53.83,
    "arc": 60.58,
    "hellaswag": 82.04,
    "mmlu": 55.57,
    "truthfulqa": 48.41,
    "winogrande": 76.32,
    "gsm8k": 0.08,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 19.2,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "a4e1f8f62740d676c25eedb4f29f4e776dcc0c22",
    "model_name_for_query": "Envoid/Libra-19B",
    "link": "https://huggingface.co/Envoid/Libra-19B",
    "author": "Envoid"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
    "average": 53.8,
    "arc": 58.62,
    "hellaswag": 82.56,
    "mmlu": 55.84,
    "truthfulqa": 42.09,
    "winogrande": 76.64,
    "gsm8k": 7.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "001a5f96daea57b5f256c2df270b35653b439f6f",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test-help-steer-filtered-orig",
    "average": 53.77,
    "arc": 57.59,
    "hellaswag": 80.42,
    "mmlu": 57.24,
    "truthfulqa": 41.1,
    "winogrande": 76.64,
    "gsm8k": 9.63,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bda6d45ddb3ef73df4d198d95416c66872429927",
    "model_name_for_query": "Weyaxi/test-help-steer-filtered-orig",
    "link": "https://huggingface.co/Weyaxi/test-help-steer-filtered-orig",
    "author": "Weyaxi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-hf_Open-Platypus-8bit-att",
    "average": 53.75,
    "arc": 57.51,
    "hellaswag": 82.14,
    "mmlu": 54.56,
    "truthfulqa": 42.21,
    "winogrande": 76.56,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "83a8e51d0a72dcfbe5de13dc7ee10dc20e91602e",
    "model_name_for_query": "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-8bit-att",
    "link": "https://huggingface.co/NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-8bit-att",
    "author": "NekoPunchBBB"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Kimiko-13B-fp16",
    "average": 53.75,
    "arc": 59.22,
    "hellaswag": 82.35,
    "mmlu": 55.85,
    "truthfulqa": 39.55,
    "winogrande": 76.72,
    "gsm8k": 8.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "27868769e2d6b1af46337f0997c71b0577952a3d",
    "model_name_for_query": "TheBloke/Kimiko-13B-fp16",
    "link": "https://huggingface.co/TheBloke/Kimiko-13B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "GiftedConvo13bLoraNoEconsE4",
    "average": 53.74,
    "arc": 59.9,
    "hellaswag": 84.11,
    "mmlu": 54.67,
    "truthfulqa": 41.94,
    "winogrande": 74.03,
    "gsm8k": 7.81,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "f3d421aadb29830345bf392f793ce3c33e7d68c5",
    "model_name_for_query": "NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEconsE4",
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEconsE4",
    "author": "NobodyExistsOnTheInternet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
    "average": 53.74,
    "arc": 58.53,
    "hellaswag": 82.47,
    "mmlu": 53.9,
    "truthfulqa": 37.92,
    "winogrande": 76.8,
    "gsm8k": 12.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1d776fed32c0863d991d266fea6ca64750444fec",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2-13B-QLoRa",
    "average": 53.74,
    "arc": 57.51,
    "hellaswag": 82.55,
    "mmlu": 57.34,
    "truthfulqa": 43.38,
    "winogrande": 76.64,
    "gsm8k": 5.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e62a8fafce0d64ac03d465a4e915bc1f50776a08",
    "model_name_for_query": "yeontaek/Platypus2-13B-QLoRa",
    "link": "https://huggingface.co/yeontaek/Platypus2-13B-QLoRa",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zarafusionex-1.2-l2-7b",
    "average": 53.73,
    "arc": 56.66,
    "hellaswag": 79.16,
    "mmlu": 51.94,
    "truthfulqa": 51.29,
    "winogrande": 74.74,
    "gsm8k": 8.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "68ca01427848528ab21263fd06720a081b09d063",
    "model_name_for_query": "zarakiquemparte/zarafusionex-1.2-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zarafusionex-1.2-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
    "average": 53.71,
    "arc": 57.25,
    "hellaswag": 81.49,
    "mmlu": 55.9,
    "truthfulqa": 39.79,
    "winogrande": 75.77,
    "gsm8k": 12.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a12fb5937e6904977e8123b0d5ef21283b6895d4",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
    "average": 53.71,
    "arc": 57.25,
    "hellaswag": 81.79,
    "mmlu": 53.96,
    "truthfulqa": 39.66,
    "winogrande": 77.82,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8a75b17d4b60f820159bb0100f26f438727bb199",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-v1.3-PL-lora_unload",
    "average": 53.7,
    "arc": 54.86,
    "hellaswag": 80.41,
    "mmlu": 52.2,
    "truthfulqa": 49.62,
    "winogrande": 76.09,
    "gsm8k": 9.02,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5582369752583b02df3cba4bd2a733d12265cddb",
    "model_name_for_query": "Lajonbot/vicuna-13b-v1.3-PL-lora_unload",
    "link": "https://huggingface.co/Lajonbot/vicuna-13b-v1.3-PL-lora_unload",
    "author": "Lajonbot"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gaodrew-gorgonzola-13b has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/215\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #215</a>",
    "average": 53.7,
    "arc": 50.94,
    "hellaswag": 77.65,
    "mmlu": 68.93,
    "truthfulqa": 40.63,
    "winogrande": 75.45,
    "gsm8k": 8.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a53fbe358d4cb546916847d861ccfaf7c724a103",
    "model_name_for_query": "gaodrew/gaodrew-gorgonzola-13b",
    "link": "https://huggingface.co/gaodrew/gaodrew-gorgonzola-13b",
    "author": "gaodrew"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
    "average": 53.69,
    "arc": 55.72,
    "hellaswag": 81.55,
    "mmlu": 53.9,
    "truthfulqa": 41.89,
    "winogrande": 77.19,
    "gsm8k": 11.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "eb934db4644738a74143b381445213979c8858ed",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-huangyt_FINETUNE2_3w",
    "average": 53.69,
    "arc": 58.62,
    "hellaswag": 82.32,
    "mmlu": 54.25,
    "truthfulqa": 38.17,
    "winogrande": 76.8,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "08bc7112a775dd4223d441355f3d619694013789",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-chat-dutch",
    "average": 53.69,
    "arc": 59.3,
    "hellaswag": 81.45,
    "mmlu": 55.82,
    "truthfulqa": 38.23,
    "winogrande": 76.64,
    "gsm8k": 10.69,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-sa-4.0",
    "params": 13.02,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "428508a0cf288c0f5b7891c9b2f758ddf4d62c26",
    "model_name_for_query": "BramVanroy/Llama-2-13b-chat-dutch",
    "link": "https://huggingface.co/BramVanroy/Llama-2-13b-chat-dutch",
    "author": "BramVanroy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13b-gpt4-1.1",
    "average": 53.68,
    "arc": 59.04,
    "hellaswag": 83.05,
    "mmlu": 49.41,
    "truthfulqa": 46.62,
    "winogrande": 75.77,
    "gsm8k": 8.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "19c7060adcb34d42e742fe51dd36b8657ac069b7",
    "model_name_for_query": "jondurbin/airoboros-13b-gpt4-1.1",
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
    "average": 53.68,
    "arc": 56.23,
    "hellaswag": 81.98,
    "mmlu": 55.87,
    "truthfulqa": 39.76,
    "winogrande": 76.72,
    "gsm8k": 11.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "cc3c5e5a874cf4ff4f94ea919e819f8a914c8acb",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "?",
    "model": "bimoGPT-llama2-13b",
    "average": 53.68,
    "arc": 58.79,
    "hellaswag": 82.08,
    "mmlu": 55.6,
    "truthfulqa": 37.82,
    "winogrande": 76.48,
    "gsm8k": 11.3,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "openrail",
    "params": 13.0,
    "likes": 6.0,
    "still_on_hub": false,
    "revision": "c29b67965ea55da3e2ac678eef7ffdf36f8ef5ab",
    "model_name_for_query": "shareAI/bimoGPT-llama2-13b",
    "link": "https://huggingface.co/shareAI/bimoGPT-llama2-13b",
    "author": "shareAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Llama-2-13B-fp16",
    "average": 53.67,
    "arc": 59.3,
    "hellaswag": 82.15,
    "mmlu": 55.67,
    "truthfulqa": 37.39,
    "winogrande": 76.64,
    "gsm8k": 10.84,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 51.0,
    "still_on_hub": true,
    "revision": "b2e65e8ad4bb35e5abaee0170ebd5fc2134a50bb",
    "model_name_for_query": "TheBloke/Llama-2-13B-fp16",
    "link": "https://huggingface.co/TheBloke/Llama-2-13B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Starlight-13B",
    "average": 53.67,
    "arc": 59.3,
    "hellaswag": 82.15,
    "mmlu": 55.67,
    "truthfulqa": 37.39,
    "winogrande": 76.64,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "cb9fced568b1abd881133c642c427aaa488f00cc",
    "model_name_for_query": "NewstaR/Starlight-13B",
    "link": "https://huggingface.co/NewstaR/Starlight-13B",
    "author": "NewstaR"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Flash-Llama-13B",
    "average": 53.67,
    "arc": 59.3,
    "hellaswag": 82.15,
    "mmlu": 55.67,
    "truthfulqa": 37.39,
    "winogrande": 76.64,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "81b40096471a8980e3e1a8998f358bd363033783",
    "model_name_for_query": "TaylorAI/Flash-Llama-13B",
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-13B",
    "author": "TaylorAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
    "average": 53.66,
    "arc": 55.8,
    "hellaswag": 82.27,
    "mmlu": 55.63,
    "truthfulqa": 38.15,
    "winogrande": 77.43,
    "gsm8k": 12.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "48b8ceeb62e5ca897f284bbc0923201689af7c89",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-22b-blocktriangular",
    "average": 53.65,
    "arc": 58.28,
    "hellaswag": 82.69,
    "mmlu": 54.53,
    "truthfulqa": 39.23,
    "winogrande": 75.93,
    "gsm8k": 11.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 21.62,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "7adbaa5b8e122bb93bf510d8655ec4132d7b4a8a",
    "model_name_for_query": "chargoddard/llama2-22b-blocktriangular",
    "link": "https://huggingface.co/chargoddard/llama2-22b-blocktriangular",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13b-gpt4",
    "average": 53.64,
    "arc": 59.39,
    "hellaswag": 83.29,
    "mmlu": 47.89,
    "truthfulqa": 47.65,
    "winogrande": 75.77,
    "gsm8k": 7.88,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "c0eef6e6f63d4b11953539308717cea0079b44f9",
    "model_name_for_query": "jondurbin/airoboros-13b-gpt4",
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4",
    "author": "jondurbin"
  },
  {
    "T": "?",
    "model": "llama2-22b",
    "average": 53.64,
    "arc": 58.53,
    "hellaswag": 82.55,
    "mmlu": 54.68,
    "truthfulqa": 39.84,
    "winogrande": 76.32,
    "gsm8k": 9.93,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 21.62,
    "likes": 35.0,
    "still_on_hub": true,
    "revision": "2bece0787009b4b584f49d0e0d1b49ecf4a52da9",
    "model_name_for_query": "chargoddard/llama2-22b",
    "link": "https://huggingface.co/chargoddard/llama2-22b",
    "author": "chargoddard"
  },
  {
    "T": "\u2b55",
    "model": "platypus2-22b-relora",
    "average": 53.64,
    "arc": 57.51,
    "hellaswag": 82.36,
    "mmlu": 54.94,
    "truthfulqa": 43.62,
    "winogrande": 77.11,
    "gsm8k": 6.29,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 21.83,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "15bca3e9b25cc2f280fec21686ef3bc445217503",
    "model_name_for_query": "chargoddard/platypus2-22b-relora",
    "link": "https://huggingface.co/chargoddard/platypus2-22b-relora",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PuffedLIMA13bQLORA",
    "average": 53.63,
    "arc": 59.9,
    "hellaswag": 84.39,
    "mmlu": 53.68,
    "truthfulqa": 39.9,
    "winogrande": 75.22,
    "gsm8k": 8.72,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "7da6d235d625e16c850ccd0b947dee40071b1f89",
    "model_name_for_query": "NobodyExistsOnTheInternet/PuffedLIMA13bQLORA",
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/PuffedLIMA13bQLORA",
    "author": "NobodyExistsOnTheInternet"
  },
  {
    "T": "\u2b55",
    "model": "deacon-13b",
    "average": 53.63,
    "arc": 57.85,
    "hellaswag": 82.63,
    "mmlu": 55.25,
    "truthfulqa": 39.33,
    "winogrande": 76.32,
    "gsm8k": 10.39,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6c3a002f6c9e8a481a7375d91856d603bf6dd040",
    "model_name_for_query": "KnutJaegersberg/deacon-13b",
    "link": "https://huggingface.co/KnutJaegersberg/deacon-13b",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
    "average": 53.62,
    "arc": 59.04,
    "hellaswag": 81.15,
    "mmlu": 53.0,
    "truthfulqa": 40.16,
    "winogrande": 76.48,
    "gsm8k": 11.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ac40ecf48cf5f7168e8c3929632c654bc834c3d7",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-FINETUNE3_TEST2",
    "average": 53.62,
    "arc": 54.69,
    "hellaswag": 81.48,
    "mmlu": 56.8,
    "truthfulqa": 39.93,
    "winogrande": 76.24,
    "gsm8k": 12.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9e6431061bd13852a7435f5fe7a6eb0bbd148e14",
    "model_name_for_query": "wei123602/llama2-13b-FINETUNE3_TEST2",
    "link": "https://huggingface.co/wei123602/llama2-13b-FINETUNE3_TEST2",
    "author": "wei123602"
  },
  {
    "T": "\u2b55",
    "model": "tora-13b-v1.0",
    "average": 53.62,
    "arc": 58.96,
    "hellaswag": 82.31,
    "mmlu": 54.73,
    "truthfulqa": 40.25,
    "winogrande": 75.61,
    "gsm8k": 9.86,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "0636c1f582c979a5a292cc5f3dc293800b1494e2",
    "model_name_for_query": "llm-agents/tora-13b-v1.0",
    "link": "https://huggingface.co/llm-agents/tora-13b-v1.0",
    "author": "llm-agents"
  },
  {
    "T": "\u2b55",
    "model": "MistralInstructLongish",
    "average": 53.62,
    "arc": 60.75,
    "hellaswag": 81.86,
    "mmlu": 60.49,
    "truthfulqa": 40.55,
    "winogrande": 76.56,
    "gsm8k": 1.52,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "813c4707970cb5bf3e2a49f7f350af59e7032c24",
    "model_name_for_query": "KnutJaegersberg/MistralInstructLongish",
    "link": "https://huggingface.co/KnutJaegersberg/MistralInstructLongish",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PuffedConvo13bLoraE4",
    "average": 53.62,
    "arc": 59.81,
    "hellaswag": 84.39,
    "mmlu": 53.62,
    "truthfulqa": 39.87,
    "winogrande": 75.22,
    "gsm8k": 8.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "40e4fce0c25bd23f6011b424748ee2b5374b98d5",
    "model_name_for_query": "NobodyExistsOnTheInternet/PuffedConvo13bLoraE4",
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/PuffedConvo13bLoraE4",
    "author": "NobodyExistsOnTheInternet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-FINETUNE4_TEST",
    "average": 53.62,
    "arc": 54.78,
    "hellaswag": 81.52,
    "mmlu": 56.03,
    "truthfulqa": 39.14,
    "winogrande": 77.03,
    "gsm8k": 13.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0ed198a814192b06e60715112d2a4b6bfd630806",
    "model_name_for_query": "wei123602/Llama-2-13b-FINETUNE4_TEST",
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_TEST",
    "author": "wei123602"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Hermes-13b-pl-lora_unload",
    "average": 53.61,
    "arc": 57.08,
    "hellaswag": 81.49,
    "mmlu": 49.17,
    "truthfulqa": 48.3,
    "winogrande": 76.4,
    "gsm8k": 9.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d0ef3991a11c4dc2ea2f832d4082c89c3c5e810c",
    "model_name_for_query": "Aspik101/Nous-Hermes-13b-pl-lora_unload",
    "link": "https://huggingface.co/Aspik101/Nous-Hermes-13b-pl-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Python-Code-13B",
    "average": 53.61,
    "arc": 58.79,
    "hellaswag": 81.66,
    "mmlu": 54.78,
    "truthfulqa": 42.83,
    "winogrande": 74.03,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 13.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "981454b6a2275f787592589609df7f2bf558706d",
    "model_name_for_query": "ajibawa-2023/Python-Code-13B",
    "link": "https://huggingface.co/ajibawa-2023/Python-Code-13B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-ft-mc4_nl_cleaned_tiny",
    "average": 53.6,
    "arc": 59.3,
    "hellaswag": 82.04,
    "mmlu": 54.67,
    "truthfulqa": 38.03,
    "winogrande": 77.27,
    "gsm8k": 10.31,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b23fe7d174653b87dc08507d9b83504a8dddbc45",
    "model_name_for_query": "BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny",
    "link": "https://huggingface.co/BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny",
    "author": "BramVanroy"
  },
  {
    "T": "\u2b55",
    "model": "WizardLM-1.0-Uncensored-CodeLlama-34b",
    "average": 53.59,
    "arc": 56.4,
    "hellaswag": 75.45,
    "mmlu": 54.51,
    "truthfulqa": 43.06,
    "winogrande": 72.45,
    "gsm8k": 19.64,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "3e8df2cf4a4ee1c0b2d079cb7be70024d425ea8c",
    "model_name_for_query": "ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b",
    "link": "https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
    "average": 53.58,
    "arc": 54.35,
    "hellaswag": 82.13,
    "mmlu": 55.33,
    "truthfulqa": 39.6,
    "winogrande": 77.19,
    "gsm8k": 12.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1646a2b77ddeaf0f848c96ed68726556c7539729",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "tulu-13B-fp16",
    "average": 53.58,
    "arc": 53.92,
    "hellaswag": 80.66,
    "mmlu": 53.19,
    "truthfulqa": 43.84,
    "winogrande": 75.61,
    "gsm8k": 14.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "532aeb363b0ceee155b3cf9479ef635b797cee7c",
    "model_name_for_query": "TheBloke/tulu-13B-fp16",
    "link": "https://huggingface.co/TheBloke/tulu-13B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
    "average": 53.57,
    "arc": 58.96,
    "hellaswag": 81.94,
    "mmlu": 55.0,
    "truthfulqa": 40.26,
    "winogrande": 76.56,
    "gsm8k": 8.72,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "30edbe648df2661dd779cd19ef613e6914dcc8e0",
    "model_name_for_query": "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "StableBeluga-7B",
    "average": 53.56,
    "arc": 56.31,
    "hellaswag": 79.14,
    "mmlu": 52.71,
    "truthfulqa": 50.19,
    "winogrande": 75.22,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 112.0,
    "still_on_hub": true,
    "revision": "329adcfc39f48dce183eb0b155b732dbe03c6304",
    "model_name_for_query": "stabilityai/StableBeluga-7B",
    "link": "https://huggingface.co/stabilityai/StableBeluga-7B",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-orca-v1",
    "average": 53.56,
    "arc": 56.31,
    "hellaswag": 79.14,
    "mmlu": 52.71,
    "truthfulqa": 50.19,
    "winogrande": 75.22,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 6.61,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "e501f231277671710384ba0397da2c4486865958",
    "model_name_for_query": "circulus/Llama-2-7b-orca-v1",
    "link": "https://huggingface.co/circulus/Llama-2-7b-orca-v1",
    "author": "circulus"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolphin-llama-13b",
    "average": 53.56,
    "arc": 55.55,
    "hellaswag": 77.11,
    "mmlu": 52.16,
    "truthfulqa": 52.23,
    "winogrande": 69.93,
    "gsm8k": 14.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 56.0,
    "still_on_hub": true,
    "revision": "b6d16c3e1cffef5e914863f41fd96152dafddd6f",
    "model_name_for_query": "ehartford/dolphin-llama-13b",
    "link": "https://huggingface.co/ehartford/dolphin-llama-13b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-llama-13b-2-epochs",
    "average": 53.55,
    "arc": 57.94,
    "hellaswag": 82.4,
    "mmlu": 48.56,
    "truthfulqa": 47.27,
    "winogrande": 76.87,
    "gsm8k": 8.26,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "0e3796192f7edf43968541b9454ea35da4a2b1c5",
    "model_name_for_query": "dvruette/oasst-llama-13b-2-epochs",
    "link": "https://huggingface.co/dvruette/oasst-llama-13b-2-epochs",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "guanaco-13B-HF",
    "average": 53.54,
    "arc": 57.85,
    "hellaswag": 83.84,
    "mmlu": 48.28,
    "truthfulqa": 46.73,
    "winogrande": 75.85,
    "gsm8k": 8.72,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "bd59c700815124df616a17f5b49a0bc51590b231",
    "model_name_for_query": "TheBloke/guanaco-13B-HF",
    "link": "https://huggingface.co/TheBloke/guanaco-13B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "tableBeluga-7B-instruct-pl-lora_unload",
    "average": 53.54,
    "arc": 56.23,
    "hellaswag": 79.12,
    "mmlu": 52.7,
    "truthfulqa": 50.19,
    "winogrande": 75.22,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "eeb22ca9481a5ed7e131a329324494f234300a45",
    "model_name_for_query": "Lajonbot/tableBeluga-7B-instruct-pl-lora_unload",
    "link": "https://huggingface.co/Lajonbot/tableBeluga-7B-instruct-pl-lora_unload",
    "author": "Lajonbot"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-22b-blocktriangular",
    "average": 53.53,
    "arc": 58.53,
    "hellaswag": 82.59,
    "mmlu": 54.64,
    "truthfulqa": 39.3,
    "winogrande": 76.32,
    "gsm8k": 9.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 21.62,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "40a51343ae776b5cb39f2b4343ae8f9b676ffd58",
    "model_name_for_query": "chargoddard/llama2-22b-blocktriangular",
    "link": "https://huggingface.co/chargoddard/llama2-22b-blocktriangular",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama-13b",
    "average": 53.53,
    "arc": 58.96,
    "hellaswag": 79.71,
    "mmlu": 49.1,
    "truthfulqa": 49.59,
    "winogrande": 75.61,
    "gsm8k": 8.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "dd326f89ce885844d714d9ab33603e0d17f56cc5",
    "model_name_for_query": "YeungNLP/firefly-llama-13b",
    "link": "https://huggingface.co/YeungNLP/firefly-llama-13b",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-Open_Platypus_and_ccp_2.6w",
    "average": 53.52,
    "arc": 58.96,
    "hellaswag": 82.51,
    "mmlu": 56.12,
    "truthfulqa": 40.07,
    "winogrande": 76.64,
    "gsm8k": 6.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2929bfa1049db46df94f5710755178d18a981665",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
    "average": 53.52,
    "arc": 55.03,
    "hellaswag": 81.97,
    "mmlu": 56.64,
    "truthfulqa": 38.07,
    "winogrande": 77.19,
    "gsm8k": 12.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "555486843f613276b6edb480f6d37b9203daa226",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama13B-quant8-testv1-openorca-customdataset",
    "average": 53.5,
    "arc": 60.49,
    "hellaswag": 82.97,
    "mmlu": 54.44,
    "truthfulqa": 37.34,
    "winogrande": 75.69,
    "gsm8k": 10.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f364d000bedac80e72aa103c08b77aee1b61b7da",
    "model_name_for_query": "IGeniusDev/llama13B-quant8-testv1-openorca-customdataset",
    "link": "https://huggingface.co/IGeniusDev/llama13B-quant8-testv1-openorca-customdataset",
    "author": "IGeniusDev"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-13b-chat",
    "average": 53.5,
    "arc": 58.62,
    "hellaswag": 80.85,
    "mmlu": 47.76,
    "truthfulqa": 48.73,
    "winogrande": 76.72,
    "gsm8k": 8.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "27002e974774c3599e6a4d731dd44e68b9e41f92",
    "model_name_for_query": "bofenghuang/vigogne-13b-chat",
    "link": "https://huggingface.co/bofenghuang/vigogne-13b-chat",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-mistral-7b-v13",
    "average": 53.5,
    "arc": 52.3,
    "hellaswag": 75.09,
    "mmlu": 56.34,
    "truthfulqa": 50.81,
    "winogrande": 71.74,
    "gsm8k": 14.71,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.13,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "e6c4cc00e1bb2aa2082c2b8fd93c949aa36ce300",
    "model_name_for_query": "OpenBuddy/openbuddy-mistral-7b-v13",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-mistral-7b-v13",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama-13b-v1.2",
    "average": 53.49,
    "arc": 56.74,
    "hellaswag": 80.34,
    "mmlu": 48.9,
    "truthfulqa": 51.0,
    "winogrande": 75.93,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c0a56d9f5a15bea07493191b5a6295f6797a9b2c",
    "model_name_for_query": "YeungNLP/firefly-llama-13b-v1.2",
    "link": "https://huggingface.co/YeungNLP/firefly-llama-13b-v1.2",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
    "average": 53.48,
    "arc": 55.8,
    "hellaswag": 81.74,
    "mmlu": 55.09,
    "truthfulqa": 39.12,
    "winogrande": 76.32,
    "gsm8k": 12.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aefc3a122cb054b070a212d1127600775aded4be",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_v3_7b",
    "average": 53.47,
    "arc": 56.91,
    "hellaswag": 79.64,
    "mmlu": 52.37,
    "truthfulqa": 50.51,
    "winogrande": 74.27,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 37.0,
    "still_on_hub": true,
    "revision": "a1583d2f02041fb37df28eeae4da644d8dff33eb",
    "model_name_for_query": "psmathur/orca_mini_v3_7b",
    "link": "https://huggingface.co/psmathur/orca_mini_v3_7b",
    "author": "psmathur"
  },
  {
    "T": "\u2b55",
    "model": "orca_mini_v3_7b",
    "average": 53.47,
    "arc": 56.91,
    "hellaswag": 79.64,
    "mmlu": 52.37,
    "truthfulqa": 50.51,
    "winogrande": 74.27,
    "gsm8k": 7.13,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 37.0,
    "still_on_hub": true,
    "revision": "f9849ea6bf0f6ebb78dca1cea1c7a3ef8f7d715c",
    "model_name_for_query": "pankajmathur/orca_mini_v3_7b",
    "link": "https://huggingface.co/pankajmathur/orca_mini_v3_7b",
    "author": "pankajmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama2-13b-chat",
    "average": 53.46,
    "arc": 57.51,
    "hellaswag": 77.94,
    "mmlu": 52.56,
    "truthfulqa": 48.18,
    "winogrande": 74.74,
    "gsm8k": 9.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.97,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9497e3bd12e19e1300bc7b1980fbe232420134b9",
    "model_name_for_query": "YeungNLP/firefly-llama2-13b-chat",
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b-chat",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
    "average": 53.44,
    "arc": 55.8,
    "hellaswag": 82.1,
    "mmlu": 55.33,
    "truthfulqa": 39.82,
    "winogrande": 76.24,
    "gsm8k": 11.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "86f255afabc8986c73376cafd98628a068649022",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
    "average": 53.43,
    "arc": 57.94,
    "hellaswag": 81.19,
    "mmlu": 53.43,
    "truthfulqa": 40.48,
    "winogrande": 76.72,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "15f1b122d60631091419cb8e668a28737b92a0e0",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "tigerbot-13b-base",
    "average": 53.42,
    "arc": 53.84,
    "hellaswag": 77.05,
    "mmlu": 53.57,
    "truthfulqa": 44.06,
    "winogrande": 74.98,
    "gsm8k": 17.06,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "2df5ed76be7eff0962f2d816a64eca1e78e1cbf3",
    "model_name_for_query": "TigerResearch/tigerbot-13b-base",
    "link": "https://huggingface.co/TigerResearch/tigerbot-13b-base",
    "author": "TigerResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zarafusionex-1.1-l2-7b",
    "average": 53.41,
    "arc": 56.14,
    "hellaswag": 79.34,
    "mmlu": 52.1,
    "truthfulqa": 50.66,
    "winogrande": 74.43,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "3268ff5291934a14f3f5e7013bbb408f33adb542",
    "model_name_for_query": "zarakiquemparte/zarafusionex-1.1-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zarafusionex-1.1-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "?",
    "model": "QuantumLM",
    "average": 53.41,
    "arc": 55.8,
    "hellaswag": 79.74,
    "mmlu": 54.17,
    "truthfulqa": 46.71,
    "winogrande": 74.19,
    "gsm8k": 9.86,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "9058130b416355b37f5f78777748aa56d98a4da0",
    "model_name_for_query": "quantumaikr/QuantumLM",
    "link": "https://huggingface.co/quantumaikr/QuantumLM",
    "author": "quantumaikr"
  },
  {
    "T": "\u2b55",
    "model": "samantha-mistral-instruct-7b",
    "average": 53.4,
    "arc": 53.5,
    "hellaswag": 75.14,
    "mmlu": 51.72,
    "truthfulqa": 58.81,
    "winogrande": 70.4,
    "gsm8k": 10.84,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "3a33eea0858d411617c472c3c0ae39f17d2b3f5d",
    "model_name_for_query": "ehartford/samantha-mistral-instruct-7b",
    "link": "https://huggingface.co/ehartford/samantha-mistral-instruct-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-30b-instruct",
    "average": 53.4,
    "arc": 58.45,
    "hellaswag": 84.31,
    "mmlu": 49.15,
    "truthfulqa": 38.05,
    "winogrande": 75.14,
    "gsm8k": 15.31,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-3.0",
    "params": 29.96,
    "likes": 93.0,
    "still_on_hub": true,
    "revision": "2abf1163dd8c9b11f07d805c06e6ec90a1f2037e",
    "model_name_for_query": "mosaicml/mpt-30b-instruct",
    "link": "https://huggingface.co/mosaicml/mpt-30b-instruct",
    "author": "mosaicml"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT4-x-Alpasta-13b",
    "average": 53.38,
    "arc": 58.53,
    "hellaswag": 79.92,
    "mmlu": 46.03,
    "truthfulqa": 53.06,
    "winogrande": 73.95,
    "gsm8k": 8.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "50af05b015446110a2dc52a1b4b341142c98e62b",
    "model_name_for_query": "Aeala/GPT4-x-Alpasta-13b",
    "link": "https://huggingface.co/Aeala/GPT4-x-Alpasta-13b",
    "author": "Aeala"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
    "average": 53.38,
    "arc": 55.89,
    "hellaswag": 81.38,
    "mmlu": 53.77,
    "truthfulqa": 40.25,
    "winogrande": 76.72,
    "gsm8k": 12.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a8b15badead658df6ec5b884b813962b9fd29cfb",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "GiftedConvo13bLoraNoEcons",
    "average": 53.35,
    "arc": 59.39,
    "hellaswag": 83.19,
    "mmlu": 55.15,
    "truthfulqa": 40.56,
    "winogrande": 74.03,
    "gsm8k": 7.81,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9d7031e7d956dd2d25c61d85f594d115ce65b172",
    "model_name_for_query": "NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEcons",
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEcons",
    "author": "NobodyExistsOnTheInternet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
    "average": 53.35,
    "arc": 56.4,
    "hellaswag": 81.93,
    "mmlu": 53.63,
    "truthfulqa": 39.23,
    "winogrande": 76.95,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dd61a482fa2f71efe6f22aae6949355ca4b06ccc",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-13b-2.1",
    "average": 53.34,
    "arc": 59.47,
    "hellaswag": 82.47,
    "mmlu": 54.83,
    "truthfulqa": 44.65,
    "winogrande": 75.06,
    "gsm8k": 3.56,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "172e30e56e939f73d7d00a165c2d49cbd284481f",
    "model_name_for_query": "jondurbin/airoboros-l2-13b-2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
    "average": 53.32,
    "arc": 58.36,
    "hellaswag": 81.1,
    "mmlu": 54.53,
    "truthfulqa": 37.02,
    "winogrande": 76.64,
    "gsm8k": 12.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5cbcd9c0a6b9a19f0d099e653cde18e11bf95303",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "?",
    "model": "vicuna-13b-v1.3.0-GPTQ",
    "average": 53.29,
    "arc": 54.35,
    "hellaswag": 79.47,
    "mmlu": 51.97,
    "truthfulqa": 50.88,
    "winogrande": 74.66,
    "gsm8k": 8.42,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "6ef1f8d8638ea2d6681a8e3da73be57c501d847b",
    "model_name_for_query": "TheBloke/vicuna-13b-v1.3.0-GPTQ",
    "link": "https://huggingface.co/TheBloke/vicuna-13b-v1.3.0-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13B-1.1-HF",
    "average": 53.29,
    "arc": 52.73,
    "hellaswag": 80.13,
    "mmlu": 51.94,
    "truthfulqa": 52.08,
    "winogrande": 74.19,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 96.0,
    "still_on_hub": true,
    "revision": "8c71dbe9221e83d2ec72e4dc08beccfc78b563c0",
    "model_name_for_query": "TheBloke/vicuna-13B-1.1-HF",
    "link": "https://huggingface.co/TheBloke/vicuna-13B-1.1-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-1.1",
    "average": 53.29,
    "arc": 52.73,
    "hellaswag": 80.13,
    "mmlu": 51.94,
    "truthfulqa": 52.08,
    "winogrande": 74.19,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 134.0,
    "still_on_hub": true,
    "revision": "bfcc6ca66694310be6c85ba0638597f4256c4143",
    "model_name_for_query": "eachadea/vicuna-13b-1.1",
    "link": "https://huggingface.co/eachadea/vicuna-13b-1.1",
    "author": "eachadea"
  },
  {
    "T": "\ud83d\udd36",
    "model": "delta13b",
    "average": 53.29,
    "arc": 52.73,
    "hellaswag": 80.13,
    "mmlu": 51.94,
    "truthfulqa": 52.08,
    "winogrande": 74.19,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "83fa0860990df1db35550f973ba4306449e35412",
    "model_name_for_query": "pillowtalks-ai/delta13b",
    "link": "https://huggingface.co/pillowtalks-ai/delta13b",
    "author": "pillowtalks-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Vicuna-13B-CoT",
    "average": 53.29,
    "arc": 52.73,
    "hellaswag": 80.13,
    "mmlu": 51.94,
    "truthfulqa": 52.08,
    "winogrande": 74.19,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "346e3c46959cf9f1e03feffa761afe020c0fb6a8",
    "model_name_for_query": "kevinpro/Vicuna-13B-CoT",
    "link": "https://huggingface.co/kevinpro/Vicuna-13B-CoT",
    "author": "kevinpro"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Vicuna-13B-CoT-fp16",
    "average": 53.28,
    "arc": 52.73,
    "hellaswag": 80.14,
    "mmlu": 51.9,
    "truthfulqa": 52.08,
    "winogrande": 74.19,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "fe74a0ece9089828b301bd0f067ae5f257516179",
    "model_name_for_query": "TheBloke/Vicuna-13B-CoT-fp16",
    "link": "https://huggingface.co/TheBloke/Vicuna-13B-CoT-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-v1.1",
    "average": 53.28,
    "arc": 52.73,
    "hellaswag": 80.14,
    "mmlu": 51.9,
    "truthfulqa": 52.08,
    "winogrande": 74.19,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 96.0,
    "still_on_hub": true,
    "revision": "8c71dbe9221e83d2ec72e4dc08beccfc78b563c0",
    "model_name_for_query": "lmsys/vicuna-13b-v1.1",
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.1",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b-delta-v1.1",
    "average": 53.28,
    "arc": 52.73,
    "hellaswag": 80.14,
    "mmlu": 51.9,
    "truthfulqa": 52.08,
    "winogrande": 74.19,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 402.0,
    "still_on_hub": true,
    "revision": "ffed4c7cf1b9814812078efbe29ec3f610ea39e7",
    "model_name_for_query": "lmsys/vicuna-13b-delta-v1.1",
    "link": "https://huggingface.co/lmsys/vicuna-13b-delta-v1.1",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13B-GPTQ",
    "average": 53.26,
    "arc": 59.13,
    "hellaswag": 81.48,
    "mmlu": 54.45,
    "truthfulqa": 37.07,
    "winogrande": 76.16,
    "gsm8k": 11.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "llama2",
    "params": 16.23,
    "likes": 99.0,
    "still_on_hub": true,
    "revision": "b7db471d1789802a3a8e3b93cdd66a9f046f17c3",
    "model_name_for_query": "TheBloke/Llama-2-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/Llama-2-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
    "average": 53.23,
    "arc": 56.31,
    "hellaswag": 81.43,
    "mmlu": 55.3,
    "truthfulqa": 39.11,
    "winogrande": 76.8,
    "gsm8k": 10.46,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0d8d502e4e5ef89592dd0d3bc7223eaf7f77f78b",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-2.1-llama-2-13B-QLoRa",
    "average": 53.23,
    "arc": 59.73,
    "hellaswag": 82.91,
    "mmlu": 54.77,
    "truthfulqa": 45.14,
    "winogrande": 74.03,
    "gsm8k": 2.81,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ebf991c8d34314caab6ccc6b078c681d20bac39a",
    "model_name_for_query": "yeontaek/airoboros-2.1-llama-2-13B-QLoRa",
    "link": "https://huggingface.co/yeontaek/airoboros-2.1-llama-2-13B-QLoRa",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE2_TEST_2.2w",
    "average": 53.2,
    "arc": 56.23,
    "hellaswag": 82.7,
    "mmlu": 55.35,
    "truthfulqa": 39.55,
    "winogrande": 76.72,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3be177b35f1b44d147751ab38ca6d8a008eb6b7f",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE2_TEST_2.2w",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE2_TEST_2.2w",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-Llemma-7B",
    "average": 53.19,
    "arc": 46.5,
    "hellaswag": 61.69,
    "mmlu": 47.66,
    "truthfulqa": 39.61,
    "winogrande": 62.75,
    "gsm8k": 60.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "e31ec61dccd8fa24f44f0592a518491ef76a2235",
    "model_name_for_query": "meta-math/MetaMath-Llemma-7B",
    "link": "https://huggingface.co/meta-math/MetaMath-Llemma-7B",
    "author": "meta-math"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
    "average": 53.18,
    "arc": 54.78,
    "hellaswag": 81.4,
    "mmlu": 54.73,
    "truthfulqa": 41.02,
    "winogrande": 76.64,
    "gsm8k": 10.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8702b433008a62e9f8bf15e70ba15fa7100e991c",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zarafusionix-l2-7b",
    "average": 53.18,
    "arc": 55.55,
    "hellaswag": 79.4,
    "mmlu": 51.21,
    "truthfulqa": 51.05,
    "winogrande": 74.66,
    "gsm8k": 7.2,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "13d0e2498a4b5f53f6dc2464f20e093b07a4bd4b",
    "model_name_for_query": "zarakiquemparte/zarafusionix-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zarafusionix-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-V1-1-SuperHOT-8K-fp16",
    "average": 53.16,
    "arc": 58.62,
    "hellaswag": 81.07,
    "mmlu": 48.32,
    "truthfulqa": 54.19,
    "winogrande": 76.01,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "83905656ca3e63877b8d9f3a74118da0c9bc6939",
    "model_name_for_query": "TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-fp16",
    "link": "https://huggingface.co/TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "Athena-Platypus2-13B-QLora-0.80-epoch",
    "average": 53.16,
    "arc": 56.66,
    "hellaswag": 80.56,
    "mmlu": 55.43,
    "truthfulqa": 53.62,
    "winogrande": 72.61,
    "gsm8k": 0.08,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7b6c11b4df16079dfdd1e8dd8c489a8835c7cc4",
    "model_name_for_query": "TFLai/Athena-Platypus2-13B-QLora-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Athena-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\u2b55",
    "model": "Airboros2.1-Platypus2-13B-QLora-0.80-epoch",
    "average": 53.15,
    "arc": 58.96,
    "hellaswag": 82.46,
    "mmlu": 54.62,
    "truthfulqa": 47.71,
    "winogrande": 75.14,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "45bd1e47218ba2e075e03f6407980eb839e67eb3",
    "model_name_for_query": "TFLai/Airboros2.1-Platypus2-13B-QLora-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Airboros2.1-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\u2b55",
    "model": "vigogne2-enno-13b-sft-lora-4bit",
    "average": 53.15,
    "arc": 62.03,
    "hellaswag": 82.65,
    "mmlu": 54.11,
    "truthfulqa": 42.98,
    "winogrande": 76.95,
    "gsm8k": 0.15,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2a1b03977395eee44742abda63a4787ea5371d06",
    "model_name_for_query": "Enno-Ai/vigogne2-enno-13b-sft-lora-4bit",
    "link": "https://huggingface.co/Enno-Ai/vigogne2-enno-13b-sft-lora-4bit",
    "author": "Enno-Ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Airoboros-L2-13B-2.1-GPTQ",
    "average": 53.14,
    "arc": 58.96,
    "hellaswag": 81.72,
    "mmlu": 53.16,
    "truthfulqa": 44.68,
    "winogrande": 74.35,
    "gsm8k": 5.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "llama2",
    "params": 16.23,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "d90d96e40b9359cb5c35e6b6c8f0eb24896e827b",
    "model_name_for_query": "TheBloke/Airoboros-L2-13B-2.1-GPTQ",
    "link": "https://huggingface.co/TheBloke/Airoboros-L2-13B-2.1-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
    "average": 53.14,
    "arc": 59.04,
    "hellaswag": 82.33,
    "mmlu": 55.36,
    "truthfulqa": 35.75,
    "winogrande": 76.32,
    "gsm8k": 10.01,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "a3ed7416156963f49bf4dc056188e006c0c214d2",
    "model_name_for_query": "dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-13b-pretrained-sft-do2",
    "average": 53.12,
    "arc": 58.96,
    "hellaswag": 80.32,
    "mmlu": 47.25,
    "truthfulqa": 47.41,
    "winogrande": 75.53,
    "gsm8k": 9.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "6cb016f5bfcbc24ee08312b52f08ef5e8f860871",
    "model_name_for_query": "dvruette/llama-13b-pretrained-sft-do2",
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained-sft-do2",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MLewd-L2-13B",
    "average": 53.12,
    "arc": 58.28,
    "hellaswag": 82.32,
    "mmlu": 54.67,
    "truthfulqa": 48.66,
    "winogrande": 73.48,
    "gsm8k": 1.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "feb1fa71e0b24261d3ca428b4aed881dd31f166e",
    "model_name_for_query": "Undi95/MLewd-L2-13B",
    "link": "https://huggingface.co/Undi95/MLewd-L2-13B",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "posi_13b",
    "average": 53.12,
    "arc": 59.64,
    "hellaswag": 82.52,
    "mmlu": 56.56,
    "truthfulqa": 42.14,
    "winogrande": 76.24,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ff4eeb0f876c41553c302020041a0e78a15f9aa7",
    "model_name_for_query": "jjaaaww/posi_13b",
    "link": "https://huggingface.co/jjaaaww/posi_13b",
    "author": "jjaaaww"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-13b-pretrained-sft-epoch-1",
    "average": 53.11,
    "arc": 57.25,
    "hellaswag": 79.99,
    "mmlu": 45.52,
    "truthfulqa": 44.45,
    "winogrande": 77.58,
    "gsm8k": 13.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1f839c019153789c15bbc45ecbb512d0f5015881",
    "model_name_for_query": "dvruette/llama-13b-pretrained-sft-epoch-1",
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained-sft-epoch-1",
    "author": "dvruette"
  },
  {
    "T": "?",
    "model": "manticore-13b-chat-pyg-GPTQ",
    "average": 53.11,
    "arc": 57.85,
    "hellaswag": 81.07,
    "mmlu": 47.56,
    "truthfulqa": 47.77,
    "winogrande": 75.93,
    "gsm8k": 8.49,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 33.0,
    "still_on_hub": true,
    "revision": "923f27245d13058c9c1b3ab0eab6c6c93ffc162e",
    "model_name_for_query": "TheBloke/manticore-13b-chat-pyg-GPTQ",
    "link": "https://huggingface.co/TheBloke/manticore-13b-chat-pyg-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_7b_mmlu",
    "average": 53.1,
    "arc": 56.14,
    "hellaswag": 79.13,
    "mmlu": 60.04,
    "truthfulqa": 40.95,
    "winogrande": 74.43,
    "gsm8k": 7.88,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "553178f8d5d69eb1dfa5b9503d2ce0c1e481e5b1",
    "model_name_for_query": "itsliupeng/llama2_7b_mmlu",
    "link": "https://huggingface.co/itsliupeng/llama2_7b_mmlu",
    "author": "itsliupeng"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-FINETUNE3_TEST",
    "average": 53.09,
    "arc": 53.67,
    "hellaswag": 79.66,
    "mmlu": 54.48,
    "truthfulqa": 40.22,
    "winogrande": 75.93,
    "gsm8k": 14.56,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "22cea7bf138eb0d6c962812df2b2235290acbee2",
    "model_name_for_query": "wei123602/llama2-13b-FINETUNE3_TEST",
    "link": "https://huggingface.co/wei123602/llama2-13b-FINETUNE3_TEST",
    "author": "wei123602"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
    "average": 53.06,
    "arc": 57.76,
    "hellaswag": 80.78,
    "mmlu": 54.32,
    "truthfulqa": 40.8,
    "winogrande": 76.72,
    "gsm8k": 7.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ebe1b75fa315a9b55f686368070a0bcd0245ee39",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FINETUNE3_TEST4",
    "average": 53.02,
    "arc": 55.63,
    "hellaswag": 81.31,
    "mmlu": 52.13,
    "truthfulqa": 41.14,
    "winogrande": 76.72,
    "gsm8k": 11.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5195e87bb34317c5aaf201faa476aae78ecc9f1b",
    "model_name_for_query": "wei123602/FINETUNE3_TEST4",
    "link": "https://huggingface.co/wei123602/FINETUNE3_TEST4",
    "author": "wei123602"
  },
  {
    "T": "\u2b55",
    "model": "LlongOrca-7B-16k",
    "average": 53.02,
    "arc": 57.51,
    "hellaswag": 79.44,
    "mmlu": 49.35,
    "truthfulqa": 49.84,
    "winogrande": 74.51,
    "gsm8k": 7.51,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 39.0,
    "still_on_hub": true,
    "revision": "1370c7c595e6c8394e6332bc535ae25e21def85b",
    "model_name_for_query": "Open-Orca/LlongOrca-7B-16k",
    "link": "https://huggingface.co/Open-Orca/LlongOrca-7B-16k",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-13b-gpt4-1.4.1",
    "average": 53.02,
    "arc": 59.13,
    "hellaswag": 82.78,
    "mmlu": 55.62,
    "truthfulqa": 40.27,
    "winogrande": 73.32,
    "gsm8k": 6.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "35ff51ebe5668269dfd33a9ed94412d88f1f4b65",
    "model_name_for_query": "jondurbin/airoboros-l2-13b-gpt4-1.4.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-gpt4-1.4.1",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "Walter-Mistral-7B",
    "average": 53.0,
    "arc": 58.87,
    "hellaswag": 83.43,
    "mmlu": 58.65,
    "truthfulqa": 39.93,
    "winogrande": 77.03,
    "gsm8k": 0.08,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d7ccd4f0360c397765578521efaed394fe00dbf5",
    "model_name_for_query": "KnutJaegersberg/Walter-Mistral-7B",
    "link": "https://huggingface.co/KnutJaegersberg/Walter-Mistral-7B",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-13b-pretrained-dropout",
    "average": 52.99,
    "arc": 56.4,
    "hellaswag": 79.34,
    "mmlu": 46.59,
    "truthfulqa": 48.6,
    "winogrande": 75.22,
    "gsm8k": 11.83,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "045c84727d495bfb4b612a2482ce0d807c067b46",
    "model_name_for_query": "dvruette/llama-13b-pretrained-dropout",
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained-dropout",
    "author": "dvruette"
  },
  {
    "T": "\u2b55",
    "model": "Huginn-19b-prototype",
    "average": 52.99,
    "arc": 59.22,
    "hellaswag": 81.03,
    "mmlu": 55.73,
    "truthfulqa": 41.15,
    "winogrande": 76.4,
    "gsm8k": 4.4,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 19.36,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d2c8cc15c57da217ff29ebaaae4bc4f57d6b21b0",
    "model_name_for_query": "The-Face-Of-Goonery/Huginn-19b-prototype",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-19b-prototype",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\u2b55",
    "model": "LIMA2-13b-hf",
    "average": 52.98,
    "arc": 60.24,
    "hellaswag": 83.69,
    "mmlu": 53.17,
    "truthfulqa": 41.81,
    "winogrande": 73.24,
    "gsm8k": 5.76,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ed3535921eb24e0737f9a6cda70b1a3fd71532cd",
    "model_name_for_query": "heegyu/LIMA2-13b-hf",
    "link": "https://huggingface.co/heegyu/LIMA2-13b-hf",
    "author": "heegyu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Alpacino-SuperCOT-13B",
    "average": 52.97,
    "arc": 58.36,
    "hellaswag": 81.69,
    "mmlu": 47.89,
    "truthfulqa": 45.42,
    "winogrande": 76.95,
    "gsm8k": 7.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "3a82b04684fe99d59556421c3f96a187049a3cec",
    "model_name_for_query": "xzuyn/Alpacino-SuperCOT-13B",
    "link": "https://huggingface.co/xzuyn/Alpacino-SuperCOT-13B",
    "author": "xzuyn"
  },
  {
    "T": "\ud83d\udd36",
    "model": "digital-socrates-7b",
    "average": 52.95,
    "arc": 54.44,
    "hellaswag": 75.99,
    "mmlu": 51.41,
    "truthfulqa": 44.88,
    "winogrande": 73.09,
    "gsm8k": 17.89,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5d26db18b95778c31dc8425871052f495b267563",
    "model_name_for_query": "allenai/digital-socrates-7b",
    "link": "https://huggingface.co/allenai/digital-socrates-7b",
    "author": "allenai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zaraxe-l2-7b",
    "average": 52.95,
    "arc": 57.17,
    "hellaswag": 79.34,
    "mmlu": 51.0,
    "truthfulqa": 49.11,
    "winogrande": 73.48,
    "gsm8k": 7.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0875bf202aedeef7a58d7382fd6f55f5bca12968",
    "model_name_for_query": "zarakiquemparte/zaraxe-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zaraxe-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
    "average": 52.94,
    "arc": 58.45,
    "hellaswag": 81.97,
    "mmlu": 55.02,
    "truthfulqa": 35.85,
    "winogrande": 75.69,
    "gsm8k": 10.69,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5a89844b1aea3f0573e696143ec66727df4b5d79",
    "model_name_for_query": "dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "baize-v2-13b",
    "average": 52.94,
    "arc": 56.91,
    "hellaswag": 79.29,
    "mmlu": 49.72,
    "truthfulqa": 47.88,
    "winogrande": 74.9,
    "gsm8k": 8.95,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "a3c4bbccca8b650700a49a225582c17bb49b446b",
    "model_name_for_query": "project-baize/baize-v2-13b",
    "link": "https://huggingface.co/project-baize/baize-v2-13b",
    "author": "project-baize"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-llama2-13b-v11-bf16",
    "average": 52.93,
    "arc": 52.99,
    "hellaswag": 75.38,
    "mmlu": 51.36,
    "truthfulqa": 47.94,
    "winogrande": 71.03,
    "gsm8k": 18.88,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.88,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4d4e72c553e9d60fdc208663b0a1c0364caa2f30",
    "model_name_for_query": "OpenBuddy/openbuddy-llama2-13b-v11-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v11-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-100step-flan-v2",
    "average": 52.92,
    "arc": 53.24,
    "hellaswag": 78.43,
    "mmlu": 48.43,
    "truthfulqa": 45.66,
    "winogrande": 72.3,
    "gsm8k": 19.48,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0f1873b505a5f32ca429c164a229bab663eaf617",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-100step-flan-v2",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-100step-flan-v2",
    "author": "Korabbit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-22b-chat-wizard-uncensored",
    "average": 52.9,
    "arc": 56.23,
    "hellaswag": 80.39,
    "mmlu": 53.62,
    "truthfulqa": 45.76,
    "winogrande": 70.24,
    "gsm8k": 11.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 21.83,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "90cffebc8f530161505b84740ff6c8f646299d6c",
    "model_name_for_query": "nkpz/llama2-22b-chat-wizard-uncensored",
    "link": "https://huggingface.co/nkpz/llama2-22b-chat-wizard-uncensored",
    "author": "nkpz"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13b-platypus-vicuna-wizard",
    "average": 52.9,
    "arc": 61.26,
    "hellaswag": 82.31,
    "mmlu": 55.21,
    "truthfulqa": 41.91,
    "winogrande": 75.77,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "71aa919fc15fa9d9def9185791b15a3f76e7bd8d",
    "model_name_for_query": "pe-nlp/llama-2-13b-platypus-vicuna-wizard",
    "link": "https://huggingface.co/pe-nlp/llama-2-13b-platypus-vicuna-wizard",
    "author": "pe-nlp"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-13b-ft-instruct-es",
    "average": 52.89,
    "arc": 59.39,
    "hellaswag": 81.51,
    "mmlu": 54.31,
    "truthfulqa": 37.81,
    "winogrande": 75.77,
    "gsm8k": 8.57,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "772b53f64f484fa0d651d453bcefc35a0f52f251",
    "model_name_for_query": "clibrain/Llama-2-13b-ft-instruct-es",
    "link": "https://huggingface.co/clibrain/Llama-2-13b-ft-instruct-es",
    "author": "clibrain"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-13b-fintune2-4E",
    "average": 52.88,
    "arc": 55.89,
    "hellaswag": 80.95,
    "mmlu": 53.73,
    "truthfulqa": 42.72,
    "winogrande": 73.09,
    "gsm8k": 10.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "645ede9d6ec60d8fa051bc7ad32ab5f7bfdc066d",
    "model_name_for_query": "wei123602/llama2-13b-fintune2-4E",
    "link": "https://huggingface.co/wei123602/llama2-13b-fintune2-4E",
    "author": "wei123602"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-100step-flan",
    "average": 52.88,
    "arc": 52.9,
    "hellaswag": 78.44,
    "mmlu": 48.4,
    "truthfulqa": 45.67,
    "winogrande": 72.38,
    "gsm8k": 19.48,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1d502ae9a15c38118baa5ae55e048a080cb05c89",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-100step-flan",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-100step-flan",
    "author": "Korabbit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
    "average": 52.88,
    "arc": 55.97,
    "hellaswag": 81.53,
    "mmlu": 54.42,
    "truthfulqa": 40.72,
    "winogrande": 75.06,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "905fc0b26dcb9e1fc5be99e73596e0884f9b71df",
    "model_name_for_query": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "archangel_sft-kto_llama13b",
    "average": 52.87,
    "arc": 56.14,
    "hellaswag": 80.8,
    "mmlu": 47.84,
    "truthfulqa": 39.42,
    "winogrande": 76.16,
    "gsm8k": 16.83,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d596fb0060168006360610d673c2c35edcbbf110",
    "model_name_for_query": "ContextualAI/archangel_sft-kto_llama13b",
    "link": "https://huggingface.co/ContextualAI/archangel_sft-kto_llama13b",
    "author": "ContextualAI"
  },
  {
    "T": "?",
    "model": "chimera-inst-chat-13b-hf",
    "average": 52.86,
    "arc": 55.38,
    "hellaswag": 78.93,
    "mmlu": 50.6,
    "truthfulqa": 50.12,
    "winogrande": 73.95,
    "gsm8k": 8.19,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "a6943d2d30d0af904b3321559157d589e60f9e0f",
    "model_name_for_query": "Yhyu13/chimera-inst-chat-13b-hf",
    "link": "https://huggingface.co/Yhyu13/chimera-inst-chat-13b-hf",
    "author": "Yhyu13"
  },
  {
    "T": "\u2b55",
    "model": "japanese-stablelm-instruct-gamma-7b",
    "average": 52.82,
    "arc": 50.68,
    "hellaswag": 78.68,
    "mmlu": 54.82,
    "truthfulqa": 39.77,
    "winogrande": 73.72,
    "gsm8k": 19.26,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "044918151c5b3910d12f2e489fb7c60752048e1e",
    "model_name_for_query": "stabilityai/japanese-stablelm-instruct-gamma-7b",
    "link": "https://huggingface.co/stabilityai/japanese-stablelm-instruct-gamma-7b",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "mpt-30b",
    "average": 52.77,
    "arc": 55.97,
    "hellaswag": 82.42,
    "mmlu": 48.0,
    "truthfulqa": 38.42,
    "winogrande": 74.9,
    "gsm8k": 16.91,
    "model_type": "pretrained",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 29.96,
    "likes": 183.0,
    "still_on_hub": true,
    "revision": "0261af71d7177453889f868d26607dec8d5aaa2e",
    "model_name_for_query": "mosaicml/mpt-30b",
    "link": "https://huggingface.co/mosaicml/mpt-30b",
    "author": "mosaicml"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-13B-no_robots-alpaca-lora",
    "average": 52.77,
    "arc": 58.87,
    "hellaswag": 82.43,
    "mmlu": 53.11,
    "truthfulqa": 40.46,
    "winogrande": 75.3,
    "gsm8k": 6.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "581aba329e607533c299746bb9eb4154a7aab139",
    "model_name_for_query": "Undi95/Llama2-13B-no_robots-alpaca-lora",
    "link": "https://huggingface.co/Undi95/Llama2-13B-no_robots-alpaca-lora",
    "author": "Undi95"
  },
  {
    "T": "\u2b55",
    "model": "ypotryll-22b-epoch2-qlora",
    "average": 52.75,
    "arc": 59.22,
    "hellaswag": 80.66,
    "mmlu": 54.52,
    "truthfulqa": 40.42,
    "winogrande": 76.32,
    "gsm8k": 5.38,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "?",
    "params": 22.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "26fdd8fa420d72ed835c7d17086f0441db0985d4",
    "model_name_for_query": "chargoddard/ypotryll-22b-epoch2-qlora",
    "link": "https://huggingface.co/chargoddard/ypotryll-22b-epoch2-qlora",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wizard-vicuna-13B-HF",
    "average": 52.75,
    "arc": 54.69,
    "hellaswag": 79.18,
    "mmlu": 48.88,
    "truthfulqa": 49.62,
    "winogrande": 74.82,
    "gsm8k": 9.33,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "12dc8aacb474522ae2a83c18cb0fdf0907987f8f",
    "model_name_for_query": "TheBloke/wizard-vicuna-13B-HF",
    "link": "https://huggingface.co/TheBloke/wizard-vicuna-13B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_v2_13b",
    "average": 52.75,
    "arc": 55.12,
    "hellaswag": 79.69,
    "mmlu": 50.07,
    "truthfulqa": 52.56,
    "winogrande": 72.69,
    "gsm8k": 6.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 12.85,
    "likes": 30.0,
    "still_on_hub": true,
    "revision": "1058709314f7ca090937d0a2b7b37b0b3a8f12a3",
    "model_name_for_query": "psmathur/orca_mini_v2_13b",
    "link": "https://huggingface.co/psmathur/orca_mini_v2_13b",
    "author": "psmathur"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-200step-flan-v2",
    "average": 52.75,
    "arc": 52.65,
    "hellaswag": 78.04,
    "mmlu": 48.51,
    "truthfulqa": 45.42,
    "winogrande": 72.93,
    "gsm8k": 18.95,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "35e4747656b719af659625092174f188584934c1",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-200step-flan-v2",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-flan-v2",
    "author": "Korabbit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "EverythingLM-13b-V2-16k",
    "average": 52.75,
    "arc": 58.7,
    "hellaswag": 80.88,
    "mmlu": 49.69,
    "truthfulqa": 47.37,
    "winogrande": 73.01,
    "gsm8k": 6.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 31.0,
    "still_on_hub": true,
    "revision": "943f932ae1ae462389e6d2db5273158530749fff",
    "model_name_for_query": "totally-not-an-llm/EverythingLM-13b-V2-16k",
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-V2-16k",
    "author": "totally-not-an-llm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wizard-vicuna-13b",
    "average": 52.73,
    "arc": 54.69,
    "hellaswag": 79.18,
    "mmlu": 48.88,
    "truthfulqa": 49.62,
    "winogrande": 74.82,
    "gsm8k": 9.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "419dc5acc391de54a60d0b041e94e767d1ef2032",
    "model_name_for_query": "junelee/wizard-vicuna-13b",
    "link": "https://huggingface.co/junelee/wizard-vicuna-13b",
    "author": "junelee"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openchat_8192",
    "average": 52.72,
    "arc": 59.56,
    "hellaswag": 81.44,
    "mmlu": 46.26,
    "truthfulqa": 46.7,
    "winogrande": 74.98,
    "gsm8k": 7.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 220.0,
    "still_on_hub": true,
    "revision": "f661da5af278fbda8a43b19ff0250e4efc103e3e",
    "model_name_for_query": "openchat/openchat_8192",
    "link": "https://huggingface.co/openchat/openchat_8192",
    "author": "openchat"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-7B-v1.2",
    "average": 52.71,
    "arc": 54.35,
    "hellaswag": 79.29,
    "mmlu": 49.33,
    "truthfulqa": 48.92,
    "winogrande": 73.56,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "85ea4f4818478084eedd01e958ac5cc7cf64b3bb",
    "model_name_for_query": "migtissera/Synthia-7B-v1.2",
    "link": "https://huggingface.co/migtissera/Synthia-7B-v1.2",
    "author": "migtissera"
  },
  {
    "T": "?",
    "model": "Dans-PersonalityEngine-13b",
    "average": 52.71,
    "arc": 58.45,
    "hellaswag": 82.3,
    "mmlu": 47.58,
    "truthfulqa": 41.12,
    "winogrande": 77.51,
    "gsm8k": 9.33,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "3b37c31e04419adcc91eddb57f24fd6f9ac91938",
    "model_name_for_query": "PocketDoc/Dans-PersonalityEngine-13b",
    "link": "https://huggingface.co/PocketDoc/Dans-PersonalityEngine-13b",
    "author": "PocketDoc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MetaMath-13B-V1.0",
    "average": 52.71,
    "arc": 49.49,
    "hellaswag": 76.48,
    "mmlu": 47.74,
    "truthfulqa": 41.58,
    "winogrande": 72.45,
    "gsm8k": 28.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "0b448f6f64808f8bca94dc871e96a3eae7e95621",
    "model_name_for_query": "meta-math/MetaMath-13B-V1.0",
    "link": "https://huggingface.co/meta-math/MetaMath-13B-V1.0",
    "author": "meta-math"
  },
  {
    "T": "\u2b55",
    "model": "yehoon_llama2",
    "average": 52.71,
    "arc": 54.78,
    "hellaswag": 78.98,
    "mmlu": 51.29,
    "truthfulqa": 49.17,
    "winogrande": 74.74,
    "gsm8k": 7.28,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "443cb81ce988ea6c0b1e20132c170463d559367e",
    "model_name_for_query": "Yehoon/yehoon_llama2",
    "link": "https://huggingface.co/Yehoon/yehoon_llama2",
    "author": "Yehoon"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mcq-hal-vicuna-13b-v1.5",
    "average": 52.7,
    "arc": 55.97,
    "hellaswag": 80.72,
    "mmlu": 52.85,
    "truthfulqa": 45.03,
    "winogrande": 72.77,
    "gsm8k": 8.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bb3029bce8347b09c2fd6908475b195bcabe53e3",
    "model_name_for_query": "luffycodes/mcq-hal-vicuna-13b-v1.5",
    "link": "https://huggingface.co/luffycodes/mcq-hal-vicuna-13b-v1.5",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Capybara-7B",
    "average": 52.7,
    "arc": 55.29,
    "hellaswag": 80.73,
    "mmlu": 48.72,
    "truthfulqa": 51.13,
    "winogrande": 73.32,
    "gsm8k": 6.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": ["mit"],
    "params": 6.61,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "42dfc6f7d735670e2f3e30b0919708a81f9a0df9",
    "model_name_for_query": "NousResearch/Nous-Capybara-7B",
    "link": "https://huggingface.co/NousResearch/Nous-Capybara-7B",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tulpar-7b-v0",
    "average": 52.69,
    "arc": 56.31,
    "hellaswag": 79.01,
    "mmlu": 52.55,
    "truthfulqa": 51.68,
    "winogrande": 73.88,
    "gsm8k": 2.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "d7c2bc52a3ae13571357f51273ae948caf84400e",
    "model_name_for_query": "HyperbeeAI/Tulpar-7b-v0",
    "link": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v0",
    "author": "HyperbeeAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Capybara-7B",
    "average": 52.69,
    "arc": 55.2,
    "hellaswag": 80.76,
    "mmlu": 48.8,
    "truthfulqa": 51.07,
    "winogrande": 73.4,
    "gsm8k": 6.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": ["mit"],
    "params": 6.61,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "42dfc6f7d735670e2f3e30b0919708a81f9a0df9",
    "model_name_for_query": "NousResearch/Capybara-7B",
    "link": "https://huggingface.co/NousResearch/Capybara-7B",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeEngine",
    "average": 52.68,
    "arc": 58.36,
    "hellaswag": 82.27,
    "mmlu": 54.18,
    "truthfulqa": 45.18,
    "winogrande": 74.59,
    "gsm8k": 1.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f57879831c39f2dcb656cb2c9e9ce5878e92bb44",
    "model_name_for_query": "Undi95/CodeEngine",
    "link": "https://huggingface.co/Undi95/CodeEngine",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mcq-vicuna-13b-v1.5",
    "average": 52.68,
    "arc": 56.66,
    "hellaswag": 81.09,
    "mmlu": 53.3,
    "truthfulqa": 43.99,
    "winogrande": 73.01,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f769a92cfeffe8ee07beee8814ce7eca7cd62805",
    "model_name_for_query": "luffycodes/mcq-vicuna-13b-v1.5",
    "link": "https://huggingface.co/luffycodes/mcq-vicuna-13b-v1.5",
    "author": "luffycodes"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-Trismegistus-7B",
    "average": 52.66,
    "arc": 54.1,
    "hellaswag": 77.91,
    "mmlu": 54.49,
    "truthfulqa": 49.36,
    "winogrande": 70.17,
    "gsm8k": 9.93,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 59.0,
    "still_on_hub": true,
    "revision": "0a5752d096ebab21759dbe203f6b7c7f6092faf2",
    "model_name_for_query": "teknium/Mistral-Trismegistus-7B",
    "link": "https://huggingface.co/teknium/Mistral-Trismegistus-7B",
    "author": "teknium"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-13b-gpt4-m2.0",
    "average": 52.66,
    "arc": 59.22,
    "hellaswag": 81.02,
    "mmlu": 53.73,
    "truthfulqa": 39.7,
    "winogrande": 73.64,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "a852b77f7d0777092c76898bc83f8e657ca2af3e",
    "model_name_for_query": "jondurbin/airoboros-l2-13b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "leo-hessianai-13b",
    "average": 52.65,
    "arc": 57.25,
    "hellaswag": 81.94,
    "mmlu": 53.65,
    "truthfulqa": 38.03,
    "winogrande": 76.09,
    "gsm8k": 8.95,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "a947965cb07ca12a38ff981fe65b618d7dea28d3",
    "model_name_for_query": "LeoLM/leo-hessianai-13b",
    "link": "https://huggingface.co/LeoLM/leo-hessianai-13b",
    "author": "LeoLM"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-200step-flan",
    "average": 52.62,
    "arc": 52.47,
    "hellaswag": 78.02,
    "mmlu": 48.42,
    "truthfulqa": 45.47,
    "winogrande": 72.69,
    "gsm8k": 18.65,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "03550d05aac147dde6d70b7b63f4a1661ecf5cb3",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-200step-flan",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-flan",
    "author": "Korabbit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-mistral-7b-v13.1",
    "average": 52.62,
    "arc": 52.56,
    "hellaswag": 75.73,
    "mmlu": 56.68,
    "truthfulqa": 50.44,
    "winogrande": 71.59,
    "gsm8k": 8.72,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.13,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b64386bde3d7850a01df763f5c777c74888d34fc",
    "model_name_for_query": "OpenBuddy/openbuddy-mistral-7b-v13.1",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-mistral-7b-v13.1",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LIMA-13b-hf",
    "average": 52.61,
    "arc": 57.42,
    "hellaswag": 81.68,
    "mmlu": 48.72,
    "truthfulqa": 41.76,
    "winogrande": 77.19,
    "gsm8k": 8.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "98faa74a9b41cbd9033904cd58420705936849eb",
    "model_name_for_query": "heegyu/LIMA-13b-hf",
    "link": "https://huggingface.co/heegyu/LIMA-13b-hf",
    "author": "heegyu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chinese-Llama-2-7b",
    "average": 52.59,
    "arc": 52.99,
    "hellaswag": 75.64,
    "mmlu": 50.74,
    "truthfulqa": 48.94,
    "winogrande": 72.77,
    "gsm8k": 14.48,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 6.61,
    "likes": 261.0,
    "still_on_hub": true,
    "revision": "72efd71d7f89d9c46008b7a574faf90300ed9ba8",
    "model_name_for_query": "LinkSoul/Chinese-Llama-2-7b",
    "link": "https://huggingface.co/LinkSoul/Chinese-Llama-2-7b",
    "author": "LinkSoul"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "japanese-stablelm-base-gamma-7b",
    "average": 52.59,
    "arc": 50.34,
    "hellaswag": 77.47,
    "mmlu": 54.75,
    "truthfulqa": 41.2,
    "winogrande": 73.95,
    "gsm8k": 17.82,
    "model_type": "pretrained",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "e1c3840c716485077b688296fefa8e5641249843",
    "model_name_for_query": "stabilityai/japanese-stablelm-base-gamma-7b",
    "link": "https://huggingface.co/stabilityai/japanese-stablelm-base-gamma-7b",
    "author": "stabilityai"
  },
  {
    "T": "?",
    "model": "Wizard-Vicuna-13B-juniper",
    "average": 52.55,
    "arc": 55.89,
    "hellaswag": 79.75,
    "mmlu": 44.99,
    "truthfulqa": 54.72,
    "winogrande": 72.69,
    "gsm8k": 7.28,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "24f58beb9ed4cf635fc962853ed71d0f4b1909ba",
    "model_name_for_query": "frank098/Wizard-Vicuna-13B-juniper",
    "link": "https://huggingface.co/frank098/Wizard-Vicuna-13B-juniper",
    "author": "frank098"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama_13b_sharegpt94k_fastchat",
    "average": 52.55,
    "arc": 53.75,
    "hellaswag": 79.47,
    "mmlu": 51.5,
    "truthfulqa": 49.54,
    "winogrande": 72.61,
    "gsm8k": 8.42,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "388bc2f82a1ee8b963c7f94f9c7b6743f7214306",
    "model_name_for_query": "wahaha1987/llama_13b_sharegpt94k_fastchat",
    "link": "https://huggingface.co/wahaha1987/llama_13b_sharegpt94k_fastchat",
    "author": "wahaha1987"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mcq-vicuna-13b-v1.5",
    "average": 52.55,
    "arc": 56.23,
    "hellaswag": 81.15,
    "mmlu": 53.38,
    "truthfulqa": 44.08,
    "winogrande": 72.93,
    "gsm8k": 7.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f769a92cfeffe8ee07beee8814ce7eca7cd62805",
    "model_name_for_query": "luffycodes/mcq-vicuna-13b-v1.5",
    "link": "https://huggingface.co/luffycodes/mcq-vicuna-13b-v1.5",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-dolphin-orca-platypus-34b",
    "average": 52.53,
    "arc": 52.47,
    "hellaswag": 74.13,
    "mmlu": 53.47,
    "truthfulqa": 47.14,
    "winogrande": 73.24,
    "gsm8k": 14.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "57e18e617b4fd7ab61bd7da8ee9516513ad76842",
    "model_name_for_query": "uukuguy/speechless-codellama-dolphin-orca-platypus-34b",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-dolphin-orca-platypus-34b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-34b-v1.0",
    "average": 52.53,
    "arc": 52.47,
    "hellaswag": 74.13,
    "mmlu": 53.47,
    "truthfulqa": 47.14,
    "winogrande": 73.24,
    "gsm8k": 14.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1d64d871cd56da3031e19bc267ef8bd0b85b9936",
    "model_name_for_query": "speechlessai/speechless-codellama-34b-v1.0",
    "link": "https://huggingface.co/speechlessai/speechless-codellama-34b-v1.0",
    "author": "speechlessai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-34b-v2.0",
    "average": 52.51,
    "arc": 54.35,
    "hellaswag": 75.65,
    "mmlu": 54.67,
    "truthfulqa": 45.21,
    "winogrande": 73.56,
    "gsm8k": 11.6,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 33.48,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "cb81174d72dbe06f8db1c406ef97981532de6f09",
    "model_name_for_query": "uukuguy/speechless-codellama-34b-v2.0",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-34b-v2.0",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-hf-chat-lora-v2",
    "average": 52.5,
    "arc": 55.03,
    "hellaswag": 78.81,
    "mmlu": 51.35,
    "truthfulqa": 44.05,
    "winogrande": 74.9,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0b8e61d3325cddbad207cbf885c2b5db6a83a059",
    "model_name_for_query": "lvkaokao/llama2-7b-hf-chat-lora-v2",
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-chat-lora-v2",
    "author": "lvkaokao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-13b-gpt4-2.0",
    "average": 52.49,
    "arc": 59.04,
    "hellaswag": 82.82,
    "mmlu": 54.71,
    "truthfulqa": 36.47,
    "winogrande": 74.19,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "ec556571acc6783fea4414e4ca72d291c563b6dc",
    "model_name_for_query": "jondurbin/airoboros-l2-13b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "Mistral-7B-golden",
    "average": 52.49,
    "arc": 60.75,
    "hellaswag": 44.42,
    "mmlu": 59.29,
    "truthfulqa": 53.51,
    "winogrande": 76.64,
    "gsm8k": 20.32,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "unknown",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bc4624485fef5a2e3fcde465eaf2191cb1df1877",
    "model_name_for_query": "liuda1/Mistral-7B-golden",
    "link": "https://huggingface.co/liuda1/Mistral-7B-golden",
    "author": "liuda1"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-longlora-32k-ft",
    "average": 52.49,
    "arc": 59.47,
    "hellaswag": 82.61,
    "mmlu": 52.13,
    "truthfulqa": 37.44,
    "winogrande": 75.53,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "6d17c854025b0bd54ce572ac803f1bb052875dbf",
    "model_name_for_query": "Yukang/Llama-2-13b-longlora-32k-ft",
    "link": "https://huggingface.co/Yukang/Llama-2-13b-longlora-32k-ft",
    "author": "Yukang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-hf-chat-lora-v3",
    "average": 52.48,
    "arc": 57.25,
    "hellaswag": 78.62,
    "mmlu": 50.57,
    "truthfulqa": 50.62,
    "winogrande": 76.32,
    "gsm8k": 1.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "79047f667253c878ad3143b016e3dcb3df707572",
    "model_name_for_query": "lvkaokao/llama2-7b-hf-chat-lora-v3",
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-chat-lora-v3",
    "author": "lvkaokao"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-10-sparsity",
    "average": 52.48,
    "arc": 53.16,
    "hellaswag": 78.26,
    "mmlu": 48.18,
    "truthfulqa": 45.29,
    "winogrande": 71.59,
    "gsm8k": 18.42,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9dda6f163ab399b0ae0fd19d6fe8ec37d9ff97be",
    "model_name_for_query": "wang7776/Llama-2-7b-chat-hf-10-sparsity",
    "link": "https://huggingface.co/wang7776/Llama-2-7b-chat-hf-10-sparsity",
    "author": "wang7776"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-7b-openorca-mc-v2",
    "average": 52.47,
    "arc": 55.55,
    "hellaswag": 81.26,
    "mmlu": 48.3,
    "truthfulqa": 51.49,
    "winogrande": 72.85,
    "gsm8k": 5.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1e74a9cca843cdeb8591d4e4f4320dc1870adf1b",
    "model_name_for_query": "beaugogh/Llama2-7b-openorca-mc-v2",
    "link": "https://huggingface.co/beaugogh/Llama2-7b-openorca-mc-v2",
    "author": "beaugogh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama_mirror_13b_v1.0",
    "average": 52.46,
    "arc": 57.59,
    "hellaswag": 80.53,
    "mmlu": 48.0,
    "truthfulqa": 44.54,
    "winogrande": 76.64,
    "gsm8k": 7.43,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "379cb8f080110f3418155029f534f67a79e25db4",
    "model_name_for_query": "lizhuang144/llama_mirror_13b_v1.0",
    "link": "https://huggingface.co/lizhuang144/llama_mirror_13b_v1.0",
    "author": "lizhuang144"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-2-7b-chat",
    "average": 52.45,
    "arc": 55.63,
    "hellaswag": 78.71,
    "mmlu": 50.98,
    "truthfulqa": 47.21,
    "winogrande": 74.43,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "7a1b76feabe3e0ed007ea83ee93f7644156d3b23",
    "model_name_for_query": "bofenghuang/vigogne-2-7b-chat",
    "link": "https://huggingface.co/bofenghuang/vigogne-2-7b-chat",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-13b-supercot",
    "average": 52.44,
    "arc": 56.06,
    "hellaswag": 81.71,
    "mmlu": 45.36,
    "truthfulqa": 48.55,
    "winogrande": 75.77,
    "gsm8k": 7.2,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "f6953fa162b487a3d4c6bdc7b7951e09576c2ae5",
    "model_name_for_query": "ausboss/llama-13b-supercot",
    "link": "https://huggingface.co/ausboss/llama-13b-supercot",
    "author": "ausboss"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CAMEL-13B-Combined-Data",
    "average": 52.44,
    "arc": 55.63,
    "hellaswag": 79.25,
    "mmlu": 49.74,
    "truthfulqa": 47.42,
    "winogrande": 75.45,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "6d98f2801f13d89de7978ee9f348a52ea46a24ec",
    "model_name_for_query": "camel-ai/CAMEL-13B-Combined-Data",
    "link": "https://huggingface.co/camel-ai/CAMEL-13B-Combined-Data",
    "author": "camel-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-PileOfSets-Mk1-llama-13b-merged",
    "average": 52.43,
    "arc": 58.79,
    "hellaswag": 81.79,
    "mmlu": 48.12,
    "truthfulqa": 41.24,
    "winogrande": 76.16,
    "gsm8k": 8.49,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a7e5484df8aceae7800ae9301a3954cf74b527e9",
    "model_name_for_query": "PocketDoc/Dans-PileOfSets-Mk1-llama-13b-merged",
    "link": "https://huggingface.co/PocketDoc/Dans-PileOfSets-Mk1-llama-13b-merged",
    "author": "PocketDoc"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-300step-flan-v2",
    "average": 52.41,
    "arc": 52.56,
    "hellaswag": 77.76,
    "mmlu": 48.51,
    "truthfulqa": 45.14,
    "winogrande": 72.53,
    "gsm8k": 17.97,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a2191bd90b04396016b7420dd14675916056f44a",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-300step-flan-v2",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-300step-flan-v2",
    "author": "Korabbit"
  },
  {
    "T": "\u2b55",
    "model": "PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch",
    "average": 52.41,
    "arc": 54.52,
    "hellaswag": 79.36,
    "mmlu": 55.15,
    "truthfulqa": 54.32,
    "winogrande": 71.11,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4b5aabc51907e4cba49f373c6dc09a2634f2fb8a",
    "model_name_for_query": "TFLai/PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zararp-l2-7b",
    "average": 52.39,
    "arc": 56.31,
    "hellaswag": 79.19,
    "mmlu": 51.36,
    "truthfulqa": 51.26,
    "winogrande": 74.51,
    "gsm8k": 1.74,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6032c5106970f98d59925959fbd330ae4b1d1a7e",
    "model_name_for_query": "zarakiquemparte/zararp-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zararp-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Alpacino13b",
    "average": 52.39,
    "arc": 58.53,
    "hellaswag": 81.31,
    "mmlu": 47.92,
    "truthfulqa": 41.66,
    "winogrande": 76.95,
    "gsm8k": 7.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 29.0,
    "still_on_hub": true,
    "revision": "7092a5c8dec649694dd66ff8cfe5452ce52e6a40",
    "model_name_for_query": "digitous/Alpacino13b",
    "link": "https://huggingface.co/digitous/Alpacino13b",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-7B-guanaco-dolphin-500",
    "average": 52.38,
    "arc": 56.74,
    "hellaswag": 81.63,
    "mmlu": 48.69,
    "truthfulqa": 46.94,
    "winogrande": 74.27,
    "gsm8k": 5.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "afe00170f084f773e401ba7d738d692533cca6b4",
    "model_name_for_query": "mncai/Llama2-7B-guanaco-dolphin-500",
    "link": "https://huggingface.co/mncai/Llama2-7B-guanaco-dolphin-500",
    "author": "mncai"
  },
  {
    "T": "\u2b55",
    "model": "Huginn-22b-Prototype",
    "average": 52.36,
    "arc": 57.68,
    "hellaswag": 80.69,
    "mmlu": 49.81,
    "truthfulqa": 52.11,
    "winogrande": 71.59,
    "gsm8k": 2.27,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 21.83,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "29222b05794abb862ad0aaaf3020696c9f599810",
    "model_name_for_query": "The-Face-Of-Goonery/Huginn-22b-Prototype",
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-22b-Prototype",
    "author": "The-Face-Of-Goonery"
  },
  {
    "T": "\ud83d\udd36",
    "model": "EverythingLM-13b-16k",
    "average": 52.33,
    "arc": 56.57,
    "hellaswag": 80.58,
    "mmlu": 50.18,
    "truthfulqa": 47.46,
    "winogrande": 72.77,
    "gsm8k": 6.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 29.0,
    "still_on_hub": true,
    "revision": "8456a856a8b115b05e76a7d0d945853b10ac71e2",
    "model_name_for_query": "totally-not-an-llm/EverythingLM-13b-16k",
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-16k",
    "author": "totally-not-an-llm"
  },
  {
    "T": "\u2b55",
    "model": "Llama2-7b-openorca-mc-v2-dpo",
    "average": 52.32,
    "arc": 54.78,
    "hellaswag": 81.48,
    "mmlu": 47.2,
    "truthfulqa": 53.13,
    "winogrande": 72.85,
    "gsm8k": 4.47,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "734a6f0c69e1e53b988c107926bc17cb0536f851",
    "model_name_for_query": "beaugogh/Llama2-7b-openorca-mc-v2-dpo",
    "link": "https://huggingface.co/beaugogh/Llama2-7b-openorca-mc-v2-dpo",
    "author": "beaugogh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-atom-13b-v9-bf16",
    "average": 52.31,
    "arc": 51.19,
    "hellaswag": 75.99,
    "mmlu": 49.33,
    "truthfulqa": 48.66,
    "winogrande": 73.32,
    "gsm8k": 15.39,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 12.94,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "35bb2c73953f6ea40be6f0c8c6b2dfa7ecbaa0df",
    "model_name_for_query": "OpenBuddy/openbuddy-atom-13b-v9-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-atom-13b-v9-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13b-gpt4-1.2",
    "average": 52.31,
    "arc": 58.36,
    "hellaswag": 81.61,
    "mmlu": 48.84,
    "truthfulqa": 47.54,
    "winogrande": 73.64,
    "gsm8k": 3.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "482bd38b65e73fde13f5d03fed2bee7acda8fadd",
    "model_name_for_query": "jondurbin/airoboros-13b-gpt4-1.2",
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.2",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-13b",
    "average": 52.3,
    "arc": 51.71,
    "hellaswag": 79.94,
    "mmlu": 50.84,
    "truthfulqa": 52.68,
    "winogrande": 71.03,
    "gsm8k": 7.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 95.0,
    "still_on_hub": true,
    "revision": "ac4218770a58baaaaf25201076fe082abb6ffd13",
    "model_name_for_query": "eachadea/vicuna-13b",
    "link": "https://huggingface.co/eachadea/vicuna-13b",
    "author": "eachadea"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Asimov-7B-v2",
    "average": 52.29,
    "arc": 54.27,
    "hellaswag": 78.72,
    "mmlu": 52.59,
    "truthfulqa": 45.44,
    "winogrande": 71.82,
    "gsm8k": 10.92,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "4bit",
    "license": "mit",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0aeea2284ac78cac081bee88e5a98a19bb987227",
    "model_name_for_query": "prithivida/Asimov-7B-v2",
    "link": "https://huggingface.co/prithivida/Asimov-7B-v2",
    "author": "prithivida"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-7B-guanaco-1k",
    "average": 52.28,
    "arc": 55.12,
    "hellaswag": 80.53,
    "mmlu": 47.93,
    "truthfulqa": 47.69,
    "winogrande": 74.82,
    "gsm8k": 7.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5f3194b779897bbc4c4218a9dddc44a9b5faea15",
    "model_name_for_query": "mncai/Llama2-7B-guanaco-1k",
    "link": "https://huggingface.co/mncai/Llama2-7B-guanaco-1k",
    "author": "mncai"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-441step-flan-v2",
    "average": 52.28,
    "arc": 52.13,
    "hellaswag": 77.63,
    "mmlu": 48.52,
    "truthfulqa": 45.02,
    "winogrande": 72.53,
    "gsm8k": 17.82,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "daede60607179be05b5d6e90b4c6777806b10fb8",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-441step-flan-v2",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-441step-flan-v2",
    "author": "Korabbit"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2-13B-QLoRA-0.80-epoch",
    "average": 52.27,
    "arc": 57.76,
    "hellaswag": 81.63,
    "mmlu": 55.63,
    "truthfulqa": 39.7,
    "winogrande": 75.93,
    "gsm8k": 2.96,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "cc-by-nc-4.0",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "114eb8efd2de1c9eae85d92de490b95c854dfae9",
    "model_name_for_query": "TFLai/Platypus2-13B-QLoRA-0.80-epoch",
    "link": "https://huggingface.co/TFLai/Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7B-LoRA-assemble",
    "average": 52.26,
    "arc": 57.34,
    "hellaswag": 78.81,
    "mmlu": 50.75,
    "truthfulqa": 53.18,
    "winogrande": 73.48,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "72e866a96a2e9afc6527c8d757c69088c3a069c8",
    "model_name_for_query": "oh-yeontaek/llama-2-7B-LoRA-assemble",
    "link": "https://huggingface.co/oh-yeontaek/llama-2-7B-LoRA-assemble",
    "author": "oh-yeontaek"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-200step-merged",
    "average": 52.26,
    "arc": 52.05,
    "hellaswag": 77.38,
    "mmlu": 48.65,
    "truthfulqa": 44.6,
    "winogrande": 71.9,
    "gsm8k": 18.95,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "858de1c14854e55d5141b8d1b3954b335044669e",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-200step-merged",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-merged",
    "author": "Korabbit"
  },
  {
    "T": "\u2b55",
    "model": "Llama2-7b-openorca-mc-v1",
    "average": 52.24,
    "arc": 55.63,
    "hellaswag": 80.17,
    "mmlu": 48.44,
    "truthfulqa": 51.62,
    "winogrande": 73.48,
    "gsm8k": 4.09,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2c4096fa2129665fb127f1c2a1302f30565a5265",
    "model_name_for_query": "beaugogh/Llama2-7b-openorca-mc-v1",
    "link": "https://huggingface.co/beaugogh/Llama2-7b-openorca-mc-v1",
    "author": "beaugogh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zararp-1.1-l2-7b",
    "average": 52.22,
    "arc": 56.48,
    "hellaswag": 78.85,
    "mmlu": 51.49,
    "truthfulqa": 51.99,
    "winogrande": 73.4,
    "gsm8k": 1.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "31fa6527a3285d5fd320219d7c2dadde07b83718",
    "model_name_for_query": "zarakiquemparte/zararp-1.1-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zararp-1.1-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "?",
    "model": "L2-7b-Hermes-Synthia",
    "average": 52.21,
    "arc": 51.02,
    "hellaswag": 79.12,
    "mmlu": 47.88,
    "truthfulqa": 46.77,
    "winogrande": 74.51,
    "gsm8k": 13.95,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6f9bd33be62c4b5dbbb8d76ad30d61c3ceb01641",
    "model_name_for_query": "LTC-AI-Labs/L2-7b-Hermes-Synthia",
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Hermes-Synthia",
    "author": "LTC-AI-Labs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Hermes-13B-SuperHOT-8K-fp16",
    "average": 52.18,
    "arc": 55.29,
    "hellaswag": 81.87,
    "mmlu": 48.23,
    "truthfulqa": 51.19,
    "winogrande": 75.3,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "b407c1ece029ad5693d38e6e0931e9482962ed15",
    "model_name_for_query": "TheBloke/Nous-Hermes-13B-SuperHOT-8K-fp16",
    "link": "https://huggingface.co/TheBloke/Nous-Hermes-13B-SuperHOT-8K-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-llama-13b-1000-steps",
    "average": 52.18,
    "arc": 58.11,
    "hellaswag": 81.52,
    "mmlu": 48.65,
    "truthfulqa": 35.99,
    "winogrande": 77.51,
    "gsm8k": 11.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d2cd599cc40db3370009f45d6caa7e486cb6d31f",
    "model_name_for_query": "dvruette/oasst-llama-13b-1000-steps",
    "link": "https://huggingface.co/dvruette/oasst-llama-13b-1000-steps",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Tulpar-7b-v1",
    "average": 52.16,
    "arc": 57.0,
    "hellaswag": 79.69,
    "mmlu": 51.33,
    "truthfulqa": 51.83,
    "winogrande": 72.45,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "719d8e1eb4a820f01e0a92ef6220d041964bb472",
    "model_name_for_query": "HyperbeeAI/Tulpar-7b-v1",
    "link": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v1",
    "author": "HyperbeeAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
    "average": 52.15,
    "arc": 57.0,
    "hellaswag": 80.32,
    "mmlu": 47.08,
    "truthfulqa": 53.46,
    "winogrande": 74.35,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "other",
    "params": 16.22,
    "likes": 44.0,
    "still_on_hub": true,
    "revision": "085eb5cd394f30d72bf5efcf83a580e87264b3e8",
    "model_name_for_query": "TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-1.3-L2-13B",
    "average": 52.15,
    "arc": 56.83,
    "hellaswag": 81.7,
    "mmlu": 52.79,
    "truthfulqa": 50.23,
    "winogrande": 71.11,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "45ba2f603769aa6b97639962f522b8d7398c2393",
    "model_name_for_query": "Sao10K/Stheno-1.3-L2-13B",
    "link": "https://huggingface.co/Sao10K/Stheno-1.3-L2-13B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
    "average": 52.13,
    "arc": 57.17,
    "hellaswag": 79.57,
    "mmlu": 50.24,
    "truthfulqa": 52.51,
    "winogrande": 72.93,
    "gsm8k": 0.38,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9c4a7444d6fb12931e50f111053e016531fe60b7",
    "model_name_for_query": "xxyyy123/mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
    "link": "https://huggingface.co/xxyyy123/mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
    "author": "xxyyy123"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Alpagasus-2-13B-QLoRA-pipeline",
    "average": 52.13,
    "arc": 58.28,
    "hellaswag": 80.98,
    "mmlu": 54.14,
    "truthfulqa": 34.21,
    "winogrande": 75.93,
    "gsm8k": 9.25,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "other",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": false,
    "revision": "86329885e029c1f4fb6ff6b6f3409007158499e7",
    "model_name_for_query": "StudentLLM/Alpagasus-2-13B-QLoRA-pipeline",
    "link": "https://huggingface.co/StudentLLM/Alpagasus-2-13B-QLoRA-pipeline",
    "author": "StudentLLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ANIMA-Nectar-v2",
    "average": 52.13,
    "arc": 53.24,
    "hellaswag": 76.63,
    "mmlu": 54.21,
    "truthfulqa": 49.04,
    "winogrande": 74.11,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "304e41b614d1ac9debccfa266887640b508c9823",
    "model_name_for_query": "Biomimicry-AI/ANIMA-Nectar-v2",
    "link": "https://huggingface.co/Biomimicry-AI/ANIMA-Nectar-v2",
    "author": "Biomimicry-AI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Xwin-LM-7B-V0.1",
    "average": 52.08,
    "arc": 56.57,
    "hellaswag": 79.4,
    "mmlu": 49.98,
    "truthfulqa": 47.89,
    "winogrande": 73.32,
    "gsm8k": 5.31,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 73.0,
    "still_on_hub": true,
    "revision": "470e680120a7249d6e8a875345015ddba1711100",
    "model_name_for_query": "Xwin-LM/Xwin-LM-7B-V0.1",
    "link": "https://huggingface.co/Xwin-LM/Xwin-LM-7B-V0.1",
    "author": "Xwin-LM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5",
    "average": 52.06,
    "arc": 53.24,
    "hellaswag": 77.39,
    "mmlu": 51.04,
    "truthfulqa": 50.34,
    "winogrande": 72.14,
    "gsm8k": 8.19,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "de56c35b1763eaae20f4d60efd64af0a9091ebe5",
    "model_name_for_query": "lmsys/vicuna-7b-v1.5",
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-layla",
    "average": 52.05,
    "arc": 54.18,
    "hellaswag": 79.34,
    "mmlu": 49.7,
    "truthfulqa": 46.5,
    "winogrande": 74.11,
    "gsm8k": 8.49,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "733016abcd2abee63eb45ed63d2bba14b91da217",
    "model_name_for_query": "l3utterfly/llama2-7b-layla",
    "link": "https://huggingface.co/l3utterfly/llama2-7b-layla",
    "author": "l3utterfly"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Beluga-WVG-Test",
    "average": 52.04,
    "arc": 53.75,
    "hellaswag": 78.38,
    "mmlu": 51.57,
    "truthfulqa": 45.76,
    "winogrande": 74.9,
    "gsm8k": 7.88,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b90c207e248c0ad541274c2eb5ef76da1181802f",
    "model_name_for_query": "LTC-AI-Labs/L2-7b-Beluga-WVG-Test",
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Beluga-WVG-Test",
    "author": "LTC-AI-Labs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-hf-chat-lora",
    "average": 52.03,
    "arc": 55.72,
    "hellaswag": 78.75,
    "mmlu": 47.99,
    "truthfulqa": 43.11,
    "winogrande": 75.85,
    "gsm8k": 10.77,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e92a1439ac8d2edb5e311b8a42e13ed7c5e70db5",
    "model_name_for_query": "lvkaokao/llama2-7b-hf-chat-lora",
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-chat-lora",
    "author": "lvkaokao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-2-7b-instruct",
    "average": 52.02,
    "arc": 56.23,
    "hellaswag": 79.97,
    "mmlu": 47.17,
    "truthfulqa": 49.51,
    "winogrande": 75.45,
    "gsm8k": 3.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "8f4dd9c870f748322989168af5c109e16b01c63d",
    "model_name_for_query": "bofenghuang/vigogne-2-7b-instruct",
    "link": "https://huggingface.co/bofenghuang/vigogne-2-7b-instruct",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Llama-2-7b-chat-hf-20-sparsity",
    "average": 52.01,
    "arc": 52.47,
    "hellaswag": 77.91,
    "mmlu": 47.27,
    "truthfulqa": 45.88,
    "winogrande": 70.72,
    "gsm8k": 17.82,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7b44f4902cde1b21b48c87c0379c7aab819436ef",
    "model_name_for_query": "wang7776/Llama-2-7b-chat-hf-20-sparsity",
    "link": "https://huggingface.co/wang7776/Llama-2-7b-chat-hf-20-sparsity",
    "author": "wang7776"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bactrian-x-llama-13b-merged",
    "average": 52.0,
    "arc": 56.4,
    "hellaswag": 79.33,
    "mmlu": 48.4,
    "truthfulqa": 48.38,
    "winogrande": 73.95,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cc5ee2231066c147423f89e9df40f7364c3275a5",
    "model_name_for_query": "haonan-li/bactrian-x-llama-13b-merged",
    "link": "https://huggingface.co/haonan-li/bactrian-x-llama-13b-merged",
    "author": "haonan-li"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5",
    "average": 51.99,
    "arc": 53.24,
    "hellaswag": 77.39,
    "mmlu": 50.82,
    "truthfulqa": 50.33,
    "winogrande": 72.06,
    "gsm8k": 8.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "de56c35b1763eaae20f4d60efd64af0a9091ebe5",
    "model_name_for_query": "lmsys/vicuna-7b-v1.5",
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Qwen-LLaMAfied-7B-Chat",
    "average": 51.99,
    "arc": 50.94,
    "hellaswag": 83.47,
    "mmlu": 53.52,
    "truthfulqa": 46.09,
    "winogrande": 73.16,
    "gsm8k": 4.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4d70cf0047a7a5cd2c864bc2606e81f0830e4405",
    "model_name_for_query": "JosephusCheung/Qwen-LLaMAfied-7B-Chat",
    "link": "https://huggingface.co/JosephusCheung/Qwen-LLaMAfied-7B-Chat",
    "author": "JosephusCheung"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-mistral-7b-v13-base",
    "average": 51.99,
    "arc": 52.9,
    "hellaswag": 76.12,
    "mmlu": 57.54,
    "truthfulqa": 52.82,
    "winogrande": 71.35,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.13,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8ff18d61b1c8295ecd73153b8e0b63934187a50e",
    "model_name_for_query": "OpenBuddy/openbuddy-mistral-7b-v13-base",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-mistral-7b-v13-base",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "spicyboros-7b-2.2",
    "average": 51.95,
    "arc": 56.57,
    "hellaswag": 80.09,
    "mmlu": 48.47,
    "truthfulqa": 47.22,
    "winogrande": 74.51,
    "gsm8k": 4.85,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "fdf075081555f3ed84c037e8dd3fe85c3b3609d7",
    "model_name_for_query": "jondurbin/spicyboros-7b-2.2",
    "link": "https://huggingface.co/jondurbin/spicyboros-7b-2.2",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "10k_v1_lora_qkvo_rank28_v2",
    "average": 51.95,
    "arc": 55.38,
    "hellaswag": 79.21,
    "mmlu": 50.5,
    "truthfulqa": 52.75,
    "winogrande": 73.24,
    "gsm8k": 0.61,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "70e38a7424544193f0ad6a93ae26a5bfd15e4e90",
    "model_name_for_query": "xxyyy123/10k_v1_lora_qkvo_rank28_v2",
    "link": "https://huggingface.co/xxyyy123/10k_v1_lora_qkvo_rank28_v2",
    "author": "xxyyy123"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-13b-vicuna-wizard",
    "average": 51.94,
    "arc": 57.76,
    "hellaswag": 82.16,
    "mmlu": 54.68,
    "truthfulqa": 41.11,
    "winogrande": 74.98,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b51bf8c4e132308751cc8b9d9c1131539f79f07f",
    "model_name_for_query": "pe-nlp/llama-2-13b-vicuna-wizard",
    "link": "https://huggingface.co/pe-nlp/llama-2-13b-vicuna-wizard",
    "author": "pe-nlp"
  },
  {
    "T": "\u2b55",
    "model": "Yi-6b-200k-dpo",
    "average": 51.93,
    "arc": 43.09,
    "hellaswag": 74.53,
    "mmlu": 64.0,
    "truthfulqa": 45.51,
    "winogrande": 73.09,
    "gsm8k": 11.37,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.06,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "925c5fbaeccb321ba8edbde79c3d994adc460a41",
    "model_name_for_query": "chinoll/Yi-6b-200k-dpo",
    "link": "https://huggingface.co/chinoll/Yi-6b-200k-dpo",
    "author": "chinoll"
  },
  {
    "T": "\u2b55",
    "model": "Yi-7b-dpo",
    "average": 51.93,
    "arc": 43.09,
    "hellaswag": 74.53,
    "mmlu": 64.0,
    "truthfulqa": 45.51,
    "winogrande": 73.09,
    "gsm8k": 11.37,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.06,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "925c5fbaeccb321ba8edbde79c3d994adc460a41",
    "model_name_for_query": "chinoll/Yi-7b-dpo",
    "link": "https://huggingface.co/chinoll/Yi-7b-dpo",
    "author": "chinoll"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nous-Hermes-llama-2-7b",
    "average": 51.87,
    "arc": 55.12,
    "hellaswag": 78.94,
    "mmlu": 48.34,
    "truthfulqa": 49.01,
    "winogrande": 74.03,
    "gsm8k": 5.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": ["mit"],
    "params": 6.74,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "60e58acecdc1552e1b1752a38d1d91d942d1c3f0",
    "model_name_for_query": "NousResearch/Nous-Hermes-llama-2-7b",
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udd36",
    "model": "manatee-7b",
    "average": 51.84,
    "arc": 54.52,
    "hellaswag": 78.95,
    "mmlu": 49.26,
    "truthfulqa": 46.77,
    "winogrande": 74.51,
    "gsm8k": 7.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "e66094c43ffe6c5b3f4164cd4ba048d3bc422fd0",
    "model_name_for_query": "ashercn97/manatee-7b",
    "link": "https://huggingface.co/ashercn97/manatee-7b",
    "author": "ashercn97"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Synthia-7B",
    "average": 51.83,
    "arc": 56.14,
    "hellaswag": 78.6,
    "mmlu": 50.35,
    "truthfulqa": 45.03,
    "winogrande": 74.27,
    "gsm8k": 6.6,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4f9e95665d95b4c692910190ff77257216e476f1",
    "model_name_for_query": "migtissera/Synthia-7B",
    "link": "https://huggingface.co/migtissera/Synthia-7B",
    "author": "migtissera"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Medusa-1.1-L2-7B",
    "average": 51.8,
    "arc": 56.48,
    "hellaswag": 78.57,
    "mmlu": 51.56,
    "truthfulqa": 47.7,
    "winogrande": 75.06,
    "gsm8k": 1.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.74,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "df23c3d22bc546dbce0267415e94bdb482446c06",
    "model_name_for_query": "Sao10K/Medusa-1.1-L2-7B",
    "link": "https://huggingface.co/Sao10K/Medusa-1.1-L2-7B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Elliott-Chinese-LLaMa-GPTQ",
    "average": 51.79,
    "arc": 51.02,
    "hellaswag": 75.23,
    "mmlu": 49.58,
    "truthfulqa": 45.09,
    "winogrande": 72.61,
    "gsm8k": 17.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 53.9,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bbbca62bb340b4ae0a19ba93dae38fc9f9787c16",
    "model_name_for_query": "elliotthwang/Elliott-Chinese-LLaMa-GPTQ",
    "link": "https://huggingface.co/elliotthwang/Elliott-Chinese-LLaMa-GPTQ",
    "author": "elliotthwang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Stheno-Mix-L2-20B",
    "average": 51.79,
    "arc": 57.76,
    "hellaswag": 79.63,
    "mmlu": 52.51,
    "truthfulqa": 51.8,
    "winogrande": 68.98,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 20.63,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6f9dcdaae6ef9071effe63d2107abe8b9712345b",
    "model_name_for_query": "Sao10K/Stheno-Mix-L2-20B",
    "link": "https://huggingface.co/Sao10K/Stheno-Mix-L2-20B",
    "author": "Sao10K"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-13b-gpt4-1.3",
    "average": 51.76,
    "arc": 58.53,
    "hellaswag": 81.6,
    "mmlu": 46.96,
    "truthfulqa": 45.29,
    "winogrande": 75.85,
    "gsm8k": 2.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "32a474742c2a235ca12c96afaea57dcb6b46ef56",
    "model_name_for_query": "jondurbin/airoboros-13b-gpt4-1.3",
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.3",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Orca-WVG-Test",
    "average": 51.72,
    "arc": 54.86,
    "hellaswag": 78.25,
    "mmlu": 51.13,
    "truthfulqa": 43.68,
    "winogrande": 74.35,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6073a87872eb36149404bfb7d60e0108074ee1c3",
    "model_name_for_query": "Lazycuber/L2-7b-Orca-WVG-Test",
    "link": "https://huggingface.co/Lazycuber/L2-7b-Orca-WVG-Test",
    "author": "Lazycuber"
  },
  {
    "T": "\u2b55",
    "model": "blossom-v2-llama2-7b",
    "average": 51.71,
    "arc": 54.1,
    "hellaswag": 78.57,
    "mmlu": 51.66,
    "truthfulqa": 46.84,
    "winogrande": 74.35,
    "gsm8k": 4.78,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8c71cdb481ce6bbda3b2042e5526a232ab23825c",
    "model_name_for_query": "Azure99/blossom-v2-llama2-7b",
    "link": "https://huggingface.co/Azure99/blossom-v2-llama2-7b",
    "author": "Azure99"
  },
  {
    "T": "\ud83d\udd36",
    "model": "em_german_leo_mistral",
    "average": 51.69,
    "arc": 52.82,
    "hellaswag": 78.03,
    "mmlu": 50.03,
    "truthfulqa": 50.19,
    "winogrande": 73.48,
    "gsm8k": 5.61,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "aa63a32154923034fb89b1408d3d7ffa994d3327",
    "model_name_for_query": "jphme/em_german_leo_mistral",
    "link": "https://huggingface.co/jphme/em_german_leo_mistral",
    "author": "jphme"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ALMA-13B-Pretrain",
    "average": 51.68,
    "arc": 56.91,
    "hellaswag": 80.15,
    "mmlu": 50.31,
    "truthfulqa": 37.44,
    "winogrande": 76.4,
    "gsm8k": 8.87,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "69e9e12d8bab66dffdcb15fa534fc3f0dc34acec",
    "model_name_for_query": "haoranxu/ALMA-13B-Pretrain",
    "link": "https://huggingface.co/haoranxu/ALMA-13B-Pretrain",
    "author": "haoranxu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-ziya-13b",
    "average": 51.67,
    "arc": 55.38,
    "hellaswag": 78.47,
    "mmlu": 45.18,
    "truthfulqa": 49.29,
    "winogrande": 74.82,
    "gsm8k": 6.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.89,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "9a21051ae490d2f8ab8b1181c1b45e0412d71a90",
    "model_name_for_query": "YeungNLP/firefly-ziya-13b",
    "link": "https://huggingface.co/YeungNLP/firefly-ziya-13b",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Base-test-WVG",
    "average": 51.66,
    "arc": 54.27,
    "hellaswag": 77.81,
    "mmlu": 51.07,
    "truthfulqa": 46.28,
    "winogrande": 73.56,
    "gsm8k": 6.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2491546f1219c3e9bb1a8cf37fbecf0b299c2177",
    "model_name_for_query": "LTC-AI-Labs/L2-7b-Base-test-WVG",
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Base-test-WVG",
    "author": "LTC-AI-Labs"
  },
  {
    "T": "\u2b55",
    "model": "LosslessMegaCoder-llama2-7b-mini",
    "average": 51.66,
    "arc": 53.5,
    "hellaswag": 77.38,
    "mmlu": 49.72,
    "truthfulqa": 45.77,
    "winogrande": 74.03,
    "gsm8k": 9.55,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "186b105d61054611d0b921a55c220d41c6aefe43",
    "model_name_for_query": "rombodawg/LosslessMegaCoder-llama2-7b-mini",
    "link": "https://huggingface.co/rombodawg/LosslessMegaCoder-llama2-7b-mini",
    "author": "rombodawg"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "shisa-base-7b-v1",
    "average": 51.64,
    "arc": 52.3,
    "hellaswag": 77.63,
    "mmlu": 23.12,
    "truthfulqa": 42.4,
    "winogrande": 78.53,
    "gsm8k": 35.86,
    "model_type": "pretrained",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.96,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "5aa465caca707816a4bb36b4980aef5d102d76fb",
    "model_name_for_query": "augmxnt/shisa-base-7b-v1",
    "link": "https://huggingface.co/augmxnt/shisa-base-7b-v1",
    "author": "augmxnt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Elliott-Chinese-LLaMa-GPTQ-V1.0",
    "average": 51.64,
    "arc": 50.68,
    "hellaswag": 75.36,
    "mmlu": 49.33,
    "truthfulqa": 44.7,
    "winogrande": 72.38,
    "gsm8k": 17.36,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 53.9,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "01305dc473ba231519fe71e7f4b2d1e3f6aa9bc8",
    "model_name_for_query": "elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V1.0",
    "link": "https://huggingface.co/elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V1.0",
    "author": "elliotthwang"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "stable-vicuna-13B-HF",
    "average": 51.64,
    "arc": 53.33,
    "hellaswag": 78.5,
    "mmlu": 50.29,
    "truthfulqa": 48.38,
    "winogrande": 75.22,
    "gsm8k": 4.09,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 12.85,
    "likes": 95.0,
    "still_on_hub": true,
    "revision": "2b099b2be0dafb2606ae9808c0f6183fe4bff7bc",
    "model_name_for_query": "TheBloke/stable-vicuna-13B-HF",
    "link": "https://huggingface.co/TheBloke/stable-vicuna-13B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2xOpenOrca-13B-LoRa-v2",
    "average": 51.61,
    "arc": 58.62,
    "hellaswag": 81.17,
    "mmlu": 50.23,
    "truthfulqa": 43.43,
    "winogrande": 76.16,
    "gsm8k": 0.08,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "568ac6a5f1a9f5eb6bc09efb2188740d771ed0e9",
    "model_name_for_query": "yeontaek/Platypus2xOpenOrca-13B-LoRa-v2",
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-LoRa-v2",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-7b-ludwig-alpaca",
    "average": 51.6,
    "arc": 54.01,
    "hellaswag": 78.73,
    "mmlu": 45.8,
    "truthfulqa": 41.91,
    "winogrande": 74.27,
    "gsm8k": 14.86,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "7928584c0329c3ed88915a823033908be90ba657",
    "model_name_for_query": "rufjdk5480/llama-7b-ludwig-alpaca",
    "link": "https://huggingface.co/rufjdk5480/llama-7b-ludwig-alpaca",
    "author": "rufjdk5480"
  },
  {
    "T": "\u2b55",
    "model": "tamil-llama-13b-instruct-v0.1",
    "average": 51.59,
    "arc": 54.52,
    "hellaswag": 79.35,
    "mmlu": 50.37,
    "truthfulqa": 41.22,
    "winogrande": 76.56,
    "gsm8k": 7.51,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7d6d6f23f69d1d8806ac21eec7ef8feba63c0e67",
    "model_name_for_query": "abhinand/tamil-llama-13b-instruct-v0.1",
    "link": "https://huggingface.co/abhinand/tamil-llama-13b-instruct-v0.1",
    "author": "abhinand"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-16k",
    "average": 51.58,
    "arc": 54.69,
    "hellaswag": 77.32,
    "mmlu": 49.51,
    "truthfulqa": 50.41,
    "winogrande": 71.11,
    "gsm8k": 6.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 55.0,
    "still_on_hub": true,
    "revision": "9a93d7d11fac7f3f9074510b80092b53bc1a5bec",
    "model_name_for_query": "lmsys/vicuna-7b-v1.5-16k",
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5-16k",
    "author": "lmsys"
  },
  {
    "T": "\u2b55",
    "model": "Yousei-22B",
    "average": 51.56,
    "arc": 55.89,
    "hellaswag": 78.55,
    "mmlu": 52.31,
    "truthfulqa": 50.68,
    "winogrande": 71.51,
    "gsm8k": 0.45,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 21.83,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "ae8f93963266d31000433f1a52d43435e1473e2b",
    "model_name_for_query": "Envoid/Yousei-22B",
    "link": "https://huggingface.co/Envoid/Yousei-22B",
    "author": "Envoid"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-MysteryModel-13b",
    "average": 51.54,
    "arc": 57.0,
    "hellaswag": 80.35,
    "mmlu": 52.06,
    "truthfulqa": 45.0,
    "winogrande": 74.82,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c38a9df20162455b53eb35d38a9b67fb824559e8",
    "model_name_for_query": "PocketDoc/Dans-MysteryModel-13b",
    "link": "https://huggingface.co/PocketDoc/Dans-MysteryModel-13b",
    "author": "PocketDoc"
  },
  {
    "T": "\u2b55",
    "model": "llama2-7b-hf-instruction-lora",
    "average": 51.54,
    "arc": 55.38,
    "hellaswag": 78.57,
    "mmlu": 49.39,
    "truthfulqa": 41.83,
    "winogrande": 74.19,
    "gsm8k": 9.86,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f660a40323b29040e78097acca320517ed242512",
    "model_name_for_query": "lvkaokao/llama2-7b-hf-instruction-lora",
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-instruction-lora",
    "author": "lvkaokao"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-c34b-2.1",
    "average": 51.52,
    "arc": 54.69,
    "hellaswag": 76.45,
    "mmlu": 55.08,
    "truthfulqa": 46.15,
    "winogrande": 68.43,
    "gsm8k": 8.34,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "2caa8ce3aab012bf34c7c531827f6befc7cc1c98",
    "model_name_for_query": "jondurbin/airoboros-c34b-2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-c34b-2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Elliott-Chinese-LLaMa-GPTQ-V2.0",
    "average": 51.47,
    "arc": 50.77,
    "hellaswag": 75.36,
    "mmlu": 49.41,
    "truthfulqa": 44.7,
    "winogrande": 72.61,
    "gsm8k": 16.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 52.86,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ebffe57ba6cc70b60ff5295889abc62d91eeb4dd",
    "model_name_for_query": "elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V2.0",
    "link": "https://huggingface.co/elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V2.0",
    "author": "elliotthwang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-PL-lora_unload",
    "average": 51.46,
    "arc": 53.5,
    "hellaswag": 76.74,
    "mmlu": 49.69,
    "truthfulqa": 49.68,
    "winogrande": 71.98,
    "gsm8k": 7.2,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "92bf763ce7ae0bfe155bfd60190eed64582e5080",
    "model_name_for_query": "Lajonbot/vicuna-7b-v1.5-PL-lora_unload",
    "link": "https://huggingface.co/Lajonbot/vicuna-7b-v1.5-PL-lora_unload",
    "author": "Lajonbot"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-class-tutor-7b-ep3",
    "average": 51.45,
    "arc": 52.13,
    "hellaswag": 78.07,
    "mmlu": 51.32,
    "truthfulqa": 52.3,
    "winogrande": 71.19,
    "gsm8k": 3.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "724cf8becd6dbb0b67070c34711ef6d60ad5f216",
    "model_name_for_query": "luffycodes/vicuna-class-tutor-7b-ep3",
    "link": "https://huggingface.co/luffycodes/vicuna-class-tutor-7b-ep3",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pwen-VL-Chat-20_30",
    "average": 51.45,
    "arc": 50.17,
    "hellaswag": 72.21,
    "mmlu": 56.34,
    "truthfulqa": 42.52,
    "winogrande": 68.35,
    "gsm8k": 19.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "64a9b89fb18140fc1af1f11471dc9fe34ebc7446",
    "model_name_for_query": "JosephusCheung/Pwen-VL-Chat-20_30",
    "link": "https://huggingface.co/JosephusCheung/Pwen-VL-Chat-20_30",
    "author": "JosephusCheung"
  },
  {
    "T": "?",
    "model": "MistralLite",
    "average": 51.45,
    "arc": 59.56,
    "hellaswag": 81.84,
    "mmlu": 50.93,
    "truthfulqa": 37.87,
    "winogrande": 77.43,
    "gsm8k": 1.06,
    "model_type": "",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 334.0,
    "still_on_hub": true,
    "revision": "23486089ab7ba741b34adc69ab7555885f8abe71",
    "model_name_for_query": "amazon/MistralLite",
    "link": "https://huggingface.co/amazon/MistralLite",
    "author": "amazon"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM_13B_juniper",
    "average": 51.45,
    "arc": 55.38,
    "hellaswag": 77.2,
    "mmlu": 45.46,
    "truthfulqa": 51.5,
    "winogrande": 71.11,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2204970fc0d96b071e2b1b003fbc5c87cfc46840",
    "model_name_for_query": "frank098/WizardLM_13B_juniper",
    "link": "https://huggingface.co/frank098/WizardLM_13B_juniper",
    "author": "frank098"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_7b_zh",
    "average": 51.44,
    "arc": 52.05,
    "hellaswag": 74.88,
    "mmlu": 60.69,
    "truthfulqa": 42.86,
    "winogrande": 71.74,
    "gsm8k": 6.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "410711781d2e24226c0d62959e4990d1de851c3c",
    "model_name_for_query": "itsliupeng/llama2_7b_zh",
    "link": "https://huggingface.co/itsliupeng/llama2_7b_zh",
    "author": "itsliupeng"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zoyllm-7b-slimorca",
    "average": 51.44,
    "arc": 50.6,
    "hellaswag": 72.12,
    "mmlu": 48.78,
    "truthfulqa": 49.13,
    "winogrande": 67.32,
    "gsm8k": 20.7,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-sa-4.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4b49caa2c42b3e8757f986624b047dab485ee26f",
    "model_name_for_query": "tlphams/zoyllm-7b-slimorca",
    "link": "https://huggingface.co/tlphams/zoyllm-7b-slimorca",
    "author": "tlphams"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CAMEL-13B-Role-Playing-Data",
    "average": 51.42,
    "arc": 54.95,
    "hellaswag": 79.25,
    "mmlu": 46.61,
    "truthfulqa": 46.35,
    "winogrande": 74.03,
    "gsm8k": 7.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "762ecb0d85572c8f8bcbca06d27f7f64a4d74615",
    "model_name_for_query": "camel-ai/CAMEL-13B-Role-Playing-Data",
    "link": "https://huggingface.co/camel-ai/CAMEL-13B-Role-Playing-Data",
    "author": "camel-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-16k",
    "average": 51.42,
    "arc": 54.18,
    "hellaswag": 77.31,
    "mmlu": 49.3,
    "truthfulqa": 50.35,
    "winogrande": 71.03,
    "gsm8k": 6.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 55.0,
    "still_on_hub": true,
    "revision": "9a93d7d11fac7f3f9074510b80092b53bc1a5bec",
    "model_name_for_query": "lmsys/vicuna-7b-v1.5-16k",
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5-16k",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Baichuan2-7B-Chat-LLaMAfied",
    "average": 51.42,
    "arc": 52.47,
    "hellaswag": 74.04,
    "mmlu": 53.88,
    "truthfulqa": 48.04,
    "winogrande": 69.14,
    "gsm8k": 10.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.99,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "da2cd76e2d61bf0247bd67a4f2835319c54a7d62",
    "model_name_for_query": "hiyouga/Baichuan2-7B-Chat-LLaMAfied",
    "link": "https://huggingface.co/hiyouga/Baichuan2-7B-Chat-LLaMAfied",
    "author": "hiyouga"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-22b-daydreamer-v3",
    "average": 51.39,
    "arc": 56.06,
    "hellaswag": 80.07,
    "mmlu": 52.49,
    "truthfulqa": 42.43,
    "winogrande": 73.48,
    "gsm8k": 3.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 21.62,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "e6c74222958328e50712aa00294dc818c24075b2",
    "model_name_for_query": "nkpz/llama2-22b-daydreamer-v3",
    "link": "https://huggingface.co/nkpz/llama2-22b-daydreamer-v3",
    "author": "nkpz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Colossal-LLaMA-2-7b-base",
    "average": 51.39,
    "arc": 53.5,
    "hellaswag": 70.5,
    "mmlu": 54.4,
    "truthfulqa": 50.19,
    "winogrande": 70.01,
    "gsm8k": 9.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.76,
    "likes": 54.0,
    "still_on_hub": true,
    "revision": "1f30e4f2037e1e30122667639b8ef37138e85057",
    "model_name_for_query": "hpcai-tech/Colossal-LLaMA-2-7b-base",
    "link": "https://huggingface.co/hpcai-tech/Colossal-LLaMA-2-7b-base",
    "author": "hpcai-tech"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrca-Preview1-13B",
    "average": 51.38,
    "arc": 54.95,
    "hellaswag": 78.19,
    "mmlu": 50.12,
    "truthfulqa": 49.05,
    "winogrande": 71.03,
    "gsm8k": 4.93,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 143.0,
    "still_on_hub": true,
    "revision": "d120381b03051b60a7c77ec3fb1be6c3c1546466",
    "model_name_for_query": "Open-Orca/OpenOrca-Preview1-13B",
    "link": "https://huggingface.co/Open-Orca/OpenOrca-Preview1-13B",
    "author": "Open-Orca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "kuchiki-1.1-l2-7b",
    "average": 51.36,
    "arc": 54.18,
    "hellaswag": 78.0,
    "mmlu": 48.14,
    "truthfulqa": 49.96,
    "winogrande": 73.16,
    "gsm8k": 4.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "10fe70fec0df5c4dcbdfd2e9ec74830c41b3cfd2",
    "model_name_for_query": "zarakiquemparte/kuchiki-1.1-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/kuchiki-1.1-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-13b",
    "average": 51.36,
    "arc": 56.23,
    "hellaswag": 80.93,
    "mmlu": 47.67,
    "truthfulqa": 39.48,
    "winogrande": 76.24,
    "gsm8k": 7.58,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "other",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "4022c52fcc7473ce7364bb5ac166195903ea1efb",
    "model_name_for_query": "huggingface/llama-13b",
    "link": "https://huggingface.co/huggingface/llama-13b",
    "author": "huggingface"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Hermes-WVG-Test",
    "average": 51.35,
    "arc": 54.95,
    "hellaswag": 78.48,
    "mmlu": 48.36,
    "truthfulqa": 45.72,
    "winogrande": 74.74,
    "gsm8k": 5.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "eb5b1d65fdf916ca71f89a46eb91175c1c630a57",
    "model_name_for_query": "LTC-AI-Labs/L2-7b-Hermes-WVG-Test",
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Hermes-WVG-Test",
    "author": "LTC-AI-Labs"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-13b",
    "average": 51.33,
    "arc": 56.14,
    "hellaswag": 80.92,
    "mmlu": 47.61,
    "truthfulqa": 39.48,
    "winogrande": 76.24,
    "gsm8k": 7.58,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 13.02,
    "likes": 119.0,
    "still_on_hub": true,
    "revision": "bf57045473f207bb1de1ed035ace226f4d9f9bba",
    "model_name_for_query": "huggyllama/llama-13b",
    "link": "https://huggingface.co/huggyllama/llama-13b",
    "author": "huggyllama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "kuchiki-l2-7b",
    "average": 51.33,
    "arc": 54.35,
    "hellaswag": 78.44,
    "mmlu": 47.74,
    "truthfulqa": 49.88,
    "winogrande": 73.09,
    "gsm8k": 4.47,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "745c34e70aa92056e8cd79c1d16e8fcfe1797645",
    "model_name_for_query": "zarakiquemparte/kuchiki-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/kuchiki-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt4all-alpaca-oa-codealpaca-lora-13b",
    "average": 51.33,
    "arc": 56.14,
    "hellaswag": 80.93,
    "mmlu": 47.66,
    "truthfulqa": 39.48,
    "winogrande": 76.16,
    "gsm8k": 7.58,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 13.0,
    "likes": 11.0,
    "still_on_hub": false,
    "revision": "13443d633eaa5b7e1a90ac9cdb4a4d51b1c8d0d1",
    "model_name_for_query": "jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b",
    "link": "https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b",
    "author": "jordiclive"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Luna-AI-Llama2-Uncensored",
    "average": 51.29,
    "arc": 54.35,
    "hellaswag": 78.6,
    "mmlu": 46.7,
    "truthfulqa": 45.5,
    "winogrande": 72.77,
    "gsm8k": 9.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 6.61,
    "likes": 101.0,
    "still_on_hub": true,
    "revision": "6b5e1067e412cc5750aec7415a065671df3618be",
    "model_name_for_query": "Tap-M/Luna-AI-Llama2-Uncensored",
    "link": "https://huggingface.co/Tap-M/Luna-AI-Llama2-Uncensored",
    "author": "Tap-M"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zarablend-l2-7b",
    "average": 51.29,
    "arc": 54.44,
    "hellaswag": 78.62,
    "mmlu": 47.61,
    "truthfulqa": 49.38,
    "winogrande": 73.32,
    "gsm8k": 4.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "8b14e71ae3f52c409a25e1ac98dd05e0bb91eaff",
    "model_name_for_query": "zarakiquemparte/zarablend-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zarablend-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ko-en-llama2-13b",
    "average": 51.27,
    "arc": 58.19,
    "hellaswag": 81.89,
    "mmlu": 52.02,
    "truthfulqa": 39.96,
    "winogrande": 74.82,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "2768cf6f955b65868ccbb20658e2cc444b2f3be9",
    "model_name_for_query": "hyunseoki/ko-en-llama2-13b",
    "link": "https://huggingface.co/hyunseoki/ko-en-llama2-13b",
    "author": "hyunseoki"
  },
  {
    "T": "\u2b55",
    "model": "OpenHermes-7B",
    "average": 51.26,
    "arc": 56.14,
    "hellaswag": 78.32,
    "mmlu": 48.62,
    "truthfulqa": 45.0,
    "winogrande": 74.51,
    "gsm8k": 5.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 6.61,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "74edb1ad58d3d517ef46c4e2a31081084ecbc473",
    "model_name_for_query": "teknium/OpenHermes-7B",
    "link": "https://huggingface.co/teknium/OpenHermes-7B",
    "author": "teknium"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-claude-chat-rp",
    "average": 51.25,
    "arc": 54.95,
    "hellaswag": 80.05,
    "mmlu": 47.03,
    "truthfulqa": 43.47,
    "winogrande": 74.74,
    "gsm8k": 7.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4309eedebe8ba5709e0cc7cf186cb783f3bc8060",
    "model_name_for_query": "Norquinal/llama-2-7b-claude-chat-rp",
    "link": "https://huggingface.co/Norquinal/llama-2-7b-claude-chat-rp",
    "author": "Norquinal"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zarablend-1.1-l2-7b",
    "average": 51.25,
    "arc": 54.86,
    "hellaswag": 78.58,
    "mmlu": 47.89,
    "truthfulqa": 49.0,
    "winogrande": 72.61,
    "gsm8k": 4.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e46bfa43829cbea7608192a6d07bcc147387fdb7",
    "model_name_for_query": "zarakiquemparte/zarablend-1.1-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zarablend-1.1-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Synthia-WVG-Test",
    "average": 51.25,
    "arc": 55.97,
    "hellaswag": 77.89,
    "mmlu": 49.48,
    "truthfulqa": 44.11,
    "winogrande": 74.11,
    "gsm8k": 5.91,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "23ae02efba01c37abe3cff0fedc7d2d9644fe98e",
    "model_name_for_query": "LTC-AI-Labs/L2-7b-Synthia-WVG-Test",
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Synthia-WVG-Test",
    "author": "LTC-AI-Labs"
  },
  {
    "T": "\u2b55",
    "model": "airoboros-l2-7b-2.2.1",
    "average": 51.22,
    "arc": 55.03,
    "hellaswag": 80.06,
    "mmlu": 47.64,
    "truthfulqa": 44.65,
    "winogrande": 73.8,
    "gsm8k": 6.14,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "eafbba6fec094a17ca7bce6d9605cac97b90a483",
    "model_name_for_query": "jondurbin/airoboros-l2-7b-2.2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-2.2.1",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7B-physics",
    "average": 51.22,
    "arc": 52.9,
    "hellaswag": 77.71,
    "mmlu": 48.83,
    "truthfulqa": 48.93,
    "winogrande": 71.9,
    "gsm8k": 7.05,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5e66b59c145586266b2351a63f0cf1b4f62f5454",
    "model_name_for_query": "Harshvir/Llama-2-7B-physics",
    "link": "https://huggingface.co/Harshvir/Llama-2-7B-physics",
    "author": "Harshvir"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MentaLLaMA-chat-7B",
    "average": 51.17,
    "arc": 52.82,
    "hellaswag": 76.1,
    "mmlu": 47.51,
    "truthfulqa": 44.02,
    "winogrande": 70.4,
    "gsm8k": 16.15,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "eb0b119279aada6404042c69763aaadb5be5000d",
    "model_name_for_query": "klyang/MentaLLaMA-chat-7B",
    "link": "https://huggingface.co/klyang/MentaLLaMA-chat-7B",
    "author": "klyang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "koala-13B-HF",
    "average": 51.16,
    "arc": 52.99,
    "hellaswag": 77.59,
    "mmlu": 45.32,
    "truthfulqa": 50.23,
    "winogrande": 74.03,
    "gsm8k": 6.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 40.0,
    "still_on_hub": true,
    "revision": "b20f96a0171ce4c0fa27d6048215ebe710521587",
    "model_name_for_query": "TheBloke/koala-13B-HF",
    "link": "https://huggingface.co/TheBloke/koala-13B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LexPodLM-13B",
    "average": 51.14,
    "arc": 57.76,
    "hellaswag": 81.04,
    "mmlu": 48.38,
    "truthfulqa": 43.48,
    "winogrande": 76.16,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "3553d84037addc97678f99a3464be4c866a0c268",
    "model_name_for_query": "64bits/LexPodLM-13B",
    "link": "https://huggingface.co/64bits/LexPodLM-13B",
    "author": "64bits"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-Chinese-7b-Chat",
    "average": 51.13,
    "arc": 52.39,
    "hellaswag": 77.52,
    "mmlu": 47.72,
    "truthfulqa": 46.87,
    "winogrande": 74.27,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 104.0,
    "still_on_hub": true,
    "revision": "4c3bc725f71898c6a1acd4ea98a2f8d74d1b1b6b",
    "model_name_for_query": "FlagAlpha/Llama2-Chinese-7b-Chat",
    "link": "https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat",
    "author": "FlagAlpha"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-2-26b-trenchcoat-stack",
    "average": 51.13,
    "arc": 55.03,
    "hellaswag": 79.9,
    "mmlu": 53.73,
    "truthfulqa": 40.48,
    "winogrande": 74.74,
    "gsm8k": 2.88,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 25.7,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "075d67c3223f4b379ab7f997c3787cd0630d80f7",
    "model_name_for_query": "chargoddard/llama-2-26b-trenchcoat-stack",
    "link": "https://huggingface.co/chargoddard/llama-2-26b-trenchcoat-stack",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "EverythingLM-13b-V3-16k",
    "average": 51.11,
    "arc": 58.19,
    "hellaswag": 80.12,
    "mmlu": 50.48,
    "truthfulqa": 45.18,
    "winogrande": 70.72,
    "gsm8k": 1.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "1de9244bfadb947f80872727f76790cbc76e7142",
    "model_name_for_query": "totally-not-an-llm/EverythingLM-13b-V3-16k",
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-V3-16k",
    "author": "totally-not-an-llm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-2-7b",
    "average": 51.11,
    "arc": 54.01,
    "hellaswag": 78.23,
    "mmlu": 49.11,
    "truthfulqa": 43.78,
    "winogrande": 75.14,
    "gsm8k": 6.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.74,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "983f8ad5c156f4a0e4d2b7b5f1146981ad2e8a8b",
    "model_name_for_query": "PygmalionAI/pygmalion-2-7b",
    "link": "https://huggingface.co/PygmalionAI/pygmalion-2-7b",
    "author": "PygmalionAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "finetuned-llama2-chat-5000-v1.0-squad",
    "average": 51.09,
    "arc": 50.94,
    "hellaswag": 76.61,
    "mmlu": 46.43,
    "truthfulqa": 44.45,
    "winogrande": 71.98,
    "gsm8k": 16.15,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "apache-2.0",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "67c1301cb8a9ea7eb6e2b2c1829719ef746465d3",
    "model_name_for_query": "abdulrahman-nuzha/finetuned-llama2-chat-5000-v1.0-squad",
    "link": "https://huggingface.co/abdulrahman-nuzha/finetuned-llama2-chat-5000-v1.0-squad",
    "author": "abdulrahman-nuzha"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2guanacotest",
    "average": 51.08,
    "arc": 51.62,
    "hellaswag": 77.55,
    "mmlu": 48.49,
    "truthfulqa": 43.88,
    "winogrande": 73.16,
    "gsm8k": 11.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "679d17809939a0bf9b79bbb027898cbea64045b2",
    "model_name_for_query": "abhishek/llama2guanacotest",
    "link": "https://huggingface.co/abhishek/llama2guanacotest",
    "author": "abhishek"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Samantha-1.11-7b",
    "average": 51.07,
    "arc": 55.03,
    "hellaswag": 79.12,
    "mmlu": 40.51,
    "truthfulqa": 50.37,
    "winogrande": 74.19,
    "gsm8k": 7.2,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "730cbd8f3077f3d24001aab714def991f1e4e7e8",
    "model_name_for_query": "ehartford/Samantha-1.11-7b",
    "link": "https://huggingface.co/ehartford/Samantha-1.11-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-7b-sharegpt4",
    "average": 51.05,
    "arc": 55.72,
    "hellaswag": 80.94,
    "mmlu": 47.47,
    "truthfulqa": 48.34,
    "winogrande": 71.19,
    "gsm8k": 2.65,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "922d1d963ad1b042c30b774a818d9f6180c28075",
    "model_name_for_query": "beaugogh/Llama2-7b-sharegpt4",
    "link": "https://huggingface.co/beaugogh/Llama2-7b-sharegpt4",
    "author": "beaugogh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama2-7b-sharegpt4",
    "average": 51.05,
    "arc": 55.72,
    "hellaswag": 80.94,
    "mmlu": 47.47,
    "truthfulqa": 48.34,
    "winogrande": 71.19,
    "gsm8k": 2.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "8ecaba5dd0e9929f5858cfe9f5f8cd8ba285c9e5",
    "model_name_for_query": "HWERI/Llama2-7b-sharegpt4",
    "link": "https://huggingface.co/HWERI/Llama2-7b-sharegpt4",
    "author": "HWERI"
  },
  {
    "T": "\u2b55",
    "model": "WizardVicuna2-13b-hf",
    "average": 51.05,
    "arc": 55.38,
    "hellaswag": 79.14,
    "mmlu": 48.46,
    "truthfulqa": 42.43,
    "winogrande": 73.48,
    "gsm8k": 7.43,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6cfd95e2dcdb6996afa9eb5c63273a1a3524c6c6",
    "model_name_for_query": "heegyu/WizardVicuna2-13b-hf",
    "link": "https://huggingface.co/heegyu/WizardVicuna2-13b-hf",
    "author": "heegyu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-guanaco-fp16",
    "average": 51.04,
    "arc": 54.86,
    "hellaswag": 79.65,
    "mmlu": 46.38,
    "truthfulqa": 43.83,
    "winogrande": 75.22,
    "gsm8k": 6.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "f769fed10874af73ad12115efd044cb4a64506b0",
    "model_name_for_query": "Mikael110/llama-2-7b-guanaco-fp16",
    "link": "https://huggingface.co/Mikael110/llama-2-7b-guanaco-fp16",
    "author": "Mikael110"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chinese-llama-2-13b",
    "average": 51.04,
    "arc": 55.8,
    "hellaswag": 79.53,
    "mmlu": 53.01,
    "truthfulqa": 38.24,
    "winogrande": 75.69,
    "gsm8k": 3.94,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.97,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "484c8a18b02f95eb2b6f6302105cf9a329e76ec8",
    "model_name_for_query": "ziqingyang/chinese-llama-2-13b",
    "link": "https://huggingface.co/ziqingyang/chinese-llama-2-13b",
    "author": "ziqingyang"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Llama-2-7b-chat-hf-30-sparsity",
    "average": 51.02,
    "arc": 52.47,
    "hellaswag": 76.58,
    "mmlu": 45.57,
    "truthfulqa": 44.82,
    "winogrande": 69.61,
    "gsm8k": 17.06,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c3d07c4f8b6a509334d0f63e5057e9447f01b318",
    "model_name_for_query": "wang7776/Llama-2-7b-chat-hf-30-sparsity",
    "link": "https://huggingface.co/wang7776/Llama-2-7b-chat-hf-30-sparsity",
    "author": "wang7776"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mistral-Pygmalion-7b",
    "average": 51.02,
    "arc": 54.44,
    "hellaswag": 78.48,
    "mmlu": 49.23,
    "truthfulqa": 41.82,
    "winogrande": 75.3,
    "gsm8k": 6.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-nd-4.0",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4e5fa9ae7f572b4841b02c3f96d8a3c7a7e59521",
    "model_name_for_query": "Delcos/Mistral-Pygmalion-7b",
    "link": "https://huggingface.co/Delcos/Mistral-Pygmalion-7b",
    "author": "Delcos"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-claude-chat",
    "average": 50.98,
    "arc": 54.44,
    "hellaswag": 80.66,
    "mmlu": 46.74,
    "truthfulqa": 41.39,
    "winogrande": 74.9,
    "gsm8k": 7.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e65d34ed31cdcd2637f6284aa0605f30ef5a9381",
    "model_name_for_query": "Norquinal/llama-2-7b-claude-chat",
    "link": "https://huggingface.co/Norquinal/llama-2-7b-claude-chat",
    "author": "Norquinal"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vic15-exp-syn-fight-cp3838",
    "average": 50.97,
    "arc": 51.79,
    "hellaswag": 75.79,
    "mmlu": 50.23,
    "truthfulqa": 49.61,
    "winogrande": 71.82,
    "gsm8k": 6.6,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "91ce25dbdb67793ad1fcfdfd59f7603c2be65aea",
    "model_name_for_query": "AlekseyKorshuk/vic15-exp-syn-fight-cp3838",
    "link": "https://huggingface.co/AlekseyKorshuk/vic15-exp-syn-fight-cp3838",
    "author": "AlekseyKorshuk"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Llama-2-7b-hf",
    "average": 50.97,
    "arc": 53.07,
    "hellaswag": 78.59,
    "mmlu": 46.87,
    "truthfulqa": 38.76,
    "winogrande": 74.03,
    "gsm8k": 14.48,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 679.0,
    "still_on_hub": false,
    "revision": "e8f058fa738b6b308540024e9aa12e274e291f75",
    "model_name_for_query": "meta-llama/Llama-2-7b-hf",
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-hf",
    "author": "meta-llama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dorflan",
    "average": 50.96,
    "arc": 54.44,
    "hellaswag": 75.78,
    "mmlu": 51.36,
    "truthfulqa": 51.17,
    "winogrande": 72.61,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5d8e7e5764ace89e6ccd1deece33b0e8a4b4587b",
    "model_name_for_query": "formulae/Dorflan",
    "link": "https://huggingface.co/formulae/Dorflan",
    "author": "formulae"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-instruct-peft",
    "average": 50.94,
    "arc": 51.19,
    "hellaswag": 78.92,
    "mmlu": 46.63,
    "truthfulqa": 48.5,
    "winogrande": 74.43,
    "gsm8k": 5.99,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "unknown",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "0fc43413117187e0723cdac133068ab527c80fe2",
    "model_name_for_query": "dfurman/llama-2-7b-instruct-peft",
    "link": "https://huggingface.co/dfurman/llama-2-7b-instruct-peft",
    "author": "dfurman"
  },
  {
    "T": "\u2b55",
    "model": "LLaMa-2-PeanutButter_v18_B-7B",
    "average": 50.94,
    "arc": 54.61,
    "hellaswag": 81.0,
    "mmlu": 47.07,
    "truthfulqa": 41.93,
    "winogrande": 74.51,
    "gsm8k": 6.52,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "bc8c239cacf1e3211f05e27be67a74d84c12aea9",
    "model_name_for_query": "PeanutJar/LLaMa-2-PeanutButter_v18_B-7B",
    "link": "https://huggingface.co/PeanutJar/LLaMa-2-PeanutButter_v18_B-7B",
    "author": "PeanutJar"
  },
  {
    "T": "\u2b55",
    "model": "cria-llama2-7b-v1.3",
    "average": 50.93,
    "arc": 52.73,
    "hellaswag": 78.58,
    "mmlu": 48.3,
    "truthfulqa": 45.58,
    "winogrande": 71.9,
    "gsm8k": 8.49,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "163a5bec7b6f5aaa4667aa6a95746deff50ceab1",
    "model_name_for_query": "davzoku/cria-llama2-7b-v1.3",
    "link": "https://huggingface.co/davzoku/cria-llama2-7b-v1.3",
    "author": "davzoku"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-100step-v2",
    "average": 50.89,
    "arc": 52.65,
    "hellaswag": 78.25,
    "mmlu": 48.47,
    "truthfulqa": 45.18,
    "winogrande": 72.3,
    "gsm8k": 8.49,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4ee3182f614473f9ea3b6e429b01872bc90e89f1",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-100step-v2",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-100step-v2",
    "author": "Korabbit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Barcenas-7b",
    "average": 50.87,
    "arc": 55.12,
    "hellaswag": 77.4,
    "mmlu": 49.27,
    "truthfulqa": 43.64,
    "winogrande": 73.64,
    "gsm8k": 6.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "770fa73981a599e935c21a95b1817a553c726694",
    "model_name_for_query": "Danielbrdz/Barcenas-7b",
    "link": "https://huggingface.co/Danielbrdz/Barcenas-7b",
    "author": "Danielbrdz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-13b-2.1",
    "average": 50.84,
    "arc": 55.12,
    "hellaswag": 80.24,
    "mmlu": 50.89,
    "truthfulqa": 44.62,
    "winogrande": 71.9,
    "gsm8k": 2.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 12.85,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "172e30e56e939f73d7d00a165c2d49cbd284481f",
    "model_name_for_query": "jondurbin/airoboros-l2-13b-2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Guanaco-Vicuna-7B-L2",
    "average": 50.83,
    "arc": 53.24,
    "hellaswag": 78.89,
    "mmlu": 46.77,
    "truthfulqa": 42.75,
    "winogrande": 75.37,
    "gsm8k": 7.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ba8e755feab0bbf90675dcb9f8875a42f92112a5",
    "model_name_for_query": "LTC-AI-Labs/Guanaco-Vicuna-7B-L2",
    "link": "https://huggingface.co/LTC-AI-Labs/Guanaco-Vicuna-7B-L2",
    "author": "LTC-AI-Labs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama2-13b-pretrain",
    "average": 50.77,
    "arc": 53.92,
    "hellaswag": 79.1,
    "mmlu": 51.25,
    "truthfulqa": 36.24,
    "winogrande": 75.53,
    "gsm8k": 8.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.97,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f87d66f9c4541c575a6fad3c19a31b11568e0dfb",
    "model_name_for_query": "YeungNLP/firefly-llama2-13b-pretrain",
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b-pretrain",
    "author": "YeungNLP"
  },
  {
    "T": "\u2b55",
    "model": "LLaMa-2-PeanutButter_v10-7B",
    "average": 50.75,
    "arc": 55.29,
    "hellaswag": 81.69,
    "mmlu": 46.97,
    "truthfulqa": 43.78,
    "winogrande": 70.88,
    "gsm8k": 5.91,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "f98bb987216448aa3aa89e575a7494fae8b68066",
    "model_name_for_query": "PeanutJar/LLaMa-2-PeanutButter_v10-7B",
    "link": "https://huggingface.co/PeanutJar/LLaMa-2-PeanutButter_v10-7B",
    "author": "PeanutJar"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "Llama-2-7b-chat-hf",
    "average": 50.74,
    "arc": 52.9,
    "hellaswag": 78.55,
    "mmlu": 48.32,
    "truthfulqa": 45.57,
    "winogrande": 71.74,
    "gsm8k": 7.35,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 1415.0,
    "still_on_hub": false,
    "revision": "b7701a9e825e79a5ab18b5801be113c2160cc627",
    "model_name_for_query": "meta-llama/Llama-2-7b-chat-hf",
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf",
    "author": "meta-llama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-timedial-unit-080082",
    "average": 50.74,
    "arc": 52.82,
    "hellaswag": 76.07,
    "mmlu": 50.47,
    "truthfulqa": 43.54,
    "winogrande": 73.72,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "372c90543ebb2a317fb9b51ff3890cc270e5ce3a",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080082",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080082",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-timedial-unit-080091",
    "average": 50.71,
    "arc": 52.82,
    "hellaswag": 76.1,
    "mmlu": 50.58,
    "truthfulqa": 43.4,
    "winogrande": 73.72,
    "gsm8k": 7.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ae7e0fb58f4201bb14fd4e641d0d6dcc22674e0e",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080091",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080091",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-chat-finetune-AUTOMATE",
    "average": 50.68,
    "arc": 53.07,
    "hellaswag": 75.59,
    "mmlu": 48.8,
    "truthfulqa": 44.73,
    "winogrande": 73.24,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "55862462a23ab43fb73d4c784f1518ab4645764c",
    "model_name_for_query": "revolutionarybukhari/Llama-2-7b-chat-finetune-AUTOMATE",
    "link": "https://huggingface.co/revolutionarybukhari/Llama-2-7b-chat-finetune-AUTOMATE",
    "author": "revolutionarybukhari"
  },
  {
    "T": "\u2b55",
    "model": "kollama2-7b-v2",
    "average": 50.66,
    "arc": 53.33,
    "hellaswag": 78.5,
    "mmlu": 43.61,
    "truthfulqa": 46.37,
    "winogrande": 75.61,
    "gsm8k": 6.52,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "d5b6e9d5b882d4f6ba322396e027925ed915f848",
    "model_name_for_query": "psyche/kollama2-7b-v2",
    "link": "https://huggingface.co/psyche/kollama2-7b-v2",
    "author": "psyche"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Qwen-LLaMAfied-HFTok-7B-Chat",
    "average": 50.64,
    "arc": 50.51,
    "hellaswag": 83.65,
    "mmlu": 51.53,
    "truthfulqa": 44.23,
    "winogrande": 71.43,
    "gsm8k": 2.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.1,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "b8d5c09c83b1ef23668cb9209dbc43c0df2de8ae",
    "model_name_for_query": "vonjack/Qwen-LLaMAfied-HFTok-7B-Chat",
    "link": "https://huggingface.co/vonjack/Qwen-LLaMAfied-HFTok-7B-Chat",
    "author": "vonjack"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Base-WVG-Uncensored",
    "average": 50.63,
    "arc": 53.24,
    "hellaswag": 79.13,
    "mmlu": 46.65,
    "truthfulqa": 42.59,
    "winogrande": 75.14,
    "gsm8k": 7.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "67ede9be6ceffdf574294351cca937d88d7d448d",
    "model_name_for_query": "LTC-AI-Labs/L2-7b-Base-WVG-Uncensored",
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Base-WVG-Uncensored",
    "author": "LTC-AI-Labs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LaOT",
    "average": 50.62,
    "arc": 55.63,
    "hellaswag": 78.96,
    "mmlu": 50.3,
    "truthfulqa": 44.72,
    "winogrande": 74.11,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "df3a2c77a63a370405c7711b323e7ffa550cdd9e",
    "model_name_for_query": "DopeorNope/LaOT",
    "link": "https://huggingface.co/DopeorNope/LaOT",
    "author": "DopeorNope"
  },
  {
    "T": "\ud83d\udd36",
    "model": "zaraxls-l2-7b",
    "average": 50.61,
    "arc": 54.44,
    "hellaswag": 78.94,
    "mmlu": 50.39,
    "truthfulqa": 46.51,
    "winogrande": 73.16,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cc1dad50689b3ebcc1c9c67f275da6b4bb63e2ce",
    "model_name_for_query": "zarakiquemparte/zaraxls-l2-7b",
    "link": "https://huggingface.co/zarakiquemparte/zaraxls-l2-7b",
    "author": "zarakiquemparte"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ANIMA-Nectar-v3",
    "average": 50.58,
    "arc": 49.49,
    "hellaswag": 75.99,
    "mmlu": 53.34,
    "truthfulqa": 46.16,
    "winogrande": 73.72,
    "gsm8k": 4.78,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8ff9dd66d8cb8fba5c745e5bdb9928c4fc9889e4",
    "model_name_for_query": "Severian/ANIMA-Nectar-v3",
    "link": "https://huggingface.co/Severian/ANIMA-Nectar-v3",
    "author": "Severian"
  },
  {
    "T": "\ud83d\udd36",
    "model": "trurl-2-7b",
    "average": 50.58,
    "arc": 53.41,
    "hellaswag": 75.29,
    "mmlu": 50.0,
    "truthfulqa": 45.42,
    "winogrande": 72.22,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "e26ca5f157c60fc527170cc04db7fc0ea04ad26f",
    "model_name_for_query": "Voicelab/trurl-2-7b",
    "link": "https://huggingface.co/Voicelab/trurl-2-7b",
    "author": "Voicelab"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-7b-guanaco-instruct-sharded",
    "average": 50.58,
    "arc": 53.75,
    "hellaswag": 78.69,
    "mmlu": 46.65,
    "truthfulqa": 43.93,
    "winogrande": 72.61,
    "gsm8k": 7.81,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.74,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "fc7a3abbc3b9a9b3e163ef3c4844307ac270fca7",
    "model_name_for_query": "guardrail/llama-2-7b-guanaco-instruct-sharded",
    "link": "https://huggingface.co/guardrail/llama-2-7b-guanaco-instruct-sharded",
    "author": "guardrail"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-rockwell-final",
    "average": 50.55,
    "arc": 52.73,
    "hellaswag": 79.1,
    "mmlu": 47.88,
    "truthfulqa": 47.21,
    "winogrande": 68.43,
    "gsm8k": 7.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "de4cfe99e9e3db62733b40f48b2b11faf9abe4bf",
    "model_name_for_query": "maximuslee07/llama-2-7b-rockwell-final",
    "link": "https://huggingface.co/maximuslee07/llama-2-7b-rockwell-final",
    "author": "maximuslee07"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-mmlu-val-mcq-7b-ep2",
    "average": 50.55,
    "arc": 53.33,
    "hellaswag": 77.73,
    "mmlu": 46.85,
    "truthfulqa": 43.87,
    "winogrande": 71.27,
    "gsm8k": 10.24,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a6e6639ddaed9b2a8a549424f8c8a2d2bca241d4",
    "model_name_for_query": "luffycodes/vicuna-mmlu-val-mcq-7b-ep2",
    "link": "https://huggingface.co/luffycodes/vicuna-mmlu-val-mcq-7b-ep2",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Guanaco-Uncensored",
    "average": 50.55,
    "arc": 50.6,
    "hellaswag": 76.99,
    "mmlu": 48.93,
    "truthfulqa": 43.42,
    "winogrande": 75.37,
    "gsm8k": 7.96,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9d49378c69c00113cf7f6e66d1ddb9d9b003dddc",
    "model_name_for_query": "Lazycuber/L2-7b-Guanaco-Uncensored",
    "link": "https://huggingface.co/Lazycuber/L2-7b-Guanaco-Uncensored",
    "author": "Lazycuber"
  },
  {
    "T": "\ud83d\udd36",
    "model": "trurl-2-7b-pl-instruct_unload",
    "average": 50.52,
    "arc": 53.16,
    "hellaswag": 74.64,
    "mmlu": 49.89,
    "truthfulqa": 45.74,
    "winogrande": 72.3,
    "gsm8k": 7.43,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "768d800e4dbe3fc95334f30ca7cd02113d3e3fd3",
    "model_name_for_query": "Aspik101/trurl-2-7b-pl-instruct_unload",
    "link": "https://huggingface.co/Aspik101/trurl-2-7b-pl-instruct_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "monika-ddlc-7b-v1",
    "average": 50.49,
    "arc": 54.95,
    "hellaswag": 76.78,
    "mmlu": 45.61,
    "truthfulqa": 43.94,
    "winogrande": 72.85,
    "gsm8k": 8.79,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4157d696bb0015da3ba26a58c1d24925515e4125",
    "model_name_for_query": "922-CA/monika-ddlc-7b-v1",
    "link": "https://huggingface.co/922-CA/monika-ddlc-7b-v1",
    "author": "922-CA"
  },
  {
    "T": "\u2b55",
    "model": "WizardCoder-Python-34B-V1.0",
    "average": 50.46,
    "arc": 52.13,
    "hellaswag": 74.78,
    "mmlu": 49.15,
    "truthfulqa": 48.85,
    "winogrande": 68.35,
    "gsm8k": 9.48,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 33.48,
    "likes": 616.0,
    "still_on_hub": true,
    "revision": "5cdc34e4a81d202f1d4a3b5d60e028aab895dfeb",
    "model_name_for_query": "WizardLM/WizardCoder-Python-34B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "L2-7b-Base-Guanaco-Uncensored",
    "average": 50.45,
    "arc": 52.22,
    "hellaswag": 79.08,
    "mmlu": 46.63,
    "truthfulqa": 42.97,
    "winogrande": 74.51,
    "gsm8k": 7.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dd51a3b26ad378e2953c947a1e4c2f8febe0cb52",
    "model_name_for_query": "Lazycuber/L2-7b-Base-Guanaco-Uncensored",
    "link": "https://huggingface.co/Lazycuber/L2-7b-Base-Guanaco-Uncensored",
    "author": "Lazycuber"
  },
  {
    "T": "?",
    "model": "gpt4-x-alpaca",
    "average": 50.41,
    "arc": 52.82,
    "hellaswag": 79.59,
    "mmlu": 48.19,
    "truthfulqa": 48.88,
    "winogrande": 70.17,
    "gsm8k": 2.81,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 456.0,
    "still_on_hub": true,
    "revision": "6a571f458cab9a23d14324ec63e0abd1744c8353",
    "model_name_for_query": "chavinlo/gpt4-x-alpaca",
    "link": "https://huggingface.co/chavinlo/gpt4-x-alpaca",
    "author": "chavinlo"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
    "average": 50.4,
    "arc": 53.67,
    "hellaswag": 78.21,
    "mmlu": 45.9,
    "truthfulqa": 46.13,
    "winogrande": 73.8,
    "gsm8k": 4.7,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1295069e9fef63aed87d36fe108d6c934cb34ded",
    "model_name_for_query": "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-chat-hf-dpo",
    "average": 50.38,
    "arc": 53.67,
    "hellaswag": 78.79,
    "mmlu": 46.78,
    "truthfulqa": 43.97,
    "winogrande": 71.74,
    "gsm8k": 7.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ec98429034fc84a4555dd4e3db4d6af534a03832",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-chat-hf-dpo",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-dpo",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Koss-7B-chat",
    "average": 50.37,
    "arc": 53.67,
    "hellaswag": 78.79,
    "mmlu": 46.72,
    "truthfulqa": 43.97,
    "winogrande": 71.74,
    "gsm8k": 7.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-4.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b1ab836d9ebf7029fafa07949b51d3838501d537",
    "model_name_for_query": "NewstaR/Koss-7B-chat",
    "link": "https://huggingface.co/NewstaR/Koss-7B-chat",
    "author": "NewstaR"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-delta-v1.1",
    "average": 50.37,
    "arc": 53.67,
    "hellaswag": 77.5,
    "mmlu": 45.61,
    "truthfulqa": 48.95,
    "winogrande": 70.96,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 197.0,
    "still_on_hub": true,
    "revision": "24fb8e1e9cc78e0aa7ef154b026c4a83296e3fc4",
    "model_name_for_query": "lmsys/vicuna-7b-delta-v1.1",
    "link": "https://huggingface.co/lmsys/vicuna-7b-delta-v1.1",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-1.1",
    "average": 50.37,
    "arc": 53.67,
    "hellaswag": 77.46,
    "mmlu": 45.63,
    "truthfulqa": 48.94,
    "winogrande": 70.96,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 109.0,
    "still_on_hub": true,
    "revision": "9d8eea215e00b388a22e8f050768ea8911d41f1d",
    "model_name_for_query": "eachadea/vicuna-7b-1.1",
    "link": "https://huggingface.co/eachadea/vicuna-7b-1.1",
    "author": "eachadea"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna_7B_vanilla_1.1",
    "average": 50.37,
    "arc": 53.67,
    "hellaswag": 77.46,
    "mmlu": 45.63,
    "truthfulqa": 48.94,
    "winogrande": 70.96,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "d971d788db19648ad16bf77ec3f1de35ebf9a8e0",
    "model_name_for_query": "Ejafa/vicuna_7B_vanilla_1.1",
    "link": "https://huggingface.co/Ejafa/vicuna_7B_vanilla_1.1",
    "author": "Ejafa"
  },
  {
    "T": "\ud83d\udd36",
    "model": "spatial-vicuna-7b-v1.5-LoRA",
    "average": 50.36,
    "arc": 50.77,
    "hellaswag": 74.63,
    "mmlu": 48.13,
    "truthfulqa": 49.36,
    "winogrande": 72.38,
    "gsm8k": 6.9,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "dc71924cfb214b91461d35178e6ea6fef7946f13",
    "model_name_for_query": "joehuangx/spatial-vicuna-7b-v1.5-LoRA",
    "link": "https://huggingface.co/joehuangx/spatial-vicuna-7b-v1.5-LoRA",
    "author": "joehuangx"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-timedial",
    "average": 50.35,
    "arc": 52.9,
    "hellaswag": 76.29,
    "mmlu": 50.47,
    "truthfulqa": 41.6,
    "winogrande": 73.56,
    "gsm8k": 7.28,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1e1709818cca48af4cd31c07c493f996854aa10f",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-timedial",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-timedial",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lacda-2-7B-chat-v0.1",
    "average": 50.29,
    "arc": 53.07,
    "hellaswag": 77.57,
    "mmlu": 46.03,
    "truthfulqa": 44.57,
    "winogrande": 74.19,
    "gsm8k": 6.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "afca346816726b83e331bb4d93246ed5146e1675",
    "model_name_for_query": "willnguyen/lacda-2-7B-chat-v0.1",
    "link": "https://huggingface.co/willnguyen/lacda-2-7B-chat-v0.1",
    "author": "willnguyen"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Yi-Ko-6B",
    "average": 50.27,
    "arc": 48.89,
    "hellaswag": 74.48,
    "mmlu": 55.72,
    "truthfulqa": 37.09,
    "winogrande": 72.93,
    "gsm8k": 12.51,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 6.18,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "8f2f500574cd3c2972f05b7ae6e2807819cce051",
    "model_name_for_query": "beomi/Yi-Ko-6B",
    "link": "https://huggingface.co/beomi/Yi-Ko-6B",
    "author": "beomi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "smol-3b",
    "average": 50.27,
    "arc": 46.33,
    "hellaswag": 68.23,
    "mmlu": 46.33,
    "truthfulqa": 50.73,
    "winogrande": 65.35,
    "gsm8k": 24.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 3.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "21c18e02cbd8becf5cb48eaff485379b6d62a2cd",
    "model_name_for_query": "rishiraj/smol-3b",
    "link": "https://huggingface.co/rishiraj/smol-3b",
    "author": "rishiraj"
  },
  {
    "T": "\u2b55",
    "model": "Asclepius-Llama2-13B",
    "average": 50.25,
    "arc": 55.89,
    "hellaswag": 79.66,
    "mmlu": 52.38,
    "truthfulqa": 40.76,
    "winogrande": 72.69,
    "gsm8k": 0.15,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 13.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "579271bebb894d89369205060d151120a217ce81",
    "model_name_for_query": "starmpcc/Asclepius-Llama2-13B",
    "link": "https://huggingface.co/starmpcc/Asclepius-Llama2-13B",
    "author": "starmpcc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "tulu-7B-fp16",
    "average": 50.24,
    "arc": 50.17,
    "hellaswag": 77.04,
    "mmlu": 47.63,
    "truthfulqa": 41.61,
    "winogrande": 73.8,
    "gsm8k": 11.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "8a026683f79119643f4007da4e9155c7849792cc",
    "model_name_for_query": "TheBloke/tulu-7B-fp16",
    "link": "https://huggingface.co/TheBloke/tulu-7B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-hf-instruct-pl-lora_unload",
    "average": 50.23,
    "arc": 53.75,
    "hellaswag": 78.34,
    "mmlu": 46.8,
    "truthfulqa": 42.34,
    "winogrande": 73.95,
    "gsm8k": 6.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3dfef350be9c8ce92c2d314dbe96a002bd6ca97d",
    "model_name_for_query": "Aspik101/Llama-2-7b-hf-instruct-pl-lora_unload",
    "link": "https://huggingface.co/Aspik101/Llama-2-7b-hf-instruct-pl-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MiniChat-1.5-3B",
    "average": 50.23,
    "arc": 46.5,
    "hellaswag": 68.28,
    "mmlu": 46.67,
    "truthfulqa": 50.71,
    "winogrande": 65.04,
    "gsm8k": 24.18,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "886af9601d57d8675c09bab02144b68366cd4437",
    "model_name_for_query": "GeneZC/MiniChat-1.5-3B",
    "link": "https://huggingface.co/GeneZC/MiniChat-1.5-3B",
    "author": "GeneZC"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLongMA-2-13b-16k",
    "average": 50.22,
    "arc": 54.27,
    "hellaswag": 79.63,
    "mmlu": 50.97,
    "truthfulqa": 37.71,
    "winogrande": 72.77,
    "gsm8k": 5.99,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "c2defe28e2f3f10460baf8f778b00986a53aa7a2",
    "model_name_for_query": "conceptofmind/LLongMA-2-13b-16k",
    "link": "https://huggingface.co/conceptofmind/LLongMA-2-13b-16k",
    "author": "conceptofmind"
  },
  {
    "T": "\ud83d\udd36",
    "model": "stack-llama-2",
    "average": 50.21,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.8,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 10.01,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "bigscience-openrail-m",
    "params": 6.61,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "28a206689c0097738177840a40e455a308db2d7d",
    "model_name_for_query": "kashif/stack-llama-2",
    "link": "https://huggingface.co/kashif/stack-llama-2",
    "author": "kashif"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-afr-200step-v2",
    "average": 50.21,
    "arc": 51.79,
    "hellaswag": 77.41,
    "mmlu": 48.55,
    "truthfulqa": 43.69,
    "winogrande": 71.9,
    "gsm8k": 7.88,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a3575a542e1dc3db4a7794b8f36b104c93b39875",
    "model_name_for_query": "Korabbit/Llama-2-7b-chat-hf-afr-200step-v2",
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-v2",
    "author": "Korabbit"
  },
  {
    "T": "\ud83d\udd36",
    "model": "elliott_Llama-2-7b-hf",
    "average": 50.2,
    "arc": 53.16,
    "hellaswag": 78.33,
    "mmlu": 47.09,
    "truthfulqa": 42.11,
    "winogrande": 73.64,
    "gsm8k": 6.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ac5d22e14c2c7a400519da5d12d88e4fe683ccfa",
    "model_name_for_query": "elliotthwang/elliott_Llama-2-7b-hf",
    "link": "https://huggingface.co/elliotthwang/elliott_Llama-2-7b-hf",
    "author": "elliotthwang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Platypus2-mini-7B",
    "average": 50.18,
    "arc": 53.33,
    "hellaswag": 78.81,
    "mmlu": 45.58,
    "truthfulqa": 42.0,
    "winogrande": 75.14,
    "gsm8k": 6.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4ede4a6f8a8d6cc3bfff8b98837116c74c280f63",
    "model_name_for_query": "edor/Platypus2-mini-7B",
    "link": "https://huggingface.co/edor/Platypus2-mini-7B",
    "author": "edor"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ALMA-13B",
    "average": 50.16,
    "arc": 56.83,
    "hellaswag": 80.29,
    "mmlu": 49.92,
    "truthfulqa": 37.57,
    "winogrande": 76.32,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 13.0,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "6798d9501a71b203be0610e640ec92fc08ea8dc6",
    "model_name_for_query": "haoranxu/ALMA-13B",
    "link": "https://huggingface.co/haoranxu/ALMA-13B",
    "author": "haoranxu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-hf-guanaco-1k",
    "average": 50.13,
    "arc": 51.62,
    "hellaswag": 76.73,
    "mmlu": 47.45,
    "truthfulqa": 44.79,
    "winogrande": 72.77,
    "gsm8k": 7.43,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bdb57c5c992872ced47f48cb2177a5fa159f926a",
    "model_name_for_query": "quantumaikr/llama-2-7b-hf-guanaco-1k",
    "link": "https://huggingface.co/quantumaikr/llama-2-7b-hf-guanaco-1k",
    "author": "quantumaikr"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-hf-guanaco",
    "average": 50.12,
    "arc": 52.47,
    "hellaswag": 78.75,
    "mmlu": 45.33,
    "truthfulqa": 43.9,
    "winogrande": 74.19,
    "gsm8k": 6.07,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6c1fc95e67b11f1011a3b2fc1aa05c7b83251e40",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-hf-guanaco",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-hf-guanaco",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "elm-test",
    "average": 50.09,
    "arc": 53.16,
    "hellaswag": 78.98,
    "mmlu": 47.04,
    "truthfulqa": 39.51,
    "winogrande": 74.35,
    "gsm8k": 7.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aa8f81624d897aa493474bcd96dc3feae9f7a535",
    "model_name_for_query": "TinyPixel/elm-test",
    "link": "https://huggingface.co/TinyPixel/elm-test",
    "author": "TinyPixel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLongMA-2-13b-16k",
    "average": 50.09,
    "arc": 54.27,
    "hellaswag": 79.66,
    "mmlu": 50.86,
    "truthfulqa": 37.68,
    "winogrande": 72.61,
    "gsm8k": 5.46,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "c2defe28e2f3f10460baf8f778b00986a53aa7a2",
    "model_name_for_query": "conceptofmind/LLongMA-2-13b-16k",
    "link": "https://huggingface.co/conceptofmind/LLongMA-2-13b-16k",
    "author": "conceptofmind"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7B-32K-Instruct",
    "average": 50.02,
    "arc": 51.11,
    "hellaswag": 78.51,
    "mmlu": 46.11,
    "truthfulqa": 44.86,
    "winogrande": 73.88,
    "gsm8k": 5.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 111.0,
    "still_on_hub": true,
    "revision": "35696b9a7ab330dcbe240ff76fb44ab1eccf45bf",
    "model_name_for_query": "togethercomputer/Llama-2-7B-32K-Instruct",
    "link": "https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-chat-hf-guanaco",
    "average": 50.02,
    "arc": 50.51,
    "hellaswag": 76.72,
    "mmlu": 48.03,
    "truthfulqa": 43.36,
    "winogrande": 72.93,
    "gsm8k": 8.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5d33696ee324899d52fc43794b46009fea08a9af",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-chat-hf-guanaco",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-guanaco",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
    "average": 50.0,
    "arc": 53.75,
    "hellaswag": 78.76,
    "mmlu": 46.02,
    "truthfulqa": 43.31,
    "winogrande": 73.48,
    "gsm8k": 4.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6ba5416f618ed3e11b409326e84c36fa542f0951",
    "model_name_for_query": "dhmeltzer/llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
    "average": 49.98,
    "arc": 54.1,
    "hellaswag": 78.74,
    "mmlu": 45.44,
    "truthfulqa": 43.4,
    "winogrande": 73.64,
    "gsm8k": 4.55,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "f1f3b9fdb1e2d8d8fa913d57a8fe15d7bdf72c20",
    "model_name_for_query": "dhmeltzer/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
    "author": "dhmeltzer"
  },
  {
    "T": "\u2b55",
    "model": "Platypus2-7B",
    "average": 49.97,
    "arc": 55.2,
    "hellaswag": 78.84,
    "mmlu": 49.83,
    "truthfulqa": 40.64,
    "winogrande": 73.48,
    "gsm8k": 1.82,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-sa-4.0",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "f784afa7887b0738d92ea470797582756f02e630",
    "model_name_for_query": "garage-bAInd/Platypus2-7B",
    "link": "https://huggingface.co/garage-bAInd/Platypus2-7B",
    "author": "garage-bAInd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-hf-small-shards-Samantha-V1-SFT",
    "average": 49.96,
    "arc": 53.16,
    "hellaswag": 77.71,
    "mmlu": 43.47,
    "truthfulqa": 45.28,
    "winogrande": 73.8,
    "gsm8k": 6.37,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c39cee3821269e7fdffa690c2d0836c74dfebd25",
    "model_name_for_query": "RoversX/llama-2-7b-hf-small-shards-Samantha-V1-SFT",
    "link": "https://huggingface.co/RoversX/llama-2-7b-hf-small-shards-Samantha-V1-SFT",
    "author": "RoversX"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mamba-gpt-7b",
    "average": 49.96,
    "arc": 51.19,
    "hellaswag": 75.4,
    "mmlu": 47.47,
    "truthfulqa": 42.06,
    "winogrande": 71.67,
    "gsm8k": 11.98,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cb0b04b1bff7921614efbd87d5b87bac04c58d13",
    "model_name_for_query": "CobraMamba/mamba-gpt-7b",
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-7b",
    "author": "CobraMamba"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lima-test",
    "average": 49.96,
    "arc": 53.07,
    "hellaswag": 78.88,
    "mmlu": 46.42,
    "truthfulqa": 39.4,
    "winogrande": 74.03,
    "gsm8k": 7.96,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4d6a006c6341f29b11c02f19bf9535f51b4da1b5",
    "model_name_for_query": "TinyPixel/lima-test",
    "link": "https://huggingface.co/TinyPixel/lima-test",
    "author": "TinyPixel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Uncensored-Jordan-7B",
    "average": 49.95,
    "arc": 51.28,
    "hellaswag": 77.37,
    "mmlu": 45.69,
    "truthfulqa": 47.5,
    "winogrande": 71.11,
    "gsm8k": 6.75,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 7.0,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "96a9fbe5aaef8410a8d0dad25f3cc97b408c4efb",
    "model_name_for_query": "ajibawa-2023/Uncensored-Jordan-7B",
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Jordan-7B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-coder-7b",
    "average": 49.95,
    "arc": 54.01,
    "hellaswag": 78.35,
    "mmlu": 46.25,
    "truthfulqa": 38.49,
    "winogrande": 75.45,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "f21c0d5e3f9f8c5addf093358e6885afa9602296",
    "model_name_for_query": "mrm8488/llama-2-coder-7b",
    "link": "https://huggingface.co/mrm8488/llama-2-coder-7b",
    "author": "mrm8488"
  },
  {
    "T": "\u2b55",
    "model": "LLaMa-2-PeanutButter_v18_A-7B",
    "average": 49.88,
    "arc": 53.16,
    "hellaswag": 78.11,
    "mmlu": 45.54,
    "truthfulqa": 40.37,
    "winogrande": 74.9,
    "gsm8k": 7.2,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "15b2fa81418792841014f589e61d1d9e30457040",
    "model_name_for_query": "PeanutJar/LLaMa-2-PeanutButter_v18_A-7B",
    "link": "https://huggingface.co/PeanutJar/LLaMa-2-PeanutButter_v18_A-7B",
    "author": "PeanutJar"
  },
  {
    "T": "\ud83d\udd36",
    "model": "yayi-7b-llama2",
    "average": 49.88,
    "arc": 54.78,
    "hellaswag": 77.94,
    "mmlu": 41.35,
    "truthfulqa": 44.02,
    "winogrande": 74.51,
    "gsm8k": 6.67,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "18a4ed38285c732efc583a4bd883b3a681f8d005",
    "model_name_for_query": "wenge-research/yayi-7b-llama2",
    "link": "https://huggingface.co/wenge-research/yayi-7b-llama2",
    "author": "wenge-research"
  },
  {
    "T": "\ud83d\udd36",
    "model": "testmodel2",
    "average": 49.88,
    "arc": 53.24,
    "hellaswag": 78.78,
    "mmlu": 46.61,
    "truthfulqa": 39.17,
    "winogrande": 73.8,
    "gsm8k": 7.66,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "cb1111653997cee2818ffcf13a1c37237ea2934d",
    "model_name_for_query": "TinyPixel/testmodel2",
    "link": "https://huggingface.co/TinyPixel/testmodel2",
    "author": "TinyPixel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-chat-hf-instruct-pl-lora_unload",
    "average": 49.86,
    "arc": 52.99,
    "hellaswag": 77.49,
    "mmlu": 47.12,
    "truthfulqa": 42.61,
    "winogrande": 72.06,
    "gsm8k": 6.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f838fda8d2b97effae1e8af4dbb6217eab14fb7e",
    "model_name_for_query": "Lajonbot/Llama-2-7b-chat-hf-instruct-pl-lora_unload",
    "link": "https://huggingface.co/Lajonbot/Llama-2-7b-chat-hf-instruct-pl-lora_unload",
    "author": "Lajonbot"
  },
  {
    "T": "\ud83d\udd36",
    "model": "kollama2-7b",
    "average": 49.81,
    "arc": 53.24,
    "hellaswag": 78.78,
    "mmlu": 42.31,
    "truthfulqa": 44.56,
    "winogrande": 73.95,
    "gsm8k": 5.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "48fca4ba1e2d31ff4fbe6856b9b93ad2d97da8b7",
    "model_name_for_query": "psyche/kollama2-7b",
    "link": "https://huggingface.co/psyche/kollama2-7b",
    "author": "psyche"
  },
  {
    "T": "\ud83d\udd36",
    "model": "testmodel-3",
    "average": 49.79,
    "arc": 53.24,
    "hellaswag": 78.72,
    "mmlu": 46.57,
    "truthfulqa": 38.75,
    "winogrande": 73.88,
    "gsm8k": 7.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a1fbc4d8a2c1a3d211325bdff9e7f0539fa7a2b1",
    "model_name_for_query": "TinyPixel/testmodel-3",
    "link": "https://huggingface.co/TinyPixel/testmodel-3",
    "author": "TinyPixel"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardMath-7B-V1.0",
    "average": 49.78,
    "arc": 54.1,
    "hellaswag": 79.55,
    "mmlu": 45.97,
    "truthfulqa": 43.65,
    "winogrande": 72.69,
    "gsm8k": 2.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "06dbd3e0da08255c575e585cb82e0554c1d2707a",
    "model_name_for_query": "WizardLM/WizardMath-7B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardMath-7B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\u2b55",
    "model": "ELYZA-japanese-Llama-2-7b-instruct",
    "average": 49.78,
    "arc": 53.16,
    "hellaswag": 78.25,
    "mmlu": 47.07,
    "truthfulqa": 39.08,
    "winogrande": 73.24,
    "gsm8k": 7.88,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "48fa08b3098a23d3671e09565499a4cfbaff1923",
    "model_name_for_query": "elyza/ELYZA-japanese-Llama-2-7b-instruct",
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-instruct",
    "author": "elyza"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.3",
    "average": 49.78,
    "arc": 50.43,
    "hellaswag": 76.92,
    "mmlu": 48.14,
    "truthfulqa": 47.01,
    "winogrande": 70.48,
    "gsm8k": 5.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 112.0,
    "still_on_hub": true,
    "revision": "ac066c83424c4a7221aa10c0ebe074b24d3bcdb6",
    "model_name_for_query": "lmsys/vicuna-7b-v1.3",
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.3",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-to-mistral-diff",
    "average": 49.78,
    "arc": 53.41,
    "hellaswag": 78.56,
    "mmlu": 46.43,
    "truthfulqa": 38.71,
    "winogrande": 74.03,
    "gsm8k": 7.51,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 10.0,
    "still_on_hub": false,
    "revision": "16c279c5e7d12b8a6ff7771881808ef253a406b9",
    "model_name_for_query": "undi95/llama2-to-mistral-diff",
    "link": "https://huggingface.co/undi95/llama2-to-mistral-diff",
    "author": "undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-chat-hf-v4",
    "average": 49.78,
    "arc": 53.41,
    "hellaswag": 78.56,
    "mmlu": 46.43,
    "truthfulqa": 38.71,
    "winogrande": 74.03,
    "gsm8k": 7.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "405c54ec7aea0735996ef5ff6ede6c35ab930381",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
    "average": 49.77,
    "arc": 51.79,
    "hellaswag": 76.41,
    "mmlu": 49.58,
    "truthfulqa": 40.33,
    "winogrande": 73.4,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "26626ea669172be6bc8e6b2b0bc5f14aef8061aa",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "yayi-7b-llama2",
    "average": 49.75,
    "arc": 55.03,
    "hellaswag": 77.84,
    "mmlu": 40.92,
    "truthfulqa": 44.02,
    "winogrande": 73.72,
    "gsm8k": 6.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "f1a9e8d91e5b636cde3ea7fcf752a9f0234bd92a",
    "model_name_for_query": "wenge-research/yayi-7b-llama2",
    "link": "https://huggingface.co/wenge-research/yayi-7b-llama2",
    "author": "wenge-research"
  },
  {
    "T": "\u2b55",
    "model": "llama-2-7b-hf_open-platypus",
    "average": 49.73,
    "arc": 51.45,
    "hellaswag": 78.63,
    "mmlu": 43.6,
    "truthfulqa": 43.71,
    "winogrande": 74.43,
    "gsm8k": 6.6,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c7e776f3f3afc0fa22cb7aff0d00522e571e9b29",
    "model_name_for_query": "lgaalves/llama-2-7b-hf_open-platypus",
    "link": "https://huggingface.co/lgaalves/llama-2-7b-hf_open-platypus",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test-llama2-7b",
    "average": 49.73,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.86,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "ebe2e68699cb7ab6bb22688f265c89be2ac0fa6d",
    "model_name_for_query": "bongchoi/test-llama2-7b",
    "link": "https://huggingface.co/bongchoi/test-llama2-7b",
    "author": "bongchoi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test_llama2_7b",
    "average": 49.73,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.86,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "69a4886f51ed752216cdd7f41a584d14240126f9",
    "model_name_for_query": "yeen214/test_llama2_7b",
    "link": "https://huggingface.co/yeen214/test_llama2_7b",
    "author": "yeen214"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Starlight-7B",
    "average": 49.73,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.8,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1f7436c458ebc3d8d31b91091c1a7a48e942cd3b",
    "model_name_for_query": "NewstaR/Starlight-7B",
    "link": "https://huggingface.co/NewstaR/Starlight-7B",
    "author": "NewstaR"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Flash-Llama-7B",
    "average": 49.73,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.8,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "27c84ef23d850582453e1cc2dcea13de48da090f",
    "model_name_for_query": "TaylorAI/Flash-Llama-7B",
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-7B",
    "author": "TaylorAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-chat-hf-v2",
    "average": 49.73,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.8,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1c97650d4b919e2c6a2829778caa3a109935a58c",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-chat-hf-v2",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v2",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-chat-hf-v4",
    "average": 49.73,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.8,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "405c54ec7aea0735996ef5ff6ede6c35ab930381",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "araproje-llama2-7b-hf",
    "average": 49.73,
    "arc": 53.07,
    "hellaswag": 78.57,
    "mmlu": 46.8,
    "truthfulqa": 38.75,
    "winogrande": 74.03,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7fe54f507e762b0f62265813aef908765b1298c0",
    "model_name_for_query": "ibranze/araproje-llama2-7b-hf",
    "link": "https://huggingface.co/ibranze/araproje-llama2-7b-hf",
    "author": "ibranze"
  },
  {
    "T": "\u2b55",
    "model": "cria-llama2-7b-v1.3_peft",
    "average": 49.72,
    "arc": 51.45,
    "hellaswag": 77.35,
    "mmlu": 46.47,
    "truthfulqa": 45.52,
    "winogrande": 70.8,
    "gsm8k": 6.75,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "6864fa8ee43fa4d6b4f3ae055bbf464a5dcca570",
    "model_name_for_query": "davzoku/cria-llama2-7b-v1.3_peft",
    "link": "https://huggingface.co/davzoku/cria-llama2-7b-v1.3_peft",
    "author": "davzoku"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ToolLLaMA-7b-LoRA",
    "average": 49.72,
    "arc": 52.99,
    "hellaswag": 78.62,
    "mmlu": 46.87,
    "truthfulqa": 38.67,
    "winogrande": 74.35,
    "gsm8k": 6.82,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 7.0,
    "still_on_hub": false,
    "revision": "67f2e8af850049a86fb9ee8ef581deb0f51e58e6",
    "model_name_for_query": "ToolBench/ToolLLaMA-7b-LoRA",
    "link": "https://huggingface.co/ToolBench/ToolLLaMA-7b-LoRA",
    "author": "ToolBench"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
    "average": 49.71,
    "arc": 53.67,
    "hellaswag": 78.09,
    "mmlu": 45.63,
    "truthfulqa": 41.72,
    "winogrande": 73.56,
    "gsm8k": 5.61,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2af3d3acb0466fef466512bc17b9bf57024629e8",
    "model_name_for_query": "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
    "link": "https://huggingface.co/dhmeltzer/Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-mixed-datasets",
    "average": 49.7,
    "arc": 51.71,
    "hellaswag": 76.44,
    "mmlu": 50.13,
    "truthfulqa": 39.57,
    "winogrande": 73.24,
    "gsm8k": 7.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9c74b9396ff6b33e7a7622e59aa1f46103d993fe",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-mixed-datasets",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mixed-datasets",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "finetuned-llama-v2.0",
    "average": 49.67,
    "arc": 53.16,
    "hellaswag": 77.75,
    "mmlu": 43.69,
    "truthfulqa": 39.08,
    "winogrande": 74.43,
    "gsm8k": 9.93,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "apache-2.0",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9ffa847a1a0b229ea9c218e865bcf20f78556a8e",
    "model_name_for_query": "abdulrahman-nuzha/finetuned-llama-v2.0",
    "link": "https://huggingface.co/abdulrahman-nuzha/finetuned-llama-v2.0",
    "author": "abdulrahman-nuzha"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_7b_chat_uncensored",
    "average": 49.67,
    "arc": 53.58,
    "hellaswag": 78.66,
    "mmlu": 44.49,
    "truthfulqa": 41.34,
    "winogrande": 74.11,
    "gsm8k": 5.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 152.0,
    "still_on_hub": true,
    "revision": "e9a972b12c6b59bfbcf30fe3779c2c933ce755bd",
    "model_name_for_query": "georgesung/llama2_7b_chat_uncensored",
    "link": "https://huggingface.co/georgesung/llama2_7b_chat_uncensored",
    "author": "georgesung"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chinese-alpaca-plus-13b-hf",
    "average": 49.66,
    "arc": 53.16,
    "hellaswag": 73.51,
    "mmlu": 48.81,
    "truthfulqa": 45.32,
    "winogrande": 75.06,
    "gsm8k": 2.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.94,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "a118d2c35573b9a70c6f5b56fba4b657f74ce00c",
    "model_name_for_query": "shibing624/chinese-alpaca-plus-13b-hf",
    "link": "https://huggingface.co/shibing624/chinese-alpaca-plus-13b-hf",
    "author": "shibing624"
  },
  {
    "T": "\ud83d\udd36",
    "model": "starchat-beta",
    "average": 49.66,
    "arc": 52.47,
    "hellaswag": 80.59,
    "mmlu": 42.85,
    "truthfulqa": 47.22,
    "winogrande": 69.69,
    "gsm8k": 5.16,
    "model_type": "fine-tuned",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": "bigcode-openrail-m",
    "params": 15.52,
    "likes": 222.0,
    "still_on_hub": true,
    "revision": "b1bcda690655777373f57ea6614eb095ec2c886f",
    "model_name_for_query": "HuggingFaceH4/starchat-beta",
    "link": "https://huggingface.co/HuggingFaceH4/starchat-beta",
    "author": "HuggingFaceH4"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7B-32K-Instruct",
    "average": 49.65,
    "arc": 51.37,
    "hellaswag": 78.47,
    "mmlu": 45.53,
    "truthfulqa": 45.01,
    "winogrande": 72.85,
    "gsm8k": 4.7,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "llama2",
    "params": 6.61,
    "likes": 111.0,
    "still_on_hub": true,
    "revision": "b050a6f17d46e32c4b90a30492f14746589f74b7",
    "model_name_for_query": "togethercomputer/Llama-2-7B-32K-Instruct",
    "link": "https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct",
    "author": "togethercomputer"
  },
  {
    "T": "\u2b55",
    "model": "FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
    "average": 49.64,
    "arc": 52.47,
    "hellaswag": 79.08,
    "mmlu": 47.58,
    "truthfulqa": 37.14,
    "winogrande": 74.74,
    "gsm8k": 6.82,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "819f3f384e37f8906a62a8048556c9e58e495c02",
    "model_name_for_query": "TaylorAI/FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
    "link": "https://huggingface.co/TaylorAI/FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
    "author": "TaylorAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-7b-2.1",
    "average": 49.64,
    "arc": 54.44,
    "hellaswag": 78.68,
    "mmlu": 44.45,
    "truthfulqa": 43.95,
    "winogrande": 74.11,
    "gsm8k": 2.2,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "699491e2e73cc2936205db143f59c1a686b88f14",
    "model_name_for_query": "jondurbin/airoboros-l2-7b-2.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "longchat-13b-16k",
    "average": 49.64,
    "arc": 53.58,
    "hellaswag": 77.67,
    "mmlu": 45.24,
    "truthfulqa": 47.07,
    "winogrande": 70.09,
    "gsm8k": 4.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 123.0,
    "still_on_hub": true,
    "revision": "70e2e38b82f1e25d8b90b50fbfc2361123bef45f",
    "model_name_for_query": "lmsys/longchat-13b-16k",
    "link": "https://huggingface.co/lmsys/longchat-13b-16k",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-ft-instruct-es",
    "average": 49.63,
    "arc": 53.67,
    "hellaswag": 77.83,
    "mmlu": 46.58,
    "truthfulqa": 38.82,
    "winogrande": 75.22,
    "gsm8k": 5.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "b62f431c88b232204ea7046f9d906ae1daa68437",
    "model_name_for_query": "clibrain/Llama-2-7b-ft-instruct-es",
    "link": "https://huggingface.co/clibrain/Llama-2-7b-ft-instruct-es",
    "author": "clibrain"
  },
  {
    "T": "\u2b55",
    "model": "airocoder-34b-2.1",
    "average": 49.61,
    "arc": 54.18,
    "hellaswag": 73.84,
    "mmlu": 50.67,
    "truthfulqa": 40.7,
    "winogrande": 69.93,
    "gsm8k": 8.34,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "f66e783ac783837b3f59f274ecf55f18a9221cd0",
    "model_name_for_query": "jondurbin/airocoder-34b-2.1",
    "link": "https://huggingface.co/jondurbin/airocoder-34b-2.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "meditron-7b-chat",
    "average": 49.59,
    "arc": 50.77,
    "hellaswag": 75.37,
    "mmlu": 40.49,
    "truthfulqa": 48.56,
    "winogrande": 73.16,
    "gsm8k": 9.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b2e32b581d1484c831654fb2c03d2d29e7f520d7",
    "model_name_for_query": "malhajar/meditron-7b-chat",
    "link": "https://huggingface.co/malhajar/meditron-7b-chat",
    "author": "malhajar"
  },
  {
    "T": "\u2b55",
    "model": "llama2-13b-chinese-v2",
    "average": 49.58,
    "arc": 53.92,
    "hellaswag": 74.64,
    "mmlu": 49.74,
    "truthfulqa": 45.43,
    "winogrande": 71.59,
    "gsm8k": 2.2,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.94,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "8f6b11ca4344ac230d6b55defa4e04e60a39f9b5",
    "model_name_for_query": "gywy/llama2-13b-chinese-v2",
    "link": "https://huggingface.co/gywy/llama2-13b-chinese-v2",
    "author": "gywy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-1-percent-open-orca-1000-steps-v0",
    "average": 49.56,
    "arc": 51.28,
    "hellaswag": 78.75,
    "mmlu": 44.68,
    "truthfulqa": 45.83,
    "winogrande": 74.11,
    "gsm8k": 2.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a893ebef4b818de1968dd9e932da2f513d16386a",
    "model_name_for_query": "sia-ai/llama-2-7b-1-percent-open-orca-1000-steps-v0",
    "link": "https://huggingface.co/sia-ai/llama-2-7b-1-percent-open-orca-1000-steps-v0",
    "author": "sia-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "perry-7b",
    "average": 49.55,
    "arc": 51.79,
    "hellaswag": 76.43,
    "mmlu": 46.18,
    "truthfulqa": 40.08,
    "winogrande": 72.53,
    "gsm8k": 10.31,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f35ae37b436637cd3e14d086324ccdaccfd69045",
    "model_name_for_query": "dotvignesh/perry-7b",
    "link": "https://huggingface.co/dotvignesh/perry-7b",
    "author": "dotvignesh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "13B-Ouroboros",
    "average": 49.54,
    "arc": 57.42,
    "hellaswag": 82.11,
    "mmlu": 51.43,
    "truthfulqa": 47.99,
    "winogrande": 57.85,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "97981254d4b0ac0d1472376f602c004670070fdd",
    "model_name_for_query": "CalderaAI/13B-Ouroboros",
    "link": "https://huggingface.co/CalderaAI/13B-Ouroboros",
    "author": "CalderaAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-7b-gpt4-1.4.1",
    "average": 49.54,
    "arc": 55.12,
    "hellaswag": 79.6,
    "mmlu": 45.17,
    "truthfulqa": 40.29,
    "winogrande": 74.27,
    "gsm8k": 2.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "77bdd1f049f27876c38b68782fc240518208f391",
    "model_name_for_query": "jondurbin/airoboros-l2-7b-gpt4-1.4.1",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-gpt4-1.4.1",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-ko-7B-model",
    "average": 49.52,
    "arc": 56.31,
    "hellaswag": 79.51,
    "mmlu": 45.71,
    "truthfulqa": 40.98,
    "winogrande": 72.06,
    "gsm8k": 2.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.67,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "03d23910fa0f9b0542ce7634cbcd36983321f55a",
    "model_name_for_query": "jb723/llama2-ko-7B-model",
    "link": "https://huggingface.co/jb723/llama2-ko-7B-model",
    "author": "jb723"
  },
  {
    "T": "\ud83d\udd36",
    "model": "instruct-13b",
    "average": 49.52,
    "arc": 56.14,
    "hellaswag": 80.27,
    "mmlu": 47.89,
    "truthfulqa": 36.97,
    "winogrande": 73.56,
    "gsm8k": 2.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "agpl-3.0",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "142e198df473fd0cd4370b0d50be5f57e1da399b",
    "model_name_for_query": "llama-anon/instruct-13b",
    "link": "https://huggingface.co/llama-anon/instruct-13b",
    "author": "llama-anon"
  },
  {
    "T": "?",
    "model": "QuantumLM-7B",
    "average": 49.51,
    "arc": 50.26,
    "hellaswag": 76.1,
    "mmlu": 45.27,
    "truthfulqa": 46.25,
    "winogrande": 71.51,
    "gsm8k": 7.66,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f44998432fb90d88094ddf42e57ec458877a197f",
    "model_name_for_query": "quantumaikr/QuantumLM-7B",
    "link": "https://huggingface.co/quantumaikr/QuantumLM-7B",
    "author": "quantumaikr"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "tamil-llama-13b-base-v0.1",
    "average": 49.5,
    "arc": 52.82,
    "hellaswag": 79.95,
    "mmlu": 52.05,
    "truthfulqa": 36.56,
    "winogrande": 75.61,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6cbdb6b6088910459cd104b1752177ab52e7f892",
    "model_name_for_query": "abhinand/tamil-llama-13b-base-v0.1",
    "link": "https://huggingface.co/abhinand/tamil-llama-13b-base-v0.1",
    "author": "abhinand"
  },
  {
    "T": "?",
    "model": "Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
    "average": 49.47,
    "arc": 52.82,
    "hellaswag": 79.63,
    "mmlu": 39.83,
    "truthfulqa": 52.55,
    "winogrande": 71.82,
    "gsm8k": 0.15,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "bd3c66e626c81de4977f197e1534bd3dfa2f569d",
    "model_name_for_query": "TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
    "link": "https://huggingface.co/TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Guanaco-7B-Uncensored",
    "average": 49.35,
    "arc": 52.13,
    "hellaswag": 78.77,
    "mmlu": 43.42,
    "truthfulqa": 44.45,
    "winogrande": 73.09,
    "gsm8k": 4.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "db068e363e66e5d4b131e1d7a42a3a849e406a9b",
    "model_name_for_query": "Fredithefish/Guanaco-7B-Uncensored",
    "link": "https://huggingface.co/Fredithefish/Guanaco-7B-Uncensored",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-mathgpt-v4",
    "average": 49.35,
    "arc": 50.94,
    "hellaswag": 75.56,
    "mmlu": 43.78,
    "truthfulqa": 41.96,
    "winogrande": 69.14,
    "gsm8k": 14.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c5072a762070c6b3756385c63805348c155004b5",
    "model_name_for_query": "rameshm/llama-2-13b-mathgpt-v4",
    "link": "https://huggingface.co/rameshm/llama-2-13b-mathgpt-v4",
    "author": "rameshm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-openllama-13b-v7-fp16",
    "average": 49.31,
    "arc": 47.61,
    "hellaswag": 72.24,
    "mmlu": 47.74,
    "truthfulqa": 48.73,
    "winogrande": 69.69,
    "gsm8k": 9.86,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.89,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "8690c065bccd3e897ccbf3d8aa24b0216a6f5dba",
    "model_name_for_query": "OpenBuddy/openbuddy-openllama-13b-v7-fp16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-openllama-13b-v7-fp16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-int4-python-code-18k",
    "average": 49.3,
    "arc": 52.13,
    "hellaswag": 78.55,
    "mmlu": 46.25,
    "truthfulqa": 37.69,
    "winogrande": 74.98,
    "gsm8k": 6.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aed968a4b3f3b716064eb8b50c5ae24b38007627",
    "model_name_for_query": "qualis2006/llama-2-7b-int4-python-code-18k",
    "link": "https://huggingface.co/qualis2006/llama-2-7b-int4-python-code-18k",
    "author": "qualis2006"
  },
  {
    "T": "\u2b55",
    "model": "leo-hessianai-7b-chat",
    "average": 49.29,
    "arc": 52.56,
    "hellaswag": 77.61,
    "mmlu": 45.58,
    "truthfulqa": 44.89,
    "winogrande": 69.93,
    "gsm8k": 5.16,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "7c343a501f5cd3b768d2f78d9941b760fd66815d",
    "model_name_for_query": "LeoLM/leo-hessianai-7b-chat",
    "link": "https://huggingface.co/LeoLM/leo-hessianai-7b-chat",
    "author": "LeoLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-7b-chat",
    "average": 49.27,
    "arc": 52.47,
    "hellaswag": 78.35,
    "mmlu": 39.51,
    "truthfulqa": 44.52,
    "winogrande": 73.16,
    "gsm8k": 7.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "9af636df9c8693ea857b62442bd1c6c73d657dc6",
    "model_name_for_query": "bofenghuang/vigogne-7b-chat",
    "link": "https://huggingface.co/bofenghuang/vigogne-7b-chat",
    "author": "bofenghuang"
  },
  {
    "T": "\u2b55",
    "model": "LIMA2-7b-hf",
    "average": 49.27,
    "arc": 53.24,
    "hellaswag": 80.6,
    "mmlu": 43.22,
    "truthfulqa": 44.74,
    "winogrande": 69.93,
    "gsm8k": 3.87,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6a1aa59cb7624f059728840ce68b20b1070ebdcb",
    "model_name_for_query": "heegyu/LIMA2-7b-hf",
    "link": "https://huggingface.co/heegyu/LIMA2-7b-hf",
    "author": "heegyu"
  },
  {
    "T": "?",
    "model": "Pygmalion-Vicuna-1.1-7b",
    "average": 49.25,
    "arc": 52.82,
    "hellaswag": 78.66,
    "mmlu": 43.61,
    "truthfulqa": 42.21,
    "winogrande": 71.98,
    "gsm8k": 6.22,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "bdac596568769d1ba4af8df9a611eee9723adf29",
    "model_name_for_query": "TehVenom/Pygmalion-Vicuna-1.1-7b",
    "link": "https://huggingface.co/TehVenom/Pygmalion-Vicuna-1.1-7b",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
    "average": 49.22,
    "arc": 53.41,
    "hellaswag": 77.9,
    "mmlu": 43.56,
    "truthfulqa": 40.81,
    "winogrande": 74.59,
    "gsm8k": 5.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6ca41503b383c654aee8d5496e70fbdfaa33db10",
    "model_name_for_query": "dhmeltzer/llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\u2b55",
    "model": "llama-v2-7b-32kC-Security",
    "average": 49.19,
    "arc": 49.83,
    "hellaswag": 77.33,
    "mmlu": 44.41,
    "truthfulqa": 47.96,
    "winogrande": 71.74,
    "gsm8k": 3.87,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 5.0,
    "still_on_hub": false,
    "revision": "0ae2abdc539a79ad84b141f894d614adf3754882",
    "model_name_for_query": "venkycs/llama-v2-7b-32kC-Security",
    "link": "https://huggingface.co/venkycs/llama-v2-7b-32kC-Security",
    "author": "venkycs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama_7b_sharegpt94k_fastchat",
    "average": 49.19,
    "arc": 53.24,
    "hellaswag": 76.94,
    "mmlu": 44.64,
    "truthfulqa": 45.34,
    "winogrande": 70.64,
    "gsm8k": 4.32,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "2d82abff150b7a5ae484f9cd7c64c72fd4eaf7f5",
    "model_name_for_query": "wahaha1987/llama_7b_sharegpt94k_fastchat",
    "link": "https://huggingface.co/wahaha1987/llama_7b_sharegpt94k_fastchat",
    "author": "wahaha1987"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-RetroRodeo-13b",
    "average": 49.15,
    "arc": 53.84,
    "hellaswag": 79.63,
    "mmlu": 48.93,
    "truthfulqa": 38.73,
    "winogrande": 73.8,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "102f9fdad903f5eaffe1ed8173ae56081072e429",
    "model_name_for_query": "PocketDoc/Dans-RetroRodeo-13b",
    "link": "https://huggingface.co/PocketDoc/Dans-RetroRodeo-13b",
    "author": "PocketDoc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7B-physics",
    "average": 49.15,
    "arc": 49.49,
    "hellaswag": 75.88,
    "mmlu": 46.58,
    "truthfulqa": 49.31,
    "winogrande": 69.38,
    "gsm8k": 4.25,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2147983e9493347c3424c07403f65e7a81c0b19f",
    "model_name_for_query": "FelixChao/vicuna-7B-physics",
    "link": "https://huggingface.co/FelixChao/vicuna-7B-physics",
    "author": "FelixChao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ELYZA-japanese-Llama-2-7b-fast-instruct",
    "average": 49.15,
    "arc": 53.75,
    "hellaswag": 77.55,
    "mmlu": 46.85,
    "truthfulqa": 38.84,
    "winogrande": 71.59,
    "gsm8k": 6.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.66,
    "likes": 42.0,
    "still_on_hub": true,
    "revision": "89de33d1ad568855853196802aeaecd799c6586f",
    "model_name_for_query": "elyza/ELYZA-japanese-Llama-2-7b-fast-instruct",
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-fast-instruct",
    "author": "elyza"
  },
  {
    "T": "\ud83d\udd36",
    "model": "scarlett-7b",
    "average": 49.09,
    "arc": 57.17,
    "hellaswag": 80.27,
    "mmlu": 36.11,
    "truthfulqa": 48.52,
    "winogrande": 72.14,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "0715b738e750830ba7213f26fe32fa1cc1bb15b3",
    "model_name_for_query": "ajibawa-2023/scarlett-7b",
    "link": "https://huggingface.co/ajibawa-2023/scarlett-7b",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_7b_code",
    "average": 49.05,
    "arc": 52.13,
    "hellaswag": 75.71,
    "mmlu": 48.05,
    "truthfulqa": 38.76,
    "winogrande": 71.51,
    "gsm8k": 8.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "0e6d1edd87c8753b55d280179c8fb0e65ebf5fa2",
    "model_name_for_query": "itsliupeng/llama2_7b_code",
    "link": "https://huggingface.co/itsliupeng/llama2_7b_code",
    "author": "itsliupeng"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Baichuan2-7B-Base-LLaMAfied",
    "average": 48.99,
    "arc": 49.57,
    "hellaswag": 73.45,
    "mmlu": 54.86,
    "truthfulqa": 37.54,
    "winogrande": 70.72,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.99,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "dc5bda435771212fc73a8c6556fbdf4fcd87f96d",
    "model_name_for_query": "hiyouga/Baichuan2-7B-Base-LLaMAfied",
    "link": "https://huggingface.co/hiyouga/Baichuan2-7B-Base-LLaMAfied",
    "author": "hiyouga"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-mmlu-val-only-correct-mcq-7b-ep2",
    "average": 48.96,
    "arc": 52.99,
    "hellaswag": 77.67,
    "mmlu": 47.92,
    "truthfulqa": 43.17,
    "winogrande": 71.9,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f0606bca9bea0afdd1dd8c26f0664b65f4dc5967",
    "model_name_for_query": "luffycodes/vicuna-mmlu-val-only-correct-mcq-7b-ep2",
    "link": "https://huggingface.co/luffycodes/vicuna-mmlu-val-only-correct-mcq-7b-ep2",
    "author": "luffycodes"
  },
  {
    "T": "\u2b55",
    "model": "tora-code-34b-v1.0",
    "average": 48.95,
    "arc": 50.43,
    "hellaswag": 75.54,
    "mmlu": 46.78,
    "truthfulqa": 39.66,
    "winogrande": 68.19,
    "gsm8k": 13.12,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "cbb33eea774cc03d4363c424d81e8c9d58332274",
    "model_name_for_query": "llm-agents/tora-code-34b-v1.0",
    "link": "https://huggingface.co/llm-agents/tora-code-34b-v1.0",
    "author": "llm-agents"
  },
  {
    "T": "\u2b55",
    "model": "mistral-megamerge-dare-7b",
    "average": 48.93,
    "arc": 55.29,
    "hellaswag": 70.48,
    "mmlu": 43.05,
    "truthfulqa": 51.08,
    "winogrande": 67.09,
    "gsm8k": 6.6,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f116230ee12e55d1716b89e1b114dd2ee3d397bd",
    "model_name_for_query": "martyn/mistral-megamerge-dare-7b",
    "link": "https://huggingface.co/martyn/mistral-megamerge-dare-7b",
    "author": "martyn"
  },
  {
    "T": "?",
    "model": "Llama-2-7b-hf",
    "average": 48.93,
    "arc": 53.07,
    "hellaswag": 77.74,
    "mmlu": 43.8,
    "truthfulqa": 38.98,
    "winogrande": 74.59,
    "gsm8k": 5.38,
    "model_type": "",
    "architecture": "?",
    "precision": "4bit",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9",
    "model_name_for_query": "meta-llama/Llama-2-7b-hf",
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-hf",
    "author": "meta-llama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MedicWizard-7B",
    "average": 48.88,
    "arc": 53.5,
    "hellaswag": 78.39,
    "mmlu": 44.61,
    "truthfulqa": 41.32,
    "winogrande": 70.56,
    "gsm8k": 4.93,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "0b3ef975fb5e8ac1eae775160ab54c98221889df",
    "model_name_for_query": "xzuyn/MedicWizard-7B",
    "link": "https://huggingface.co/xzuyn/MedicWizard-7B",
    "author": "xzuyn"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chinese-alpaca-2-7b",
    "average": 48.85,
    "arc": 49.57,
    "hellaswag": 72.62,
    "mmlu": 46.5,
    "truthfulqa": 48.63,
    "winogrande": 70.01,
    "gsm8k": 5.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.7,
    "likes": 93.0,
    "still_on_hub": true,
    "revision": "ab2476bffedeed752daedd77e71900578e136e7c",
    "model_name_for_query": "ziqingyang/chinese-alpaca-2-7b",
    "link": "https://huggingface.co/ziqingyang/chinese-alpaca-2-7b",
    "author": "ziqingyang"
  },
  {
    "T": "?",
    "model": "opencoderplus",
    "average": 48.84,
    "arc": 50.6,
    "hellaswag": 78.22,
    "mmlu": 42.73,
    "truthfulqa": 50.72,
    "winogrande": 66.14,
    "gsm8k": 4.62,
    "model_type": "",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 15.52,
    "likes": 100.0,
    "still_on_hub": true,
    "revision": "845e9e4452dd4440760b3d5f680400fc014e91b5",
    "model_name_for_query": "openchat/opencoderplus",
    "link": "https://huggingface.co/openchat/opencoderplus",
    "author": "openchat"
  },
  {
    "T": "\u2b55",
    "model": "llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
    "average": 48.82,
    "arc": 54.35,
    "hellaswag": 78.06,
    "mmlu": 45.35,
    "truthfulqa": 37.11,
    "winogrande": 73.4,
    "gsm8k": 4.62,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "684c4f4612fadae47c2c7db9fe9e9be4aaafc7e2",
    "model_name_for_query": "dhmeltzer/llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-chat-hf-v3",
    "average": 48.81,
    "arc": 52.22,
    "hellaswag": 76.78,
    "mmlu": 45.89,
    "truthfulqa": 38.38,
    "winogrande": 73.4,
    "gsm8k": 6.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a5269bc93a7f98e192e34553cec1302877ca4327",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-class-shishya-all-hal-7b-ep3",
    "average": 48.75,
    "arc": 45.48,
    "hellaswag": 77.21,
    "mmlu": 51.54,
    "truthfulqa": 44.83,
    "winogrande": 71.03,
    "gsm8k": 2.43,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5a1424eb777c8a3ce94ab31486510da8f617d17e",
    "model_name_for_query": "luffycodes/vicuna-class-shishya-all-hal-7b-ep3",
    "link": "https://huggingface.co/luffycodes/vicuna-class-shishya-all-hal-7b-ep3",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.3-instruct-pl-lora_unload",
    "average": 48.74,
    "arc": 48.04,
    "hellaswag": 76.28,
    "mmlu": 47.42,
    "truthfulqa": 44.4,
    "winogrande": 70.09,
    "gsm8k": 6.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e4b19d9d6168b32402da4ab2b5ec7ff27cf40d9b",
    "model_name_for_query": "Aspik101/vicuna-7b-v1.3-instruct-pl-lora_unload",
    "link": "https://huggingface.co/Aspik101/vicuna-7b-v1.3-instruct-pl-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\u2b55",
    "model": "leo-hessianai-7b-chat-bilingual",
    "average": 48.72,
    "arc": 51.02,
    "hellaswag": 76.03,
    "mmlu": 44.68,
    "truthfulqa": 47.16,
    "winogrande": 70.72,
    "gsm8k": 2.73,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "5ee98fd03b310e3081f0c9986c5153b27ec5dce6",
    "model_name_for_query": "LeoLM/leo-hessianai-7b-chat-bilingual",
    "link": "https://huggingface.co/LeoLM/leo-hessianai-7b-chat-bilingual",
    "author": "LeoLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GOAT-7B-Community",
    "average": 48.71,
    "arc": 48.81,
    "hellaswag": 74.63,
    "mmlu": 49.58,
    "truthfulqa": 42.48,
    "winogrande": 72.3,
    "gsm8k": 4.47,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 34.0,
    "still_on_hub": true,
    "revision": "a7073a0f5142ce04aaa1603b0812b358f62a8de8",
    "model_name_for_query": "GOAT-AI/GOAT-7B-Community",
    "link": "https://huggingface.co/GOAT-AI/GOAT-7B-Community",
    "author": "GOAT-AI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ELYZA-japanese-Llama-2-7b",
    "average": 48.7,
    "arc": 52.22,
    "hellaswag": 76.42,
    "mmlu": 44.6,
    "truthfulqa": 37.92,
    "winogrande": 72.69,
    "gsm8k": 8.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "976887c5891284db204320860bb84b71d598063e",
    "model_name_for_query": "elyza/ELYZA-japanese-Llama-2-7b",
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b",
    "author": "elyza"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2-7b-chat-hf-v3",
    "average": 48.65,
    "arc": 51.96,
    "hellaswag": 76.7,
    "mmlu": 45.36,
    "truthfulqa": 38.31,
    "winogrande": 73.56,
    "gsm8k": 5.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a5269bc93a7f98e192e34553cec1302877ca4327",
    "model_name_for_query": "TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dans-CreepingSenseOfDoom",
    "average": 48.58,
    "arc": 53.33,
    "hellaswag": 78.9,
    "mmlu": 48.09,
    "truthfulqa": 37.84,
    "winogrande": 73.32,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "efc7cbc5d0461c137e8ea0c83e54bc5357188783",
    "model_name_for_query": "PocketDoc/Dans-CreepingSenseOfDoom",
    "link": "https://huggingface.co/PocketDoc/Dans-CreepingSenseOfDoom",
    "author": "PocketDoc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b-gpt4-1.1",
    "average": 48.57,
    "arc": 54.61,
    "hellaswag": 80.15,
    "mmlu": 39.25,
    "truthfulqa": 41.22,
    "winogrande": 73.09,
    "gsm8k": 3.11,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "5a45a16bac51ed9529a6dc2eab7355cc61eefb5b",
    "model_name_for_query": "jondurbin/airoboros-7b-gpt4-1.1",
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.1",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "youri-7b-chat",
    "average": 48.51,
    "arc": 51.19,
    "hellaswag": 76.09,
    "mmlu": 46.06,
    "truthfulqa": 41.17,
    "winogrande": 75.06,
    "gsm8k": 1.52,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "96d1690c4a1fa192ab26c4be8f9c79e1faed8346",
    "model_name_for_query": "rinna/youri-7b-chat",
    "link": "https://huggingface.co/rinna/youri-7b-chat",
    "author": "rinna"
  },
  {
    "T": "\u2b55",
    "model": "tora-7b-v1.0",
    "average": 48.5,
    "arc": 52.47,
    "hellaswag": 78.68,
    "mmlu": 45.9,
    "truthfulqa": 37.9,
    "winogrande": 73.56,
    "gsm8k": 2.5,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "717edbee98945192b1a396fc9c337c5b32d6c79c",
    "model_name_for_query": "llm-agents/tora-7b-v1.0",
    "link": "https://huggingface.co/llm-agents/tora-7b-v1.0",
    "author": "llm-agents"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pygmalion-13b-Merged",
    "average": 48.49,
    "arc": 56.48,
    "hellaswag": 80.02,
    "mmlu": 42.93,
    "truthfulqa": 35.86,
    "winogrande": 75.53,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "f96308083033c84db47b6c093da3817c085c87c7",
    "model_name_for_query": "TehVenom/Pygmalion-13b-Merged",
    "link": "https://huggingface.co/TehVenom/Pygmalion-13b-Merged",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Llama-2-7B-GPTQ",
    "average": 48.48,
    "arc": 52.05,
    "hellaswag": 77.59,
    "mmlu": 43.99,
    "truthfulqa": 39.32,
    "winogrande": 72.93,
    "gsm8k": 5.0,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "GPTQ",
    "license": "llama2",
    "params": 9.05,
    "likes": 58.0,
    "still_on_hub": true,
    "revision": "ecd7ab9f6adc36ecbe0d751eeea0d90ae1863c3b",
    "model_name_for_query": "TheBloke/Llama-2-7B-GPTQ",
    "link": "https://huggingface.co/TheBloke/Llama-2-7B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-Uncensored",
    "average": 48.48,
    "arc": 50.94,
    "hellaswag": 76.64,
    "mmlu": 43.96,
    "truthfulqa": 46.73,
    "winogrande": 70.56,
    "gsm8k": 2.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 433.0,
    "still_on_hub": true,
    "revision": "9025c5f96fef9525da9238369ad082961b0e9494",
    "model_name_for_query": "ehartford/WizardLM-13B-Uncensored",
    "link": "https://huggingface.co/ehartford/WizardLM-13B-Uncensored",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "medalpaca-7b",
    "average": 48.45,
    "arc": 54.1,
    "hellaswag": 80.42,
    "mmlu": 41.47,
    "truthfulqa": 40.46,
    "winogrande": 71.19,
    "gsm8k": 3.03,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc",
    "params": 6.61,
    "likes": 30.0,
    "still_on_hub": true,
    "revision": "b57b9f5ff34059e485b769973d023021fc66a8f7",
    "model_name_for_query": "medalpaca/medalpaca-7b",
    "link": "https://huggingface.co/medalpaca/medalpaca-7b",
    "author": "medalpaca"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7B-chemical",
    "average": 48.42,
    "arc": 49.83,
    "hellaswag": 74.42,
    "mmlu": 44.1,
    "truthfulqa": 51.7,
    "winogrande": 67.17,
    "gsm8k": 3.34,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fbf6476ebfa856ffe743e41f8d4413c15b2127c9",
    "model_name_for_query": "FelixChao/vicuna-7B-chemical",
    "link": "https://huggingface.co/FelixChao/vicuna-7B-chemical",
    "author": "FelixChao"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b-gpt4-1.4",
    "average": 48.4,
    "arc": 53.92,
    "hellaswag": 80.33,
    "mmlu": 38.61,
    "truthfulqa": 41.05,
    "winogrande": 72.77,
    "gsm8k": 3.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "cae1ab8991f66bbe66ae95ed23a87846e7343047",
    "model_name_for_query": "jondurbin/airoboros-7b-gpt4-1.4",
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.4",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-7b-gpt4-2.0",
    "average": 48.38,
    "arc": 52.9,
    "hellaswag": 78.53,
    "mmlu": 45.09,
    "truthfulqa": 39.45,
    "winogrande": 71.11,
    "gsm8k": 3.18,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "8432fe95c426ca7709cf2d31a64eee612c4dea42",
    "model_name_for_query": "jondurbin/airoboros-l2-7b-gpt4-2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-gpt4-2.0",
    "author": "jondurbin"
  },
  {
    "T": "?",
    "model": "pygmalion-instruct",
    "average": 48.37,
    "arc": 52.56,
    "hellaswag": 77.65,
    "mmlu": 35.94,
    "truthfulqa": 42.13,
    "winogrande": 72.06,
    "gsm8k": 9.86,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 6.74,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "1665b271316dfee05b2a8daf8b9d6c22ed0aef60",
    "model_name_for_query": "AlpinDale/pygmalion-instruct",
    "link": "https://huggingface.co/AlpinDale/pygmalion-instruct",
    "author": "AlpinDale"
  },
  {
    "T": "\ud83d\udd36",
    "model": "AlpacaGPT4-7B-elina",
    "average": 48.35,
    "arc": 55.03,
    "hellaswag": 78.79,
    "mmlu": 37.5,
    "truthfulqa": 41.53,
    "winogrande": 72.69,
    "gsm8k": 4.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "bbece5e3f8ee9be09c8defc536a95c6ef780c681",
    "model_name_for_query": "LLMs/AlpacaGPT4-7B-elina",
    "link": "https://huggingface.co/LLMs/AlpacaGPT4-7B-elina",
    "author": "LLMs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13b-OpenAssistant-Uncensored",
    "average": 48.32,
    "arc": 48.55,
    "hellaswag": 76.03,
    "mmlu": 43.15,
    "truthfulqa": 49.4,
    "winogrande": 69.77,
    "gsm8k": 3.03,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "ff8e15fd68119d36ae1f0cebaa87f16e2ad3c732",
    "model_name_for_query": "Monero/WizardLM-13b-OpenAssistant-Uncensored",
    "link": "https://huggingface.co/Monero/WizardLM-13b-OpenAssistant-Uncensored",
    "author": "Monero"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mist_LLaMA-2-7B-1024_V3",
    "average": 48.31,
    "arc": 51.37,
    "hellaswag": 77.74,
    "mmlu": 41.34,
    "truthfulqa": 41.21,
    "winogrande": 73.32,
    "gsm8k": 4.85,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "05ec8f4a568777e1e543acdf8a587e080fb18fba",
    "model_name_for_query": "Juniplayground/Mist_LLaMA-2-7B-1024_V3",
    "link": "https://huggingface.co/Juniplayground/Mist_LLaMA-2-7B-1024_V3",
    "author": "Juniplayground"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Wizard-Vicuna-7B-Uncensored-HF",
    "average": 48.27,
    "arc": 53.41,
    "hellaswag": 78.85,
    "mmlu": 37.09,
    "truthfulqa": 43.48,
    "winogrande": 72.22,
    "gsm8k": 4.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "b802f1b4401d0b2242137160c20cc11b9ffd3a4c",
    "model_name_for_query": "TheBloke/Wizard-Vicuna-7B-Uncensored-HF",
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Wizard-Vicuna-7B-Uncensored",
    "average": 48.27,
    "arc": 53.41,
    "hellaswag": 78.85,
    "mmlu": 37.09,
    "truthfulqa": 43.48,
    "winogrande": 72.22,
    "gsm8k": 4.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 63.0,
    "still_on_hub": true,
    "revision": "1097285acd9c48a1d09bc0a9844d365384732111",
    "model_name_for_query": "ehartford/Wizard-Vicuna-7B-Uncensored",
    "link": "https://huggingface.co/ehartford/Wizard-Vicuna-7B-Uncensored",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "NexusRaven-V2-13B",
    "average": 48.21,
    "arc": 45.14,
    "hellaswag": 67.4,
    "mmlu": 44.88,
    "truthfulqa": 44.54,
    "winogrande": 66.38,
    "gsm8k": 20.92,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 13.0,
    "likes": 180.0,
    "still_on_hub": true,
    "revision": "3bec1dcc7cb6f1895a923e66d87438e903bebb57",
    "model_name_for_query": "Nexusflow/NexusRaven-V2-13B",
    "link": "https://huggingface.co/Nexusflow/NexusRaven-V2-13B",
    "author": "Nexusflow"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-mctaco",
    "average": 48.02,
    "arc": 45.65,
    "hellaswag": 75.65,
    "mmlu": 49.27,
    "truthfulqa": 43.12,
    "winogrande": 69.93,
    "gsm8k": 4.47,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "883b0fa4158de8207d0a94f4b8cb188e6250aa9d",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-mctaco",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenLlama13B-Guanaco",
    "average": 47.99,
    "arc": 51.19,
    "hellaswag": 75.24,
    "mmlu": 43.76,
    "truthfulqa": 38.4,
    "winogrande": 71.74,
    "gsm8k": 7.58,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "42ed3023ae1afe861f533570be881a03b10fc860",
    "model_name_for_query": "titan087/OpenLlama13B-Guanaco",
    "link": "https://huggingface.co/titan087/OpenLlama13B-Guanaco",
    "author": "titan087"
  },
  {
    "T": "\ud83d\udd36",
    "model": "longchat-7b-v1.5-32k",
    "average": 47.95,
    "arc": 51.71,
    "hellaswag": 74.97,
    "mmlu": 43.16,
    "truthfulqa": 44.42,
    "winogrande": 68.67,
    "gsm8k": 4.78,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 44.0,
    "still_on_hub": true,
    "revision": "16deb633ef4d6a18d5750239edc5a85ffeaf3918",
    "model_name_for_query": "lmsys/longchat-7b-v1.5-32k",
    "link": "https://huggingface.co/lmsys/longchat-7b-v1.5-32k",
    "author": "lmsys"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-l2-7b-gpt4-m2.0",
    "average": 47.95,
    "arc": 50.51,
    "hellaswag": 76.87,
    "mmlu": 45.35,
    "truthfulqa": 41.34,
    "winogrande": 69.53,
    "gsm8k": 4.09,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "67729407add902e3d4d36bb105d7c011fb368ea5",
    "model_name_for_query": "jondurbin/airoboros-l2-7b-gpt4-m2.0",
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-gpt4-m2.0",
    "author": "jondurbin"
  },
  {
    "T": "\u2b55",
    "model": "Stable-Vicuna-13B",
    "average": 47.95,
    "arc": 53.41,
    "hellaswag": 78.57,
    "mmlu": 50.37,
    "truthfulqa": 48.36,
    "winogrande": 56.99,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 12.85,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "51f3d9eaa71de287c96195abd0ff954839857b19",
    "model_name_for_query": "LLMs/Stable-Vicuna-13B",
    "link": "https://huggingface.co/LLMs/Stable-Vicuna-13B",
    "author": "LLMs"
  },
  {
    "T": "?",
    "model": "tigerbot-7b-base",
    "average": 47.93,
    "arc": 47.7,
    "hellaswag": 72.08,
    "mmlu": 45.11,
    "truthfulqa": 42.27,
    "winogrande": 69.61,
    "gsm8k": 10.84,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.73,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "300831494aa1eb16e59799310a09531f60dcc904",
    "model_name_for_query": "TigerResearch/tigerbot-7b-base",
    "link": "https://huggingface.co/TigerResearch/tigerbot-7b-base",
    "author": "TigerResearch"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "openllama-7b-icl",
    "average": 47.93,
    "arc": 47.95,
    "hellaswag": 77.04,
    "mmlu": 44.37,
    "truthfulqa": 37.06,
    "winogrande": 70.17,
    "gsm8k": 10.99,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d6317fed3b190cc4d4c27b9f27ccf7c77f0b2e3b",
    "model_name_for_query": "itsliupeng/openllama-7b-icl",
    "link": "https://huggingface.co/itsliupeng/openllama-7b-icl",
    "author": "itsliupeng"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-7b-chat-hf-phr_mental_health-2048",
    "average": 47.92,
    "arc": 52.39,
    "hellaswag": 75.39,
    "mmlu": 39.77,
    "truthfulqa": 42.89,
    "winogrande": 71.19,
    "gsm8k": 5.91,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "81d424a431ab7fa4ff725925b6d0e4269d4563e4",
    "model_name_for_query": "vibhorag101/llama-2-7b-chat-hf-phr_mental_health-2048",
    "link": "https://huggingface.co/vibhorag101/llama-2-7b-chat-hf-phr_mental_health-2048",
    "author": "vibhorag101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama_7b_qlora_pds-eval",
    "average": 47.9,
    "arc": 53.92,
    "hellaswag": 78.13,
    "mmlu": 32.98,
    "truthfulqa": 45.6,
    "winogrande": 72.61,
    "gsm8k": 4.17,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "d20419e1d9e9a6a59ced3edf5169e8e7b3e8394c",
    "model_name_for_query": "DevaMalla/llama_7b_qlora_pds-eval",
    "link": "https://huggingface.co/DevaMalla/llama_7b_qlora_pds-eval",
    "author": "DevaMalla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Uncensored-Frank-7B",
    "average": 47.9,
    "arc": 54.27,
    "hellaswag": 76.52,
    "mmlu": 37.5,
    "truthfulqa": 43.86,
    "winogrande": 70.24,
    "gsm8k": 5.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "65bbcb80158a6d2e133bba99a90142caf4e2e242",
    "model_name_for_query": "ajibawa-2023/Uncensored-Frank-7B",
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Frank-7B",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-class-shishya-ac-hal-7b-ep3",
    "average": 47.89,
    "arc": 44.62,
    "hellaswag": 76.98,
    "mmlu": 50.96,
    "truthfulqa": 43.03,
    "winogrande": 71.74,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a76df6b71b959745a5f1804791071332ee6522ba",
    "model_name_for_query": "luffycodes/vicuna-class-shishya-ac-hal-7b-ep3",
    "link": "https://huggingface.co/luffycodes/vicuna-class-shishya-ac-hal-7b-ep3",
    "author": "luffycodes"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-chat-hf-flan2022-1.2M",
    "average": 47.89,
    "arc": 49.57,
    "hellaswag": 76.25,
    "mmlu": 45.99,
    "truthfulqa": 42.17,
    "winogrande": 71.82,
    "gsm8k": 1.52,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "825506858e4603745a479215b8dea1524bfab6a0",
    "model_name_for_query": "synapsoft/Llama-2-7b-chat-hf-flan2022-1.2M",
    "link": "https://huggingface.co/synapsoft/Llama-2-7b-chat-hf-flan2022-1.2M",
    "author": "synapsoft"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ALMA-7B-Ja-V2",
    "average": 47.85,
    "arc": 52.39,
    "hellaswag": 77.92,
    "mmlu": 44.72,
    "truthfulqa": 38.66,
    "winogrande": 73.4,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "c2497586b28f419ad12c734600d08b2a5784ddc1",
    "model_name_for_query": "webbigdata/ALMA-7B-Ja-V2",
    "link": "https://huggingface.co/webbigdata/ALMA-7B-Ja-V2",
    "author": "webbigdata"
  },
  {
    "T": "\ud83d\udd36",
    "model": "goims",
    "average": 47.8,
    "arc": 49.49,
    "hellaswag": 72.67,
    "mmlu": 43.85,
    "truthfulqa": 44.8,
    "winogrande": 69.69,
    "gsm8k": 6.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.76,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9ef1045ca31f670d9cbf820af904b33a097cd787",
    "model_name_for_query": "golaxy/goims",
    "link": "https://huggingface.co/golaxy/goims",
    "author": "golaxy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-7b-8k-chat",
    "average": 47.78,
    "arc": 48.04,
    "hellaswag": 77.62,
    "mmlu": 41.88,
    "truthfulqa": 43.68,
    "winogrande": 71.03,
    "gsm8k": 4.4,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 6.65,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "ef97b878a279cd1765fbed7b8321fb3cff1aa5b5",
    "model_name_for_query": "mosaicml/mpt-7b-8k-chat",
    "link": "https://huggingface.co/mosaicml/mpt-7b-8k-chat",
    "author": "mosaicml"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vigogne-7b-instruct",
    "average": 47.76,
    "arc": 51.96,
    "hellaswag": 78.11,
    "mmlu": 38.43,
    "truthfulqa": 42.47,
    "winogrande": 72.85,
    "gsm8k": 2.73,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 6.61,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "c6e2f515a0b289478118b5b75ff74107002ad962",
    "model_name_for_query": "bofenghuang/vigogne-7b-instruct",
    "link": "https://huggingface.co/bofenghuang/vigogne-7b-instruct",
    "author": "bofenghuang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "KoreanLM-hf",
    "average": 47.73,
    "arc": 51.45,
    "hellaswag": 76.77,
    "mmlu": 40.61,
    "truthfulqa": 44.34,
    "winogrande": 69.77,
    "gsm8k": 3.41,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "a7261e7ae6ee76c78e1ba1ac8c59bcc3e0868bf9",
    "model_name_for_query": "quantumaikr/KoreanLM-hf",
    "link": "https://huggingface.co/quantumaikr/KoreanLM-hf",
    "author": "quantumaikr"
  },
  {
    "T": "\ud83d\udd36",
    "model": "leo-hessianai-7b",
    "average": 47.72,
    "arc": 51.96,
    "hellaswag": 75.84,
    "mmlu": 42.85,
    "truthfulqa": 37.94,
    "winogrande": 72.14,
    "gsm8k": 5.61,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "88c5ac07006ea8f1b5d10aa4f03f0d624dd27e56",
    "model_name_for_query": "LeoLM/leo-hessianai-7b",
    "link": "https://huggingface.co/LeoLM/leo-hessianai-7b",
    "author": "LeoLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b-gpt4",
    "average": 47.7,
    "arc": 53.07,
    "hellaswag": 78.69,
    "mmlu": 38.9,
    "truthfulqa": 40.72,
    "winogrande": 73.09,
    "gsm8k": 1.74,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "d9bcb0ad365bfacdf95128bc1272b4106aff7be9",
    "model_name_for_query": "jondurbin/airoboros-7b-gpt4",
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b-gpt4-fp16",
    "average": 47.7,
    "arc": 53.07,
    "hellaswag": 78.67,
    "mmlu": 38.88,
    "truthfulqa": 40.73,
    "winogrande": 73.09,
    "gsm8k": 1.74,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "14aa50fba9f6418c0d5e2d24087eb802931040ef",
    "model_name_for_query": "TheBloke/airoboros-7b-gpt4-fp16",
    "link": "https://huggingface.co/TheBloke/airoboros-7b-gpt4-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "phi-1_5",
    "average": 47.69,
    "arc": 52.9,
    "hellaswag": 63.79,
    "mmlu": 43.89,
    "truthfulqa": 40.89,
    "winogrande": 72.22,
    "gsm8k": 12.43,
    "model_type": "pretrained",
    "architecture": "MixFormerSequentialForCausalLM",
    "precision": "bfloat16",
    "license": "other",
    "params": 0.0,
    "likes": 916.0,
    "still_on_hub": true,
    "revision": "ea95720a352172db6fcbcd89032bfb1cb8481797",
    "model_name_for_query": "microsoft/phi-1_5",
    "link": "https://huggingface.co/microsoft/phi-1_5",
    "author": "microsoft"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ELYZA-japanese-Llama-2-7b-fast",
    "average": 47.67,
    "arc": 51.88,
    "hellaswag": 75.46,
    "mmlu": 44.34,
    "truthfulqa": 36.45,
    "winogrande": 71.59,
    "gsm8k": 6.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.66,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "e326078aa122fb1c4973997952d7b8630071776a",
    "model_name_for_query": "elyza/ELYZA-japanese-Llama-2-7b-fast",
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-fast",
    "author": "elyza"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_v2_ger_7b",
    "average": 47.65,
    "arc": 49.83,
    "hellaswag": 75.5,
    "mmlu": 39.1,
    "truthfulqa": 45.74,
    "winogrande": 71.59,
    "gsm8k": 4.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "175965f50907c6a8cd40f1a4b10d28342969c066",
    "model_name_for_query": "jphme/orca_mini_v2_ger_7b",
    "link": "https://huggingface.co/jphme/orca_mini_v2_ger_7b",
    "author": "jphme"
  },
  {
    "T": "\u2b55",
    "model": "openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
    "average": 47.65,
    "arc": 50.85,
    "hellaswag": 74.89,
    "mmlu": 40.02,
    "truthfulqa": 47.23,
    "winogrande": 69.06,
    "gsm8k": 3.87,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cdffb3488c5cb1a9aa5039a6b3bc72af24827db0",
    "model_name_for_query": "openthaigpt/openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
    "link": "https://huggingface.co/openthaigpt/openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
    "author": "openthaigpt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-chinese-replication-v1.1",
    "average": 47.65,
    "arc": 42.83,
    "hellaswag": 71.47,
    "mmlu": 47.47,
    "truthfulqa": 47.24,
    "winogrande": 67.4,
    "gsm8k": 9.48,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.94,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "259ab0967975012a546f2362d6cd03ab10768157",
    "model_name_for_query": "keyfan/vicuna-chinese-replication-v1.1",
    "link": "https://huggingface.co/keyfan/vicuna-chinese-replication-v1.1",
    "author": "keyfan"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gowizardlm",
    "average": 47.64,
    "arc": 49.74,
    "hellaswag": 71.9,
    "mmlu": 42.96,
    "truthfulqa": 47.66,
    "winogrande": 69.61,
    "gsm8k": 3.94,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.76,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "385f2d164e7fe780e053276d95d36240f2368c21",
    "model_name_for_query": "golaxy/gowizardlm",
    "link": "https://huggingface.co/golaxy/gowizardlm",
    "author": "golaxy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MiniMerlin-3B",
    "average": 47.63,
    "arc": 44.37,
    "hellaswag": 66.56,
    "mmlu": 43.21,
    "truthfulqa": 47.07,
    "winogrande": 64.4,
    "gsm8k": 20.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 3.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7fefc3d23e77c699aadba55c40d9e364eb73baf0",
    "model_name_for_query": "teilomillet/MiniMerlin-3B",
    "link": "https://huggingface.co/teilomillet/MiniMerlin-3B",
    "author": "teilomillet"
  },
  {
    "T": "\u2b55",
    "model": "baize-healthcare-lora-7B",
    "average": 47.62,
    "arc": 54.1,
    "hellaswag": 77.32,
    "mmlu": 37.09,
    "truthfulqa": 39.96,
    "winogrande": 72.85,
    "gsm8k": 4.4,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.0,
    "likes": 16.0,
    "still_on_hub": false,
    "revision": "e3eb8bb0d8840431afe24760d964f8ba57edd83e",
    "model_name_for_query": "project-baize/baize-healthcare-lora-7B",
    "link": "https://huggingface.co/project-baize/baize-healthcare-lora-7B",
    "author": "project-baize"
  },
  {
    "T": "\ud83d\udd36",
    "model": "starcoderplus",
    "average": 47.61,
    "arc": 48.72,
    "hellaswag": 77.3,
    "mmlu": 43.72,
    "truthfulqa": 37.85,
    "winogrande": 70.01,
    "gsm8k": 8.04,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 15.52,
    "likes": 181.0,
    "still_on_hub": false,
    "revision": "95be82087c33f14ee9941c812a154a9dd66efe72",
    "model_name_for_query": "bigcode/starcoderplus",
    "link": "https://huggingface.co/bigcode/starcoderplus",
    "author": "bigcode"
  },
  {
    "T": "\ud83d\udd36",
    "model": "metharme-7b",
    "average": 47.48,
    "arc": 53.67,
    "hellaswag": 78.62,
    "mmlu": 35.91,
    "truthfulqa": 39.16,
    "winogrande": 72.53,
    "gsm8k": 5.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "62ca156891feead8db117be8f5f35687b6274e6e",
    "model_name_for_query": "Neko-Institute-of-Science/metharme-7b",
    "link": "https://huggingface.co/Neko-Institute-of-Science/metharme-7b",
    "author": "Neko-Institute-of-Science"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama_7b_qlora_cds",
    "average": 47.43,
    "arc": 52.47,
    "hellaswag": 77.76,
    "mmlu": 32.38,
    "truthfulqa": 46.14,
    "winogrande": 71.74,
    "gsm8k": 4.09,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "b6b5c65c5c1cce34d24c8f790bb0cc011e0f0808",
    "model_name_for_query": "DevaMalla/llama_7b_qlora_cds",
    "link": "https://huggingface.co/DevaMalla/llama_7b_qlora_cds",
    "author": "DevaMalla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "effi-7b",
    "average": 47.42,
    "arc": 55.12,
    "hellaswag": 78.07,
    "mmlu": 35.91,
    "truthfulqa": 39.71,
    "winogrande": 72.53,
    "gsm8k": 3.18,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": false,
    "revision": "d58c62ee27cae60392bd0bd53e1fd05ea82e273b",
    "model_name_for_query": "aiplanet/effi-7b",
    "link": "https://huggingface.co/aiplanet/effi-7b",
    "author": "aiplanet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b-gpt4-1.2",
    "average": 47.42,
    "arc": 52.13,
    "hellaswag": 78.14,
    "mmlu": 38.64,
    "truthfulqa": 41.79,
    "winogrande": 71.67,
    "gsm8k": 2.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "431fda60009d9b37a73211123ffb9c797764e182",
    "model_name_for_query": "jondurbin/airoboros-7b-gpt4-1.2",
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.2",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_v2_7b",
    "average": 47.41,
    "arc": 50.77,
    "hellaswag": 76.02,
    "mmlu": 39.5,
    "truthfulqa": 43.86,
    "winogrande": 71.43,
    "gsm8k": 2.88,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 6.61,
    "likes": 34.0,
    "still_on_hub": true,
    "revision": "165850882991d7fa4eabab577a03ed84e0713bfa",
    "model_name_for_query": "psmathur/orca_mini_v2_7b",
    "link": "https://huggingface.co/psmathur/orca_mini_v2_7b",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b",
    "average": 47.4,
    "arc": 53.07,
    "hellaswag": 77.65,
    "mmlu": 37.23,
    "truthfulqa": 43.39,
    "winogrande": 70.96,
    "gsm8k": 2.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "7ea67f85ff3a7a8ec77f1819dec3e56779b764b1",
    "model_name_for_query": "jondurbin/airoboros-7b",
    "link": "https://huggingface.co/jondurbin/airoboros-7b",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-shishya-7b-ep3-v1",
    "average": 47.4,
    "arc": 45.9,
    "hellaswag": 76.36,
    "mmlu": 50.04,
    "truthfulqa": 40.32,
    "winogrande": 71.74,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "082cf758aa3f6d8f956056003b5b3b6cde447d88",
    "model_name_for_query": "luffycodes/vicuna-shishya-7b-ep3-v1",
    "link": "https://huggingface.co/luffycodes/vicuna-shishya-7b-ep3-v1",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CAlign-alpaca-7b",
    "average": 47.39,
    "arc": 50.94,
    "hellaswag": 74.55,
    "mmlu": 38.56,
    "truthfulqa": 46.89,
    "winogrande": 72.06,
    "gsm8k": 1.36,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f5cc642a10160a014e2afeefcd57d4781994c51e",
    "model_name_for_query": "jxhong/CAlign-alpaca-7b",
    "link": "https://huggingface.co/jxhong/CAlign-alpaca-7b",
    "author": "jxhong"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-7b-8k-instruct",
    "average": 47.37,
    "arc": 45.9,
    "hellaswag": 74.47,
    "mmlu": 41.97,
    "truthfulqa": 35.21,
    "winogrande": 65.98,
    "gsm8k": 20.7,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-3.0",
    "params": 6.65,
    "likes": 23.0,
    "still_on_hub": true,
    "revision": "736f68aceeb61298a5de3cf5ae81d0bc2697edf4",
    "model_name_for_query": "mosaicml/mpt-7b-8k-instruct",
    "link": "https://huggingface.co/mosaicml/mpt-7b-8k-instruct",
    "author": "mosaicml"
  },
  {
    "T": "\ud83d\udd36",
    "model": "guanaco-7B-HF",
    "average": 47.34,
    "arc": 52.99,
    "hellaswag": 80.05,
    "mmlu": 35.32,
    "truthfulqa": 39.2,
    "winogrande": 71.43,
    "gsm8k": 5.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "293c24105fa15afa127a2ec3905fdc2a0a3a6dac",
    "model_name_for_query": "TheBloke/guanaco-7B-HF",
    "link": "https://huggingface.co/TheBloke/guanaco-7B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "open_llama_13b",
    "average": 47.26,
    "arc": 51.19,
    "hellaswag": 75.23,
    "mmlu": 43.75,
    "truthfulqa": 38.08,
    "winogrande": 72.06,
    "gsm8k": 3.26,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 434.0,
    "still_on_hub": true,
    "revision": "b6d7fde8392250730d24cc2fcfa3b7e5f9a03ce8",
    "model_name_for_query": "openlm-research/open_llama_13b",
    "link": "https://huggingface.co/openlm-research/open_llama_13b",
    "author": "openlm-research"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Mixtral-8x7B-MoE-RP-Story",
    "average": 47.23,
    "arc": 51.54,
    "hellaswag": 70.0,
    "mmlu": 43.04,
    "truthfulqa": 41.53,
    "winogrande": 67.32,
    "gsm8k": 9.93,
    "model_type": "fine-tuned",
    "architecture": "MixtralForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-4.0",
    "params": 46.7,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "ce4a4e4ffec063a3e338b6ebc328365270b6c5f0",
    "model_name_for_query": "Undi95/Mixtral-8x7B-MoE-RP-Story",
    "link": "https://huggingface.co/Undi95/Mixtral-8x7B-MoE-RP-Story",
    "author": "Undi95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLlama13B-Finetune-v1",
    "average": 47.19,
    "arc": 45.82,
    "hellaswag": 69.36,
    "mmlu": 45.05,
    "truthfulqa": 44.97,
    "winogrande": 66.93,
    "gsm8k": 10.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "40ff78ce37efcaf83718534c494829a573b9d719",
    "model_name_for_query": "FelixChao/CodeLlama13B-Finetune-v1",
    "link": "https://huggingface.co/FelixChao/CodeLlama13B-Finetune-v1",
    "author": "FelixChao"
  },
  {
    "T": "\u2b55",
    "model": "mpt-7b-8k-instruct",
    "average": 47.18,
    "arc": 45.48,
    "hellaswag": 74.41,
    "mmlu": 42.11,
    "truthfulqa": 35.06,
    "winogrande": 65.51,
    "gsm8k": 20.55,
    "model_type": "instruction-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-sa-3.0",
    "params": 6.65,
    "likes": 23.0,
    "still_on_hub": true,
    "revision": "736f68aceeb61298a5de3cf5ae81d0bc2697edf4",
    "model_name_for_query": "mosaicml/mpt-7b-8k-instruct",
    "link": "https://huggingface.co/mosaicml/mpt-7b-8k-instruct",
    "author": "mosaicml"
  },
  {
    "T": "\u2b55",
    "model": "Asclepius-Llama2-7B",
    "average": 47.15,
    "arc": 50.85,
    "hellaswag": 76.53,
    "mmlu": 43.61,
    "truthfulqa": 43.31,
    "winogrande": 68.27,
    "gsm8k": 0.3,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "2f15bd8250d7825307e59cc2c785074ebbec3395",
    "model_name_for_query": "starmpcc/Asclepius-Llama2-7B",
    "link": "https://huggingface.co/starmpcc/Asclepius-Llama2-7B",
    "author": "starmpcc"
  },
  {
    "T": "\ud83d\udd36",
    "model": "youri-7b",
    "average": 47.11,
    "arc": 49.06,
    "hellaswag": 74.89,
    "mmlu": 42.22,
    "truthfulqa": 36.03,
    "winogrande": 71.82,
    "gsm8k": 8.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "2be40b8a7b669c4520bc04ce954bdbd7d4b0da7e",
    "model_name_for_query": "rinna/youri-7b",
    "link": "https://huggingface.co/rinna/youri-7b",
    "author": "rinna"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "openllama-7b-base",
    "average": 47.09,
    "arc": 46.16,
    "hellaswag": 76.4,
    "mmlu": 42.82,
    "truthfulqa": 36.65,
    "winogrande": 70.88,
    "gsm8k": 9.63,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "24d98f339fabfa479e3c85404f5e4dda9e43dcd1",
    "model_name_for_query": "itsliupeng/openllama-7b-base",
    "link": "https://huggingface.co/itsliupeng/openllama-7b-base",
    "author": "itsliupeng"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLaMA-2-7B-32K",
    "average": 47.07,
    "arc": 47.53,
    "hellaswag": 76.14,
    "mmlu": 43.33,
    "truthfulqa": 39.23,
    "winogrande": 71.9,
    "gsm8k": 4.32,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 465.0,
    "still_on_hub": true,
    "revision": "aef6d8946ae1015bdb65c478a2dd73b58daaef47",
    "model_name_for_query": "togethercomputer/LLaMA-2-7B-32K",
    "link": "https://huggingface.co/togethercomputer/LLaMA-2-7B-32K",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-gpt-3.5-turbo-100k-7b",
    "average": 47.05,
    "arc": 53.07,
    "hellaswag": 76.16,
    "mmlu": 33.63,
    "truthfulqa": 45.07,
    "winogrande": 70.8,
    "gsm8k": 3.56,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "53887996c0f17f7711d182537505a895fb404542",
    "model_name_for_query": "jondurbin/airoboros-gpt-3.5-turbo-100k-7b",
    "link": "https://huggingface.co/jondurbin/airoboros-gpt-3.5-turbo-100k-7b",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PygmalionCoT-7b",
    "average": 47.0,
    "arc": 51.45,
    "hellaswag": 76.92,
    "mmlu": 33.35,
    "truthfulqa": 48.13,
    "winogrande": 68.9,
    "gsm8k": 3.26,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.74,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "c03ac527360663d17bb142405251028eec843ed9",
    "model_name_for_query": "notstoic/PygmalionCoT-7b",
    "link": "https://huggingface.co/notstoic/PygmalionCoT-7b",
    "author": "notstoic"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chatdoctor",
    "average": 46.95,
    "arc": 53.75,
    "hellaswag": 78.54,
    "mmlu": 35.95,
    "truthfulqa": 43.55,
    "winogrande": 69.93,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LLaMAForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "8fdcfdda6877d7f21173dfac48b2c14499ba8264",
    "model_name_for_query": "mncai/chatdoctor",
    "link": "https://huggingface.co/mncai/chatdoctor",
    "author": "mncai"
  },
  {
    "T": "?",
    "model": "llama7b-wizardlm-unfiltered",
    "average": 46.94,
    "arc": 52.99,
    "hellaswag": 77.89,
    "mmlu": 36.41,
    "truthfulqa": 37.75,
    "winogrande": 72.3,
    "gsm8k": 4.32,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "2123beec77083c414b2ae51dd25b7a870b0b936c",
    "model_name_for_query": "ausboss/llama7b-wizardlm-unfiltered",
    "link": "https://huggingface.co/ausboss/llama7b-wizardlm-unfiltered",
    "author": "ausboss"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolphin-llama2-7b",
    "average": 46.94,
    "arc": 46.59,
    "hellaswag": 67.52,
    "mmlu": 48.37,
    "truthfulqa": 49.72,
    "winogrande": 63.77,
    "gsm8k": 5.69,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 64.0,
    "still_on_hub": true,
    "revision": "85aa4f67191fd016ab7ea8c389fddb5d9e5a9a52",
    "model_name_for_query": "ehartford/dolphin-llama2-7b",
    "link": "https://huggingface.co/ehartford/dolphin-llama2-7b",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b-gpt4-1.3",
    "average": 46.91,
    "arc": 52.47,
    "hellaswag": 77.98,
    "mmlu": 41.97,
    "truthfulqa": 35.73,
    "winogrande": 72.3,
    "gsm8k": 0.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7b5f77827636bbf3174c48ca16e774c89d71d7bd",
    "model_name_for_query": "jondurbin/airoboros-7b-gpt4-1.3",
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.3",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama_7b_lora",
    "average": 46.77,
    "arc": 54.86,
    "hellaswag": 79.1,
    "mmlu": 33.63,
    "truthfulqa": 34.74,
    "winogrande": 72.77,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "7f4cbd810b4bef0d75c1fd3f551146b4ea97d9fd",
    "model_name_for_query": "DevaMalla/llama_7b_lora",
    "link": "https://huggingface.co/DevaMalla/llama_7b_lora",
    "author": "DevaMalla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "baize-v2-7b",
    "average": 46.72,
    "arc": 48.98,
    "hellaswag": 75.06,
    "mmlu": 39.6,
    "truthfulqa": 41.39,
    "winogrande": 71.11,
    "gsm8k": 4.17,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 23.0,
    "still_on_hub": true,
    "revision": "e4731c2c2671e2d0b47b5eba08c753ca21671fab",
    "model_name_for_query": "project-baize/baize-v2-7b",
    "link": "https://huggingface.co/project-baize/baize-v2-7b",
    "author": "project-baize"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-dolphin-orca-platypus-13b",
    "average": 46.7,
    "arc": 44.8,
    "hellaswag": 68.6,
    "mmlu": 44.03,
    "truthfulqa": 46.28,
    "winogrande": 66.93,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "0c41023f8f665946a2c46c3823afee431408bcbd",
    "model_name_for_query": "uukuguy/speechless-codellama-dolphin-orca-platypus-13b",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-dolphin-orca-platypus-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-platypus-13b",
    "average": 46.68,
    "arc": 46.16,
    "hellaswag": 68.88,
    "mmlu": 44.55,
    "truthfulqa": 44.98,
    "winogrande": 66.14,
    "gsm8k": 9.4,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7a771bd8899b9ef4ba9680e96f84dc85810a67d6",
    "model_name_for_query": "uukuguy/speechless-codellama-platypus-13b",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-platypus-13b",
    "author": "uukuguy"
  },
  {
    "T": "\u2b55",
    "model": "dolphin-2.2-yi-34b-200k",
    "average": 46.67,
    "arc": 42.15,
    "hellaswag": 68.18,
    "mmlu": 55.47,
    "truthfulqa": 45.93,
    "winogrande": 64.56,
    "gsm8k": 3.71,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 34.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c4e02a3a5c7a9d51f8b0cad85952dfdfb34c9413",
    "model_name_for_query": "ehartford/dolphin-2.2-yi-34b-200k",
    "link": "https://huggingface.co/ehartford/dolphin-2.2-yi-34b-200k",
    "author": "ehartford"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gogpt2-7b",
    "average": 46.65,
    "arc": 46.76,
    "hellaswag": 71.53,
    "mmlu": 42.85,
    "truthfulqa": 47.85,
    "winogrande": 68.67,
    "gsm8k": 2.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.76,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "ee60ed402dedf24b6154aef05df54512e02fc9e2",
    "model_name_for_query": "golaxy/gogpt2-7b",
    "link": "https://huggingface.co/golaxy/gogpt2-7b",
    "author": "golaxy"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "OpenHathi-7B-Hi-v0.1-Base",
    "average": 46.64,
    "arc": 49.49,
    "hellaswag": 74.34,
    "mmlu": 41.38,
    "truthfulqa": 37.46,
    "winogrande": 71.27,
    "gsm8k": 5.91,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.87,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "2cbb156ab4426113115bc3387b06d1940015119a",
    "model_name_for_query": "sarvamai/OpenHathi-7B-Hi-v0.1-Base",
    "link": "https://huggingface.co/sarvamai/OpenHathi-7B-Hi-v0.1-Base",
    "author": "sarvamai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama_7b_qlora",
    "average": 46.61,
    "arc": 55.12,
    "hellaswag": 78.26,
    "mmlu": 35.71,
    "truthfulqa": 33.98,
    "winogrande": 72.06,
    "gsm8k": 4.55,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "7f94b0be78193abc54722cf723541c3800426f7b",
    "model_name_for_query": "DevaMalla/llama_7b_qlora",
    "link": "https://huggingface.co/DevaMalla/llama_7b_qlora",
    "author": "DevaMalla"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "stablelm-3b-4e1t",
    "average": 46.58,
    "arc": 46.59,
    "hellaswag": 75.94,
    "mmlu": 45.23,
    "truthfulqa": 37.2,
    "winogrande": 71.19,
    "gsm8k": 3.34,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 2.8,
    "likes": 192.0,
    "still_on_hub": false,
    "revision": "a4750ace0db6f08d7bbba0aa52a585f231ea3cde",
    "model_name_for_query": "stabilityai/stablelm-3b-4e1t",
    "link": "https://huggingface.co/stabilityai/stablelm-3b-4e1t",
    "author": "stabilityai"
  },
  {
    "T": "?",
    "model": "alpaca-native",
    "average": 46.58,
    "arc": 52.3,
    "hellaswag": 77.09,
    "mmlu": 41.6,
    "truthfulqa": 37.58,
    "winogrande": 69.46,
    "gsm8k": 1.44,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 249.0,
    "still_on_hub": true,
    "revision": "cc7773cac2478231807c56ef2f02292d98f85cf5",
    "model_name_for_query": "chavinlo/alpaca-native",
    "link": "https://huggingface.co/chavinlo/alpaca-native",
    "author": "chavinlo"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gogpt2-13b",
    "average": 46.55,
    "arc": 48.38,
    "hellaswag": 71.78,
    "mmlu": 44.5,
    "truthfulqa": 44.73,
    "winogrande": 67.88,
    "gsm8k": 2.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.04,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "16d4c4214fa8d5a962b9064a8b958076b7c79a17",
    "model_name_for_query": "golaxy/gogpt2-13b",
    "link": "https://huggingface.co/golaxy/gogpt2-13b",
    "author": "golaxy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama7b_alpaca_1gpu_bf16",
    "average": 46.49,
    "arc": 52.73,
    "hellaswag": 78.78,
    "mmlu": 36.26,
    "truthfulqa": 33.71,
    "winogrande": 72.93,
    "gsm8k": 4.55,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "305683c1b95f6888b8668dbc6b56d9efa5d07fef",
    "model_name_for_query": "DevaMalla/llama7b_alpaca_1gpu_bf16",
    "link": "https://huggingface.co/DevaMalla/llama7b_alpaca_1gpu_bf16",
    "author": "DevaMalla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pygmalion_AlpacaLora-7b",
    "average": 46.49,
    "arc": 53.24,
    "hellaswag": 76.92,
    "mmlu": 35.92,
    "truthfulqa": 39.44,
    "winogrande": 72.22,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "1f61442e1238062095b31b4909c5e9ab26105794",
    "model_name_for_query": "TehVenom/Pygmalion_AlpacaLora-7b",
    "link": "https://huggingface.co/TehVenom/Pygmalion_AlpacaLora-7b",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "nart-100k-7b",
    "average": 46.39,
    "arc": 54.1,
    "hellaswag": 78.47,
    "mmlu": 34.98,
    "truthfulqa": 36.74,
    "winogrande": 70.48,
    "gsm8k": 3.56,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-nd-4.0",
    "params": 6.61,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "50e61b8e6cc17cb3fbcb490fe3dc7e2c8b248378",
    "model_name_for_query": "jerryjalapeno/nart-100k-7b",
    "link": "https://huggingface.co/jerryjalapeno/nart-100k-7b",
    "author": "jerryjalapeno"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gogpt-7b",
    "average": 46.38,
    "arc": 48.81,
    "hellaswag": 73.79,
    "mmlu": 43.03,
    "truthfulqa": 41.0,
    "winogrande": 69.77,
    "gsm8k": 1.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.76,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "7eb70c0e330b7d3ff490047ddbb153bb96294882",
    "model_name_for_query": "golaxy/gogpt-7b",
    "link": "https://huggingface.co/golaxy/gogpt-7b",
    "author": "golaxy"
  },
  {
    "T": "?",
    "model": "llama-7b",
    "average": 46.37,
    "arc": 50.94,
    "hellaswag": 77.81,
    "mmlu": 35.69,
    "truthfulqa": 34.33,
    "winogrande": 71.43,
    "gsm8k": 8.04,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.74,
    "likes": 226.0,
    "still_on_hub": true,
    "revision": "8416d3fefb0cb3ff5775a7b13c1692d10ff1aa16",
    "model_name_for_query": "huggyllama/llama-7b",
    "link": "https://huggingface.co/huggyllama/llama-7b",
    "author": "huggyllama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-7b-gpt4-1.4.1-qlora",
    "average": 46.34,
    "arc": 52.73,
    "hellaswag": 77.89,
    "mmlu": 38.77,
    "truthfulqa": 36.07,
    "winogrande": 70.32,
    "gsm8k": 2.27,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "91ffa900ed637cf5fd904d96e6985b6f7857ad64",
    "model_name_for_query": "jondurbin/airoboros-7b-gpt4-1.4.1-qlora",
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.4.1-qlora",
    "author": "jondurbin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "yayi-13b-llama2",
    "average": 46.32,
    "arc": 48.55,
    "hellaswag": 74.82,
    "mmlu": 38.68,
    "truthfulqa": 42.19,
    "winogrande": 69.69,
    "gsm8k": 4.02,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 12.85,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "9fc1bc4409b9e71f54213245a91c2742fbf7b3d0",
    "model_name_for_query": "wenge-research/yayi-13b-llama2",
    "link": "https://huggingface.co/wenge-research/yayi-13b-llama2",
    "author": "wenge-research"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-dolphin-orca-platypus-13b",
    "average": 46.32,
    "arc": 45.82,
    "hellaswag": 67.71,
    "mmlu": 45.88,
    "truthfulqa": 44.67,
    "winogrande": 65.35,
    "gsm8k": 8.49,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "25e1c346c2a01588a728307d5c35fbeecd58b51b",
    "model_name_for_query": "speechlessai/speechless-codellama-dolphin-orca-platypus-13b",
    "link": "https://huggingface.co/speechlessai/speechless-codellama-dolphin-orca-platypus-13b",
    "author": "speechlessai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-orca-13b",
    "average": 46.28,
    "arc": 46.33,
    "hellaswag": 67.71,
    "mmlu": 47.19,
    "truthfulqa": 46.66,
    "winogrande": 63.77,
    "gsm8k": 5.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "a82467de3cb9438aa8f9e0ea8ea692f16a5724b2",
    "model_name_for_query": "uukuguy/speechless-codellama-orca-13b",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open_llama_7b_v2_med_instruct",
    "average": 46.24,
    "arc": 46.5,
    "hellaswag": 76.91,
    "mmlu": 42.32,
    "truthfulqa": 40.33,
    "winogrande": 69.3,
    "gsm8k": 2.05,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "cabb47abd422a2d67161e2d038265ee23be45fb8",
    "model_name_for_query": "yhyhy3/open_llama_7b_v2_med_instruct",
    "link": "https://huggingface.co/yhyhy3/open_llama_7b_v2_med_instruct",
    "author": "yhyhy3"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-llama2-7b-pretrain",
    "average": 46.18,
    "arc": 48.63,
    "hellaswag": 74.83,
    "mmlu": 41.04,
    "truthfulqa": 39.08,
    "winogrande": 70.24,
    "gsm8k": 3.26,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "444c85ef809f8793d84b0813ab78bec50700cfcf",
    "model_name_for_query": "YeungNLP/firefly-llama2-7b-pretrain",
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-7b-pretrain",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "stablelm-base-alpha-7b-v2",
    "average": 46.18,
    "arc": 47.35,
    "hellaswag": 77.08,
    "mmlu": 45.1,
    "truthfulqa": 36.46,
    "winogrande": 68.51,
    "gsm8k": 2.58,
    "model_type": "pretrained",
    "architecture": "StableLMAlphaForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 6.89,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "eb3b56fee1ad4b1efe6625bbbc7a277df8ab5b96",
    "model_name_for_query": "stabilityai/stablelm-base-alpha-7b-v2",
    "link": "https://huggingface.co/stabilityai/stablelm-base-alpha-7b-v2",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "carl-7b",
    "average": 46.16,
    "arc": 53.5,
    "hellaswag": 78.29,
    "mmlu": 33.96,
    "truthfulqa": 40.29,
    "winogrande": 68.59,
    "gsm8k": 2.35,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "de4c7af9598bebc47dd43253c972be719f3195d6",
    "model_name_for_query": "ajibawa-2023/carl-7b",
    "link": "https://huggingface.co/ajibawa-2023/carl-7b",
    "author": "ajibawa-2023"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-class-shishya-7b-ep3",
    "average": 46.14,
    "arc": 40.61,
    "hellaswag": 76.72,
    "mmlu": 50.77,
    "truthfulqa": 36.87,
    "winogrande": 71.9,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c2bd682b9f3babbb3bc84f84856fabe69a3c21d0",
    "model_name_for_query": "luffycodes/vicuna-class-shishya-7b-ep3",
    "link": "https://huggingface.co/luffycodes/vicuna-class-shishya-7b-ep3",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "bloom",
    "average": 46.07,
    "arc": 50.43,
    "hellaswag": 76.41,
    "mmlu": 30.85,
    "truthfulqa": 39.76,
    "winogrande": 72.06,
    "gsm8k": 6.9,
    "model_type": "pretrained",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 176.25,
    "likes": 461.0,
    "still_on_hub": true,
    "revision": "053d9cd9fbe814e091294f67fcfedb3397b954bb",
    "model_name_for_query": "bigscience/bloom",
    "link": "https://huggingface.co/bigscience/bloom",
    "author": "bigscience"
  },
  {
    "T": "\ud83d\udd36",
    "model": "baichuan-vicuna-chinese-7b",
    "average": 46.06,
    "arc": 43.52,
    "hellaswag": 71.12,
    "mmlu": 46.87,
    "truthfulqa": 42.45,
    "winogrande": 66.85,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 61.0,
    "still_on_hub": true,
    "revision": "6cdb9e75cd473e31e87067c2a0b646083247d9ab",
    "model_name_for_query": "fireballoon/baichuan-vicuna-chinese-7b",
    "link": "https://huggingface.co/fireballoon/baichuan-vicuna-chinese-7b",
    "author": "fireballoon"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test-custom-llama",
    "average": 46.05,
    "arc": 52.3,
    "hellaswag": 77.49,
    "mmlu": 36.61,
    "truthfulqa": 33.81,
    "winogrande": 72.06,
    "gsm8k": 4.02,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d985610bef080473e40f01c53266083c5f0c3169",
    "model_name_for_query": "illuin/test-custom-llama",
    "link": "https://huggingface.co/illuin/test-custom-llama",
    "author": "illuin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-7b",
    "average": 46.04,
    "arc": 51.37,
    "hellaswag": 77.81,
    "mmlu": 35.68,
    "truthfulqa": 34.54,
    "winogrande": 72.22,
    "gsm8k": 4.62,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 38.0,
    "still_on_hub": true,
    "revision": "6473f9996d758fde48a181f37cc5de575aff1606",
    "model_name_for_query": "Neko-Institute-of-Science/pygmalion-7b",
    "link": "https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b",
    "author": "Neko-Institute-of-Science"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-mctaco-modified2",
    "average": 46.03,
    "arc": 42.92,
    "hellaswag": 73.97,
    "mmlu": 48.49,
    "truthfulqa": 40.43,
    "winogrande": 69.69,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8e1930bbbbdeb4f6f4639e837f09d9878bbf7831",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified2",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco-modified2",
    "author": "Charlie911"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-13b-Instruct-hf",
    "average": 45.82,
    "arc": 44.54,
    "hellaswag": 64.93,
    "mmlu": 38.89,
    "truthfulqa": 45.88,
    "winogrande": 68.03,
    "gsm8k": 12.66,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 66.0,
    "still_on_hub": true,
    "revision": "b9f91b7351ecd589118d883afa23d5c93a38c612",
    "model_name_for_query": "codellama/CodeLlama-13b-Instruct-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-13b-Instruct-hf",
    "author": "codellama"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-13B-Instruct-fp16",
    "average": 45.82,
    "arc": 44.62,
    "hellaswag": 64.94,
    "mmlu": 38.77,
    "truthfulqa": 45.88,
    "winogrande": 68.03,
    "gsm8k": 12.66,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "521c208c7251ccd3e44ccd9500b6bed419bca565",
    "model_name_for_query": "TheBloke/CodeLlama-13B-Instruct-fp16",
    "link": "https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Planner-7B-fp16",
    "average": 45.65,
    "arc": 51.02,
    "hellaswag": 77.82,
    "mmlu": 35.71,
    "truthfulqa": 34.33,
    "winogrande": 71.43,
    "gsm8k": 3.56,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "afb4604a06c8541960fb51240259777764c4ce7e",
    "model_name_for_query": "TheBloke/Planner-7B-fp16",
    "link": "https://huggingface.co/TheBloke/Planner-7B-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-7b",
    "average": 45.65,
    "arc": 51.02,
    "hellaswag": 77.82,
    "mmlu": 35.71,
    "truthfulqa": 34.33,
    "winogrande": 71.43,
    "gsm8k": 3.56,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "other",
    "params": 6.74,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "f356572651e58fb337d610470d4b36976e7fb802",
    "model_name_for_query": "huggingface/llama-7b",
    "link": "https://huggingface.co/huggingface/llama-7b",
    "author": "huggingface"
  },
  {
    "T": "\u2b55",
    "model": "speechless-codellama-platypus-13b",
    "average": 45.64,
    "arc": 45.31,
    "hellaswag": 68.63,
    "mmlu": 42.82,
    "truthfulqa": 42.38,
    "winogrande": 65.59,
    "gsm8k": 9.1,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "81cb1bca46ce646b8339501537837e02116de1b8",
    "model_name_for_query": "uukuguy/speechless-codellama-platypus-13b",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-platypus-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama-base-7b",
    "average": 45.62,
    "arc": 50.94,
    "hellaswag": 77.8,
    "mmlu": 35.67,
    "truthfulqa": 34.34,
    "winogrande": 71.43,
    "gsm8k": 3.56,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e01d89d8e444f7d751ea58feaf22ff8c9af69d2a",
    "model_name_for_query": "DevaMalla/llama-base-7b",
    "link": "https://huggingface.co/DevaMalla/llama-base-7b",
    "author": "DevaMalla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PandaLM-Alpaca-7B-v1",
    "average": 45.59,
    "arc": 50.85,
    "hellaswag": 77.36,
    "mmlu": 35.91,
    "truthfulqa": 36.63,
    "winogrande": 71.9,
    "gsm8k": 0.91,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7fe5cb1a7009fdade8dfcfec335527997a730fcf",
    "model_name_for_query": "WeOpenML/PandaLM-Alpaca-7B-v1",
    "link": "https://huggingface.co/WeOpenML/PandaLM-Alpaca-7B-v1",
    "author": "WeOpenML"
  },
  {
    "T": "\u2b55",
    "model": "WizardCoder-Python-13B-LoRa",
    "average": 45.56,
    "arc": 47.78,
    "hellaswag": 69.6,
    "mmlu": 38.76,
    "truthfulqa": 43.97,
    "winogrande": 65.43,
    "gsm8k": 7.81,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "32ffc44ffdf1adfe2d8ef219327fbd534f3d5955",
    "model_name_for_query": "yeontaek/WizardCoder-Python-13B-LoRa",
    "link": "https://huggingface.co/yeontaek/WizardCoder-Python-13B-LoRa",
    "author": "yeontaek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "tamil-llama-7b-instruct-v0.1",
    "average": 45.52,
    "arc": 48.04,
    "hellaswag": 70.97,
    "mmlu": 39.95,
    "truthfulqa": 41.7,
    "winogrande": 70.64,
    "gsm8k": 1.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "36f04b36c781ff994af41060df09491bde54105d",
    "model_name_for_query": "abhinand/tamil-llama-7b-instruct-v0.1",
    "link": "https://huggingface.co/abhinand/tamil-llama-7b-instruct-v0.1",
    "author": "abhinand"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Chinese-LLaMA-2-7B-hf",
    "average": 45.44,
    "arc": 48.04,
    "hellaswag": 73.25,
    "mmlu": 35.04,
    "truthfulqa": 39.92,
    "winogrande": 70.17,
    "gsm8k": 6.22,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.64,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "a2d55220b3d0693825fe69e1174653dc6cc4a920",
    "model_name_for_query": "Linly-AI/Chinese-LLaMA-2-7B-hf",
    "link": "https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf",
    "author": "Linly-AI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chinese-llama-plus-13b-hf",
    "average": 45.39,
    "arc": 46.25,
    "hellaswag": 71.88,
    "mmlu": 40.74,
    "truthfulqa": 39.89,
    "winogrande": 73.09,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.94,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "f17a52b8067d551a814069d2c710e1f5c487a3ce",
    "model_name_for_query": "shibing624/chinese-llama-plus-13b-hf",
    "link": "https://huggingface.co/shibing624/chinese-llama-plus-13b-hf",
    "author": "shibing624"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-7b-chat",
    "average": 45.39,
    "arc": 46.5,
    "hellaswag": 75.51,
    "mmlu": 37.62,
    "truthfulqa": 40.16,
    "winogrande": 68.43,
    "gsm8k": 4.09,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 6.65,
    "likes": 485.0,
    "still_on_hub": true,
    "revision": "64e5c9c9fb53a8e89690c2dee75a5add37f7113e",
    "model_name_for_query": "mosaicml/mpt-7b-chat",
    "link": "https://huggingface.co/mosaicml/mpt-7b-chat",
    "author": "mosaicml"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-mctaco-modified1",
    "average": 45.38,
    "arc": 40.87,
    "hellaswag": 73.4,
    "mmlu": 47.42,
    "truthfulqa": 39.87,
    "winogrande": 69.46,
    "gsm8k": 1.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a7749ff092ef03900de34b69d41c767a6a48ea9e",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified1",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco-modified1",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-ko-7b",
    "average": 45.32,
    "arc": 48.46,
    "hellaswag": 75.28,
    "mmlu": 39.56,
    "truthfulqa": 34.49,
    "winogrande": 72.14,
    "gsm8k": 1.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.86,
    "likes": 85.0,
    "still_on_hub": true,
    "revision": "d5c58cc2cae21b4fb96aaad2658acc898ab22d99",
    "model_name_for_query": "beomi/llama-2-ko-7b",
    "link": "https://huggingface.co/beomi/llama-2-ko-7b",
    "author": "beomi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ALMA-7B",
    "average": 45.32,
    "arc": 50.34,
    "hellaswag": 75.5,
    "mmlu": 38.04,
    "truthfulqa": 35.64,
    "winogrande": 72.38,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.0,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "b570315dd26452a07cf15cf6feecce839e1327a6",
    "model_name_for_query": "haoranxu/ALMA-7B",
    "link": "https://huggingface.co/haoranxu/ALMA-7B",
    "author": "haoranxu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MiniChat-3B",
    "average": 45.31,
    "arc": 44.03,
    "hellaswag": 67.19,
    "mmlu": 39.17,
    "truthfulqa": 45.67,
    "winogrande": 65.27,
    "gsm8k": 10.54,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "123d23bd291bb2d5fdb3b91dc1570d0b11654a78",
    "model_name_for_query": "GeneZC/MiniChat-3B",
    "link": "https://huggingface.co/GeneZC/MiniChat-3B",
    "author": "GeneZC"
  },
  {
    "T": "\ud83d\udd36",
    "model": "giraffe-7b",
    "average": 45.29,
    "arc": 47.18,
    "hellaswag": 75.53,
    "mmlu": 38.89,
    "truthfulqa": 38.48,
    "winogrande": 68.98,
    "gsm8k": 2.65,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9af88449bed5be4709befcfbbba123ee75805479",
    "model_name_for_query": "ashercn97/giraffe-7b",
    "link": "https://huggingface.co/ashercn97/giraffe-7b",
    "author": "ashercn97"
  },
  {
    "T": "?",
    "model": "opt-iml-max-30b",
    "average": 45.28,
    "arc": 43.86,
    "hellaswag": 72.39,
    "mmlu": 41.09,
    "truthfulqa": 38.16,
    "winogrande": 73.72,
    "gsm8k": 2.5,
    "model_type": "",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 29.98,
    "likes": 34.0,
    "still_on_hub": true,
    "revision": "291753b04817a31a742631053ee361874d6db8a4",
    "model_name_for_query": "facebook/opt-iml-max-30b",
    "link": "https://huggingface.co/facebook/opt-iml-max-30b",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-openllama-7b-v12-bf16",
    "average": 45.28,
    "arc": 42.06,
    "hellaswag": 62.01,
    "mmlu": 46.53,
    "truthfulqa": 45.18,
    "winogrande": 65.04,
    "gsm8k": 10.84,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.63,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "bb94ff691996484b1a9d899a6c0956ef6750d86a",
    "model_name_for_query": "OpenBuddy/openbuddy-openllama-7b-v12-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-openllama-7b-v12-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca-2-13B-16k",
    "average": 45.22,
    "arc": 53.67,
    "hellaswag": 69.48,
    "mmlu": 41.02,
    "truthfulqa": 45.3,
    "winogrande": 60.06,
    "gsm8k": 1.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 13.02,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "0daee08a5e065d02726e9ae0f05cdfd78992cfba",
    "model_name_for_query": "NurtureAI/Orca-2-13B-16k",
    "link": "https://huggingface.co/NurtureAI/Orca-2-13B-16k",
    "author": "NurtureAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-shishya-7b-ep3-v1",
    "average": 45.19,
    "arc": 48.04,
    "hellaswag": 76.63,
    "mmlu": 46.12,
    "truthfulqa": 30.9,
    "winogrande": 69.46,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8dc109f45ef36cc7bbd0f5d83fb65ac8e768d1bd",
    "model_name_for_query": "luffycodes/llama-shishya-7b-ep3-v1",
    "link": "https://huggingface.co/luffycodes/llama-shishya-7b-ep3-v1",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ennodata-7b",
    "average": 45.13,
    "arc": 51.02,
    "hellaswag": 77.62,
    "mmlu": 33.95,
    "truthfulqa": 33.53,
    "winogrande": 70.96,
    "gsm8k": 3.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7872a492ebbb3c6a899f9acbd34dfd5f7e674fdd",
    "model_name_for_query": "Enno-Ai/ennodata-7b",
    "link": "https://huggingface.co/Enno-Ai/ennodata-7b",
    "author": "Enno-Ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "guanaco-unchained-llama-2-7b",
    "average": 45.11,
    "arc": 47.35,
    "hellaswag": 72.16,
    "mmlu": 41.76,
    "truthfulqa": 41.49,
    "winogrande": 64.48,
    "gsm8k": 3.41,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "43f3de8bcef63eec03a1b00079c08b5932c1a429",
    "model_name_for_query": "jlevin/guanaco-unchained-llama-2-7b",
    "link": "https://huggingface.co/jlevin/guanaco-unchained-llama-2-7b",
    "author": "jlevin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-coding-7b-16k-tora",
    "average": 45.1,
    "arc": 41.21,
    "hellaswag": 64.45,
    "mmlu": 39.14,
    "truthfulqa": 44.91,
    "winogrande": 63.61,
    "gsm8k": 17.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d56b5c4f649d8e722efb927d16d7589967a67fbe",
    "model_name_for_query": "uukuguy/speechless-coding-7b-16k-tora",
    "link": "https://huggingface.co/uukuguy/speechless-coding-7b-16k-tora",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "vicuna-7b-v1.5-lora-mctaco-modified4",
    "average": 45.1,
    "arc": 40.7,
    "hellaswag": 73.08,
    "mmlu": 47.26,
    "truthfulqa": 41.59,
    "winogrande": 67.88,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "715b03c8573df06f3825d1c08b307e2a83fa8bf9",
    "model_name_for_query": "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified4",
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco-modified4",
    "author": "Charlie911"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-coding-7b-16k-tora",
    "average": 45.05,
    "arc": 41.13,
    "hellaswag": 64.48,
    "mmlu": 38.86,
    "truthfulqa": 44.95,
    "winogrande": 63.85,
    "gsm8k": 17.06,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "37281f20d54d895f8e3bc660e68564244c775ac2",
    "model_name_for_query": "speechlessai/speechless-coding-7b-16k-tora",
    "link": "https://huggingface.co/speechlessai/speechless-coding-7b-16k-tora",
    "author": "speechlessai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Qwen-VL-LLaMAfied-7B-Chat",
    "average": 45.0,
    "arc": 47.35,
    "hellaswag": 69.97,
    "mmlu": 44.12,
    "truthfulqa": 42.87,
    "winogrande": 65.67,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ccbd599ac46bcfbf7020be393afeecef404bce2b",
    "model_name_for_query": "JosephusCheung/Qwen-VL-LLaMAfied-7B-Chat",
    "link": "https://huggingface.co/JosephusCheung/Qwen-VL-LLaMAfied-7B-Chat",
    "author": "JosephusCheung"
  },
  {
    "T": "?",
    "model": "llama-7b-logicot",
    "average": 44.95,
    "arc": 47.01,
    "hellaswag": 72.56,
    "mmlu": 38.93,
    "truthfulqa": 43.63,
    "winogrande": 67.56,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "8e9c93c09e6a6c7d504c88d6ca598144829bced8",
    "model_name_for_query": "csitfun/llama-7b-logicot",
    "link": "https://huggingface.co/csitfun/llama-7b-logicot",
    "author": "csitfun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-7B-Uncensored",
    "average": 44.92,
    "arc": 47.87,
    "hellaswag": 73.08,
    "mmlu": 35.42,
    "truthfulqa": 41.49,
    "winogrande": 68.43,
    "gsm8k": 3.26,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 339.0,
    "still_on_hub": true,
    "revision": "14c23f9fa775ab5ce49010418f00df06d92b0b13",
    "model_name_for_query": "ehartford/WizardLM-7B-Uncensored",
    "link": "https://huggingface.co/ehartford/WizardLM-7B-Uncensored",
    "author": "ehartford"
  },
  {
    "T": "\u2b55",
    "model": "codellama-13b-oasst-sft-v10",
    "average": 44.85,
    "arc": 45.39,
    "hellaswag": 62.36,
    "mmlu": 35.36,
    "truthfulqa": 45.02,
    "winogrande": 67.8,
    "gsm8k": 13.19,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 13.02,
    "likes": 42.0,
    "still_on_hub": true,
    "revision": "612dab2a8b2d77edb4fd36cfc28b3ffbbb20ffc1",
    "model_name_for_query": "OpenAssistant/codellama-13b-oasst-sft-v10",
    "link": "https://huggingface.co/OpenAssistant/codellama-13b-oasst-sft-v10",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLLaMA-chat-13b-Chinese",
    "average": 44.84,
    "arc": 43.26,
    "hellaswag": 63.87,
    "mmlu": 34.29,
    "truthfulqa": 48.97,
    "winogrande": 67.88,
    "gsm8k": 10.77,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 12.85,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "675b3e35a9601683c2cb4ec7f1b11d2869842f36",
    "model_name_for_query": "shareAI/CodeLLaMA-chat-13b-Chinese",
    "link": "https://huggingface.co/shareAI/CodeLLaMA-chat-13b-Chinese",
    "author": "shareAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-7b-instruct",
    "average": 44.83,
    "arc": 50.34,
    "hellaswag": 77.91,
    "mmlu": 32.35,
    "truthfulqa": 35.08,
    "winogrande": 70.48,
    "gsm8k": 2.81,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-3.0",
    "params": 6.65,
    "likes": 437.0,
    "still_on_hub": true,
    "revision": "925e0d80e50e77aaddaf9c3ced41ca4ea23a1025",
    "model_name_for_query": "mosaicml/mpt-7b-instruct",
    "link": "https://huggingface.co/mosaicml/mpt-7b-instruct",
    "author": "mosaicml"
  },
  {
    "T": "\u2b55",
    "model": "speechless-codellama-orca-13b",
    "average": 44.83,
    "arc": 44.37,
    "hellaswag": 65.2,
    "mmlu": 43.46,
    "truthfulqa": 45.94,
    "winogrande": 64.01,
    "gsm8k": 5.99,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "6fdfeabe817235df3d560a6e6465c3722bc3a4ba",
    "model_name_for_query": "uukuguy/speechless-codellama-orca-13b",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-13b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chinese-alpaca-plus-7b-hf",
    "average": 44.77,
    "arc": 49.23,
    "hellaswag": 70.48,
    "mmlu": 38.39,
    "truthfulqa": 39.72,
    "winogrande": 70.09,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.68,
    "likes": 46.0,
    "still_on_hub": true,
    "revision": "0deb5a13732f1e3e3240ea83f403c57283fe2dc8",
    "model_name_for_query": "shibing624/chinese-alpaca-plus-7b-hf",
    "link": "https://huggingface.co/shibing624/chinese-alpaca-plus-7b-hf",
    "author": "shibing624"
  },
  {
    "T": "\u2b55",
    "model": "palmyra-med-20b",
    "average": 44.71,
    "arc": 46.93,
    "hellaswag": 73.51,
    "mmlu": 44.34,
    "truthfulqa": 35.47,
    "winogrande": 65.35,
    "gsm8k": 2.65,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 20.26,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "407810f75698c95000dc0ae1a9a0457be625e972",
    "model_name_for_query": "Writer/palmyra-med-20b",
    "link": "https://huggingface.co/Writer/palmyra-med-20b",
    "author": "Writer"
  },
  {
    "T": "\u2b55",
    "model": "Poro-34B-GPTQ",
    "average": 44.67,
    "arc": 47.01,
    "hellaswag": 73.75,
    "mmlu": 32.47,
    "truthfulqa": 38.37,
    "winogrande": 71.35,
    "gsm8k": 5.08,
    "model_type": "instruction-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "GPTQ",
    "license": "apache-2.0",
    "params": 48.06,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "f6e034384e36b411d6b831157fb6063060ec1169",
    "model_name_for_query": "TheBloke/Poro-34B-GPTQ",
    "link": "https://huggingface.co/TheBloke/Poro-34B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "tamil-llama-7b-base-v0.1",
    "average": 44.52,
    "arc": 46.67,
    "hellaswag": 72.85,
    "mmlu": 40.95,
    "truthfulqa": 35.93,
    "winogrande": 70.72,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 7.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "e40f072bf68a157a18247eb08bf5b18ab8138986",
    "model_name_for_query": "abhinand/tamil-llama-7b-base-v0.1",
    "link": "https://huggingface.co/abhinand/tamil-llama-7b-base-v0.1",
    "author": "abhinand"
  },
  {
    "T": "?",
    "model": "Project-Baize-v2-7B-GPTQ",
    "average": 44.5,
    "arc": 45.99,
    "hellaswag": 73.44,
    "mmlu": 35.46,
    "truthfulqa": 39.92,
    "winogrande": 69.69,
    "gsm8k": 2.5,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 9.04,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "5dc039834e1ea42ac334458b2e3090fe3705cc59",
    "model_name_for_query": "TheBloke/Project-Baize-v2-7B-GPTQ",
    "link": "https://huggingface.co/TheBloke/Project-Baize-v2-7B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "falcon_7b_norobots",
    "average": 44.46,
    "arc": 47.87,
    "hellaswag": 77.92,
    "mmlu": 27.94,
    "truthfulqa": 36.81,
    "winogrande": 71.74,
    "gsm8k": 4.47,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "bbe8e4a0c19ec5a94f6eff680b5a55bd08e11e31",
    "model_name_for_query": "qblocks/falcon_7b_norobots",
    "link": "https://huggingface.co/qblocks/falcon_7b_norobots",
    "author": "qblocks"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Alpaca-7B-v1",
    "average": 44.41,
    "arc": 49.06,
    "hellaswag": 75.71,
    "mmlu": 33.76,
    "truthfulqa": 36.28,
    "winogrande": 71.51,
    "gsm8k": 0.15,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "be5cb84a84a859dd6e5e3efc4648d6d5d1a5d188",
    "model_name_for_query": "WeOpenML/Alpaca-7B-v1",
    "link": "https://huggingface.co/WeOpenML/Alpaca-7B-v1",
    "author": "WeOpenML"
  },
  {
    "T": "\ud83d\udd36",
    "model": "falcon_7b_norobots",
    "average": 44.4,
    "arc": 48.12,
    "hellaswag": 77.9,
    "mmlu": 28.11,
    "truthfulqa": 36.76,
    "winogrande": 71.59,
    "gsm8k": 3.94,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "bbe8e4a0c19ec5a94f6eff680b5a55bd08e11e31",
    "model_name_for_query": "qblocks/falcon_7b_norobots",
    "link": "https://huggingface.co/qblocks/falcon_7b_norobots",
    "author": "qblocks"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-shishya-7b-ep3-v2",
    "average": 44.33,
    "arc": 47.35,
    "hellaswag": 75.88,
    "mmlu": 43.84,
    "truthfulqa": 30.16,
    "winogrande": 68.75,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "679c6cb9e869df686b1ae415ed440e6cfc05f80b",
    "model_name_for_query": "luffycodes/llama-shishya-7b-ep3-v2",
    "link": "https://huggingface.co/luffycodes/llama-shishya-7b-ep3-v2",
    "author": "luffycodes"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-34b-Instruct-hf",
    "average": 44.33,
    "arc": 40.78,
    "hellaswag": 35.66,
    "mmlu": 39.72,
    "truthfulqa": 44.29,
    "winogrande": 74.51,
    "gsm8k": 31.01,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.74,
    "likes": 154.0,
    "still_on_hub": true,
    "revision": "c109b9dde086b31725fa09ff7effdc04c03c033d",
    "model_name_for_query": "codellama/CodeLlama-34b-Instruct-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf",
    "author": "codellama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "koala-7B-HF",
    "average": 44.29,
    "arc": 47.1,
    "hellaswag": 73.58,
    "mmlu": 25.53,
    "truthfulqa": 45.96,
    "winogrande": 69.93,
    "gsm8k": 3.64,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "d102fe3b68f1a5a50d547e4fd1c8b33b783c993b",
    "model_name_for_query": "TheBloke/koala-7B-HF",
    "link": "https://huggingface.co/TheBloke/koala-7B-HF",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-7b",
    "average": 44.28,
    "arc": 47.7,
    "hellaswag": 77.57,
    "mmlu": 30.8,
    "truthfulqa": 33.44,
    "winogrande": 72.14,
    "gsm8k": 4.02,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.65,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b772e556c8e8a17d087db6935e7cd019e5eefb0f",
    "model_name_for_query": "anas-awadalla/mpt-7b",
    "link": "https://huggingface.co/anas-awadalla/mpt-7b",
    "author": "anas-awadalla"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "mpt-7b",
    "average": 44.28,
    "arc": 47.7,
    "hellaswag": 77.57,
    "mmlu": 30.8,
    "truthfulqa": 33.44,
    "winogrande": 72.14,
    "gsm8k": 4.02,
    "model_type": "pretrained",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 1083.0,
    "still_on_hub": true,
    "revision": "72e5f594ce36f9cabfa2a9fd8f58b491eb467ee7",
    "model_name_for_query": "mosaicml/mpt-7b",
    "link": "https://huggingface.co/mosaicml/mpt-7b",
    "author": "mosaicml"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "open_llama_7b_v2",
    "average": 44.26,
    "arc": 43.69,
    "hellaswag": 72.2,
    "mmlu": 41.29,
    "truthfulqa": 35.54,
    "winogrande": 69.38,
    "gsm8k": 3.49,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 86.0,
    "still_on_hub": true,
    "revision": "e5961def23172a2384543940e773ab676033c963",
    "model_name_for_query": "openlm-research/open_llama_7b_v2",
    "link": "https://huggingface.co/openlm-research/open_llama_7b_v2",
    "author": "openlm-research"
  },
  {
    "T": "\u2b55",
    "model": "palmyra-20b-chat",
    "average": 44.18,
    "arc": 43.52,
    "hellaswag": 72.83,
    "mmlu": 35.18,
    "truthfulqa": 43.17,
    "winogrande": 66.46,
    "gsm8k": 3.94,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 20.26,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "3b7442b7e2240846bc9cfac545bd8861c1660aa2",
    "model_name_for_query": "Writer/palmyra-20b-chat",
    "link": "https://huggingface.co/Writer/palmyra-20b-chat",
    "author": "Writer"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "falcon-7b",
    "average": 44.17,
    "arc": 47.87,
    "hellaswag": 78.13,
    "mmlu": 27.79,
    "truthfulqa": 34.26,
    "winogrande": 72.38,
    "gsm8k": 4.62,
    "model_type": "pretrained",
    "architecture": "RWForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.92,
    "likes": 885.0,
    "still_on_hub": true,
    "revision": "378337427557d1df3e742264a2901a49f25d4eb1",
    "model_name_for_query": "tiiuae/falcon-7b",
    "link": "https://huggingface.co/tiiuae/falcon-7b",
    "author": "tiiuae"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-airoboros-orca-platypus-13b",
    "average": 44.1,
    "arc": 44.88,
    "hellaswag": 67.7,
    "mmlu": 43.16,
    "truthfulqa": 40.88,
    "winogrande": 66.14,
    "gsm8k": 1.82,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f01d3ab70cc23e31dcf5d6418406b08dc2003153",
    "model_name_for_query": "speechlessai/speechless-codellama-airoboros-orca-platypus-13b",
    "link": "https://huggingface.co/speechlessai/speechless-codellama-airoboros-orca-platypus-13b",
    "author": "speechlessai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-JT-6B-v0",
    "average": 44.05,
    "arc": 42.06,
    "hellaswag": 67.96,
    "mmlu": 49.34,
    "truthfulqa": 38.89,
    "winogrande": 64.8,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "41bd1937dbc51f9e589d310bddab5b4c1409e783",
    "model_name_for_query": "togethercomputer/GPT-JT-6B-v0",
    "link": "https://huggingface.co/togethercomputer/GPT-JT-6B-v0",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-class-shishya-7b-ep3",
    "average": 43.88,
    "arc": 40.78,
    "hellaswag": 77.04,
    "mmlu": 46.74,
    "truthfulqa": 27.94,
    "winogrande": 70.8,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "92802ec9c58b1ed64d758c0f0c8420f4000636ff",
    "model_name_for_query": "luffycodes/llama-class-shishya-7b-ep3",
    "link": "https://huggingface.co/luffycodes/llama-class-shishya-7b-ep3",
    "author": "luffycodes"
  },
  {
    "T": "\ud83d\udd36",
    "model": "BigTranslate-13B-GPTQ",
    "average": 43.86,
    "arc": 45.31,
    "hellaswag": 75.1,
    "mmlu": 31.18,
    "truthfulqa": 40.6,
    "winogrande": 70.96,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 17.99,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "f2968552d2f522023f3289747234aea5508980e2",
    "model_name_for_query": "TheBloke/BigTranslate-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/BigTranslate-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "gpt-sw3-20b-instruct",
    "average": 43.7,
    "arc": 43.17,
    "hellaswag": 71.09,
    "mmlu": 31.32,
    "truthfulqa": 41.02,
    "winogrande": 66.77,
    "gsm8k": 8.79,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 20.92,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "006477ad4c4875611f20cd927f1fd76bbf5ba5ba",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-20b-instruct",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-20b-instruct",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\u2b55",
    "model": "Llama-2-7b-hf-flan2022-1.2M",
    "average": 43.68,
    "arc": 23.29,
    "hellaswag": 78.46,
    "mmlu": 42.33,
    "truthfulqa": 37.97,
    "winogrande": 75.53,
    "gsm8k": 4.47,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "792f946a1413a7c58378d7a350b7d75b9df80561",
    "model_name_for_query": "synapsoft/Llama-2-7b-hf-flan2022-1.2M",
    "link": "https://huggingface.co/synapsoft/Llama-2-7b-hf-flan2022-1.2M",
    "author": "synapsoft"
  },
  {
    "T": "\u2b55",
    "model": "falcon_7b_3epoch_norobots",
    "average": 43.65,
    "arc": 47.61,
    "hellaswag": 77.24,
    "mmlu": 29.73,
    "truthfulqa": 36.27,
    "winogrande": 69.53,
    "gsm8k": 1.52,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "55b11c279d1a5b83f59cec0381fb41c31fd02d8d",
    "model_name_for_query": "souvik0306/falcon_7b_3epoch_norobots",
    "link": "https://huggingface.co/souvik0306/falcon_7b_3epoch_norobots",
    "author": "souvik0306"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ko-ref-llama2-13b",
    "average": 43.62,
    "arc": 48.38,
    "hellaswag": 73.56,
    "mmlu": 34.83,
    "truthfulqa": 35.82,
    "winogrande": 69.14,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c5d09631c88ab5012b48187ecd90ae773cd4bbd9",
    "model_name_for_query": "hyunseoki/ko-ref-llama2-13b",
    "link": "https://huggingface.co/hyunseoki/ko-ref-llama2-13b",
    "author": "hyunseoki"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-sw3-40b",
    "average": 43.42,
    "arc": 43.0,
    "hellaswag": 72.37,
    "mmlu": 34.97,
    "truthfulqa": 37.52,
    "winogrande": 67.96,
    "gsm8k": 4.7,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "other",
    "params": 39.93,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "ed18193e7292b5a821e5271d5dac95fffdf9617c",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-40b",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-40b",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLlama-13b-hf",
    "average": 43.35,
    "arc": 40.87,
    "hellaswag": 63.35,
    "mmlu": 32.81,
    "truthfulqa": 43.79,
    "winogrande": 67.17,
    "gsm8k": 12.13,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b7cfbbce945b966607d15ae275704922a6d04afc",
    "model_name_for_query": "NousResearch/CodeLlama-13b-hf",
    "link": "https://huggingface.co/NousResearch/CodeLlama-13b-hf",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "CodeLlama-13b-hf",
    "average": 43.35,
    "arc": 40.87,
    "hellaswag": 63.35,
    "mmlu": 32.81,
    "truthfulqa": 43.79,
    "winogrande": 67.17,
    "gsm8k": 12.13,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "55876f398020b287ac845b34ca08089acf4f4bc3",
    "model_name_for_query": "codellama/CodeLlama-13b-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-13b-hf",
    "author": "codellama"
  },
  {
    "T": "?",
    "model": "tigerbot-7b-sft",
    "average": 43.35,
    "arc": 41.64,
    "hellaswag": 60.56,
    "mmlu": 29.89,
    "truthfulqa": 58.18,
    "winogrande": 63.54,
    "gsm8k": 6.29,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.07,
    "likes": 13.0,
    "still_on_hub": false,
    "revision": "98b847905d63f74624e834db1ff95ee2814cbbd3",
    "model_name_for_query": "TigerResearch/tigerbot-7b-sft",
    "link": "https://huggingface.co/TigerResearch/tigerbot-7b-sft",
    "author": "TigerResearch"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "calm2-7b-chat",
    "average": 43.27,
    "arc": 40.27,
    "hellaswag": 68.12,
    "mmlu": 39.39,
    "truthfulqa": 41.96,
    "winogrande": 64.96,
    "gsm8k": 4.93,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 43.0,
    "still_on_hub": true,
    "revision": "f666a1e43500643cb3ff8c988a6ea5b56afe934a",
    "model_name_for_query": "cyberagent/calm2-7b-chat",
    "link": "https://huggingface.co/cyberagent/calm2-7b-chat",
    "author": "cyberagent"
  },
  {
    "T": "\u2b55",
    "model": "falcon-7b-instruct",
    "average": 43.26,
    "arc": 46.16,
    "hellaswag": 70.85,
    "mmlu": 25.84,
    "truthfulqa": 44.08,
    "winogrande": 67.96,
    "gsm8k": 4.7,
    "model_type": "instruction-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.92,
    "likes": 676.0,
    "still_on_hub": true,
    "revision": "cf4b3c42ce2fdfe24f753f0f0d179202fea59c99",
    "model_name_for_query": "tiiuae/falcon-7b-instruct",
    "link": "https://huggingface.co/tiiuae/falcon-7b-instruct",
    "author": "tiiuae"
  },
  {
    "T": "?",
    "model": "Guanaco",
    "average": 43.25,
    "arc": 50.17,
    "hellaswag": 72.69,
    "mmlu": 30.3,
    "truthfulqa": 37.64,
    "winogrande": 68.67,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 6.61,
    "likes": 213.0,
    "still_on_hub": true,
    "revision": "bed6f3bd18f07a4a379525645cbd86d622b12836",
    "model_name_for_query": "JosephusCheung/Guanaco",
    "link": "https://huggingface.co/JosephusCheung/Guanaco",
    "author": "JosephusCheung"
  },
  {
    "T": "?",
    "model": "minima-3b-layla-v1",
    "average": 43.21,
    "arc": 42.32,
    "hellaswag": 67.48,
    "mmlu": 28.44,
    "truthfulqa": 46.46,
    "winogrande": 65.9,
    "gsm8k": 8.64,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 3.0,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "844bfa44b1b3cdd1c0e39c13fbb2fdaee82ff874",
    "model_name_for_query": "l3utterfly/minima-3b-layla-v1",
    "link": "https://huggingface.co/l3utterfly/minima-3b-layla-v1",
    "author": "l3utterfly"
  },
  {
    "T": "\u2b55",
    "model": "falcon-7b-instruct",
    "average": 43.16,
    "arc": 45.82,
    "hellaswag": 70.78,
    "mmlu": 25.66,
    "truthfulqa": 44.07,
    "winogrande": 68.03,
    "gsm8k": 4.62,
    "model_type": "instruction-tuned",
    "architecture": "RWForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 6.92,
    "likes": 676.0,
    "still_on_hub": true,
    "revision": "eb410fb6ffa9028e97adb801f0d6ec46d02f8b07",
    "model_name_for_query": "tiiuae/falcon-7b-instruct",
    "link": "https://huggingface.co/tiiuae/falcon-7b-instruct",
    "author": "tiiuae"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chinese-llama-2-7b",
    "average": 43.14,
    "arc": 44.45,
    "hellaswag": 69.5,
    "mmlu": 37.47,
    "truthfulqa": 37.0,
    "winogrande": 68.98,
    "gsm8k": 1.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.7,
    "likes": 64.0,
    "still_on_hub": true,
    "revision": "557b5cbd48a4a4eb5a08e975c4b6e11ac1ed4cbc",
    "model_name_for_query": "ziqingyang/chinese-llama-2-7b",
    "link": "https://huggingface.co/ziqingyang/chinese-llama-2-7b",
    "author": "ziqingyang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-JT-6B-v1",
    "average": 43.13,
    "arc": 40.87,
    "hellaswag": 67.15,
    "mmlu": 47.19,
    "truthfulqa": 37.07,
    "winogrande": 65.27,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 302.0,
    "still_on_hub": true,
    "revision": "f34aa35f906895602c1f86f5685e598afdea8051",
    "model_name_for_query": "togethercomputer/GPT-JT-6B-v1",
    "link": "https://huggingface.co/togethercomputer/GPT-JT-6B-v1",
    "author": "togethercomputer"
  },
  {
    "T": "\u2b55",
    "model": "ex-llm-e1",
    "average": 43.11,
    "arc": 39.93,
    "hellaswag": 68.11,
    "mmlu": 39.44,
    "truthfulqa": 42.01,
    "winogrande": 64.88,
    "gsm8k": 4.32,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "5838bea0ad7153520a0a105fb81c5b895820f710",
    "model_name_for_query": "u-chom/ex-llm-e1",
    "link": "https://huggingface.co/u-chom/ex-llm-e1",
    "author": "u-chom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FinanceConnect-13B",
    "average": 43.06,
    "arc": 55.12,
    "hellaswag": 77.73,
    "mmlu": 52.08,
    "truthfulqa": 0.0,
    "winogrande": 71.82,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "apache-2.0",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9ed6c7154cd14d1a5cdbec603a3ae8c8ce05cb29",
    "model_name_for_query": "ceadar-ie/FinanceConnect-13B",
    "link": "https://huggingface.co/ceadar-ie/FinanceConnect-13B",
    "author": "ceadar-ie"
  },
  {
    "T": "?",
    "model": "phoenix-inst-chat-7b",
    "average": 43.03,
    "arc": 44.71,
    "hellaswag": 63.23,
    "mmlu": 39.06,
    "truthfulqa": 47.08,
    "winogrande": 62.83,
    "gsm8k": 1.29,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.07,
    "likes": 44.0,
    "still_on_hub": true,
    "revision": "5ed4d9570e0f76e1becb05bf467a7b4ff7b66055",
    "model_name_for_query": "FreedomIntelligence/phoenix-inst-chat-7b",
    "link": "https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b",
    "author": "FreedomIntelligence"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-NeoXT-Chat-Base-20B",
    "average": 43.02,
    "arc": 45.65,
    "hellaswag": 74.03,
    "mmlu": 29.92,
    "truthfulqa": 34.51,
    "winogrande": 67.09,
    "gsm8k": 6.9,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.24,
    "likes": 691.0,
    "still_on_hub": true,
    "revision": "d386708e84d862a65f7d2b4989f64750cb657227",
    "model_name_for_query": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "link": "https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "galpaca-30b",
    "average": 43.0,
    "arc": 49.57,
    "hellaswag": 58.2,
    "mmlu": 43.78,
    "truthfulqa": 41.16,
    "winogrande": 62.51,
    "gsm8k": 2.81,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 29.97,
    "likes": 55.0,
    "still_on_hub": true,
    "revision": "a1f0c4bedd65b485a0d4d3a3bd60d7a4599f1eaf",
    "model_name_for_query": "GeorgiaTechResearchInstitute/galpaca-30b",
    "link": "https://huggingface.co/GeorgiaTechResearchInstitute/galpaca-30b",
    "author": "GeorgiaTechResearchInstitute"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-34B-Instruct-fp16",
    "average": 43.0,
    "arc": 40.78,
    "hellaswag": 35.66,
    "mmlu": 39.72,
    "truthfulqa": 44.29,
    "winogrande": 74.51,
    "gsm8k": 23.05,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.74,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "a4d0ce949de4d5b5f74691641efb5b70736a32a8",
    "model_name_for_query": "TheBloke/CodeLlama-34B-Instruct-fp16",
    "link": "https://huggingface.co/TheBloke/CodeLlama-34B-Instruct-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Anima-7B-100K",
    "average": 42.98,
    "arc": 46.59,
    "hellaswag": 72.28,
    "mmlu": 33.4,
    "truthfulqa": 37.84,
    "winogrande": 67.09,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "e303cf09e553c38ca5e0c0816d83631801ca5776",
    "model_name_for_query": "lyogavin/Anima-7B-100K",
    "link": "https://huggingface.co/lyogavin/Anima-7B-100K",
    "author": "lyogavin"
  },
  {
    "T": "\u2b55",
    "model": "InstructPalmyra-20b",
    "average": 42.91,
    "arc": 47.1,
    "hellaswag": 73.0,
    "mmlu": 28.26,
    "truthfulqa": 41.81,
    "winogrande": 64.72,
    "gsm8k": 2.58,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.26,
    "likes": 36.0,
    "still_on_hub": true,
    "revision": "c78df447c70d4677b128b1df864b9fff8338d900",
    "model_name_for_query": "Writer/InstructPalmyra-20b",
    "link": "https://huggingface.co/Writer/InstructPalmyra-20b",
    "author": "Writer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dopeyshearedplats-2.7b-v1",
    "average": 42.9,
    "arc": 46.08,
    "hellaswag": 75.17,
    "mmlu": 29.01,
    "truthfulqa": 44.12,
    "winogrande": 62.67,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 2.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c125218041c01662dc4c59b3f344aaa4e53dfd18",
    "model_name_for_query": "vihangd/dopeyshearedplats-2.7b-v1",
    "link": "https://huggingface.co/vihangd/dopeyshearedplats-2.7b-v1",
    "author": "vihangd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-neox-20b-full-precision",
    "average": 42.87,
    "arc": 48.81,
    "hellaswag": 74.44,
    "mmlu": 26.16,
    "truthfulqa": 36.89,
    "winogrande": 68.27,
    "gsm8k": 2.65,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 20.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "20b347273d90da7c2c9eb4c32d4173dba862a0d2",
    "model_name_for_query": "dvruette/gpt-neox-20b-full-precision",
    "link": "https://huggingface.co/dvruette/gpt-neox-20b-full-precision",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "landmark-attention-llama7b-fp16",
    "average": 42.84,
    "arc": 47.35,
    "hellaswag": 65.81,
    "mmlu": 31.59,
    "truthfulqa": 42.63,
    "winogrande": 68.03,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 8.0,
    "still_on_hub": false,
    "revision": "bf8bdcb0c30cceb0ceda33cf5fde683807e39a58",
    "model_name_for_query": "TheBloke/landmark-attention-llama7b-fp16",
    "link": "https://huggingface.co/TheBloke/landmark-attention-llama7b-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "opt-66b",
    "average": 42.78,
    "arc": 46.33,
    "hellaswag": 76.25,
    "mmlu": 26.99,
    "truthfulqa": 35.43,
    "winogrande": 70.01,
    "gsm8k": 1.67,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 65.72,
    "likes": 171.0,
    "still_on_hub": true,
    "revision": "7259969061237fe940036d22bea0fd349e4485e9",
    "model_name_for_query": "facebook/opt-66b",
    "link": "https://huggingface.co/facebook/opt-66b",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-7b-v2-open-instruct",
    "average": 42.75,
    "arc": 39.76,
    "hellaswag": 70.31,
    "mmlu": 35.16,
    "truthfulqa": 39.53,
    "winogrande": 64.33,
    "gsm8k": 7.43,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-3.0",
    "params": 6.61,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "b8fbe09571a71603ab517fe897a1281005060b62",
    "model_name_for_query": "Vmware/open-llama-7b-v2-open-instruct",
    "link": "https://huggingface.co/Vmware/open-llama-7b-v2-open-instruct",
    "author": "Vmware"
  },
  {
    "T": "\u2b55",
    "model": "tora-code-13b-v1.0",
    "average": 42.7,
    "arc": 44.45,
    "hellaswag": 69.29,
    "mmlu": 36.67,
    "truthfulqa": 34.98,
    "winogrande": 62.59,
    "gsm8k": 8.19,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4bf5b528d95a507b435c24a8986afe80d5951782",
    "model_name_for_query": "llm-agents/tora-code-13b-v1.0",
    "link": "https://huggingface.co/llm-agents/tora-code-13b-v1.0",
    "author": "llm-agents"
  },
  {
    "T": "?",
    "model": "open-llama-7b-open-instruct",
    "average": 42.59,
    "arc": 49.74,
    "hellaswag": 73.67,
    "mmlu": 31.52,
    "truthfulqa": 34.65,
    "winogrande": 65.43,
    "gsm8k": 0.53,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-3.0",
    "params": 6.61,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "fdf9f034163cce67e04d55172155f0e07b1b19a0",
    "model_name_for_query": "VMware/open-llama-7b-open-instruct",
    "link": "https://huggingface.co/VMware/open-llama-7b-open-instruct",
    "author": "VMware"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "codegen-16B-nl",
    "average": 42.59,
    "arc": 46.76,
    "hellaswag": 71.87,
    "mmlu": 32.35,
    "truthfulqa": 33.95,
    "winogrande": 67.96,
    "gsm8k": 2.65,
    "model_type": "pretrained",
    "architecture": "CodeGenForCausalLM",
    "precision": "float16",
    "license": "bsd-3-clause",
    "params": 15.72,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "b65951b0cf7c5639f73caea801a892788608ed69",
    "model_name_for_query": "Salesforce/codegen-16B-nl",
    "link": "https://huggingface.co/Salesforce/codegen-16B-nl",
    "author": "Salesforce"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-gm-oasst1-en-1024-20b",
    "average": 42.58,
    "arc": 48.04,
    "hellaswag": 72.76,
    "mmlu": 25.96,
    "truthfulqa": 39.92,
    "winogrande": 66.3,
    "gsm8k": 2.5,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.24,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "1a5b8d25587eab67d837621a6c9423e7ef6df289",
    "model_name_for_query": "h2oai/h2ogpt-gm-oasst1-en-1024-20b",
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-1024-20b",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-gpt-neox-20b-1000-steps",
    "average": 42.51,
    "arc": 48.55,
    "hellaswag": 74.61,
    "mmlu": 26.39,
    "truthfulqa": 35.63,
    "winogrande": 66.77,
    "gsm8k": 3.11,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 20.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4aec11ef19103796fb21387ce925b63c9d61dae1",
    "model_name_for_query": "dvruette/oasst-gpt-neox-20b-1000-steps",
    "link": "https://huggingface.co/dvruette/oasst-gpt-neox-20b-1000-steps",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-chat-hf-phr_mental_therapy",
    "average": 42.5,
    "arc": 38.82,
    "hellaswag": 72.76,
    "mmlu": 23.12,
    "truthfulqa": 46.92,
    "winogrande": 65.59,
    "gsm8k": 7.81,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "mit",
    "params": 13.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0fe5a48f3d99492cb180fc6efda5b138677ca1de",
    "model_name_for_query": "vibhorag101/llama-2-13b-chat-hf-phr_mental_therapy",
    "link": "https://huggingface.co/vibhorag101/llama-2-13b-chat-hf-phr_mental_therapy",
    "author": "vibhorag101"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-oasst1-512-20b",
    "average": 42.44,
    "arc": 46.93,
    "hellaswag": 72.77,
    "mmlu": 26.25,
    "truthfulqa": 37.5,
    "winogrande": 68.03,
    "gsm8k": 3.18,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.24,
    "likes": 38.0,
    "still_on_hub": true,
    "revision": "3bdf6f870ca14bcc5587b666fbe57488f7854d30",
    "model_name_for_query": "h2oai/h2ogpt-oasst1-512-20b",
    "link": "https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LL7M",
    "average": 42.38,
    "arc": 44.97,
    "hellaswag": 68.81,
    "mmlu": 34.44,
    "truthfulqa": 41.39,
    "winogrande": 64.09,
    "gsm8k": 0.61,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "cc-by-nc-nd-4.0",
    "params": 6.64,
    "likes": 34.0,
    "still_on_hub": true,
    "revision": "9b31bbf38a43d41eaf166fb3573f706b23cb1c13",
    "model_name_for_query": "JosephusCheung/LL7M",
    "link": "https://huggingface.co/JosephusCheung/LL7M",
    "author": "JosephusCheung"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-7B-Instruct",
    "average": 42.38,
    "arc": 44.11,
    "hellaswag": 72.02,
    "mmlu": 37.62,
    "truthfulqa": 33.96,
    "winogrande": 64.96,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 103.0,
    "still_on_hub": true,
    "revision": "95667a602ff2646bf67fe3a57c4eb9a1edec87fe",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-7B-Instruct",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Instruct-7B-v0.1",
    "average": 42.38,
    "arc": 44.11,
    "hellaswag": 72.02,
    "mmlu": 37.62,
    "truthfulqa": 33.96,
    "winogrande": 64.96,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 103.0,
    "still_on_hub": true,
    "revision": "95667a602ff2646bf67fe3a57c4eb9a1edec87fe",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "open_llama_7b",
    "average": 42.31,
    "arc": 47.01,
    "hellaswag": 71.98,
    "mmlu": 30.49,
    "truthfulqa": 34.85,
    "winogrande": 67.96,
    "gsm8k": 1.59,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 99.0,
    "still_on_hub": true,
    "revision": "6fb184ff23774c25bf84b3628e49c8b78372c7be",
    "model_name_for_query": "openlm-research/open_llama_7b",
    "link": "https://huggingface.co/openlm-research/open_llama_7b",
    "author": "openlm-research"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bloomz-7b1-mt-sft-chat",
    "average": 42.24,
    "arc": 44.03,
    "hellaswag": 62.6,
    "mmlu": 38.64,
    "truthfulqa": 44.34,
    "winogrande": 63.3,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "bfloat16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 7.07,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "8c2dc302780fe320ee3428f3db2ee7ff3684dcef",
    "model_name_for_query": "cmarkea/bloomz-7b1-mt-sft-chat",
    "link": "https://huggingface.co/cmarkea/bloomz-7b1-mt-sft-chat",
    "author": "cmarkea"
  },
  {
    "T": "\u2b55",
    "model": "Galpaca-30b-MiniOrca",
    "average": 42.23,
    "arc": 48.89,
    "hellaswag": 57.8,
    "mmlu": 43.72,
    "truthfulqa": 41.1,
    "winogrande": 60.06,
    "gsm8k": 1.82,
    "model_type": "instruction-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 29.97,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "681d92f8f71ca3e8425da19afee89ed84baedf1d",
    "model_name_for_query": "KnutJaegersberg/Galpaca-30b-MiniOrca",
    "link": "https://huggingface.co/KnutJaegersberg/Galpaca-30b-MiniOrca",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-12b-sft-v8-7k-steps",
    "average": 42.21,
    "arc": 44.03,
    "hellaswag": 70.28,
    "mmlu": 26.55,
    "truthfulqa": 36.53,
    "winogrande": 65.27,
    "gsm8k": 10.61,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.58,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "275c9b71bfab4e271d1ed85515c61e317b6ef65e",
    "model_name_for_query": "OpenAssistant/pythia-12b-sft-v8-7k-steps",
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-7k-steps",
    "author": "OpenAssistant"
  },
  {
    "T": "?",
    "model": "bloomz-7b1",
    "average": 42.21,
    "arc": 42.49,
    "hellaswag": 63.01,
    "mmlu": 37.85,
    "truthfulqa": 45.2,
    "winogrande": 64.64,
    "gsm8k": 0.08,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 7.07,
    "likes": 110.0,
    "still_on_hub": true,
    "revision": "2f4c4f3ebcf171dbbe2bae989ea2d2f3d3486a97",
    "model_name_for_query": "bigscience/bloomz-7b1",
    "link": "https://huggingface.co/bigscience/bloomz-7b1",
    "author": "bigscience"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open_llama_13b_600bt_preview",
    "average": 42.21,
    "arc": 44.28,
    "hellaswag": 72.43,
    "mmlu": 31.47,
    "truthfulqa": 34.66,
    "winogrande": 68.43,
    "gsm8k": 1.97,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3465eaca4d293ccc6ce66888e6c8bd9032ae7071",
    "model_name_for_query": "klosax/open_llama_13b_600bt_preview",
    "link": "https://huggingface.co/klosax/open_llama_13b_600bt_preview",
    "author": "klosax"
  },
  {
    "T": "?",
    "model": "Moderator-Chan_GPT-JT-6b",
    "average": 42.17,
    "arc": 43.69,
    "hellaswag": 70.77,
    "mmlu": 35.61,
    "truthfulqa": 36.05,
    "winogrande": 65.59,
    "gsm8k": 1.29,
    "model_type": "",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f2b7cda25f6965c1551fa78e9e38676994bc6638",
    "model_name_for_query": "TehVenom/Moderator-Chan_GPT-JT-6b",
    "link": "https://huggingface.co/TehVenom/Moderator-Chan_GPT-JT-6b",
    "author": "TehVenom"
  },
  {
    "T": "?",
    "model": "bloomz-7b1-mt",
    "average": 42.14,
    "arc": 43.86,
    "hellaswag": 62.91,
    "mmlu": 37.35,
    "truthfulqa": 45.65,
    "winogrande": 63.06,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 7.07,
    "likes": 120.0,
    "still_on_hub": true,
    "revision": "76875e6ea8df98157fb032c48ad6e354fd6a077b",
    "model_name_for_query": "bigscience/bloomz-7b1-mt",
    "link": "https://huggingface.co/bigscience/bloomz-7b1-mt",
    "author": "bigscience"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "palmyra-large",
    "average": 42.09,
    "arc": 44.97,
    "hellaswag": 71.85,
    "mmlu": 28.54,
    "truthfulqa": 35.93,
    "winogrande": 67.88,
    "gsm8k": 3.41,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.26,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "40086d791942cb28f55e679cd3fb6f6b5ba4effd",
    "model_name_for_query": "Writer/palmyra-large",
    "link": "https://huggingface.co/Writer/palmyra-large",
    "author": "Writer"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "rwkv-raven-14b",
    "average": 42.09,
    "arc": 44.62,
    "hellaswag": 71.25,
    "mmlu": 25.92,
    "truthfulqa": 41.93,
    "winogrande": 66.69,
    "gsm8k": 2.12,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.89,
    "likes": 47.0,
    "still_on_hub": true,
    "revision": "359c0649b4f1d10a26ebea32908035bc00d152ee",
    "model_name_for_query": "RWKV/rwkv-raven-14b",
    "link": "https://huggingface.co/RWKV/rwkv-raven-14b",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-6b-vicuna-chatml",
    "average": 42.08,
    "arc": 40.61,
    "hellaswag": 67.73,
    "mmlu": 33.92,
    "truthfulqa": 42.76,
    "winogrande": 63.06,
    "gsm8k": 4.4,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "ee3ada91a69a194cedfabbfeab98f1499b75cb44",
    "model_name_for_query": "AlekseyKorshuk/pygmalion-6b-vicuna-chatml",
    "link": "https://huggingface.co/AlekseyKorshuk/pygmalion-6b-vicuna-chatml",
    "author": "AlekseyKorshuk"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marx-3B-V2",
    "average": 42.08,
    "arc": 44.03,
    "hellaswag": 72.92,
    "mmlu": 27.84,
    "truthfulqa": 39.92,
    "winogrande": 66.54,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "5fba568304f6f876f5b9e42026f986ea245b836b",
    "model_name_for_query": "acrastt/Marx-3B-V2",
    "link": "https://huggingface.co/acrastt/Marx-3B-V2",
    "author": "acrastt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Orca-2-7B-16k",
    "average": 42.05,
    "arc": 50.6,
    "hellaswag": 63.89,
    "mmlu": 36.68,
    "truthfulqa": 45.37,
    "winogrande": 54.22,
    "gsm8k": 1.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.74,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "ab373033e98dcdbcc3aadb51374ae392656c6603",
    "model_name_for_query": "NurtureAI/Orca-2-7B-16k",
    "link": "https://huggingface.co/NurtureAI/Orca-2-7B-16k",
    "author": "NurtureAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-tora-code-7b-v1.0",
    "average": 42.04,
    "arc": 42.66,
    "hellaswag": 65.16,
    "mmlu": 38.56,
    "truthfulqa": 42.06,
    "winogrande": 62.9,
    "gsm8k": 0.91,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7b1f87a096045f1bba8f68c62e062102218717b",
    "model_name_for_query": "uukuguy/speechless-tora-code-7b-v1.0",
    "link": "https://huggingface.co/uukuguy/speechless-tora-code-7b-v1.0",
    "author": "uukuguy"
  },
  {
    "T": "\u2b55",
    "model": "open-llama-3b-v2-instruct",
    "average": 42.02,
    "arc": 38.48,
    "hellaswag": 70.24,
    "mmlu": 39.69,
    "truthfulqa": 37.96,
    "winogrande": 65.75,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4d50e134af1d9806cbdf6bc90795b44ae689deca",
    "model_name_for_query": "mediocredev/open-llama-3b-v2-instruct",
    "link": "https://huggingface.co/mediocredev/open-llama-3b-v2-instruct",
    "author": "mediocredev"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "opt-30b",
    "average": 42.0,
    "arc": 43.26,
    "hellaswag": 74.07,
    "mmlu": 26.66,
    "truthfulqa": 35.16,
    "winogrande": 70.64,
    "gsm8k": 2.2,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 29.98,
    "likes": 133.0,
    "still_on_hub": true,
    "revision": "ceea0a90ac0f6fae7c2c34bcb40477438c152546",
    "model_name_for_query": "facebook/opt-30b",
    "link": "https://huggingface.co/facebook/opt-30b",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-gpt-neox-20b-3000-steps",
    "average": 41.97,
    "arc": 46.42,
    "hellaswag": 72.08,
    "mmlu": 26.16,
    "truthfulqa": 35.53,
    "winogrande": 68.75,
    "gsm8k": 2.88,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 20.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f0462a8b7908f61202d86e6a9a2996d8339363b5",
    "model_name_for_query": "dvruette/oasst-gpt-neox-20b-3000-steps",
    "link": "https://huggingface.co/dvruette/oasst-gpt-neox-20b-3000-steps",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-12b-sft-v8-2.5k-steps",
    "average": 41.97,
    "arc": 42.32,
    "hellaswag": 70.15,
    "mmlu": 27.36,
    "truthfulqa": 36.75,
    "winogrande": 65.67,
    "gsm8k": 9.55,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.58,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "142e306db8e279a07c557ea5a919ab7e7a4af17c",
    "model_name_for_query": "OpenAssistant/pythia-12b-sft-v8-2.5k-steps",
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-2.5k-steps",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-gm-oasst1-multilang-1024-20b",
    "average": 41.9,
    "arc": 47.44,
    "hellaswag": 72.58,
    "mmlu": 26.37,
    "truthfulqa": 34.39,
    "winogrande": 68.43,
    "gsm8k": 2.2,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.24,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "b3a6bf4250a037c09e451344e2a4e987011b79de",
    "model_name_for_query": "h2oai/h2ogpt-gm-oasst1-multilang-1024-20b",
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-multilang-1024-20b",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "yayi-7b",
    "average": 41.88,
    "arc": 46.33,
    "hellaswag": 61.72,
    "mmlu": 36.34,
    "truthfulqa": 43.7,
    "winogrande": 62.27,
    "gsm8k": 0.91,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 7.07,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "00be6c9e41a8367a855c6f18ebfa08f5ecdb2cc4",
    "model_name_for_query": "wenge-research/yayi-7b",
    "link": "https://huggingface.co/wenge-research/yayi-7b",
    "author": "wenge-research"
  },
  {
    "T": "?",
    "model": "GPT-JT-Moderation-6B",
    "average": 41.8,
    "arc": 40.53,
    "hellaswag": 67.66,
    "mmlu": 41.63,
    "truthfulqa": 37.33,
    "winogrande": 62.67,
    "gsm8k": 0.99,
    "model_type": "",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 30.0,
    "still_on_hub": true,
    "revision": "1297870783f6091294769014afddf94499966a78",
    "model_name_for_query": "togethercomputer/GPT-JT-Moderation-6B",
    "link": "https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LongAlpaca-13B",
    "average": 41.74,
    "arc": 42.58,
    "hellaswag": 72.03,
    "mmlu": 34.91,
    "truthfulqa": 36.85,
    "winogrande": 64.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "e80966ae720de9a844441a4a2bbc661106969915",
    "model_name_for_query": "Yukang/LongAlpaca-13B",
    "link": "https://huggingface.co/Yukang/LongAlpaca-13B",
    "author": "Yukang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Barcenas-3b",
    "average": 41.74,
    "arc": 43.17,
    "hellaswag": 67.82,
    "mmlu": 29.16,
    "truthfulqa": 41.56,
    "winogrande": 66.22,
    "gsm8k": 2.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 3.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "2b6b8bfd3946c02fa4a5182ed008df8ad324a406",
    "model_name_for_query": "Danielbrdz/Barcenas-3b",
    "link": "https://huggingface.co/Danielbrdz/Barcenas-3b",
    "author": "Danielbrdz"
  },
  {
    "T": "\u2b55",
    "model": "gpt-sw3-6.7b-v2-instruct",
    "average": 41.72,
    "arc": 40.78,
    "hellaswag": 67.77,
    "mmlu": 31.57,
    "truthfulqa": 40.32,
    "winogrande": 63.54,
    "gsm8k": 6.37,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "81ca95a4e93746240994d1e6797ffa64dc796bd9",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marx-3B",
    "average": 41.71,
    "arc": 43.17,
    "hellaswag": 72.68,
    "mmlu": 28.46,
    "truthfulqa": 39.09,
    "winogrande": 65.59,
    "gsm8k": 1.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "c0dcc44989cf4e006efae31abbcef7e8be8547c0",
    "model_name_for_query": "acrastt/Marx-3B",
    "link": "https://huggingface.co/acrastt/Marx-3B",
    "author": "acrastt"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-neox-20b",
    "average": 41.69,
    "arc": 45.73,
    "hellaswag": 73.45,
    "mmlu": 25.0,
    "truthfulqa": 31.61,
    "winogrande": 68.9,
    "gsm8k": 5.46,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.74,
    "likes": 433.0,
    "still_on_hub": true,
    "revision": "9369f145ca7b66ef62760f9351af951b2d53b77f",
    "model_name_for_query": "EleutherAI/gpt-neox-20b",
    "link": "https://huggingface.co/EleutherAI/gpt-neox-20b",
    "author": "EleutherAI"
  },
  {
    "T": "?",
    "model": "pythia-12b-sft-v8-rlhf-2k-steps",
    "average": 41.65,
    "arc": 43.43,
    "hellaswag": 70.08,
    "mmlu": 26.12,
    "truthfulqa": 36.06,
    "winogrande": 64.64,
    "gsm8k": 9.55,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.58,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a0debfed4a020d449e3d00f4e75f2c2aefb68db3",
    "model_name_for_query": "OpenAssistant/pythia-12b-sft-v8-rlhf-2k-steps",
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-rlhf-2k-steps",
    "author": "OpenAssistant"
  },
  {
    "T": "\u2b55",
    "model": "shearedplats-2.7b-v2",
    "average": 41.61,
    "arc": 42.41,
    "hellaswag": 72.58,
    "mmlu": 27.52,
    "truthfulqa": 39.76,
    "winogrande": 65.9,
    "gsm8k": 1.52,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 2.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2837296f28d6aa0fb6c1fe382f553e65c8e1e5f3",
    "model_name_for_query": "vihangd/shearedplats-2.7b-v2",
    "link": "https://huggingface.co/vihangd/shearedplats-2.7b-v2",
    "author": "vihangd"
  },
  {
    "T": "\u2b55",
    "model": "MiniMerlin-3b-v0.1",
    "average": 41.6,
    "arc": 40.7,
    "hellaswag": 54.06,
    "mmlu": 43.32,
    "truthfulqa": 49.65,
    "winogrande": 60.54,
    "gsm8k": 1.36,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2addcbd985f8a7f8bb7a7c21a5ec0e2505e549c6",
    "model_name_for_query": "teilomillet/MiniMerlin-3b-v0.1",
    "link": "https://huggingface.co/teilomillet/MiniMerlin-3b-v0.1",
    "author": "teilomillet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "glaive-coder-7b",
    "average": 41.56,
    "arc": 42.66,
    "hellaswag": 64.69,
    "mmlu": 37.15,
    "truthfulqa": 39.88,
    "winogrande": 59.75,
    "gsm8k": 5.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 6.61,
    "likes": 43.0,
    "still_on_hub": true,
    "revision": "72a255a58480ef0713eed988312fe82f77f94f37",
    "model_name_for_query": "glaiveai/glaive-coder-7b",
    "link": "https://huggingface.co/glaiveai/glaive-coder-7b",
    "author": "glaiveai"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "RedPajama-INCITE-7B-Base",
    "average": 41.49,
    "arc": 46.25,
    "hellaswag": 71.63,
    "mmlu": 27.68,
    "truthfulqa": 33.03,
    "winogrande": 67.32,
    "gsm8k": 3.03,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 89.0,
    "still_on_hub": true,
    "revision": "78f7e482443971f4873ba3239f0ac810a367833b",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-7B-Base",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base",
    "author": "togethercomputer"
  },
  {
    "T": "?",
    "model": "gpt4all-j",
    "average": 41.49,
    "arc": 41.98,
    "hellaswag": 64.06,
    "mmlu": 28.2,
    "truthfulqa": 42.78,
    "winogrande": 64.72,
    "gsm8k": 7.2,
    "model_type": "",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 250.0,
    "still_on_hub": true,
    "revision": "73c15208cb608be2949b7c6e4ba6d88f0176c267",
    "model_name_for_query": "nomic-ai/gpt4all-j",
    "link": "https://huggingface.co/nomic-ai/gpt4all-j",
    "author": "nomic-ai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-pythia-12b-pretrained-sft",
    "average": 41.48,
    "arc": 45.31,
    "hellaswag": 67.67,
    "mmlu": 27.81,
    "truthfulqa": 38.16,
    "winogrande": 65.9,
    "gsm8k": 4.02,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 11.58,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c21fbece4253841f2d6e15f04f60fe1ba6f990dd",
    "model_name_for_query": "dvruette/oasst-pythia-12b-pretrained-sft",
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-pretrained-sft",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "average": 41.46,
    "arc": 41.81,
    "hellaswag": 73.01,
    "mmlu": 26.36,
    "truthfulqa": 38.99,
    "winogrande": 66.69,
    "gsm8k": 1.9,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4da0c661e6df1235c9997b996c8e395b87248406",
    "model_name_for_query": "harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "link": "https://huggingface.co/harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "author": "harborwater"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "MiniMA-3B",
    "average": 41.44,
    "arc": 43.43,
    "hellaswag": 68.06,
    "mmlu": 28.69,
    "truthfulqa": 39.76,
    "winogrande": 65.98,
    "gsm8k": 2.73,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "0a2f9d6bbb3959d68fe52e07ee6f54e8242f91ec",
    "model_name_for_query": "GeneZC/MiniMA-3B",
    "link": "https://huggingface.co/GeneZC/MiniMA-3B",
    "author": "GeneZC"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-everything-v2",
    "average": 41.41,
    "arc": 42.83,
    "hellaswag": 73.28,
    "mmlu": 26.87,
    "truthfulqa": 37.26,
    "winogrande": 66.61,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "31ce2c1611d9f7d56184ceb5bff6a7e95a180c03",
    "model_name_for_query": "harborwater/open-llama-3b-everything-v2",
    "link": "https://huggingface.co/harborwater/open-llama-3b-everything-v2",
    "author": "harborwater"
  },
  {
    "T": "?",
    "model": "ReasonixPajama-3B-HF has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/236\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #236</a>",
    "average": 41.41,
    "arc": 39.25,
    "hellaswag": 63.47,
    "mmlu": 26.09,
    "truthfulqa": 55.42,
    "winogrande": 63.69,
    "gsm8k": 0.53,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.91,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "fa87c904b5921231b9f6f94b9c537cdda8783b96",
    "model_name_for_query": "Fredithefish/ReasonixPajama-3B-HF",
    "link": "https://huggingface.co/Fredithefish/ReasonixPajama-3B-HF",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mommygpt-3B",
    "average": 41.36,
    "arc": 41.89,
    "hellaswag": 71.69,
    "mmlu": 28.74,
    "truthfulqa": 37.9,
    "winogrande": 65.82,
    "gsm8k": 2.12,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "0369335d693b753774050ae44dbaf73bac39e9eb",
    "model_name_for_query": "hakurei/mommygpt-3B",
    "link": "https://huggingface.co/hakurei/mommygpt-3B",
    "author": "hakurei"
  },
  {
    "T": "?",
    "model": "orca_mini_13b",
    "average": 41.36,
    "arc": 42.06,
    "hellaswag": 63.4,
    "mmlu": 35.43,
    "truthfulqa": 43.1,
    "winogrande": 64.17,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 12.85,
    "likes": 95.0,
    "still_on_hub": true,
    "revision": "ca900c8f3145de40cd188c559b2901a2e4711546",
    "model_name_for_query": "psmathur/orca_mini_13b",
    "link": "https://huggingface.co/psmathur/orca_mini_13b",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "nucleus-22B-token-500B",
    "average": 41.33,
    "arc": 40.7,
    "hellaswag": 69.39,
    "mmlu": 30.11,
    "truthfulqa": 39.16,
    "winogrande": 67.64,
    "gsm8k": 0.99,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 21.83,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "49bb1a47c0d32b4bfa6630a4eff04a857adcd4ca",
    "model_name_for_query": "NucleusAI/nucleus-22B-token-500B",
    "link": "https://huggingface.co/NucleusAI/nucleus-22B-token-500B",
    "author": "NucleusAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-34b-uncode",
    "average": 41.33,
    "arc": 39.51,
    "hellaswag": 33.9,
    "mmlu": 38.49,
    "truthfulqa": 40.94,
    "winogrande": 74.35,
    "gsm8k": 20.77,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 33.74,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "d434d06249feb6ca511b0a09162130bcc59d84e3",
    "model_name_for_query": "chargoddard/llama-2-34b-uncode",
    "link": "https://huggingface.co/chargoddard/llama-2-34b-uncode",
    "author": "chargoddard"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-sft-4-pythia-12b-epoch-3.5",
    "average": 41.31,
    "arc": 45.73,
    "hellaswag": 68.59,
    "mmlu": 26.82,
    "truthfulqa": 37.81,
    "winogrande": 65.9,
    "gsm8k": 3.03,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.58,
    "likes": 335.0,
    "still_on_hub": true,
    "revision": "626b8c140cfdedb119dfb78c626cd772283dee33",
    "model_name_for_query": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "link": "https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_7b",
    "average": 41.27,
    "arc": 43.94,
    "hellaswag": 65.22,
    "mmlu": 29.97,
    "truthfulqa": 42.03,
    "winogrande": 66.06,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 6.61,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "6ed0dca683685cb5b9e7df599f87d311f00ba6db",
    "model_name_for_query": "psmathur/orca_mini_7b",
    "link": "https://huggingface.co/psmathur/orca_mini_7b",
    "author": "psmathur"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-NeoX-20B-Erebus",
    "average": 41.26,
    "arc": 45.48,
    "hellaswag": 72.79,
    "mmlu": 26.77,
    "truthfulqa": 32.15,
    "winogrande": 68.11,
    "gsm8k": 2.27,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.24,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "1a80940a290452af71caf17a8e520955eb338e0f",
    "model_name_for_query": "KoboldAI/GPT-NeoX-20B-Erebus",
    "link": "https://huggingface.co/KoboldAI/GPT-NeoX-20B-Erebus",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "RedPajama-INCITE-Base-7B-v0.1",
    "average": 41.25,
    "arc": 46.25,
    "hellaswag": 71.63,
    "mmlu": 27.68,
    "truthfulqa": 33.03,
    "winogrande": 67.32,
    "gsm8k": 1.59,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 89.0,
    "still_on_hub": true,
    "revision": "78f7e482443971f4873ba3239f0ac810a367833b",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-Base-7B-v0.1",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-7B-v0.1",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mamba-gpt-3b-v4",
    "average": 41.24,
    "arc": 42.58,
    "hellaswag": 71.04,
    "mmlu": 30.04,
    "truthfulqa": 37.26,
    "winogrande": 65.82,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "49cdf710c1a9178ddf616da79211fdcdb2170c3f",
    "model_name_for_query": "CobraMamba/mamba-gpt-3b-v4",
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-3b-v4",
    "author": "CobraMamba"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-v2-elmv3",
    "average": 41.14,
    "arc": 42.06,
    "hellaswag": 73.28,
    "mmlu": 27.61,
    "truthfulqa": 35.54,
    "winogrande": 64.96,
    "gsm8k": 3.41,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7e43b199ff51dc0e63934ba49758a8a31ff855de",
    "model_name_for_query": "aloobun/open-llama-3b-v2-elmv3",
    "link": "https://huggingface.co/aloobun/open-llama-3b-v2-elmv3",
    "author": "aloobun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Griffin-3B",
    "average": 41.13,
    "arc": 41.81,
    "hellaswag": 72.3,
    "mmlu": 26.36,
    "truthfulqa": 38.33,
    "winogrande": 67.01,
    "gsm8k": 0.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "edbea6fe86d0bc2673c10269828008a1cb451919",
    "model_name_for_query": "acrastt/Griffin-3B",
    "link": "https://huggingface.co/acrastt/Griffin-3B",
    "author": "acrastt"
  },
  {
    "T": "\u2b55",
    "model": "shearedplats-2.7b-v2-instruct-v0.1",
    "average": 41.13,
    "arc": 40.19,
    "hellaswag": 70.08,
    "mmlu": 28.12,
    "truthfulqa": 41.23,
    "winogrande": 65.04,
    "gsm8k": 2.12,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8eb300dc6a62166048f7ec997a0a2d8d9a5708f2",
    "model_name_for_query": "mwitiderrick/shearedplats-2.7b-v2-instruct-v0.1",
    "link": "https://huggingface.co/mwitiderrick/shearedplats-2.7b-v2-instruct-v0.1",
    "author": "mwitiderrick"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-v2-elmv3",
    "average": 41.13,
    "arc": 42.15,
    "hellaswag": 73.26,
    "mmlu": 27.16,
    "truthfulqa": 35.51,
    "winogrande": 64.96,
    "gsm8k": 3.71,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7e43b199ff51dc0e63934ba49758a8a31ff855de",
    "model_name_for_query": "aloobun/open-llama-3b-v2-elmv3",
    "link": "https://huggingface.co/aloobun/open-llama-3b-v2-elmv3",
    "author": "aloobun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-0.7T-7B-open-instruct-v1.1",
    "average": 41.11,
    "arc": 46.67,
    "hellaswag": 67.67,
    "mmlu": 28.55,
    "truthfulqa": 37.6,
    "winogrande": 65.43,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc",
    "params": 6.61,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "75741b55ad462330e3498d1506f438f835152177",
    "model_name_for_query": "VMware/open-llama-0.7T-7B-open-instruct-v1.1",
    "link": "https://huggingface.co/VMware/open-llama-0.7T-7B-open-instruct-v1.1",
    "author": "VMware"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mamba-gpt-3b-v3",
    "average": 41.11,
    "arc": 41.72,
    "hellaswag": 71.05,
    "mmlu": 27.31,
    "truthfulqa": 37.86,
    "winogrande": 67.48,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "d860a90ef6b30c695b985dd2ff382d4bbb80e857",
    "model_name_for_query": "CobraMamba/mamba-gpt-3b-v3",
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-3b-v3",
    "author": "CobraMamba"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-12b-pre-v8-12.5k-steps",
    "average": 41.1,
    "arc": 41.47,
    "hellaswag": 68.8,
    "mmlu": 26.58,
    "truthfulqa": 36.82,
    "winogrande": 65.27,
    "gsm8k": 7.66,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.58,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "37ca702e957a4b740689d67c58c284224e2fbae2",
    "model_name_for_query": "OpenAssistant/pythia-12b-pre-v8-12.5k-steps",
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-pre-v8-12.5k-steps",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-NeoX-20B-Skein",
    "average": 41.1,
    "arc": 44.97,
    "hellaswag": 72.68,
    "mmlu": 25.99,
    "truthfulqa": 31.64,
    "winogrande": 68.43,
    "gsm8k": 2.88,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 20.24,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "dd98d514b5aff4e820922c88a73d6d5bf17f332e",
    "model_name_for_query": "KoboldAI/GPT-NeoX-20B-Skein",
    "link": "https://huggingface.co/KoboldAI/GPT-NeoX-20B-Skein",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "average": 41.09,
    "arc": 41.21,
    "hellaswag": 72.88,
    "mmlu": 25.39,
    "truthfulqa": 38.87,
    "winogrande": 66.61,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4da0c661e6df1235c9997b996c8e395b87248406",
    "model_name_for_query": "harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "link": "https://huggingface.co/harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "author": "harborwater"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenLlama-Platypus-3B",
    "average": 41.05,
    "arc": 41.21,
    "hellaswag": 71.67,
    "mmlu": 29.86,
    "truthfulqa": 36.45,
    "winogrande": 65.98,
    "gsm8k": 1.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 3.43,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d3a0bf8e1181be02cc9c4c4cdfedaedacaefbfac",
    "model_name_for_query": "RobbeD/OpenLlama-Platypus-3B",
    "link": "https://huggingface.co/RobbeD/OpenLlama-Platypus-3B",
    "author": "RobbeD"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Puma-3B",
    "average": 41.02,
    "arc": 41.3,
    "hellaswag": 71.85,
    "mmlu": 27.51,
    "truthfulqa": 38.34,
    "winogrande": 66.38,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "1159e9cdd05c03d31331f329ba58e4e3444943be",
    "model_name_for_query": "acrastt/Puma-3B",
    "link": "https://huggingface.co/acrastt/Puma-3B",
    "author": "acrastt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wizard-orca-3b",
    "average": 41.0,
    "arc": 41.72,
    "hellaswag": 71.78,
    "mmlu": 24.49,
    "truthfulqa": 40.04,
    "winogrande": 66.93,
    "gsm8k": 1.06,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "ffc81b58375342f12e38a67272d95458a72e8d09",
    "model_name_for_query": "harborwater/wizard-orca-3b",
    "link": "https://huggingface.co/harborwater/wizard-orca-3b",
    "author": "harborwater"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-claude-30k",
    "average": 40.93,
    "arc": 41.72,
    "hellaswag": 72.64,
    "mmlu": 24.03,
    "truthfulqa": 38.46,
    "winogrande": 66.54,
    "gsm8k": 2.2,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "049db7fda44e5ce1e8febf5c3f45e3a93aaaa859",
    "model_name_for_query": "harborwater/open-llama-3b-claude-30k",
    "link": "https://huggingface.co/harborwater/open-llama-3b-claude-30k",
    "author": "harborwater"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Sheared-LLaMA-2.7B",
    "average": 40.84,
    "arc": 41.72,
    "hellaswag": 71.01,
    "mmlu": 26.92,
    "truthfulqa": 37.32,
    "winogrande": 67.01,
    "gsm8k": 1.06,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.62,
    "likes": 24.0,
    "still_on_hub": true,
    "revision": "16347024c4df6cd114720958964a850fc287cac0",
    "model_name_for_query": "princeton-nlp/Sheared-LLaMA-2.7B",
    "link": "https://huggingface.co/princeton-nlp/Sheared-LLaMA-2.7B",
    "author": "princeton-nlp"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-R",
    "average": 40.8,
    "arc": 41.21,
    "hellaswag": 66.89,
    "mmlu": 36.5,
    "truthfulqa": 34.22,
    "winogrande": 64.4,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "bigscience-openrail-m",
    "params": 5.84,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "92b955a3ff74aa577fa0d8517dfc314847ef60af",
    "model_name_for_query": "digitous/GPT-R",
    "link": "https://huggingface.co/digitous/GPT-R",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ShortKing-3b-v0.3",
    "average": 40.8,
    "arc": 40.96,
    "hellaswag": 70.72,
    "mmlu": 26.21,
    "truthfulqa": 38.78,
    "winogrande": 66.93,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-4.0",
    "params": 3.43,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4bcf1610eb1f3959568d5acee74833c41502bf04",
    "model_name_for_query": "AtAndDev/ShortKing-3b-v0.3",
    "link": "https://huggingface.co/AtAndDev/ShortKing-3b-v0.3",
    "author": "AtAndDev"
  },
  {
    "T": "?",
    "model": "oasst-pythia-12b-6000-steps",
    "average": 40.77,
    "arc": 45.39,
    "hellaswag": 69.68,
    "mmlu": 25.97,
    "truthfulqa": 39.85,
    "winogrande": 63.22,
    "gsm8k": 0.53,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 11.58,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e2ccc0ef8d1cc5ffc8b0e2e885f03ef50597ea8a",
    "model_name_for_query": "dvruette/oasst-pythia-12b-6000-steps",
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-6000-steps",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-sft-1-pythia-12b",
    "average": 40.77,
    "arc": 46.42,
    "hellaswag": 70.0,
    "mmlu": 26.19,
    "truthfulqa": 39.19,
    "winogrande": 62.19,
    "gsm8k": 0.61,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.58,
    "likes": 277.0,
    "still_on_hub": true,
    "revision": "293df535fe7711a5726987fc2f17dfc87de452a1",
    "model_name_for_query": "OpenAssistant/oasst-sft-1-pythia-12b",
    "link": "https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gogpt-7b-bloom",
    "average": 40.75,
    "arc": 44.62,
    "hellaswag": 62.56,
    "mmlu": 33.81,
    "truthfulqa": 40.61,
    "winogrande": 62.9,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.07,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "8f9996f852db583b982efbd671465d18ad13ffae",
    "model_name_for_query": "golaxy/gogpt-7b-bloom",
    "link": "https://huggingface.co/golaxy/gogpt-7b-bloom",
    "author": "golaxy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ko-ref-llama2-7b",
    "average": 40.75,
    "arc": 42.66,
    "hellaswag": 66.58,
    "mmlu": 30.41,
    "truthfulqa": 38.62,
    "winogrande": 66.22,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1ee08c79ae7393473754b77e82b1472ef63d5dd2",
    "model_name_for_query": "hyunseoki/ko-ref-llama2-7b",
    "link": "https://huggingface.co/hyunseoki/ko-ref-llama2-7b",
    "author": "hyunseoki"
  },
  {
    "T": "?",
    "model": "oasst-pythia-12b-flash-attn-5000-steps",
    "average": 40.73,
    "arc": 44.97,
    "hellaswag": 69.75,
    "mmlu": 26.64,
    "truthfulqa": 38.89,
    "winogrande": 63.14,
    "gsm8k": 0.99,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 11.58,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5227ec9c9def4b0bdf6c7ad95d9f77cbf458283d",
    "model_name_for_query": "dvruette/oasst-pythia-12b-flash-attn-5000-steps",
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-flash-attn-5000-steps",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-sw3-20b",
    "average": 40.71,
    "arc": 41.81,
    "hellaswag": 68.75,
    "mmlu": 28.47,
    "truthfulqa": 37.1,
    "winogrande": 67.17,
    "gsm8k": 0.99,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 20.92,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "36797b7835a9e656af456e0006465a3af48735fc",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-20b",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-20b",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chatml-pyg-v1",
    "average": 40.7,
    "arc": 37.88,
    "hellaswag": 63.29,
    "mmlu": 32.77,
    "truthfulqa": 42.61,
    "winogrande": 62.51,
    "gsm8k": 5.16,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "79d5a4d53953ca1c26bc2155f168b7e2108f377f",
    "model_name_for_query": "AlekseyKorshuk/chatml-pyg-v1",
    "link": "https://huggingface.co/AlekseyKorshuk/chatml-pyg-v1",
    "author": "AlekseyKorshuk"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-gm-oasst1-en-1024-12b",
    "average": 40.65,
    "arc": 43.09,
    "hellaswag": 69.75,
    "mmlu": 25.87,
    "truthfulqa": 38.0,
    "winogrande": 66.14,
    "gsm8k": 1.06,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.59,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "e547fffafb382fd39ef5de35ba3b5afc1b43e74d",
    "model_name_for_query": "h2oai/h2ogpt-gm-oasst1-en-1024-12b",
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-1024-12b",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fairseq-dense-13B",
    "average": 40.62,
    "arc": 40.36,
    "hellaswag": 75.51,
    "mmlu": 27.07,
    "truthfulqa": 32.83,
    "winogrande": 67.96,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.84,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "785793f6b216afd9fc664fc63e8e6c776a016825",
    "model_name_for_query": "KoboldAI/fairseq-dense-13B",
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-13B",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-everythingLM-2048",
    "average": 40.62,
    "arc": 42.75,
    "hellaswag": 71.72,
    "mmlu": 27.16,
    "truthfulqa": 34.26,
    "winogrande": 66.3,
    "gsm8k": 1.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "1f9e8d48163feb63ed190eaa982f393542a75d30",
    "model_name_for_query": "harborwater/open-llama-3b-everythingLM-2048",
    "link": "https://huggingface.co/harborwater/open-llama-3b-everythingLM-2048",
    "author": "harborwater"
  },
  {
    "T": "\u2b55",
    "model": "7B-redpajama-conditional-alpha",
    "average": 40.56,
    "arc": 42.58,
    "hellaswag": 69.91,
    "mmlu": 26.53,
    "truthfulqa": 36.42,
    "winogrande": 67.17,
    "gsm8k": 0.76,
    "model_type": "instruction-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.65,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "9a3f69a1eba3618930f222d4e013d534102a2af5",
    "model_name_for_query": "Rallio67/7B-redpajama-conditional-alpha",
    "link": "https://huggingface.co/Rallio67/7B-redpajama-conditional-alpha",
    "author": "Rallio67"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Javalion-R",
    "average": 40.51,
    "arc": 41.72,
    "hellaswag": 68.02,
    "mmlu": 30.81,
    "truthfulqa": 34.44,
    "winogrande": 65.43,
    "gsm8k": 2.65,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "b881231ab6ea85da2a9a139f282df85d1d18b002",
    "model_name_for_query": "digitous/Javalion-R",
    "link": "https://huggingface.co/digitous/Javalion-R",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-oasst1-512-12b",
    "average": 40.48,
    "arc": 42.32,
    "hellaswag": 70.24,
    "mmlu": 26.01,
    "truthfulqa": 36.41,
    "winogrande": 66.22,
    "gsm8k": 1.67,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.59,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "c6bb0fe363e0105839d34ca757793b61c9606f95",
    "model_name_for_query": "h2oai/h2ogpt-oasst1-512-12b",
    "link": "https://huggingface.co/h2oai/h2ogpt-oasst1-512-12b",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Javelin-R",
    "average": 40.39,
    "arc": 41.64,
    "hellaswag": 69.01,
    "mmlu": 30.7,
    "truthfulqa": 34.5,
    "winogrande": 64.8,
    "gsm8k": 1.67,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4c4a5caf5d9049a47f5565b72e5a53dede08ac8b",
    "model_name_for_query": "digitous/Javelin-R",
    "link": "https://huggingface.co/digitous/Javelin-R",
    "author": "digitous"
  },
  {
    "T": "?",
    "model": "oasst-pythia-12b-reference",
    "average": 40.33,
    "arc": 43.0,
    "hellaswag": 67.91,
    "mmlu": 28.33,
    "truthfulqa": 36.57,
    "winogrande": 64.96,
    "gsm8k": 1.21,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 11.58,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c5a9b7fad884e6c45ce5d2ca551aa1c03db6865f",
    "model_name_for_query": "dvruette/oasst-pythia-12b-reference",
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-reference",
    "author": "dvruette"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardCoder-Python-7B-V1.0",
    "average": 40.32,
    "arc": 41.81,
    "hellaswag": 65.06,
    "mmlu": 32.29,
    "truthfulqa": 36.32,
    "winogrande": 61.72,
    "gsm8k": 4.7,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 44.0,
    "still_on_hub": true,
    "revision": "e40673a27a4aefcff2c6d2b3b1e0681a38703e4e",
    "model_name_for_query": "WizardLM/WizardCoder-Python-7B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardCoder-Python-7B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-13b-deduped-green_devil",
    "average": 40.31,
    "arc": 42.32,
    "hellaswag": 68.89,
    "mmlu": 26.01,
    "truthfulqa": 35.56,
    "winogrande": 66.93,
    "gsm8k": 2.12,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 11.58,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "7faeb395c26189eeab9bf3a98994696687ad31a3",
    "model_name_for_query": "Pirr/pythia-13b-deduped-green_devil",
    "link": "https://huggingface.co/Pirr/pythia-13b-deduped-green_devil",
    "author": "Pirr"
  },
  {
    "T": "\u2b55",
    "model": "smartyplats-3b-v2",
    "average": 40.29,
    "arc": 41.04,
    "hellaswag": 71.19,
    "mmlu": 24.32,
    "truthfulqa": 36.66,
    "winogrande": 66.93,
    "gsm8k": 1.59,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "920609897049f674bc4a9678579f6869f6cbed13",
    "model_name_for_query": "vihangd/smartyplats-3b-v2",
    "link": "https://huggingface.co/vihangd/smartyplats-3b-v2",
    "author": "vihangd"
  },
  {
    "T": "\u2b55",
    "model": "openllama_3b_EvolInstruct_lora_merged",
    "average": 40.28,
    "arc": 40.27,
    "hellaswag": 71.6,
    "mmlu": 27.12,
    "truthfulqa": 34.78,
    "winogrande": 67.01,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-4.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c55e3e114951346f273c519d266170e4d52781e9",
    "model_name_for_query": "KnutJaegersberg/openllama_3b_EvolInstruct_lora_merged",
    "link": "https://huggingface.co/KnutJaegersberg/openllama_3b_EvolInstruct_lora_merged",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "open_llama_3b_v2",
    "average": 40.28,
    "arc": 40.27,
    "hellaswag": 71.6,
    "mmlu": 27.12,
    "truthfulqa": 34.78,
    "winogrande": 67.01,
    "gsm8k": 0.91,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.32,
    "likes": 61.0,
    "still_on_hub": true,
    "revision": "bce5d60d3b0c68318862270ec4e794d83308d80a",
    "model_name_for_query": "openlm-research/open_llama_3b_v2",
    "link": "https://huggingface.co/openlm-research/open_llama_3b_v2",
    "author": "openlm-research"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-ko-7b-Chat",
    "average": 40.27,
    "arc": 40.44,
    "hellaswag": 67.16,
    "mmlu": 30.4,
    "truthfulqa": 35.48,
    "winogrande": 66.85,
    "gsm8k": 1.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.67,
    "likes": 51.0,
    "still_on_hub": true,
    "revision": "3293b98cd8204371988f898dafa9b5a297555cbe",
    "model_name_for_query": "kfkas/Llama-2-ko-7b-Chat",
    "link": "https://huggingface.co/kfkas/Llama-2-ko-7b-Chat",
    "author": "kfkas"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-34B-Python-fp16",
    "average": 40.27,
    "arc": 38.14,
    "hellaswag": 34.8,
    "mmlu": 32.95,
    "truthfulqa": 43.57,
    "winogrande": 72.14,
    "gsm8k": 20.02,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.74,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "875f9d97fb6c9619d8867887dd1d80918ff0f593",
    "model_name_for_query": "TheBloke/CodeLlama-34B-Python-fp16",
    "link": "https://huggingface.co/TheBloke/CodeLlama-34B-Python-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-34b-Python-hf",
    "average": 40.27,
    "arc": 40.19,
    "hellaswag": 36.82,
    "mmlu": 34.79,
    "truthfulqa": 44.28,
    "winogrande": 71.19,
    "gsm8k": 14.33,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 33.74,
    "likes": 61.0,
    "still_on_hub": true,
    "revision": "3dd8ab05bbd273b9f77088b1d4015b7f1848793d",
    "model_name_for_query": "codellama/CodeLlama-34b-Python-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-34b-Python-hf",
    "author": "codellama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-llama-3b-v2-layla",
    "average": 40.25,
    "arc": 38.23,
    "hellaswag": 66.43,
    "mmlu": 28.56,
    "truthfulqa": 44.4,
    "winogrande": 62.83,
    "gsm8k": 1.06,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "465669ddafad25393ac3cfe94d3726cced112b30",
    "model_name_for_query": "l3utterfly/open-llama-3b-v2-layla",
    "link": "https://huggingface.co/l3utterfly/open-llama-3b-v2-layla",
    "author": "l3utterfly"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-ko-7b-Chat",
    "average": 40.25,
    "arc": 40.44,
    "hellaswag": 67.12,
    "mmlu": 30.19,
    "truthfulqa": 35.45,
    "winogrande": 66.61,
    "gsm8k": 1.67,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 6.67,
    "likes": 51.0,
    "still_on_hub": true,
    "revision": "3293b98cd8204371988f898dafa9b5a297555cbe",
    "model_name_for_query": "kfkas/Llama-2-ko-7b-Chat",
    "link": "https://huggingface.co/kfkas/Llama-2-ko-7b-Chat",
    "author": "kfkas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Javelin-GPTJ",
    "average": 40.23,
    "arc": 42.66,
    "hellaswag": 70.45,
    "mmlu": 26.2,
    "truthfulqa": 36.08,
    "winogrande": 64.17,
    "gsm8k": 1.82,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "bee7068ab002784420a1a30170db3906185359f2",
    "model_name_for_query": "digitous/Javelin-GPTJ",
    "link": "https://huggingface.co/digitous/Javelin-GPTJ",
    "author": "digitous"
  },
  {
    "T": "\u2b55",
    "model": "tora-code-7b-v1.0",
    "average": 40.21,
    "arc": 40.7,
    "hellaswag": 65.86,
    "mmlu": 33.34,
    "truthfulqa": 34.84,
    "winogrande": 61.56,
    "gsm8k": 4.93,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "777501b69bb0ba2675abdcaf7b1309ab05320c2e",
    "model_name_for_query": "llm-agents/tora-code-7b-v1.0",
    "link": "https://huggingface.co/llm-agents/tora-code-7b-v1.0",
    "author": "llm-agents"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Janin-R",
    "average": 40.19,
    "arc": 40.44,
    "hellaswag": 67.36,
    "mmlu": 31.24,
    "truthfulqa": 34.49,
    "winogrande": 65.35,
    "gsm8k": 2.27,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f6963f77098d8421ff4a1cf4d36f1e94c6c8f44b",
    "model_name_for_query": "digitous/Janin-R",
    "link": "https://huggingface.co/digitous/Janin-R",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Bean-3B",
    "average": 40.18,
    "arc": 40.36,
    "hellaswag": 72.0,
    "mmlu": 26.43,
    "truthfulqa": 36.11,
    "winogrande": 65.67,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4a1ce189a3fb1d58b3fa47ebe30b3c037592670c",
    "model_name_for_query": "acrastt/Bean-3B",
    "link": "https://huggingface.co/acrastt/Bean-3B",
    "author": "acrastt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Flash-Llama-3B",
    "average": 40.13,
    "arc": 40.1,
    "hellaswag": 71.56,
    "mmlu": 26.88,
    "truthfulqa": 34.74,
    "winogrande": 66.61,
    "gsm8k": 0.91,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 3.32,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "b4c7bb49171ff6955cfc1f7e33143383c57f7606",
    "model_name_for_query": "TaylorAI/Flash-Llama-3B",
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-3B",
    "author": "TaylorAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dolly_Shygmalion-6b-Dev_V8P2",
    "average": 40.11,
    "arc": 41.38,
    "hellaswag": 67.67,
    "mmlu": 28.48,
    "truthfulqa": 36.86,
    "winogrande": 64.33,
    "gsm8k": 1.97,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "6413b1d9e8b58df9d3aac91a862e8d505d8c6716",
    "model_name_for_query": "TehVenom/Dolly_Shygmalion-6b-Dev_V8P2",
    "link": "https://huggingface.co/TehVenom/Dolly_Shygmalion-6b-Dev_V8P2",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-j-6b",
    "average": 40.1,
    "arc": 41.38,
    "hellaswag": 67.54,
    "mmlu": 26.78,
    "truthfulqa": 35.96,
    "winogrande": 65.98,
    "gsm8k": 2.96,
    "model_type": "pretrained",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 1290.0,
    "still_on_hub": true,
    "revision": "47e169305d2e8376be1d31e765533382721b2cc1",
    "model_name_for_query": "EleutherAI/gpt-j-6b",
    "link": "https://huggingface.co/EleutherAI/gpt-j-6b",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "calypso-3b-alpha-v2",
    "average": 40.09,
    "arc": 41.55,
    "hellaswag": 71.48,
    "mmlu": 25.82,
    "truthfulqa": 35.73,
    "winogrande": 65.27,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 3.32,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "933fb9db10f131f7ea54f4e6024ed2acf41c711a",
    "model_name_for_query": "Xilabs/calypso-3b-alpha-v2",
    "link": "https://huggingface.co/Xilabs/calypso-3b-alpha-v2",
    "author": "Xilabs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeBarcenas-7b",
    "average": 40.09,
    "arc": 42.32,
    "hellaswag": 63.43,
    "mmlu": 33.39,
    "truthfulqa": 38.51,
    "winogrande": 60.38,
    "gsm8k": 2.5,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fe7a232baac5394e821f349cb7ef31dbd4ca2078",
    "model_name_for_query": "Danielbrdz/CodeBarcenas-7b",
    "link": "https://huggingface.co/Danielbrdz/CodeBarcenas-7b",
    "author": "Danielbrdz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLlama-34b-hf",
    "average": 40.08,
    "arc": 37.54,
    "hellaswag": 31.84,
    "mmlu": 37.2,
    "truthfulqa": 38.89,
    "winogrande": 73.4,
    "gsm8k": 21.61,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 33.48,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "4e61ec70eb258047f5bc689fa6a66f7753da52b8",
    "model_name_for_query": "NousResearch/CodeLlama-34b-hf",
    "link": "https://huggingface.co/NousResearch/CodeLlama-34b-hf",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "opt-13b",
    "average": 40.06,
    "arc": 39.93,
    "hellaswag": 71.2,
    "mmlu": 24.9,
    "truthfulqa": 34.1,
    "winogrande": 68.51,
    "gsm8k": 1.74,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 59.0,
    "still_on_hub": true,
    "revision": "e515202d1e7750da62d245fbccb2723b9c1790f5",
    "model_name_for_query": "facebook/opt-13b",
    "link": "https://huggingface.co/facebook/opt-13b",
    "author": "facebook"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-7b-Instruct-hf",
    "average": 40.05,
    "arc": 36.52,
    "hellaswag": 55.44,
    "mmlu": 34.54,
    "truthfulqa": 41.25,
    "winogrande": 64.56,
    "gsm8k": 7.96,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.74,
    "likes": 76.0,
    "still_on_hub": true,
    "revision": "7affc442e639b8aa1c4b3e98a10a2f45a21b8b4f",
    "model_name_for_query": "codellama/CodeLlama-7b-Instruct-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf",
    "author": "codellama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-J-6B-Skein",
    "average": 40.02,
    "arc": 42.58,
    "hellaswag": 68.69,
    "mmlu": 24.88,
    "truthfulqa": 38.7,
    "winogrande": 63.85,
    "gsm8k": 1.44,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "acfe27303f74129930fef5e6fadbc5f58c6b8590",
    "model_name_for_query": "KoboldAI/GPT-J-6B-Skein",
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Skein",
    "author": "KoboldAI"
  },
  {
    "T": "\u2b55",
    "model": "smartyplats-3b-v1",
    "average": 40.0,
    "arc": 40.53,
    "hellaswag": 70.85,
    "mmlu": 25.31,
    "truthfulqa": 36.53,
    "winogrande": 65.75,
    "gsm8k": 1.06,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "89272b9edb323f5ace09e097a6449554c0dcd4e7",
    "model_name_for_query": "vihangd/smartyplats-3b-v1",
    "link": "https://huggingface.co/vihangd/smartyplats-3b-v1",
    "author": "vihangd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-tools-7b",
    "average": 40.0,
    "arc": 38.91,
    "hellaswag": 57.69,
    "mmlu": 33.24,
    "truthfulqa": 44.08,
    "winogrande": 58.56,
    "gsm8k": 7.51,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "81aefc8983d1192378c2c803f0e0d14d48561117",
    "model_name_for_query": "uukuguy/speechless-tools-7b",
    "link": "https://huggingface.co/uukuguy/speechless-tools-7b",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "codegen-6B-nl",
    "average": 40.0,
    "arc": 42.32,
    "hellaswag": 68.59,
    "mmlu": 25.93,
    "truthfulqa": 34.47,
    "winogrande": 66.46,
    "gsm8k": 2.2,
    "model_type": "pretrained",
    "architecture": "CodeGenForCausalLM",
    "precision": "float16",
    "license": "bsd-3-clause",
    "params": 6.85,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "dff91c0aea702edbea3528344d01d8b9aaee6e39",
    "model_name_for_query": "Salesforce/codegen-6B-nl",
    "link": "https://huggingface.co/Salesforce/codegen-6B-nl",
    "author": "Salesforce"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Javalion-GPTJ",
    "average": 39.97,
    "arc": 41.89,
    "hellaswag": 68.69,
    "mmlu": 26.85,
    "truthfulqa": 35.44,
    "winogrande": 65.27,
    "gsm8k": 1.67,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "3ce176bc0f91cae416c78e99f964f54b12472de0",
    "model_name_for_query": "digitous/Javalion-GPTJ",
    "link": "https://huggingface.co/digitous/Javalion-GPTJ",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
    "average": 39.95,
    "arc": 41.98,
    "hellaswag": 66.82,
    "mmlu": 25.69,
    "truthfulqa": 39.67,
    "winogrande": 64.88,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 3.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e471ec778771f29992293d1660cc108f29c9c69e",
    "model_name_for_query": "Aspik101/WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
    "link": "https://huggingface.co/Aspik101/WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "rwkv-4-14b-pile",
    "average": 39.92,
    "arc": 44.45,
    "hellaswag": 71.07,
    "mmlu": 26.12,
    "truthfulqa": 32.04,
    "winogrande": 65.43,
    "gsm8k": 0.38,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.89,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4effb0fa9d15c2f383a1d159f4a40df0e09eb6d5",
    "model_name_for_query": "RWKV/rwkv-4-14b-pile",
    "link": "https://huggingface.co/RWKV/rwkv-4-14b-pile",
    "author": "RWKV"
  },
  {
    "T": "?",
    "model": "WizardLM-30B-GPTQ",
    "average": 39.9,
    "arc": 28.84,
    "hellaswag": 26.08,
    "mmlu": 24.62,
    "truthfulqa": 49.14,
    "winogrande": 76.32,
    "gsm8k": 34.42,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 35.58,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "e2e97475a9775d2fe7afba098aee37e694b9220f",
    "model_name_for_query": "TheBloke/WizardLM-30B-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-30B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
    "average": 39.89,
    "arc": 41.3,
    "hellaswag": 62.44,
    "mmlu": 27.55,
    "truthfulqa": 42.0,
    "winogrande": 64.56,
    "gsm8k": 1.52,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "29604e6e19822531b0d49d3f19abef603a97d0ec",
    "model_name_for_query": "h2oai/h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dolly_Shygmalion-6b",
    "average": 39.89,
    "arc": 41.89,
    "hellaswag": 68.48,
    "mmlu": 27.58,
    "truthfulqa": 33.91,
    "winogrande": 65.35,
    "gsm8k": 2.12,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "108fabf8a916900525492c294c50998d7c09f10b",
    "model_name_for_query": "TehVenom/Dolly_Shygmalion-6b",
    "link": "https://huggingface.co/TehVenom/Dolly_Shygmalion-6b",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Skegma-GPTJ",
    "average": 39.87,
    "arc": 43.77,
    "hellaswag": 69.22,
    "mmlu": 25.37,
    "truthfulqa": 34.67,
    "winogrande": 64.64,
    "gsm8k": 1.52,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4dff006b2ea7e8d9b067dfe8af8ca1a16bc44dce",
    "model_name_for_query": "digitous/Skegma-GPTJ",
    "link": "https://huggingface.co/digitous/Skegma-GPTJ",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PPO_Shygmalion-V8p4_Dev-6b",
    "average": 39.85,
    "arc": 40.7,
    "hellaswag": 67.04,
    "mmlu": 29.31,
    "truthfulqa": 35.57,
    "winogrande": 63.93,
    "gsm8k": 2.58,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "fa3d503bca50c947e7a5bbde4bdd82f699f65c02",
    "model_name_for_query": "TehVenom/PPO_Shygmalion-V8p4_Dev-6b",
    "link": "https://huggingface.co/TehVenom/PPO_Shygmalion-V8p4_Dev-6b",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PPO_Pygway-V8p4_Dev-6b",
    "average": 39.85,
    "arc": 40.36,
    "hellaswag": 67.15,
    "mmlu": 29.3,
    "truthfulqa": 35.26,
    "winogrande": 64.4,
    "gsm8k": 2.65,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "f30709dba36c665869f9ac8cd0cef5a8a2e7c8df",
    "model_name_for_query": "TehVenom/PPO_Pygway-V8p4_Dev-6b",
    "link": "https://huggingface.co/TehVenom/PPO_Pygway-V8p4_Dev-6b",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pythia-Chat-Base-7B",
    "average": 39.81,
    "arc": 40.02,
    "hellaswag": 68.67,
    "mmlu": 27.44,
    "truthfulqa": 34.63,
    "winogrande": 64.01,
    "gsm8k": 4.09,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 61.0,
    "still_on_hub": true,
    "revision": "97aa918c383820e1a69f042801091d7deb996c20",
    "model_name_for_query": "togethercomputer/Pythia-Chat-Base-7B",
    "link": "https://huggingface.co/togethercomputer/Pythia-Chat-Base-7B",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLlama-7b-hf",
    "average": 39.81,
    "arc": 39.85,
    "hellaswag": 59.58,
    "mmlu": 30.47,
    "truthfulqa": 38.62,
    "winogrande": 64.88,
    "gsm8k": 5.46,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "855c92912ea4a8eb5f0be1db4bf776ffd0815dac",
    "model_name_for_query": "NousResearch/CodeLlama-7b-hf",
    "link": "https://huggingface.co/NousResearch/CodeLlama-7b-hf",
    "author": "NousResearch"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "CodeLlama-7b-hf",
    "average": 39.81,
    "arc": 39.93,
    "hellaswag": 60.8,
    "mmlu": 31.12,
    "truthfulqa": 37.82,
    "winogrande": 64.01,
    "gsm8k": 5.16,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 6.74,
    "likes": 145.0,
    "still_on_hub": true,
    "revision": "be52f4ad322f5a47da121c761aeb5ba20ed77b17",
    "model_name_for_query": "codellama/CodeLlama-7b-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-7b-hf",
    "author": "codellama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Dolly_Malion-6b",
    "average": 39.77,
    "arc": 42.83,
    "hellaswag": 68.43,
    "mmlu": 27.13,
    "truthfulqa": 33.03,
    "winogrande": 65.43,
    "gsm8k": 1.74,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f239eb8d24fe26db3b0a9a69115dc305fc9351af",
    "model_name_for_query": "TehVenom/Dolly_Malion-6b",
    "link": "https://huggingface.co/TehVenom/Dolly_Malion-6b",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardVicuna-Uncensored-3B-0719",
    "average": 39.73,
    "arc": 41.38,
    "hellaswag": 66.19,
    "mmlu": 26.53,
    "truthfulqa": 39.35,
    "winogrande": 63.77,
    "gsm8k": 1.14,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "36841c80535bc3e8403e3cc084e8e65884c75076",
    "model_name_for_query": "heegyu/WizardVicuna-Uncensored-3B-0719",
    "link": "https://huggingface.co/heegyu/WizardVicuna-Uncensored-3B-0719",
    "author": "heegyu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ChanMalion",
    "average": 39.73,
    "arc": 41.89,
    "hellaswag": 68.25,
    "mmlu": 27.29,
    "truthfulqa": 33.89,
    "winogrande": 65.35,
    "gsm8k": 1.67,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "2667b0e0b705ed23f81f3e2b69673d722e8f4964",
    "model_name_for_query": "TehVenom/ChanMalion",
    "link": "https://huggingface.co/TehVenom/ChanMalion",
    "author": "TehVenom"
  },
  {
    "T": "\u2b55",
    "model": "open_llama_3b_code_instruct_0.1",
    "average": 39.72,
    "arc": 41.21,
    "hellaswag": 66.96,
    "mmlu": 27.82,
    "truthfulqa": 35.01,
    "winogrande": 65.43,
    "gsm8k": 1.9,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "be8055f68a5d53321d98c2b3e0f153034303b96c",
    "model_name_for_query": "mwitiderrick/open_llama_3b_code_instruct_0.1",
    "link": "https://huggingface.co/mwitiderrick/open_llama_3b_code_instruct_0.1",
    "author": "mwitiderrick"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-12b-deduped",
    "average": 39.7,
    "arc": 41.38,
    "hellaswag": 70.26,
    "mmlu": 25.63,
    "truthfulqa": 33.0,
    "winogrande": 66.46,
    "gsm8k": 1.44,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.59,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "39c1bd94f9dbe4ebd1d191f364cb33a2e5c47707",
    "model_name_for_query": "EleutherAI/pythia-12b-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-12b-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Janin-GPTJ",
    "average": 39.67,
    "arc": 40.87,
    "hellaswag": 67.29,
    "mmlu": 27.4,
    "truthfulqa": 36.25,
    "winogrande": 64.25,
    "gsm8k": 1.97,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a6773861798f2abea3849514aa6f60961518af9c",
    "model_name_for_query": "digitous/Janin-GPTJ",
    "link": "https://huggingface.co/digitous/Janin-GPTJ",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-J-Pyg_PPO-6B-Dev-V8p4",
    "average": 39.61,
    "arc": 40.19,
    "hellaswag": 66.43,
    "mmlu": 30.39,
    "truthfulqa": 34.76,
    "winogrande": 64.01,
    "gsm8k": 1.9,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "bigscience-openrail-m",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "930dc82245c607ce43558a0e6c0225e77b341ea6",
    "model_name_for_query": "TehVenom/GPT-J-Pyg_PPO-6B-Dev-V8p4",
    "link": "https://huggingface.co/TehVenom/GPT-J-Pyg_PPO-6B-Dev-V8p4",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-13B-Erebus",
    "average": 39.61,
    "arc": 40.02,
    "hellaswag": 70.07,
    "mmlu": 25.32,
    "truthfulqa": 34.93,
    "winogrande": 66.54,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 149.0,
    "still_on_hub": true,
    "revision": "8a949353677d2b971910a6c4afcc70e95d838c2a",
    "model_name_for_query": "KoboldAI/OPT-13B-Erebus",
    "link": "https://huggingface.co/KoboldAI/OPT-13B-Erebus",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-13B-Nerybus-Mix",
    "average": 39.61,
    "arc": 39.85,
    "hellaswag": 70.6,
    "mmlu": 24.9,
    "truthfulqa": 34.02,
    "winogrande": 67.88,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 25.0,
    "still_on_hub": true,
    "revision": "c27a7e2360dd313406719980851e89abf46ebb13",
    "model_name_for_query": "KoboldAI/OPT-13B-Nerybus-Mix",
    "link": "https://huggingface.co/KoboldAI/OPT-13B-Nerybus-Mix",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-J-6B-Shinen",
    "average": 39.6,
    "arc": 39.85,
    "hellaswag": 67.06,
    "mmlu": 27.72,
    "truthfulqa": 36.94,
    "winogrande": 64.09,
    "gsm8k": 1.97,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 5.84,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "afa5a11b24cb23eee708e17c83b920a788e9e07b",
    "model_name_for_query": "KoboldAI/GPT-J-6B-Shinen",
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Shinen",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-j-6B-Dolly",
    "average": 39.6,
    "arc": 41.3,
    "hellaswag": 65.97,
    "mmlu": 26.78,
    "truthfulqa": 37.91,
    "winogrande": 64.72,
    "gsm8k": 0.91,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "83d8c754aac12f838d7c847d4352a09396c383d0",
    "model_name_for_query": "Corianas/gpt-j-6B-Dolly",
    "link": "https://huggingface.co/Corianas/gpt-j-6B-Dolly",
    "author": "Corianas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-J-Pyg_PPO-6B",
    "average": 39.6,
    "arc": 42.06,
    "hellaswag": 67.51,
    "mmlu": 28.52,
    "truthfulqa": 31.95,
    "winogrande": 64.72,
    "gsm8k": 2.81,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "bigscience-openrail-m",
    "params": 5.84,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "cde5bab3ae16e1704c5fec54a6a7ff1169c935e6",
    "model_name_for_query": "TehVenom/GPT-J-Pyg_PPO-6B",
    "link": "https://huggingface.co/TehVenom/GPT-J-Pyg_PPO-6B",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-J-6B-Janeway",
    "average": 39.54,
    "arc": 40.87,
    "hellaswag": 67.11,
    "mmlu": 27.45,
    "truthfulqa": 35.74,
    "winogrande": 64.72,
    "gsm8k": 1.36,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 5.84,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "036bb03496d648ddc8cf932ad91df8ef1287116c",
    "model_name_for_query": "KoboldAI/GPT-J-6B-Janeway",
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Janeway",
    "author": "KoboldAI"
  },
  {
    "T": "?",
    "model": "LightGPT",
    "average": 39.54,
    "arc": 39.93,
    "hellaswag": 63.82,
    "mmlu": 28.45,
    "truthfulqa": 36.69,
    "winogrande": 64.48,
    "gsm8k": 3.87,
    "model_type": "",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 64.0,
    "still_on_hub": true,
    "revision": "1f6ffd8f162030396a3bc1ca2e3504896dbe6434",
    "model_name_for_query": "amazon/LightGPT",
    "link": "https://huggingface.co/amazon/LightGPT",
    "author": "amazon"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-13B-Nerys-v2",
    "average": 39.53,
    "arc": 39.68,
    "hellaswag": 70.53,
    "mmlu": 25.36,
    "truthfulqa": 33.5,
    "winogrande": 67.88,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 12.85,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "b0aa4f3630356f7801ca083c00b03d03da13b8bb",
    "model_name_for_query": "KoboldAI/OPT-13B-Nerys-v2",
    "link": "https://huggingface.co/KoboldAI/OPT-13B-Nerys-v2",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Chat-3B-v1",
    "average": 39.53,
    "arc": 42.83,
    "hellaswag": 67.62,
    "mmlu": 26.23,
    "truthfulqa": 34.44,
    "winogrande": 65.51,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 115.0,
    "still_on_hub": true,
    "revision": "f0e0995eba801096ed04cb87931d96a8316871af",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-sw3-6.7b-v2",
    "average": 39.49,
    "arc": 39.42,
    "hellaswag": 66.39,
    "mmlu": 30.09,
    "truthfulqa": 35.6,
    "winogrande": 64.25,
    "gsm8k": 1.21,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7a7f93d4318658b354c5411cde64e9f0121f6b1f",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-6.7b-v2",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-6.7b-v2",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardVicuna-3B-0719",
    "average": 39.48,
    "arc": 40.7,
    "hellaswag": 65.45,
    "mmlu": 25.44,
    "truthfulqa": 40.71,
    "winogrande": 63.85,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "62d3d450b8ab2bd2fb9f82383b55d1ecae33a401",
    "model_name_for_query": "heegyu/WizardVicuna-3B-0719",
    "link": "https://huggingface.co/heegyu/WizardVicuna-3B-0719",
    "author": "heegyu"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolly-v2-12b",
    "average": 39.46,
    "arc": 42.41,
    "hellaswag": 72.53,
    "mmlu": 25.92,
    "truthfulqa": 33.83,
    "winogrande": 60.85,
    "gsm8k": 1.21,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 11.58,
    "likes": 1872.0,
    "still_on_hub": true,
    "revision": "19308160448536e378e3db21a73a751579ee7fdd",
    "model_name_for_query": "databricks/dolly-v2-12b",
    "link": "https://huggingface.co/databricks/dolly-v2-12b",
    "author": "databricks"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PPO_Pygway-6b-Mix",
    "average": 39.43,
    "arc": 41.81,
    "hellaswag": 67.77,
    "mmlu": 28.42,
    "truthfulqa": 32.5,
    "winogrande": 64.4,
    "gsm8k": 1.67,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.84,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "b31d25819e00d5031ccdb22a9584f0850dcfe39c",
    "model_name_for_query": "KoboldAI/PPO_Pygway-6b-Mix",
    "link": "https://huggingface.co/KoboldAI/PPO_Pygway-6b-Mix",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
    "average": 39.38,
    "arc": 41.64,
    "hellaswag": 66.23,
    "mmlu": 27.26,
    "truthfulqa": 36.1,
    "winogrande": 64.4,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc",
    "params": 2.91,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "c588a5924749b86a6cb36a687dafa544c189bb6f",
    "model_name_for_query": "Fredithefish/RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
    "link": "https://huggingface.co/Fredithefish/RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-7B-Chat",
    "average": 39.37,
    "arc": 42.06,
    "hellaswag": 70.82,
    "mmlu": 26.94,
    "truthfulqa": 36.09,
    "winogrande": 59.83,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 87.0,
    "still_on_hub": true,
    "revision": "47b94a739e2f3164b438501c8684acc5d5acc146",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-7B-Chat",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Chat-7B-v0.1",
    "average": 39.37,
    "arc": 42.06,
    "hellaswag": 70.82,
    "mmlu": 26.94,
    "truthfulqa": 36.09,
    "winogrande": 59.83,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 87.0,
    "still_on_hub": true,
    "revision": "47b94a739e2f3164b438501c8684acc5d5acc146",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-Chat-7B-v0.1",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-7B-v0.1",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LongAlpaca-7B",
    "average": 39.36,
    "arc": 42.66,
    "hellaswag": 65.89,
    "mmlu": 27.28,
    "truthfulqa": 40.16,
    "winogrande": 60.14,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.74,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "bebfcb894b3f5170ce54e3bb98b6e565fae7b6c0",
    "model_name_for_query": "Yukang/LongAlpaca-7B",
    "link": "https://huggingface.co/Yukang/LongAlpaca-7B",
    "author": "Yukang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PPO_Shygmalion-6b",
    "average": 39.35,
    "arc": 40.27,
    "hellaswag": 66.88,
    "mmlu": 27.53,
    "truthfulqa": 34.24,
    "winogrande": 65.35,
    "gsm8k": 1.82,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "573e4546fdccc5c8a52b9d7cb23a2e10f0f2ef51",
    "model_name_for_query": "TehVenom/PPO_Shygmalion-6b",
    "link": "https://huggingface.co/TehVenom/PPO_Shygmalion-6b",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Adventien-GPTJ",
    "average": 39.31,
    "arc": 42.49,
    "hellaswag": 69.21,
    "mmlu": 25.4,
    "truthfulqa": 36.95,
    "winogrande": 60.22,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4fbfe9eae03a1d6ecf60fda8cf39c4123f0438bd",
    "model_name_for_query": "digitous/Adventien-GPTJ",
    "link": "https://huggingface.co/digitous/Adventien-GPTJ",
    "author": "digitous"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-7b-storywriter",
    "average": 39.31,
    "arc": 45.65,
    "hellaswag": 74.14,
    "mmlu": 28.8,
    "truthfulqa": 36.12,
    "winogrande": 51.14,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 690.0,
    "still_on_hub": true,
    "revision": "a5e85ae1941e31bb705adbcafce9b0dfd6f3a48b",
    "model_name_for_query": "mosaicml/mpt-7b-storywriter",
    "link": "https://huggingface.co/mosaicml/mpt-7b-storywriter",
    "author": "mosaicml"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-6.9b-deduped",
    "average": 39.3,
    "arc": 41.3,
    "hellaswag": 67.05,
    "mmlu": 26.48,
    "truthfulqa": 35.19,
    "winogrande": 64.09,
    "gsm8k": 1.67,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "372b1c08d9b5b0fc18ce86bbf294930e26e66ed5",
    "model_name_for_query": "EleutherAI/pythia-6.9b-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-6.9b-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fairseq-dense-6.7B",
    "average": 39.26,
    "arc": 39.42,
    "hellaswag": 71.26,
    "mmlu": 26.91,
    "truthfulqa": 32.73,
    "winogrande": 65.27,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.65,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "d62d83b8eb7a6ba012a762752a5b5679add3b40c",
    "model_name_for_query": "KoboldAI/fairseq-dense-6.7B",
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-6.7B",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolly-v2-7b",
    "average": 39.24,
    "arc": 44.54,
    "hellaswag": 69.64,
    "mmlu": 25.18,
    "truthfulqa": 34.88,
    "winogrande": 60.06,
    "gsm8k": 1.14,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 6.65,
    "likes": 132.0,
    "still_on_hub": true,
    "revision": "d632f0c8b75b1ae5b26b250d25bfba4e99cb7c6f",
    "model_name_for_query": "databricks/dolly-v2-7b",
    "link": "https://huggingface.co/databricks/dolly-v2-7b",
    "author": "databricks"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Chat-Instruct-3B-V1",
    "average": 39.23,
    "arc": 42.58,
    "hellaswag": 67.48,
    "mmlu": 25.99,
    "truthfulqa": 33.62,
    "winogrande": 64.8,
    "gsm8k": 0.91,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.78,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e19eef572d57fc734bf3ea07c7d0098b3901ec9b",
    "model_name_for_query": "acrastt/RedPajama-INCITE-Chat-Instruct-3B-V1",
    "link": "https://huggingface.co/acrastt/RedPajama-INCITE-Chat-Instruct-3B-V1",
    "author": "acrastt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedTulu-Uncensored-3B-0719",
    "average": 39.19,
    "arc": 40.02,
    "hellaswag": 62.55,
    "mmlu": 30.37,
    "truthfulqa": 37.59,
    "winogrande": 62.35,
    "gsm8k": 2.27,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c92bf022cddc3f57b4552ec3391df487295a2f87",
    "model_name_for_query": "heegyu/RedTulu-Uncensored-3B-0719",
    "link": "https://huggingface.co/heegyu/RedTulu-Uncensored-3B-0719",
    "author": "heegyu"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "bloom-7b1",
    "average": 39.18,
    "arc": 41.13,
    "hellaswag": 62.0,
    "mmlu": 26.25,
    "truthfulqa": 38.9,
    "winogrande": 65.43,
    "gsm8k": 1.36,
    "model_type": "pretrained",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 7.07,
    "likes": 137.0,
    "still_on_hub": true,
    "revision": "e83e90ba86f87f74aa2731cdab25ccf33976bd66",
    "model_name_for_query": "bigscience/bloom-7b1",
    "link": "https://huggingface.co/bigscience/bloom-7b1",
    "author": "bigscience"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
    "average": 39.16,
    "arc": 41.3,
    "hellaswag": 66.82,
    "mmlu": 26.1,
    "truthfulqa": 35.04,
    "winogrande": 65.43,
    "gsm8k": 0.3,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "8bit",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "a2ee88a9fa1c9ad41e0a8c15217a4b1230ec33c8",
    "model_name_for_query": "DanielSc4/RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
    "link": "https://huggingface.co/DanielSc4/RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
    "author": "DanielSc4"
  },
  {
    "T": "\ud83d\udd36",
    "model": "oasst-pythia-6.9b-4000-steps",
    "average": 39.15,
    "arc": 41.64,
    "hellaswag": 64.24,
    "mmlu": 26.26,
    "truthfulqa": 40.43,
    "winogrande": 61.8,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.65,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "0e201b6f344ac6382dda40d389e1c9144a87d027",
    "model_name_for_query": "dvruette/oasst-pythia-6.9b-4000-steps",
    "link": "https://huggingface.co/dvruette/oasst-pythia-6.9b-4000-steps",
    "author": "dvruette"
  },
  {
    "T": "\u2b55",
    "model": "weblab-10b-instruction-sft",
    "average": 39.13,
    "arc": 40.1,
    "hellaswag": 65.3,
    "mmlu": 26.66,
    "truthfulqa": 36.79,
    "winogrande": 64.09,
    "gsm8k": 1.82,
    "model_type": "instruction-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 10.47,
    "likes": 68.0,
    "still_on_hub": true,
    "revision": "112a5ad9f556078ab14a5cd93511b9db4a0d4413",
    "model_name_for_query": "matsuo-lab/weblab-10b-instruction-sft",
    "link": "https://huggingface.co/matsuo-lab/weblab-10b-instruction-sft",
    "author": "matsuo-lab"
  },
  {
    "T": "?",
    "model": "robin-33B-v2-GPTQ",
    "average": 39.1,
    "arc": 27.73,
    "hellaswag": 26.29,
    "mmlu": 23.53,
    "truthfulqa": 49.54,
    "winogrande": 79.79,
    "gsm8k": 27.75,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 35.58,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "4c2588d65302e9ca634548ed81e8650fb2975686",
    "model_name_for_query": "TheBloke/robin-33B-v2-GPTQ",
    "link": "https://huggingface.co/TheBloke/robin-33B-v2-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-6.7B-Erebus",
    "average": 39.09,
    "arc": 39.16,
    "hellaswag": 68.66,
    "mmlu": 24.58,
    "truthfulqa": 35.12,
    "winogrande": 65.98,
    "gsm8k": 1.06,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.66,
    "likes": 84.0,
    "still_on_hub": true,
    "revision": "9c4d1af96f93224e01d2f69c303fc6d6f686bdcc",
    "model_name_for_query": "KoboldAI/OPT-6.7B-Erebus",
    "link": "https://huggingface.co/KoboldAI/OPT-6.7B-Erebus",
    "author": "KoboldAI"
  },
  {
    "T": "?",
    "model": "firefly-bloom-7b1",
    "average": 39.09,
    "arc": 40.44,
    "hellaswag": 61.2,
    "mmlu": 26.83,
    "truthfulqa": 40.83,
    "winogrande": 64.56,
    "gsm8k": 0.68,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.07,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6b4385dc45c47d509b6400c41a2ff3665ad1d189",
    "model_name_for_query": "YeungNLP/firefly-bloom-7b1",
    "link": "https://huggingface.co/YeungNLP/firefly-bloom-7b1",
    "author": "YeungNLP"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "opt-6.7b",
    "average": 39.08,
    "arc": 39.16,
    "hellaswag": 68.66,
    "mmlu": 24.57,
    "truthfulqa": 35.12,
    "winogrande": 65.98,
    "gsm8k": 0.99,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.66,
    "likes": 77.0,
    "still_on_hub": true,
    "revision": "a45aa65bbeb77c1558bc99bedc6779195462dab0",
    "model_name_for_query": "facebook/opt-6.7b",
    "link": "https://huggingface.co/facebook/opt-6.7b",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Instruct-3B-v1",
    "average": 39.06,
    "arc": 41.55,
    "hellaswag": 65.48,
    "mmlu": 25.03,
    "truthfulqa": 36.41,
    "winogrande": 64.48,
    "gsm8k": 1.36,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 84.0,
    "still_on_hub": true,
    "revision": "0c66778ee09a036886741707733620b91057909a",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "author": "togethercomputer"
  },
  {
    "T": "\u2b55",
    "model": "deacon-3b",
    "average": 39.05,
    "arc": 39.68,
    "hellaswag": 66.42,
    "mmlu": 27.13,
    "truthfulqa": 36.07,
    "winogrande": 64.64,
    "gsm8k": 0.38,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 3.43,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "c96b846ce7bacf5ad231957630dc94d59f329339",
    "model_name_for_query": "KnutJaegersberg/deacon-3b",
    "link": "https://huggingface.co/KnutJaegersberg/deacon-3b",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ScarletPajama-3B-HF",
    "average": 39.04,
    "arc": 39.76,
    "hellaswag": 64.89,
    "mmlu": 27.28,
    "truthfulqa": 37.6,
    "winogrande": 64.48,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "9dd07308b6eb3f270c5762250b6d46abd6f87b6f",
    "model_name_for_query": "Fredithefish/ScarletPajama-3B-HF",
    "link": "https://huggingface.co/Fredithefish/ScarletPajama-3B-HF",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_3b",
    "average": 39.03,
    "arc": 41.55,
    "hellaswag": 61.52,
    "mmlu": 26.79,
    "truthfulqa": 42.42,
    "winogrande": 61.8,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 3.32,
    "likes": 129.0,
    "still_on_hub": true,
    "revision": "fd2754e80ce80757a3a68a840d7d287dd7def676",
    "model_name_for_query": "psmathur/orca_mini_3b",
    "link": "https://huggingface.co/psmathur/orca_mini_3b",
    "author": "psmathur"
  },
  {
    "T": "\u2b55",
    "model": "black_goo_recipe_c",
    "average": 39.01,
    "arc": 38.74,
    "hellaswag": 66.83,
    "mmlu": 26.57,
    "truthfulqa": 36.54,
    "winogrande": 64.72,
    "gsm8k": 0.68,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "78c0a6432ac0a6c2e54a2c3aac4cb70f446eb18b",
    "model_name_for_query": "KnutJaegersberg/black_goo_recipe_c",
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_c",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Guanaco-3B-Uncensored-v2",
    "average": 38.98,
    "arc": 42.15,
    "hellaswag": 66.72,
    "mmlu": 26.18,
    "truthfulqa": 35.21,
    "winogrande": 63.3,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.78,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "e07122091fd4b318dcea105b16c73144d95bc2f6",
    "model_name_for_query": "Fredithefish/Guanaco-3B-Uncensored-v2",
    "link": "https://huggingface.co/Fredithefish/Guanaco-3B-Uncensored-v2",
    "author": "Fredithefish"
  },
  {
    "T": "\u2b55",
    "model": "cross_lingual_epoch2",
    "average": 38.97,
    "arc": 39.25,
    "hellaswag": 47.92,
    "mmlu": 36.66,
    "truthfulqa": 47.9,
    "winogrande": 62.12,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "mit",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "86e59e85b234e6c882758724849d7a1e4fe0b30a",
    "model_name_for_query": "jb723/cross_lingual_epoch2",
    "link": "https://huggingface.co/jb723/cross_lingual_epoch2",
    "author": "jb723"
  },
  {
    "T": "\u2b55",
    "model": "open_llama_3b_instruct_v_0.2",
    "average": 38.97,
    "arc": 38.48,
    "hellaswag": 66.77,
    "mmlu": 25.34,
    "truthfulqa": 38.16,
    "winogrande": 63.46,
    "gsm8k": 1.59,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6ae4004fe8901c1dae19108bc37e8b744cd08539",
    "model_name_for_query": "mwitiderrick/open_llama_3b_instruct_v_0.2",
    "link": "https://huggingface.co/mwitiderrick/open_llama_3b_instruct_v_0.2",
    "author": "mwitiderrick"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Guanaco-3B-Uncensored-v2-GPTQ",
    "average": 38.95,
    "arc": 41.64,
    "hellaswag": 64.76,
    "mmlu": 26.25,
    "truthfulqa": 36.58,
    "winogrande": 64.33,
    "gsm8k": 0.15,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "GPTQ",
    "license": "apache-2.0",
    "params": 4.78,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "c80e2f01377d551ad17c8c9bac3f52578c38d653",
    "model_name_for_query": "TheBloke/Guanaco-3B-Uncensored-v2-GPTQ",
    "link": "https://huggingface.co/TheBloke/Guanaco-3B-Uncensored-v2-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Guanaco-3B-Uncensored",
    "average": 38.94,
    "arc": 42.49,
    "hellaswag": 66.99,
    "mmlu": 25.55,
    "truthfulqa": 34.71,
    "winogrande": 63.38,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.78,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "084a12f767b31c1fde681bebb14e9a291e506ea8",
    "model_name_for_query": "Fredithefish/Guanaco-3B-Uncensored",
    "link": "https://huggingface.co/Fredithefish/Guanaco-3B-Uncensored",
    "author": "Fredithefish"
  },
  {
    "T": "\u2b55",
    "model": "Healix-3B",
    "average": 38.93,
    "arc": 37.71,
    "hellaswag": 65.94,
    "mmlu": 26.02,
    "truthfulqa": 37.4,
    "winogrande": 65.75,
    "gsm8k": 0.76,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "52297e0b6845b3c1b26f336fd2a2c9b2f56ce6ba",
    "model_name_for_query": "health360/Healix-3B",
    "link": "https://huggingface.co/health360/Healix-3B",
    "author": "health360"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mamba-gpt-3b",
    "average": 38.87,
    "arc": 40.53,
    "hellaswag": 64.94,
    "mmlu": 25.35,
    "truthfulqa": 37.14,
    "winogrande": 65.04,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "21a8212e3641dd14924d6bdead0774b64dda8ce0",
    "model_name_for_query": "CobraMamba/mamba-gpt-3b",
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-3b",
    "author": "CobraMamba"
  },
  {
    "T": "?",
    "model": "FinanceConnect-13B",
    "average": 38.84,
    "arc": 22.7,
    "hellaswag": 100.0,
    "mmlu": 23.12,
    "truthfulqa": 37.68,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "adaf830e7362788b73e7ceaf8ec010409774c711",
    "model_name_for_query": "ceadar-ie/FinanceConnect-13B",
    "link": "https://huggingface.co/ceadar-ie/FinanceConnect-13B",
    "author": "ceadar-ie"
  },
  {
    "T": "?",
    "model": "galactica-6.7b-finetuned",
    "average": 38.84,
    "arc": 41.55,
    "hellaswag": 51.01,
    "mmlu": 38.03,
    "truthfulqa": 41.65,
    "winogrande": 57.7,
    "gsm8k": 3.11,
    "model_type": "",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.66,
    "likes": 34.0,
    "still_on_hub": true,
    "revision": "d86db70e16111175ff7900f71d40806ccf4b8491",
    "model_name_for_query": "OpenAssistant/galactica-6.7b-finetuned",
    "link": "https://huggingface.co/OpenAssistant/galactica-6.7b-finetuned",
    "author": "OpenAssistant"
  },
  {
    "T": "\ud83d\udd36",
    "model": "orca_mini_3b_juniper",
    "average": 38.83,
    "arc": 40.87,
    "hellaswag": 61.73,
    "mmlu": 26.37,
    "truthfulqa": 43.19,
    "winogrande": 60.3,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 3.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c08749034baa053834f1b709b6e7b88b914cd1fb",
    "model_name_for_query": "frank098/orca_mini_3b_juniper",
    "link": "https://huggingface.co/frank098/orca_mini_3b_juniper",
    "author": "frank098"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-6.7B-Nerybus-Mix",
    "average": 38.83,
    "arc": 39.16,
    "hellaswag": 68.63,
    "mmlu": 24.47,
    "truthfulqa": 34.84,
    "winogrande": 65.11,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.66,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "9afe4dca5a9dbd71cb90d1050d142837f4c739f6",
    "model_name_for_query": "KoboldAI/OPT-6.7B-Nerybus-Mix",
    "link": "https://huggingface.co/KoboldAI/OPT-6.7B-Nerybus-Mix",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-12b",
    "average": 38.82,
    "arc": 39.59,
    "hellaswag": 68.82,
    "mmlu": 26.76,
    "truthfulqa": 31.85,
    "winogrande": 64.17,
    "gsm8k": 1.74,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.59,
    "likes": 111.0,
    "still_on_hub": true,
    "revision": "35c9d7f32fbb108fb8b5bdd574eb03369d1eed49",
    "model_name_for_query": "EleutherAI/pythia-12b",
    "link": "https://huggingface.co/EleutherAI/pythia-12b",
    "author": "EleutherAI"
  },
  {
    "T": "\u2b55",
    "model": "WizardVicuna-open-llama-3b-v2",
    "average": 38.77,
    "arc": 37.71,
    "hellaswag": 66.6,
    "mmlu": 27.23,
    "truthfulqa": 36.8,
    "winogrande": 63.3,
    "gsm8k": 0.99,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1c69905286171d7d3ef3f95f8e1bbc9150bad3cd",
    "model_name_for_query": "heegyu/WizardVicuna-open-llama-3b-v2",
    "link": "https://huggingface.co/heegyu/WizardVicuna-open-llama-3b-v2",
    "author": "heegyu"
  },
  {
    "T": "\u2b55",
    "model": "black_goo_recipe_a",
    "average": 38.73,
    "arc": 38.14,
    "hellaswag": 66.56,
    "mmlu": 25.75,
    "truthfulqa": 37.46,
    "winogrande": 63.93,
    "gsm8k": 0.53,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7067f68d4d9e7b10a1aa2c9fa97456bc04678867",
    "model_name_for_query": "KnutJaegersberg/black_goo_recipe_a",
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_a",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-6B-nerys-v2",
    "average": 38.72,
    "arc": 38.4,
    "hellaswag": 68.57,
    "mmlu": 24.34,
    "truthfulqa": 34.73,
    "winogrande": 65.59,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.66,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "9e1f1498391df2c28ce35a9290a5a24b8022a43b",
    "model_name_for_query": "KoboldAI/OPT-6B-nerys-v2",
    "link": "https://huggingface.co/KoboldAI/OPT-6B-nerys-v2",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "instruct-12b",
    "average": 38.63,
    "arc": 42.58,
    "hellaswag": 66.76,
    "mmlu": 26.79,
    "truthfulqa": 31.96,
    "winogrande": 63.46,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 11.58,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "ff4699b502b79c716330b6f761002588a65dcba6",
    "model_name_for_query": "hakurei/instruct-12b",
    "link": "https://huggingface.co/hakurei/instruct-12b",
    "author": "hakurei"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-oig-oasst1-256-6_9b",
    "average": 38.62,
    "arc": 39.93,
    "hellaswag": 65.42,
    "mmlu": 26.39,
    "truthfulqa": 35.0,
    "winogrande": 63.38,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "f1c9bac89b74d3487cb092788ce828fb9520c1a7",
    "model_name_for_query": "h2oai/h2ogpt-oig-oasst1-256-6_9b",
    "link": "https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-6_9b",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "weblab-10b",
    "average": 38.59,
    "arc": 39.51,
    "hellaswag": 65.76,
    "mmlu": 26.29,
    "truthfulqa": 36.02,
    "winogrande": 62.51,
    "gsm8k": 1.44,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 10.47,
    "likes": 55.0,
    "still_on_hub": true,
    "revision": "d6fc432983b1633a4c1568d121c60de6b8c3e511",
    "model_name_for_query": "matsuo-lab/weblab-10b",
    "link": "https://huggingface.co/matsuo-lab/weblab-10b",
    "author": "matsuo-lab"
  },
  {
    "T": "\u2b55",
    "model": "black_goo_recipe_d",
    "average": 38.57,
    "arc": 37.8,
    "hellaswag": 66.5,
    "mmlu": 26.64,
    "truthfulqa": 36.46,
    "winogrande": 63.61,
    "gsm8k": 0.38,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fdf7f93837808958f9463d3c683314e7f649a088",
    "model_name_for_query": "KnutJaegersberg/black_goo_recipe_d",
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_d",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\u2b55",
    "model": "rwkv-raven-7b",
    "average": 38.55,
    "arc": 39.42,
    "hellaswag": 66.48,
    "mmlu": 23.64,
    "truthfulqa": 38.56,
    "winogrande": 62.9,
    "gsm8k": 0.3,
    "model_type": "instruction-tuned",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.19,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "a2dfc9f659be13556a25d9e38da642c6f67aeee3",
    "model_name_for_query": "RWKV/rwkv-raven-7b",
    "link": "https://huggingface.co/RWKV/rwkv-raven-7b",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "RedPajama-INCITE-Base-3B-v1",
    "average": 38.54,
    "arc": 40.19,
    "hellaswag": 64.77,
    "mmlu": 27.03,
    "truthfulqa": 33.23,
    "winogrande": 64.72,
    "gsm8k": 1.29,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 80.0,
    "still_on_hub": true,
    "revision": "094fbdd0c911feb485ce55de1952ab2e75277e1e",
    "model_name_for_query": "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "author": "togethercomputer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pyg-instruct-wizardlm",
    "average": 38.54,
    "arc": 40.96,
    "hellaswag": 66.71,
    "mmlu": 26.33,
    "truthfulqa": 31.93,
    "winogrande": 63.69,
    "gsm8k": 1.59,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f00ef7a7b0cc6f02af2a11ac764270dfd61b9e2f",
    "model_name_for_query": "Lazycuber/pyg-instruct-wizardlm",
    "link": "https://huggingface.co/Lazycuber/pyg-instruct-wizardlm",
    "author": "Lazycuber"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-30B-Erebus",
    "average": 38.53,
    "arc": 36.69,
    "hellaswag": 65.6,
    "mmlu": 24.8,
    "truthfulqa": 38.76,
    "winogrande": 65.11,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 29.97,
    "likes": 40.0,
    "still_on_hub": true,
    "revision": "a1041efcf9599c962822274e92040710579a5bf2",
    "model_name_for_query": "KoboldAI/OPT-30B-Erebus",
    "link": "https://huggingface.co/KoboldAI/OPT-30B-Erebus",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CrimsonPajama",
    "average": 38.52,
    "arc": 40.19,
    "hellaswag": 65.47,
    "mmlu": 25.95,
    "truthfulqa": 33.78,
    "winogrande": 65.19,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "ff054eeff9e3541464383d40b36d182057d01113",
    "model_name_for_query": "Fredithefish/CrimsonPajama",
    "link": "https://huggingface.co/Fredithefish/CrimsonPajama",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-oig-oasst1-512-6_9b",
    "average": 38.52,
    "arc": 40.44,
    "hellaswag": 65.58,
    "mmlu": 24.9,
    "truthfulqa": 36.68,
    "winogrande": 62.51,
    "gsm8k": 0.99,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "029a787e0d98fcd3fecffbfbeb4a75a425474937",
    "model_name_for_query": "h2oai/h2ogpt-oig-oasst1-512-6_9b",
    "link": "https://huggingface.co/h2oai/h2ogpt-oig-oasst1-512-6_9b",
    "author": "h2oai"
  },
  {
    "T": "?",
    "model": "guanaco-33B-GPTQ",
    "average": 38.51,
    "arc": 28.16,
    "hellaswag": 26.34,
    "mmlu": 24.94,
    "truthfulqa": 48.98,
    "winogrande": 78.85,
    "gsm8k": 23.81,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 35.58,
    "likes": 71.0,
    "still_on_hub": true,
    "revision": "8e42e031bfc8be3bbf31dc546d7c51fb991ff6e0",
    "model_name_for_query": "TheBloke/guanaco-33B-GPTQ",
    "link": "https://huggingface.co/TheBloke/guanaco-33B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "LLongMA-3b-LIMA",
    "average": 38.51,
    "arc": 39.08,
    "hellaswag": 67.15,
    "mmlu": 26.43,
    "truthfulqa": 34.71,
    "winogrande": 63.38,
    "gsm8k": 0.3,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 3.32,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "333b8c41e42a46a6f3aecaf8f3fa8a17c6d83990",
    "model_name_for_query": "KnutJaegersberg/LLongMA-3b-LIMA",
    "link": "https://huggingface.co/KnutJaegersberg/LLongMA-3b-LIMA",
    "author": "KnutJaegersberg"
  },
  {
    "T": "?",
    "model": "pythia-6.9b-HC3",
    "average": 38.51,
    "arc": 36.52,
    "hellaswag": 61.76,
    "mmlu": 26.94,
    "truthfulqa": 45.05,
    "winogrande": 60.77,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "c5c60ea656e921e6c5415f6feaebac4dd9b2aa2a",
    "model_name_for_query": "pszemraj/pythia-6.9b-HC3",
    "link": "https://huggingface.co/pszemraj/pythia-6.9b-HC3",
    "author": "pszemraj"
  },
  {
    "T": "\u2b55",
    "model": "black_goo_recipe_b",
    "average": 38.49,
    "arc": 37.63,
    "hellaswag": 66.72,
    "mmlu": 25.68,
    "truthfulqa": 37.09,
    "winogrande": 63.77,
    "gsm8k": 0.08,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 3.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "42faec8429cee8c9f4f5db58ffa193f6f8e0d498",
    "model_name_for_query": "KnutJaegersberg/black_goo_recipe_b",
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_b",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Chat-3B-ShareGPT-11K",
    "average": 38.47,
    "arc": 40.61,
    "hellaswag": 64.84,
    "mmlu": 26.13,
    "truthfulqa": 35.41,
    "winogrande": 63.54,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "ec33d12d08d61ed821e67b1a55ad404dc3457ebf",
    "model_name_for_query": "Fredithefish/RedPajama-INCITE-Chat-3B-ShareGPT-11K",
    "link": "https://huggingface.co/Fredithefish/RedPajama-INCITE-Chat-3B-ShareGPT-11K",
    "author": "Fredithefish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-6b",
    "average": 38.47,
    "arc": 40.53,
    "hellaswag": 67.47,
    "mmlu": 25.73,
    "truthfulqa": 32.53,
    "winogrande": 62.51,
    "gsm8k": 2.05,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 5.84,
    "likes": 690.0,
    "still_on_hub": true,
    "revision": "30e2405100eac6bd53f75964cc7345eeafd19f7d",
    "model_name_for_query": "PygmalionAI/pygmalion-6b",
    "link": "https://huggingface.co/PygmalionAI/pygmalion-6b",
    "author": "PygmalionAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-33B-V1.0-Uncensored-GPTQ",
    "average": 38.43,
    "arc": 27.39,
    "hellaswag": 26.03,
    "mmlu": 25.81,
    "truthfulqa": 48.9,
    "winogrande": 77.9,
    "gsm8k": 24.56,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 35.58,
    "likes": 37.0,
    "still_on_hub": true,
    "revision": "1c65902c620fcdf6b9c8e36ce17f21360e186a1e",
    "model_name_for_query": "TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-6b-roleplay",
    "average": 38.34,
    "arc": 40.53,
    "hellaswag": 67.47,
    "mmlu": 25.73,
    "truthfulqa": 32.53,
    "winogrande": 62.67,
    "gsm8k": 1.14,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "e49ed0bde45de0a436bff678ec4872069e8f230c",
    "model_name_for_query": "anhnv125/pygmalion-6b-roleplay",
    "link": "https://huggingface.co/anhnv125/pygmalion-6b-roleplay",
    "author": "anhnv125"
  },
  {
    "T": "?",
    "model": "DiffMerge_Pygmalion_Main-onto-V8P4",
    "average": 38.31,
    "arc": 40.53,
    "hellaswag": 67.48,
    "mmlu": 25.68,
    "truthfulqa": 32.55,
    "winogrande": 62.51,
    "gsm8k": 1.14,
    "model_type": "",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f855780745aa34c3bdbe020e4c51253d538cb21e",
    "model_name_for_query": "TehVenom/DiffMerge_Pygmalion_Main-onto-V8P4",
    "link": "https://huggingface.co/TehVenom/DiffMerge_Pygmalion_Main-onto-V8P4",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OmegLLaMA-3B",
    "average": 38.28,
    "arc": 40.36,
    "hellaswag": 66.13,
    "mmlu": 28.0,
    "truthfulqa": 33.31,
    "winogrande": 61.64,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "520c5f1ceb5c90d4011887e2a8d3becf15e7e66e",
    "model_name_for_query": "acrastt/OmegLLaMA-3B",
    "link": "https://huggingface.co/acrastt/OmegLLaMA-3B",
    "author": "acrastt"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "open_llama_3b",
    "average": 38.26,
    "arc": 39.85,
    "hellaswag": 62.65,
    "mmlu": 26.94,
    "truthfulqa": 34.97,
    "winogrande": 64.72,
    "gsm8k": 0.45,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.32,
    "likes": 112.0,
    "still_on_hub": true,
    "revision": "141067009124b9c0aea62c76b3eb952174864057",
    "model_name_for_query": "openlm-research/open_llama_3b",
    "link": "https://huggingface.co/openlm-research/open_llama_3b",
    "author": "openlm-research"
  },
  {
    "T": "\ud83d\udd36",
    "model": "koishi-instruct-3b",
    "average": 38.16,
    "arc": 40.96,
    "hellaswag": 64.54,
    "mmlu": 26.58,
    "truthfulqa": 31.65,
    "winogrande": 64.09,
    "gsm8k": 1.14,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 2.91,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "2bb7f3842398b048efa4ae2d1aafb9e2f18a8586",
    "model_name_for_query": "ewof/koishi-instruct-3b",
    "link": "https://huggingface.co/ewof/koishi-instruct-3b",
    "author": "ewof"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-6.7b",
    "average": 38.06,
    "arc": 40.1,
    "hellaswag": 65.0,
    "mmlu": 24.64,
    "truthfulqa": 32.85,
    "winogrande": 64.72,
    "gsm8k": 1.06,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.65,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "b666a6e46eeade607c73ed1334ecda3b9345e4bf",
    "model_name_for_query": "EleutherAI/pythia-6.7b",
    "link": "https://huggingface.co/EleutherAI/pythia-6.7b",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "rwkv-4-7b-pile",
    "average": 37.95,
    "arc": 39.68,
    "hellaswag": 66.31,
    "mmlu": 24.96,
    "truthfulqa": 33.65,
    "winogrande": 62.35,
    "gsm8k": 0.76,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.19,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "922e22a761427e50d7be457b31a76b1126021b8b",
    "model_name_for_query": "RWKV/rwkv-4-7b-pile",
    "link": "https://huggingface.co/RWKV/rwkv-4-7b-pile",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Galactica-6.7B-EssayWriter",
    "average": 37.75,
    "arc": 40.1,
    "hellaswag": 50.29,
    "mmlu": 33.88,
    "truthfulqa": 40.27,
    "winogrande": 58.48,
    "gsm8k": 3.49,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.66,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ac74fdd938de1ffd34832d66a25db20b0230983e",
    "model_name_for_query": "KnutJaegersberg/Galactica-6.7B-EssayWriter",
    "link": "https://huggingface.co/KnutJaegersberg/Galactica-6.7B-EssayWriter",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "test-22B",
    "average": 37.71,
    "arc": 39.42,
    "hellaswag": 64.51,
    "mmlu": 27.13,
    "truthfulqa": 37.13,
    "winogrande": 57.7,
    "gsm8k": 0.38,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 21.83,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "cd72f5954ab5801dd2c1b499e59265f7504f9ee6",
    "model_name_for_query": "Devio/test-22B",
    "link": "https://huggingface.co/Devio/test-22B",
    "author": "Devio"
  },
  {
    "T": "\u2b55",
    "model": "falcon-rw-1b-instruct-openorca",
    "average": 37.63,
    "arc": 34.56,
    "hellaswag": 60.93,
    "mmlu": 28.77,
    "truthfulqa": 37.42,
    "winogrande": 60.69,
    "gsm8k": 3.41,
    "model_type": "instruction-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "bb5f86170d8d01aa850bb216bb2797899570c13e",
    "model_name_for_query": "ericzzz/falcon-rw-1b-instruct-openorca",
    "link": "https://huggingface.co/ericzzz/falcon-rw-1b-instruct-openorca",
    "author": "ericzzz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "falcon_1b_stage2",
    "average": 37.59,
    "arc": 35.49,
    "hellaswag": 65.56,
    "mmlu": 23.83,
    "truthfulqa": 38.32,
    "winogrande": 62.35,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c3ef73a8c9dc06fae4bfe4460d2f293147aecbb0",
    "model_name_for_query": "euclaise/falcon_1b_stage2",
    "link": "https://huggingface.co/euclaise/falcon_1b_stage2",
    "author": "euclaise"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bloom-zh-3b-chat",
    "average": 37.58,
    "arc": 38.82,
    "hellaswag": 54.71,
    "mmlu": 31.62,
    "truthfulqa": 41.25,
    "winogrande": 58.64,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-openrail-m",
    "params": 3.0,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "4ea0ad223a2623fc15e8824c1c4f8e6539bc40b0",
    "model_name_for_query": "ikala/bloom-zh-3b-chat",
    "link": "https://huggingface.co/ikala/bloom-zh-3b-chat",
    "author": "ikala"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
    "average": 37.55,
    "arc": 36.43,
    "hellaswag": 61.41,
    "mmlu": 25.01,
    "truthfulqa": 37.59,
    "winogrande": 64.64,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "fdc6ff469295d0aaabec8948525b70d6688728ac",
    "model_name_for_query": "h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLlama-13B-Python-fp16",
    "average": 37.52,
    "arc": 33.19,
    "hellaswag": 44.5,
    "mmlu": 25.94,
    "truthfulqa": 43.99,
    "winogrande": 67.4,
    "gsm8k": 10.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 26.0,
    "still_on_hub": true,
    "revision": "442282f4207442b828953a72c51a919c332cba5c",
    "model_name_for_query": "TheBloke/CodeLlama-13B-Python-fp16",
    "link": "https://huggingface.co/TheBloke/CodeLlama-13B-Python-fp16",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "GoLLIE-7B",
    "average": 37.48,
    "arc": 36.09,
    "hellaswag": 57.93,
    "mmlu": 29.38,
    "truthfulqa": 39.27,
    "winogrande": 58.96,
    "gsm8k": 3.26,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 7.0,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "d3e41fef45f6a7d438c46ba7d9fce5d0d486c7a9",
    "model_name_for_query": "HiTZ/GoLLIE-7B",
    "link": "https://huggingface.co/HiTZ/GoLLIE-7B",
    "author": "HiTZ"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fairseq-dense-2.7B",
    "average": 37.41,
    "arc": 33.79,
    "hellaswag": 65.74,
    "mmlu": 26.44,
    "truthfulqa": 34.57,
    "winogrande": 63.93,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 2.78,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "4201f4b101bad2992efc8452009317a354ec52d2",
    "model_name_for_query": "KoboldAI/fairseq-dense-2.7B",
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-2.7B",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Cerebras-GPT-13B",
    "average": 37.4,
    "arc": 38.14,
    "hellaswag": 60.01,
    "mmlu": 25.92,
    "truthfulqa": 39.19,
    "winogrande": 59.83,
    "gsm8k": 1.29,
    "model_type": "pretrained",
    "architecture": "GPT2Model",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 632.0,
    "still_on_hub": true,
    "revision": "7e97fa4b15edd955094c4395d62e6f4290e365b5",
    "model_name_for_query": "cerebras/Cerebras-GPT-13B",
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-13B",
    "author": "cerebras"
  },
  {
    "T": "\u2b55",
    "model": "falcon-rw-1b-chat",
    "average": 37.37,
    "arc": 35.58,
    "hellaswag": 61.12,
    "mmlu": 24.51,
    "truthfulqa": 39.62,
    "winogrande": 61.72,
    "gsm8k": 1.67,
    "model_type": "instruction-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "61c2b3f27c8d32912d0b9ff47ebf687af2eb9e86",
    "model_name_for_query": "ericzzz/falcon-rw-1b-chat",
    "link": "https://huggingface.co/ericzzz/falcon-rw-1b-chat",
    "author": "ericzzz"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "StellarX-4B-V0",
    "average": 37.31,
    "arc": 36.95,
    "hellaswag": 61.9,
    "mmlu": 26.85,
    "truthfulqa": 34.3,
    "winogrande": 63.85,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 3.83,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "0a79832bd57a8cdadc61626fb77bdc26c85b9fa4",
    "model_name_for_query": "Dampish/StellarX-4B-V0",
    "link": "https://huggingface.co/Dampish/StellarX-4B-V0",
    "author": "Dampish"
  },
  {
    "T": "?",
    "model": "WizardLM-30B-Uncensored-GPTQ",
    "average": 37.27,
    "arc": 29.44,
    "hellaswag": 26.47,
    "mmlu": 24.35,
    "truthfulqa": 49.15,
    "winogrande": 73.16,
    "gsm8k": 21.08,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 35.58,
    "likes": 107.0,
    "still_on_hub": true,
    "revision": "43c701ddbe0bceac26c860307e06763cc5203500",
    "model_name_for_query": "TheBloke/WizardLM-30B-Uncensored-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
    "average": 37.27,
    "arc": 38.65,
    "hellaswag": 63.53,
    "mmlu": 25.16,
    "truthfulqa": 36.07,
    "winogrande": 60.14,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "8bit",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "f477d24b00e05fe4c5f8d5f933080994cfd90e4e",
    "model_name_for_query": "DanielSc4/RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
    "link": "https://huggingface.co/DanielSc4/RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
    "author": "DanielSc4"
  },
  {
    "T": "?",
    "model": "galactica-6.7b-evol-instruct-70k",
    "average": 37.27,
    "arc": 42.58,
    "hellaswag": 49.3,
    "mmlu": 32.96,
    "truthfulqa": 42.1,
    "winogrande": 56.27,
    "gsm8k": 0.38,
    "model_type": "",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 6.66,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "14fa470051d0bc38fd871643186a9edfd3a8a9aa",
    "model_name_for_query": "GeorgiaTechResearchInstitute/galactica-6.7b-evol-instruct-70k",
    "link": "https://huggingface.co/GeorgiaTechResearchInstitute/galactica-6.7b-evol-instruct-70k",
    "author": "GeorgiaTechResearchInstitute"
  },
  {
    "T": "\ud83d\udd36",
    "model": "falcon_1b_stage1",
    "average": 37.25,
    "arc": 35.15,
    "hellaswag": 62.4,
    "mmlu": 24.47,
    "truthfulqa": 40.0,
    "winogrande": 61.48,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f85d91ff3f6cadc93f7222a19b9c4930c8842366",
    "model_name_for_query": "euclaise/falcon_1b_stage1",
    "link": "https://huggingface.co/euclaise/falcon_1b_stage1",
    "author": "euclaise"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-sw3-6.7b",
    "average": 37.23,
    "arc": 36.35,
    "hellaswag": 60.75,
    "mmlu": 26.0,
    "truthfulqa": 39.04,
    "winogrande": 60.69,
    "gsm8k": 0.53,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7b20cb87e793e1b73b6a73da5261c6010f2b5410",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-6.7b",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-6.7b",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-2.7b",
    "average": 37.09,
    "arc": 37.37,
    "hellaswag": 60.74,
    "mmlu": 25.86,
    "truthfulqa": 35.4,
    "winogrande": 62.12,
    "gsm8k": 1.06,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.91,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "b9d8cace80b1a97f5ed380711aea31f2d1b24310",
    "model_name_for_query": "EleutherAI/pythia-2.7b",
    "link": "https://huggingface.co/EleutherAI/pythia-2.7b",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "falcon-rw-1b",
    "average": 37.07,
    "arc": 35.07,
    "hellaswag": 63.56,
    "mmlu": 25.28,
    "truthfulqa": 35.96,
    "winogrande": 62.04,
    "gsm8k": 0.53,
    "model_type": "pretrained",
    "architecture": "FalconForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 58.0,
    "still_on_hub": true,
    "revision": "e4b9872bb803165eb22f0a867d4e6a64d34fce19",
    "model_name_for_query": "tiiuae/falcon-rw-1b",
    "link": "https://huggingface.co/tiiuae/falcon-rw-1b",
    "author": "tiiuae"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Phind-CodeLlama-34B-v1",
    "average": 37.06,
    "arc": 27.13,
    "hellaswag": 28.28,
    "mmlu": 28.94,
    "truthfulqa": 44.94,
    "winogrande": 72.61,
    "gsm8k": 20.47,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 317.0,
    "still_on_hub": true,
    "revision": "b073c9bb418ae52ca76b4ab48ac2dfbc8622f434",
    "model_name_for_query": "Phind/Phind-CodeLlama-34B-v1",
    "link": "https://huggingface.co/Phind/Phind-CodeLlama-34B-v1",
    "author": "Phind"
  },
  {
    "T": "?",
    "model": "bloomz-3b",
    "average": 37.03,
    "arc": 36.86,
    "hellaswag": 54.95,
    "mmlu": 32.91,
    "truthfulqa": 40.34,
    "winogrande": 57.14,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 3.0,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "31eefcb2bcd69632925adf07e090debafe95436d",
    "model_name_for_query": "bigscience/bloomz-3b",
    "link": "https://huggingface.co/bigscience/bloomz-3b",
    "author": "bigscience"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-13b-Python-hf",
    "average": 37.0,
    "arc": 32.59,
    "hellaswag": 43.94,
    "mmlu": 27.23,
    "truthfulqa": 44.59,
    "winogrande": 65.04,
    "gsm8k": 8.64,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 13.02,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "ea1b775799b477fe22e64f8ac9107f28950b5c87",
    "model_name_for_query": "codellama/CodeLlama-13b-Python-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-13b-Python-hf",
    "author": "codellama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-2.7B-Erebus",
    "average": 36.96,
    "arc": 34.39,
    "hellaswag": 60.91,
    "mmlu": 26.7,
    "truthfulqa": 37.82,
    "winogrande": 61.64,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 2.65,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "39ca914ceb82f7f14a38484023bc04f0cd5d0a8d",
    "model_name_for_query": "KoboldAI/OPT-2.7B-Erebus",
    "link": "https://huggingface.co/KoboldAI/OPT-2.7B-Erebus",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bloomz-3b-sft-chat",
    "average": 36.94,
    "arc": 36.86,
    "hellaswag": 54.34,
    "mmlu": 31.49,
    "truthfulqa": 39.69,
    "winogrande": 58.88,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "bfloat16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 3.0,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "a35b6ae6809891e253b45fb5795979c33992e548",
    "model_name_for_query": "cmarkea/bloomz-3b-sft-chat",
    "link": "https://huggingface.co/cmarkea/bloomz-3b-sft-chat",
    "author": "cmarkea"
  },
  {
    "T": "\ud83d\udd36",
    "model": "blossom-v1-3b",
    "average": 36.9,
    "arc": 36.86,
    "hellaswag": 55.1,
    "mmlu": 26.7,
    "truthfulqa": 43.45,
    "winogrande": 58.88,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3235ee41e3793c98749b7bbd2bb80882a12ac889",
    "model_name_for_query": "Azure99/blossom-v1-3b",
    "link": "https://huggingface.co/Azure99/blossom-v1-3b",
    "author": "Azure99"
  },
  {
    "T": "\u2b55",
    "model": "Phind-CodeLlama-34B-v2",
    "average": 36.89,
    "arc": 24.57,
    "hellaswag": 27.6,
    "mmlu": 25.76,
    "truthfulqa": 48.37,
    "winogrande": 71.82,
    "gsm8k": 23.2,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 365.0,
    "still_on_hub": true,
    "revision": "949f61e203f91b412efe8f679c798f09f0ff4b0c",
    "model_name_for_query": "Phind/Phind-CodeLlama-34B-v2",
    "link": "https://huggingface.co/Phind/Phind-CodeLlama-34B-v2",
    "author": "Phind"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-7b-Python-hf",
    "average": 36.89,
    "arc": 31.31,
    "hellaswag": 52.86,
    "mmlu": 27.32,
    "truthfulqa": 42.21,
    "winogrande": 63.06,
    "gsm8k": 4.55,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "llama2",
    "params": 6.74,
    "likes": 54.0,
    "still_on_hub": true,
    "revision": "ec4dd26f30674fdee00ef161b55f464ce28f9c20",
    "model_name_for_query": "codellama/CodeLlama-7b-Python-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-7b-Python-hf",
    "author": "codellama"
  },
  {
    "T": "\u2b55",
    "model": "3B-redpajama-conditional-alpha",
    "average": 36.88,
    "arc": 36.26,
    "hellaswag": 61.9,
    "mmlu": 25.42,
    "truthfulqa": 36.31,
    "winogrande": 60.77,
    "gsm8k": 0.61,
    "model_type": "instruction-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 2.65,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7e2156c14b4b7981a4cd6db7b878888a98144df0",
    "model_name_for_query": "Rallio67/3B-redpajama-conditional-alpha",
    "link": "https://huggingface.co/Rallio67/3B-redpajama-conditional-alpha",
    "author": "Rallio67"
  },
  {
    "T": "\ud83d\udd36",
    "model": "falcon_1b_stage2",
    "average": 36.88,
    "arc": 33.11,
    "hellaswag": 63.19,
    "mmlu": 24.22,
    "truthfulqa": 38.4,
    "winogrande": 62.35,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "025c77e9ee457c6771c5a36dbacd064c269642a5",
    "model_name_for_query": "euclaise/falcon_1b_stage2",
    "link": "https://huggingface.co/euclaise/falcon_1b_stage2",
    "author": "euclaise"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-2.7B-Nerybus-Mix",
    "average": 36.88,
    "arc": 33.7,
    "hellaswag": 61.21,
    "mmlu": 26.6,
    "truthfulqa": 37.57,
    "winogrande": 62.04,
    "gsm8k": 0.15,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 2.65,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "b4131723cfff1fa42f6cbab546c5b4bb0d19fd83",
    "model_name_for_query": "KoboldAI/OPT-2.7B-Nerybus-Mix",
    "link": "https://huggingface.co/KoboldAI/OPT-2.7B-Nerybus-Mix",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "openbuddy-openllama-3b-v10-bf16",
    "average": 36.87,
    "arc": 36.26,
    "hellaswag": 58.38,
    "mmlu": 23.89,
    "truthfulqa": 42.04,
    "winogrande": 59.67,
    "gsm8k": 0.99,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 3.34,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "7f24d32de53aa4bc150f04ca2418604475173921",
    "model_name_for_query": "OpenBuddy/openbuddy-openllama-3b-v10-bf16",
    "link": "https://huggingface.co/OpenBuddy/openbuddy-openllama-3b-v10-bf16",
    "author": "OpenBuddy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "camel-5b-hf",
    "average": 36.81,
    "arc": 35.15,
    "hellaswag": 57.62,
    "mmlu": 26.07,
    "truthfulqa": 40.65,
    "winogrande": 61.01,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.05,
    "likes": 103.0,
    "still_on_hub": true,
    "revision": "d1438e22a33b9115af0e47ab3a0fe844cbf588a6",
    "model_name_for_query": "Writer/camel-5b-hf",
    "link": "https://huggingface.co/Writer/camel-5b-hf",
    "author": "Writer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-2.8b-4bit-alpaca",
    "average": 36.77,
    "arc": 34.73,
    "hellaswag": 58.96,
    "mmlu": 25.53,
    "truthfulqa": 39.14,
    "winogrande": 61.64,
    "gsm8k": 0.61,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "?",
    "params": 2.8,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "40e84b6d38aac92a0302c2a682498794ef0fd901",
    "model_name_for_query": "TFLai/pythia-2.8b-4bit-alpaca",
    "link": "https://huggingface.co/TFLai/pythia-2.8b-4bit-alpaca",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-2.7B-Nerys-v2",
    "average": 36.75,
    "arc": 33.28,
    "hellaswag": 61.23,
    "mmlu": 26.44,
    "truthfulqa": 37.23,
    "winogrande": 62.04,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 2.65,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "91d7afd6dbf3bbd1e4ccc6b9a2618d632a8cbb92",
    "model_name_for_query": "KoboldAI/OPT-2.7B-Nerys-v2",
    "link": "https://huggingface.co/KoboldAI/OPT-2.7B-Nerys-v2",
    "author": "KoboldAI"
  },
  {
    "T": "\u2b55",
    "model": "dopeyshearedplats-1.3b-v1",
    "average": 36.74,
    "arc": 34.39,
    "hellaswag": 64.31,
    "mmlu": 25.4,
    "truthfulqa": 38.21,
    "winogrande": 57.38,
    "gsm8k": 0.76,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 1.3,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "45aa5d406bb6975deb801e5fffa27ca23e5724a5",
    "model_name_for_query": "vihangd/dopeyshearedplats-1.3b-v1",
    "link": "https://huggingface.co/vihangd/dopeyshearedplats-1.3b-v1",
    "author": "vihangd"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "opt-2.7b",
    "average": 36.74,
    "arc": 33.96,
    "hellaswag": 61.43,
    "mmlu": 25.43,
    "truthfulqa": 37.43,
    "winogrande": 61.96,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 2.65,
    "likes": 46.0,
    "still_on_hub": true,
    "revision": "397f71a473a150c00f0fe3fc4a2f78ff3ccaf82d",
    "model_name_for_query": "facebook/opt-2.7b",
    "link": "https://huggingface.co/facebook/opt-2.7b",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLmRa-2.7B",
    "average": 36.72,
    "arc": 37.03,
    "hellaswag": 60.65,
    "mmlu": 25.58,
    "truthfulqa": 35.23,
    "winogrande": 61.56,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 2.7,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "93201b7d778272fb3252481c1cbd56f726d43e6b",
    "model_name_for_query": "L-R/LLmRa-2.7B",
    "link": "https://huggingface.co/L-R/LLmRa-2.7B",
    "author": "L-R"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-2.8b-deduped",
    "average": 36.72,
    "arc": 36.26,
    "hellaswag": 60.66,
    "mmlu": 26.78,
    "truthfulqa": 35.56,
    "winogrande": 60.22,
    "gsm8k": 0.83,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.91,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "7d977fed8c4ce9649816af8cd5fe36a639cbe5b2",
    "model_name_for_query": "EleutherAI/pythia-2.8b-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-2.8b-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chopt-2_7b",
    "average": 36.72,
    "arc": 36.01,
    "hellaswag": 63.38,
    "mmlu": 25.44,
    "truthfulqa": 37.71,
    "winogrande": 57.77,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 2.65,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "45f57352c10a1fb1ec13c4bf387a15552ca1fe65",
    "model_name_for_query": "aisquared/chopt-2_7b",
    "link": "https://huggingface.co/aisquared/chopt-2_7b",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open_llama_3b_600bt_preview",
    "average": 36.65,
    "arc": 36.86,
    "hellaswag": 59.96,
    "mmlu": 25.97,
    "truthfulqa": 32.81,
    "winogrande": 63.69,
    "gsm8k": 0.61,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d8fddf7651dfcae5aefda59d9e868c9111d8bdb3",
    "model_name_for_query": "danielhanchen/open_llama_3b_600bt_preview",
    "link": "https://huggingface.co/danielhanchen/open_llama_3b_600bt_preview",
    "author": "danielhanchen"
  },
  {
    "T": "\u2b55",
    "model": "42dot_LLM-SFT-1.3B",
    "average": 36.61,
    "arc": 36.09,
    "hellaswag": 58.96,
    "mmlu": 25.51,
    "truthfulqa": 39.98,
    "winogrande": 58.41,
    "gsm8k": 0.68,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.44,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "7474cafe5dc60549c19f89f7c49392a8a32b9199",
    "model_name_for_query": "42dot/42dot_LLM-SFT-1.3B",
    "link": "https://huggingface.co/42dot/42dot_LLM-SFT-1.3B",
    "author": "42dot"
  },
  {
    "T": "\u2b55",
    "model": "Deer-3b",
    "average": 36.55,
    "arc": 38.48,
    "hellaswag": 57.41,
    "mmlu": 25.64,
    "truthfulqa": 39.98,
    "winogrande": 57.46,
    "gsm8k": 0.3,
    "model_type": "instruction-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "53ea8f8862fc1820f0cd31f62953b7290fd79867",
    "model_name_for_query": "PSanni/Deer-3b",
    "link": "https://huggingface.co/PSanni/Deer-3b",
    "author": "PSanni"
  },
  {
    "T": "\u2b55",
    "model": "CodeLlama-7b-Python-hf",
    "average": 36.42,
    "arc": 29.27,
    "hellaswag": 50.12,
    "mmlu": 28.37,
    "truthfulqa": 41.61,
    "winogrande": 64.01,
    "gsm8k": 5.16,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 6.74,
    "likes": 54.0,
    "still_on_hub": true,
    "revision": "ec4dd26f30674fdee00ef161b55f464ce28f9c20",
    "model_name_for_query": "codellama/CodeLlama-7b-Python-hf",
    "link": "https://huggingface.co/codellama/CodeLlama-7b-Python-hf",
    "author": "codellama"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "xglm-7.5B",
    "average": 36.38,
    "arc": 34.13,
    "hellaswag": 60.77,
    "mmlu": 27.79,
    "truthfulqa": 36.66,
    "winogrande": 58.72,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 7.49,
    "likes": 43.0,
    "still_on_hub": true,
    "revision": "732d59308a844004bd9a4def972cc7c3896a38e0",
    "model_name_for_query": "facebook/xglm-7.5B",
    "link": "https://huggingface.co/facebook/xglm-7.5B",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Phind-CodeLlama-34B-Python-v1",
    "average": 36.33,
    "arc": 24.66,
    "hellaswag": 29.77,
    "mmlu": 27.95,
    "truthfulqa": 45.27,
    "winogrande": 68.82,
    "gsm8k": 21.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 231.0,
    "still_on_hub": true,
    "revision": "3aabef8c9bc1b3ec2fffed053645bc1e2d829b6c",
    "model_name_for_query": "Phind/Phind-CodeLlama-34B-Python-v1",
    "link": "https://huggingface.co/Phind/Phind-CodeLlama-34B-Python-v1",
    "author": "Phind"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Cerebras-GPT-6.7B",
    "average": 36.27,
    "arc": 35.07,
    "hellaswag": 59.36,
    "mmlu": 25.93,
    "truthfulqa": 38.02,
    "winogrande": 58.72,
    "gsm8k": 0.53,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.66,
    "likes": 61.0,
    "still_on_hub": true,
    "revision": "4f56c6e28f9a2a1c470626f1a064238806f19f09",
    "model_name_for_query": "cerebras/Cerebras-GPT-6.7B",
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-6.7B",
    "author": "cerebras"
  },
  {
    "T": "?",
    "model": "TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
    "average": 36.26,
    "arc": 33.53,
    "hellaswag": 59.38,
    "mmlu": 26.22,
    "truthfulqa": 36.79,
    "winogrande": 60.22,
    "gsm8k": 1.44,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "03978af6c0997cda809de070e056ee5ddb7e7188",
    "model_name_for_query": "TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
    "link": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
    "author": "TinyLlama"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-neo-2.7B",
    "average": 36.2,
    "arc": 33.36,
    "hellaswag": 56.24,
    "mmlu": 26.45,
    "truthfulqa": 39.78,
    "winogrande": 60.06,
    "gsm8k": 1.29,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 2.72,
    "likes": 361.0,
    "still_on_hub": true,
    "revision": "e24fa291132763e59f4a5422741b424fb5d59056",
    "model_name_for_query": "EleutherAI/gpt-neo-2.7B",
    "link": "https://huggingface.co/EleutherAI/gpt-neo-2.7B",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bertin-gpt-j-6B-alpaca",
    "average": 36.19,
    "arc": 36.01,
    "hellaswag": 54.3,
    "mmlu": 27.66,
    "truthfulqa": 43.38,
    "winogrande": 55.8,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 5.84,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "636b17d6044189343475d1889f076aba73036905",
    "model_name_for_query": "bertin-project/bertin-gpt-j-6B-alpaca",
    "link": "https://huggingface.co/bertin-project/bertin-gpt-j-6B-alpaca",
    "author": "bertin-project"
  },
  {
    "T": "\ud83d\udd36",
    "model": "falcon_1b_stage3_2",
    "average": 36.19,
    "arc": 34.56,
    "hellaswag": 58.37,
    "mmlu": 23.87,
    "truthfulqa": 39.89,
    "winogrande": 60.46,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aec2f59879ea6dfa5233611c4cf83cf3cb974d40",
    "model_name_for_query": "euclaise/falcon_1b_stage3_2",
    "link": "https://huggingface.co/euclaise/falcon_1b_stage3_2",
    "author": "euclaise"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "StellarX-4B-V0.2",
    "average": 36.15,
    "arc": 34.64,
    "hellaswag": 56.74,
    "mmlu": 25.55,
    "truthfulqa": 38.55,
    "winogrande": 61.4,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 2.65,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "605b6812956400dbde24ad7b8649a744a2ddfc8e",
    "model_name_for_query": "Dampish/StellarX-4B-V0.2",
    "link": "https://huggingface.co/Dampish/StellarX-4B-V0.2",
    "author": "Dampish"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "bloom-3b",
    "average": 36.07,
    "arc": 35.75,
    "hellaswag": 54.37,
    "mmlu": 26.59,
    "truthfulqa": 40.57,
    "winogrande": 57.62,
    "gsm8k": 1.52,
    "model_type": "pretrained",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 3.0,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "52bc5b43010b4844513826b8be3f78c7344c37d7",
    "model_name_for_query": "bigscience/bloom-3b",
    "link": "https://huggingface.co/bigscience/bloom-3b",
    "author": "bigscience"
  },
  {
    "T": "?",
    "model": "Wizard-Vicuna-13B-Uncensored-GPTQ",
    "average": 36.06,
    "arc": 29.61,
    "hellaswag": 25.47,
    "mmlu": 25.34,
    "truthfulqa": 50.25,
    "winogrande": 75.77,
    "gsm8k": 9.93,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 242.0,
    "still_on_hub": true,
    "revision": "d9b00ec47ae3546398432f0693fe2d5d92bf143b",
    "model_name_for_query": "TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ",
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "blossom-v2-3b",
    "average": 35.98,
    "arc": 35.32,
    "hellaswag": 54.1,
    "mmlu": 23.99,
    "truthfulqa": 43.11,
    "winogrande": 58.8,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1a403344de52ddb7f18548a526a927714adfe4d4",
    "model_name_for_query": "Azure99/blossom-v2-3b",
    "link": "https://huggingface.co/Azure99/blossom-v2-3b",
    "author": "Azure99"
  },
  {
    "T": "\u2b55",
    "model": "shearedplats-1.3b-v1",
    "average": 35.97,
    "arc": 35.41,
    "hellaswag": 62.75,
    "mmlu": 24.75,
    "truthfulqa": 33.93,
    "winogrande": 58.48,
    "gsm8k": 0.53,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 1.3,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7ac93152e1807ec1d732500255a747e27922fb1a",
    "model_name_for_query": "vihangd/shearedplats-1.3b-v1",
    "link": "https://huggingface.co/vihangd/shearedplats-1.3b-v1",
    "author": "vihangd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Sheared-LLaMA-1.3B",
    "average": 35.95,
    "arc": 32.85,
    "hellaswag": 60.91,
    "mmlu": 25.71,
    "truthfulqa": 37.14,
    "winogrande": 58.64,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.28,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "b1c3f74c8495e27b3963d64af0781d4a611794f3",
    "model_name_for_query": "princeton-nlp/Sheared-LLaMA-1.3B",
    "link": "https://huggingface.co/princeton-nlp/Sheared-LLaMA-1.3B",
    "author": "princeton-nlp"
  },
  {
    "T": "\ud83d\udd36",
    "model": "GPT-J-6B-Adventure",
    "average": 35.95,
    "arc": 37.12,
    "hellaswag": 61.26,
    "mmlu": 25.94,
    "truthfulqa": 34.56,
    "winogrande": 55.96,
    "gsm8k": 0.83,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "e2c00dc99f986f2430f5d34c0214969cee786755",
    "model_name_for_query": "KoboldAI/GPT-J-6B-Adventure",
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Adventure",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeLlama-34b-Python-hf",
    "average": 35.92,
    "arc": 38.05,
    "hellaswag": 34.79,
    "mmlu": 32.96,
    "truthfulqa": 43.57,
    "winogrande": 66.14,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 33.48,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "45f38e53a579a2b39298cc57ab04078722bebec0",
    "model_name_for_query": "ehartford/CodeLlama-34b-Python-hf",
    "link": "https://huggingface.co/ehartford/CodeLlama-34b-Python-hf",
    "author": "ehartford"
  },
  {
    "T": "\u2b55",
    "model": "opt-flan-iml-6.7b",
    "average": 35.84,
    "arc": 30.12,
    "hellaswag": 58.82,
    "mmlu": 25.12,
    "truthfulqa": 36.74,
    "winogrande": 64.25,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 6.66,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cbe8d60db6f3c52e653ca73e23a1c34c08127d02",
    "model_name_for_query": "MayaPH/opt-flan-iml-6.7b",
    "link": "https://huggingface.co/MayaPH/opt-flan-iml-6.7b",
    "author": "MayaPH"
  },
  {
    "T": "\u2b55",
    "model": "rwkv-raven-3b",
    "average": 35.81,
    "arc": 36.69,
    "hellaswag": 59.78,
    "mmlu": 24.87,
    "truthfulqa": 35.6,
    "winogrande": 57.46,
    "gsm8k": 0.45,
    "model_type": "instruction-tuned",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 2.86,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "1ddeea6a7313c8ba8824645d7aa88d5449458f67",
    "model_name_for_query": "RWKV/rwkv-raven-3b",
    "link": "https://huggingface.co/RWKV/rwkv-raven-3b",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "ShearedLlama-1.3b-FFT-Test1",
    "average": 35.71,
    "arc": 32.68,
    "hellaswag": 59.99,
    "mmlu": 25.69,
    "truthfulqa": 36.97,
    "winogrande": 58.72,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.3,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "68e43c006a01764d3ff2bcaeaec5289f2ddad36a",
    "model_name_for_query": "Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1",
    "link": "https://huggingface.co/Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1",
    "author": "Dans-DiscountModels"
  },
  {
    "T": "\ud83d\udd36",
    "model": "42dot_LLM-PLM-1.3B",
    "average": 35.7,
    "arc": 32.42,
    "hellaswag": 56.39,
    "mmlu": 27.09,
    "truthfulqa": 38.68,
    "winogrande": 58.88,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.44,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "a72bf57eb02cd4ea4388a344b4a5893aa95698da",
    "model_name_for_query": "42dot/42dot_LLM-PLM-1.3B",
    "link": "https://huggingface.co/42dot/42dot_LLM-PLM-1.3B",
    "author": "42dot"
  },
  {
    "T": "\ud83d\udd36",
    "model": "starcoder-finetune-selfinstruct",
    "average": 35.65,
    "arc": 31.23,
    "hellaswag": 47.66,
    "mmlu": 29.52,
    "truthfulqa": 41.63,
    "winogrande": 57.77,
    "gsm8k": 6.07,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "b21bd307ea7417185e7dc59557c399a3e4e0092b",
    "model_name_for_query": "sartmis1/starcoder-finetune-selfinstruct",
    "link": "https://huggingface.co/sartmis1/starcoder-finetune-selfinstruct",
    "author": "sartmis1"
  },
  {
    "T": "\ud83d\udd36",
    "model": "20231206094523-pretrain-Llama-2-13b-hf-76000",
    "average": 35.58,
    "arc": 31.06,
    "hellaswag": 52.03,
    "mmlu": 24.43,
    "truthfulqa": 44.71,
    "winogrande": 61.25,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.25,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "28b3ae089b5610053f2294d24667fe248405f031",
    "model_name_for_query": "zyh3826/20231206094523-pretrain-Llama-2-13b-hf-76000",
    "link": "https://huggingface.co/zyh3826/20231206094523-pretrain-Llama-2-13b-hf-76000",
    "author": "zyh3826"
  },
  {
    "T": "\ud83d\udd36",
    "model": "tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
    "average": 35.58,
    "arc": 32.85,
    "hellaswag": 58.16,
    "mmlu": 25.96,
    "truthfulqa": 38.35,
    "winogrande": 57.7,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e55b262cbd0ee52f7a4cbda136dbf1a027987c47",
    "model_name_for_query": "habanoz/tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
    "link": "https://huggingface.co/habanoz/tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
    "author": "habanoz"
  },
  {
    "T": "?",
    "model": "wizard-vicuna-13B-GPTQ",
    "average": 35.56,
    "arc": 28.67,
    "hellaswag": 25.94,
    "mmlu": 25.84,
    "truthfulqa": 48.53,
    "winogrande": 74.74,
    "gsm8k": 9.63,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 99.0,
    "still_on_hub": true,
    "revision": "936a51c0219744d7a9598d0c65a7d18e01660601",
    "model_name_for_query": "TheBloke/wizard-vicuna-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/wizard-vicuna-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1B-Chat-v0.3",
    "average": 35.56,
    "arc": 35.07,
    "hellaswag": 57.7,
    "mmlu": 25.53,
    "truthfulqa": 36.67,
    "winogrande": 57.7,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.03,
    "likes": 5.0,
    "still_on_hub": false,
    "revision": "20dd44d78aa09480bf15ca0ecc0c0780951d49a9",
    "model_name_for_query": "PY007/TinyLlama-1.1B-Chat-v0.3",
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-Chat-v0.3",
    "author": "PY007"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wangchanglm-7.5B-sft-en-sharded",
    "average": 35.55,
    "arc": 34.47,
    "hellaswag": 59.81,
    "mmlu": 26.37,
    "truthfulqa": 34.15,
    "winogrande": 58.25,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 7.49,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dd22eaea8be3fcb8c28f61b513a89d1adac00ffd",
    "model_name_for_query": "pythainlp/wangchanglm-7.5B-sft-en-sharded",
    "link": "https://huggingface.co/pythainlp/wangchanglm-7.5B-sft-en-sharded",
    "author": "pythainlp"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1B-FFT-Test2",
    "average": 35.53,
    "arc": 34.22,
    "hellaswag": 57.96,
    "mmlu": 25.54,
    "truthfulqa": 36.32,
    "winogrande": 58.8,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dfedea2fbf66c27c88cd4b2eeb0ff0f5041e3b59",
    "model_name_for_query": "Dans-DiscountModels/TinyLlama-1.1B-FFT-Test2",
    "link": "https://huggingface.co/Dans-DiscountModels/TinyLlama-1.1B-FFT-Test2",
    "author": "Dans-DiscountModels"
  },
  {
    "T": "?",
    "model": "starchat-alpha",
    "average": 35.49,
    "arc": 31.57,
    "hellaswag": 49.43,
    "mmlu": 30.76,
    "truthfulqa": 43.66,
    "winogrande": 55.09,
    "gsm8k": 2.43,
    "model_type": "",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": "bigcode-openrail-m",
    "params": 15.52,
    "likes": 220.0,
    "still_on_hub": true,
    "revision": "b693a7a7d52bed1cd7cc0fe00399db838b09c74f",
    "model_name_for_query": "HuggingFaceH4/starchat-alpha",
    "link": "https://huggingface.co/HuggingFaceH4/starchat-alpha",
    "author": "HuggingFaceH4"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-1.4.1-PI-8192-fp16",
    "average": 35.46,
    "arc": 32.0,
    "hellaswag": 53.88,
    "mmlu": 31.43,
    "truthfulqa": 38.59,
    "winogrande": 56.83,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 32.53,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "1dd7804dbbb547c1be852652ce74568ba41d4e73",
    "model_name_for_query": "bhenrym14/airoboros-33b-gpt4-1.4.1-PI-8192-fp16",
    "link": "https://huggingface.co/bhenrym14/airoboros-33b-gpt4-1.4.1-PI-8192-fp16",
    "author": "bhenrym14"
  },
  {
    "T": "\ud83d\udd36",
    "model": "ShortKingv0.1",
    "average": 35.45,
    "arc": 34.22,
    "hellaswag": 54.59,
    "mmlu": 25.78,
    "truthfulqa": 41.64,
    "winogrande": 56.04,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.42,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "6cd9b5bc13ee15b5e7e7cfb46477bc6a7c0b5d47",
    "model_name_for_query": "AtAndDev/ShortKingv0.1",
    "link": "https://huggingface.co/AtAndDev/ShortKingv0.1",
    "author": "AtAndDev"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1",
    "average": 35.45,
    "arc": 31.48,
    "hellaswag": 54.4,
    "mmlu": 25.47,
    "truthfulqa": 42.34,
    "winogrande": 57.54,
    "gsm8k": 1.44,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "74cd9eba94e77832b3081689fc5c99c37c063790",
    "model_name_for_query": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1",
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1",
    "author": "habanoz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Nape-0",
    "average": 35.43,
    "arc": 32.68,
    "hellaswag": 58.68,
    "mmlu": 24.88,
    "truthfulqa": 38.99,
    "winogrande": 57.3,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "47e07bd518b989890a7f694d39e2772e703384c9",
    "model_name_for_query": "nnpy/Nape-0",
    "link": "https://huggingface.co/nnpy/Nape-0",
    "author": "nnpy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "starcoder_mirror",
    "average": 35.43,
    "arc": 31.31,
    "hellaswag": 45.82,
    "mmlu": 29.29,
    "truthfulqa": 43.38,
    "winogrande": 57.22,
    "gsm8k": 5.53,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "eb5f39bac15ccab9463001aa203e33d49f4ff7cb",
    "model_name_for_query": "lizhuang144/starcoder_mirror",
    "link": "https://huggingface.co/lizhuang144/starcoder_mirror",
    "author": "lizhuang144"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
    "average": 35.42,
    "arc": 31.4,
    "hellaswag": 54.24,
    "mmlu": 25.36,
    "truthfulqa": 42.47,
    "winogrande": 57.7,
    "gsm8k": 1.36,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b1ec2a1e08eb790b9a32a43053316650921af943",
    "model_name_for_query": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
    "author": "habanoz"
  },
  {
    "T": "?",
    "model": "openchat_v2_openorca_preview-GPTQ",
    "average": 35.38,
    "arc": 27.99,
    "hellaswag": 26.06,
    "mmlu": 24.24,
    "truthfulqa": 50.08,
    "winogrande": 70.64,
    "gsm8k": 13.27,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "5a4c2ea612b71d7c00118f796db7189bc1a0c930",
    "model_name_for_query": "TheBloke/openchat_v2_openorca_preview-GPTQ",
    "link": "https://huggingface.co/TheBloke/openchat_v2_openorca_preview-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "chopt-1_3b",
    "average": 35.32,
    "arc": 31.48,
    "hellaswag": 56.63,
    "mmlu": 25.35,
    "truthfulqa": 40.19,
    "winogrande": 58.25,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 1.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fdd3691978f557baf9d1c20d4ede900c47f7e135",
    "model_name_for_query": "aisquared/chopt-1_3b",
    "link": "https://huggingface.co/aisquared/chopt-1_3b",
    "author": "aisquared"
  },
  {
    "T": "\u2b55",
    "model": "Walter-Llama-1B",
    "average": 35.29,
    "arc": 32.85,
    "hellaswag": 61.05,
    "mmlu": 27.46,
    "truthfulqa": 33.93,
    "winogrande": 56.43,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ae782b5a37bc961d0860e6a8edb10547bb5285d7",
    "model_name_for_query": "KnutJaegersberg/Walter-Llama-1B",
    "link": "https://huggingface.co/KnutJaegersberg/Walter-Llama-1B",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "dopeyplats-1.1b-2T-v1",
    "average": 35.28,
    "arc": 33.11,
    "hellaswag": 54.31,
    "mmlu": 24.55,
    "truthfulqa": 39.26,
    "winogrande": 58.8,
    "gsm8k": 1.67,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4ca47b470296de0e7bf3261e377aabaff9ad5c06",
    "model_name_for_query": "vihangd/dopeyplats-1.1b-2T-v1",
    "link": "https://huggingface.co/vihangd/dopeyplats-1.1b-2T-v1",
    "author": "vihangd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
    "average": 35.28,
    "arc": 31.14,
    "hellaswag": 54.31,
    "mmlu": 25.42,
    "truthfulqa": 41.72,
    "winogrande": 57.77,
    "gsm8k": 1.29,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7cd6d5ad10180127771e4326772eae3d40fa8445",
    "model_name_for_query": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
    "author": "habanoz"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "rwkv-4-3b-pile",
    "average": 35.25,
    "arc": 36.01,
    "hellaswag": 59.66,
    "mmlu": 24.67,
    "truthfulqa": 32.14,
    "winogrande": 58.33,
    "gsm8k": 0.68,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 2.86,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "7fdda3c5570d4a9711f8f02cc3a20941a5623cd3",
    "model_name_for_query": "RWKV/rwkv-4-3b-pile",
    "link": "https://huggingface.co/RWKV/rwkv-4-3b-pile",
    "author": "RWKV"
  },
  {
    "T": "\u2b55",
    "model": "Deacon-1b",
    "average": 35.21,
    "arc": 32.42,
    "hellaswag": 58.62,
    "mmlu": 24.89,
    "truthfulqa": 35.05,
    "winogrande": 59.59,
    "gsm8k": 0.68,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "77f16fd4c605fe043033d4335024fb887cedef69",
    "model_name_for_query": "KnutJaegersberg/Deacon-1b",
    "link": "https://huggingface.co/KnutJaegersberg/Deacon-1b",
    "author": "KnutJaegersberg"
  },
  {
    "T": "?",
    "model": "opt-iml-max-1.3b",
    "average": 35.21,
    "arc": 30.72,
    "hellaswag": 53.81,
    "mmlu": 27.61,
    "truthfulqa": 38.34,
    "winogrande": 60.22,
    "gsm8k": 0.53,
    "model_type": "",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 1.32,
    "likes": 34.0,
    "still_on_hub": true,
    "revision": "d60fa58f50def19751da2075791da359ca19d273",
    "model_name_for_query": "facebook/opt-iml-max-1.3b",
    "link": "https://huggingface.co/facebook/opt-iml-max-1.3b",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "palmyra-base",
    "average": 35.18,
    "arc": 31.91,
    "hellaswag": 55.39,
    "mmlu": 27.15,
    "truthfulqa": 37.57,
    "winogrande": 58.09,
    "gsm8k": 0.99,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 5.05,
    "likes": 33.0,
    "still_on_hub": true,
    "revision": "df2f3bdb7cbe4295d69cf0cbc35f3ceaf451de82",
    "model_name_for_query": "Writer/palmyra-base",
    "link": "https://huggingface.co/Writer/palmyra-base",
    "author": "Writer"
  },
  {
    "T": "?",
    "model": "wizard-mega-13B-GPTQ",
    "average": 35.18,
    "arc": 27.73,
    "hellaswag": 26.01,
    "mmlu": 24.97,
    "truthfulqa": 48.69,
    "winogrande": 74.74,
    "gsm8k": 8.95,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 102.0,
    "still_on_hub": true,
    "revision": "848bf2514f804799dd28c188e5428d497dc983fb",
    "model_name_for_query": "TheBloke/wizard-mega-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/wizard-mega-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fairseq-dense-1.3B",
    "average": 35.16,
    "arc": 31.14,
    "hellaswag": 58.39,
    "mmlu": 24.98,
    "truthfulqa": 37.43,
    "winogrande": 59.04,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.41,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "20bf1732212ea81adb45b782a25ce69e65a01ad2",
    "model_name_for_query": "KoboldAI/fairseq-dense-1.3B",
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-1.3B",
    "author": "KoboldAI"
  },
  {
    "T": "?",
    "model": "chronos-wizardlm-uc-scot-st-13B-GPTQ",
    "average": 35.15,
    "arc": 27.99,
    "hellaswag": 26.1,
    "mmlu": 25.72,
    "truthfulqa": 49.68,
    "winogrande": 74.51,
    "gsm8k": 6.9,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "c4246e4b8d3fc77b9fe4ebb1ead61cda4b83575b",
    "model_name_for_query": "TheBloke/chronos-wizardlm-uc-scot-st-13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/chronos-wizardlm-uc-scot-st-13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-1.4b-deduped-sharegpt",
    "average": 35.11,
    "arc": 34.3,
    "hellaswag": 54.49,
    "mmlu": 24.0,
    "truthfulqa": 41.81,
    "winogrande": 55.25,
    "gsm8k": 0.83,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.42,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5b50336208840f557ef3301d841e7994caaa63bb",
    "model_name_for_query": "HWERI/pythia-1.4b-deduped-sharegpt",
    "link": "https://huggingface.co/HWERI/pythia-1.4b-deduped-sharegpt",
    "author": "HWERI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-1.4b-deduped-sharegpt",
    "average": 35.11,
    "arc": 34.3,
    "hellaswag": 54.49,
    "mmlu": 24.0,
    "truthfulqa": 41.81,
    "winogrande": 55.25,
    "gsm8k": 0.83,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.42,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "03dfdc25c111a6a4a16d3da12190697611936426",
    "model_name_for_query": "beaugogh/pythia-1.4b-deduped-sharegpt",
    "link": "https://huggingface.co/beaugogh/pythia-1.4b-deduped-sharegpt",
    "author": "beaugogh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "wangchanglm-7.5B-sft-enth",
    "average": 35.11,
    "arc": 33.79,
    "hellaswag": 58.99,
    "mmlu": 24.52,
    "truthfulqa": 34.9,
    "winogrande": 57.93,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 7.49,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "eeee33ea6778a5e66184eeb4bf4294d4316b1933",
    "model_name_for_query": "pythainlp/wangchanglm-7.5B-sft-enth",
    "link": "https://huggingface.co/pythainlp/wangchanglm-7.5B-sft-enth",
    "author": "pythainlp"
  },
  {
    "T": "\ud83d\udd36",
    "model": "metharme-1.3b",
    "average": 35.04,
    "arc": 34.39,
    "hellaswag": 55.94,
    "mmlu": 25.07,
    "truthfulqa": 37.68,
    "winogrande": 56.43,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.52,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "62ec4ff53042f692ef0661e54f371747214707a4",
    "model_name_for_query": "PygmalionAI/metharme-1.3b",
    "link": "https://huggingface.co/PygmalionAI/metharme-1.3b",
    "author": "PygmalionAI"
  },
  {
    "T": "\u2b55",
    "model": "falcon-1b-t-sft",
    "average": 35.02,
    "arc": 32.94,
    "hellaswag": 57.24,
    "mmlu": 25.26,
    "truthfulqa": 38.49,
    "winogrande": 55.88,
    "gsm8k": 0.3,
    "model_type": "instruction-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3b891a0c37f8fa98301c85fcf34baae876e4cac1",
    "model_name_for_query": "KnutJaegersberg/falcon-1b-t-sft",
    "link": "https://huggingface.co/KnutJaegersberg/falcon-1b-t-sft",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLmRa-1.3B",
    "average": 35.0,
    "arc": 32.68,
    "hellaswag": 58.77,
    "mmlu": 23.23,
    "truthfulqa": 36.21,
    "winogrande": 59.04,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8d5e8bb336cb886e20a7570bc00c2381792338a5",
    "model_name_for_query": "L-R/LLmRa-1.3B",
    "link": "https://huggingface.co/L-R/LLmRa-1.3B",
    "author": "L-R"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-1.4b-deduped",
    "average": 35.0,
    "arc": 32.68,
    "hellaswag": 54.96,
    "mmlu": 25.56,
    "truthfulqa": 38.66,
    "winogrande": 57.3,
    "gsm8k": 0.83,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "77f320b24ccae4aa85a5890dbb9514bd11267bb3",
    "model_name_for_query": "EleutherAI/pythia-1.4b-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-1.4b-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "?",
    "model": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1",
    "average": 34.98,
    "arc": 30.72,
    "hellaswag": 54.32,
    "mmlu": 24.78,
    "truthfulqa": 41.67,
    "winogrande": 57.62,
    "gsm8k": 0.76,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "2b961bacab9fcd4bf9a0d6979b024fe23f61555e",
    "model_name_for_query": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1",
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1",
    "author": "habanoz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "falcon_1b_stage3",
    "average": 34.95,
    "arc": 33.11,
    "hellaswag": 54.08,
    "mmlu": 25.11,
    "truthfulqa": 37.92,
    "winogrande": 59.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "593e48197e91537b203ba288260f6580b9cbcbe6",
    "model_name_for_query": "euclaise/falcon_1b_stage3",
    "link": "https://huggingface.co/euclaise/falcon_1b_stage3",
    "author": "euclaise"
  },
  {
    "T": "?",
    "model": "TinyLlama-1.1B-Chat-v0.6",
    "average": 34.94,
    "arc": 31.66,
    "hellaswag": 55.79,
    "mmlu": 25.98,
    "truthfulqa": 34.72,
    "winogrande": 59.35,
    "gsm8k": 2.12,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "bf9ae1c8bf026667e6f810768de259bb4a7f4777",
    "model_name_for_query": "TinyLlama/TinyLlama-1.1B-Chat-v0.6",
    "link": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.6",
    "author": "TinyLlama"
  },
  {
    "T": "\ud83d\udd36",
    "model": "stablelm-7b-sft-v7-epoch-3",
    "average": 34.85,
    "arc": 36.01,
    "hellaswag": 55.81,
    "mmlu": 25.01,
    "truthfulqa": 37.02,
    "winogrande": 54.85,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 7.56,
    "likes": 65.0,
    "still_on_hub": true,
    "revision": "4c454bfc0e3618b3d574e28ba71369607e637e91",
    "model_name_for_query": "OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "link": "https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "author": "OpenAssistant"
  },
  {
    "T": "\u2b55",
    "model": "Tiny-Vicuna-1B",
    "average": 34.76,
    "arc": 33.45,
    "hellaswag": 55.92,
    "mmlu": 25.45,
    "truthfulqa": 33.82,
    "winogrande": 58.41,
    "gsm8k": 1.52,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "175336a0000f36b508575ef1a2da05755faf48c3",
    "model_name_for_query": "Jiayi-Pan/Tiny-Vicuna-1B",
    "link": "https://huggingface.co/Jiayi-Pan/Tiny-Vicuna-1B",
    "author": "Jiayi-Pan"
  },
  {
    "T": "\u2b55",
    "model": "megachat",
    "average": 34.75,
    "arc": 30.8,
    "hellaswag": 54.35,
    "mmlu": 25.55,
    "truthfulqa": 39.85,
    "winogrande": 56.99,
    "gsm8k": 0.99,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "789b259a18ca7b168ced4995138ad6195cd2e8e8",
    "model_name_for_query": "w95/megachat",
    "link": "https://huggingface.co/w95/megachat",
    "author": "w95"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lamini-neo-1.3b",
    "average": 34.73,
    "arc": 32.76,
    "hellaswag": 49.13,
    "mmlu": 28.79,
    "truthfulqa": 41.05,
    "winogrande": 56.51,
    "gsm8k": 0.15,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.32,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "a5c7ecc4d908e7a9469d080308af64ae775c733d",
    "model_name_for_query": "MBZUAI/lamini-neo-1.3b",
    "link": "https://huggingface.co/MBZUAI/lamini-neo-1.3b",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LaMini-GPT-1.5B",
    "average": 34.67,
    "arc": 31.4,
    "hellaswag": 48.38,
    "mmlu": 29.92,
    "truthfulqa": 42.47,
    "winogrande": 55.88,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.56,
    "likes": 32.0,
    "still_on_hub": true,
    "revision": "88ca6f5abe2335bac317e82684e574afdd6046b5",
    "model_name_for_query": "MBZUAI/LaMini-GPT-1.5B",
    "link": "https://huggingface.co/MBZUAI/LaMini-GPT-1.5B",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardCoder-15B-V1.0",
    "average": 34.64,
    "arc": 32.34,
    "hellaswag": 47.2,
    "mmlu": 29.43,
    "truthfulqa": 41.56,
    "winogrande": 55.17,
    "gsm8k": 2.12,
    "model_type": "fine-tuned",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": "bigscience-openrail-m",
    "params": 15.52,
    "likes": 621.0,
    "still_on_hub": true,
    "revision": "926ca1b215c4631bc5f8c3e47173381452c23e5c",
    "model_name_for_query": "WizardLM/WizardCoder-15B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardCoder-15B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "?",
    "model": "opt-1.3b",
    "average": 34.6,
    "arc": 29.52,
    "hellaswag": 54.53,
    "mmlu": 24.96,
    "truthfulqa": 38.71,
    "winogrande": 59.75,
    "gsm8k": 0.15,
    "model_type": "",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 1.32,
    "likes": 117.0,
    "still_on_hub": true,
    "revision": "8c7b10754972749675d22364c25c428b29face51",
    "model_name_for_query": "facebook/opt-1.3b",
    "link": "https://huggingface.co/facebook/opt-1.3b",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1B-Chat-v0.1",
    "average": 34.57,
    "arc": 32.0,
    "hellaswag": 54.21,
    "mmlu": 26.71,
    "truthfulqa": 39.03,
    "winogrande": 54.93,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "7abc14e7779eabc3a028bc695342869d0410dea2",
    "model_name_for_query": "PY007/TinyLlama-1.1B-Chat-v0.1",
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-Chat-v0.1",
    "author": "PY007"
  },
  {
    "T": "?",
    "model": "TinyLlama-1.1B-intermediate-step-955k-token-2T",
    "average": 34.56,
    "arc": 30.29,
    "hellaswag": 54.84,
    "mmlu": 26.47,
    "truthfulqa": 36.07,
    "winogrande": 58.33,
    "gsm8k": 1.36,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "f62ecb34ea0d4acea9d896040a4616a9538e2f36",
    "model_name_for_query": "TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T",
    "link": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T",
    "author": "TinyLlama"
  },
  {
    "T": "\u2b55",
    "model": "gpt-sw3-1.3b-instruct",
    "average": 34.54,
    "arc": 30.97,
    "hellaswag": 51.42,
    "mmlu": 26.17,
    "truthfulqa": 40.31,
    "winogrande": 56.75,
    "gsm8k": 1.59,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 1.44,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5f2f03167dedc59192ee02694e07424a890d9206",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-1.3b-instruct",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-1.3b-instruct",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "?",
    "model": "TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
    "average": 34.53,
    "arc": 31.06,
    "hellaswag": 55.02,
    "mmlu": 26.41,
    "truthfulqa": 35.08,
    "winogrande": 58.01,
    "gsm8k": 1.59,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "586c223b539e05fd8a63733c6a540f292460e639",
    "model_name_for_query": "habanoz/TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
    "author": "habanoz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "average": 34.53,
    "arc": 25.34,
    "hellaswag": 26.66,
    "mmlu": 23.36,
    "truthfulqa": 49.51,
    "winogrande": 73.72,
    "gsm8k": 8.57,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 32.53,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "468225a547a8cb0a62758d813cf9606b58506ab4",
    "model_name_for_query": "bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "link": "https://huggingface.co/bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "author": "bhenrym14"
  },
  {
    "T": "\u2b55",
    "model": "tinyllama-1.1b-chat-v0.3_platypus",
    "average": 34.5,
    "arc": 30.29,
    "hellaswag": 55.12,
    "mmlu": 26.13,
    "truthfulqa": 39.15,
    "winogrande": 55.8,
    "gsm8k": 0.53,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 1.03,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "0bb6ebe1d41d394bae0ed9107ec8d776d9d76a68",
    "model_name_for_query": "lgaalves/tinyllama-1.1b-chat-v0.3_platypus",
    "link": "https://huggingface.co/lgaalves/tinyllama-1.1b-chat-v0.3_platypus",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-1.3b",
    "average": 34.46,
    "arc": 31.14,
    "hellaswag": 51.43,
    "mmlu": 26.55,
    "truthfulqa": 39.24,
    "winogrande": 57.38,
    "gsm8k": 0.99,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "34b668ff0acfe56f2d541aa46b385557ee39eb3f",
    "model_name_for_query": "EleutherAI/pythia-1.3b",
    "link": "https://huggingface.co/EleutherAI/pythia-1.3b",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "PULI-GPTrio",
    "average": 34.42,
    "arc": 30.72,
    "hellaswag": 53.49,
    "mmlu": 24.73,
    "truthfulqa": 39.03,
    "winogrande": 57.77,
    "gsm8k": 0.76,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 7.06,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "c85efce322a0f6d93d64f7b9096525753da6913e",
    "model_name_for_query": "NYTK/PULI-GPTrio",
    "link": "https://huggingface.co/NYTK/PULI-GPTrio",
    "author": "NYTK"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt2-xl",
    "average": 34.38,
    "arc": 30.29,
    "hellaswag": 51.36,
    "mmlu": 26.54,
    "truthfulqa": 38.54,
    "winogrande": 58.25,
    "gsm8k": 1.29,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 1.56,
    "likes": 194.0,
    "still_on_hub": true,
    "revision": "33cdb5c0db5423c1879b1b9f16c352988e8754a8",
    "model_name_for_query": "gpt2-xl",
    "link": "https://huggingface.co/gpt2-xl",
    "author": "gpt2-xl"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyLlama-1.1B-intermediate-step-480k-1T",
    "average": 34.37,
    "arc": 30.89,
    "hellaswag": 52.97,
    "mmlu": 25.0,
    "truthfulqa": 39.55,
    "winogrande": 57.3,
    "gsm8k": 0.53,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.03,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "098830e58452a0a08f90eb0189ec5925803fd48b",
    "model_name_for_query": "PY007/TinyLlama-1.1B-intermediate-step-480k-1T",
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-intermediate-step-480k-1T",
    "author": "PY007"
  },
  {
    "T": "\ud83d\udd36",
    "model": "EverythingLM-13B-16K-GPTQ",
    "average": 34.37,
    "arc": 29.27,
    "hellaswag": 26.24,
    "mmlu": 25.4,
    "truthfulqa": 48.58,
    "winogrande": 71.35,
    "gsm8k": 5.38,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 16.23,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "f14d3df05577f3e1ac35e2c4ec32ce0d39b97508",
    "model_name_for_query": "TheBloke/EverythingLM-13B-16K-GPTQ",
    "link": "https://huggingface.co/TheBloke/EverythingLM-13B-16K-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "stablelm-base-alpha-7b",
    "average": 34.37,
    "arc": 32.0,
    "hellaswag": 51.78,
    "mmlu": 26.21,
    "truthfulqa": 40.19,
    "winogrande": 55.41,
    "gsm8k": 0.61,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 7.56,
    "likes": 208.0,
    "still_on_hub": true,
    "revision": "38366357b5a45e002af2d254ff3d559444ec2147",
    "model_name_for_query": "stabilityai/stablelm-base-alpha-7b",
    "link": "https://huggingface.co/stabilityai/stablelm-base-alpha-7b",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt",
    "average": 34.32,
    "arc": 34.04,
    "hellaswag": 50.51,
    "mmlu": 24.66,
    "truthfulqa": 41.8,
    "winogrande": 54.93,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "754e0c90ed5d9241fdfd5a188572b3ea2152eaa7",
    "model_name_for_query": "h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt",
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt",
    "author": "h2oai"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "xglm-4.5B",
    "average": 34.31,
    "arc": 31.48,
    "hellaswag": 57.95,
    "mmlu": 25.43,
    "truthfulqa": 35.84,
    "winogrande": 54.93,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 5.08,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "dc6a67fac06c8bca7860b84656a0cb736293a7a8",
    "model_name_for_query": "facebook/xglm-4.5B",
    "link": "https://huggingface.co/facebook/xglm-4.5B",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-sw3-1.3b",
    "average": 34.31,
    "arc": 30.38,
    "hellaswag": 50.4,
    "mmlu": 26.14,
    "truthfulqa": 39.97,
    "winogrande": 58.88,
    "gsm8k": 0.08,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.44,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b0d9545a27cfaf9a937adac72ed6953f2dc597de",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-1.3b",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-1.3b",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-4b",
    "average": 34.23,
    "arc": 31.23,
    "hellaswag": 53.29,
    "mmlu": 24.22,
    "truthfulqa": 38.72,
    "winogrande": 57.46,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 3.37,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "fbba77f9894cf738ad8d7d08fc6874856fb42507",
    "model_name_for_query": "winglian/llama-2-4b",
    "link": "https://huggingface.co/winglian/llama-2-4b",
    "author": "winglian"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LLmRa-1.3B_V2",
    "average": 34.21,
    "arc": 30.46,
    "hellaswag": 53.03,
    "mmlu": 26.06,
    "truthfulqa": 36.46,
    "winogrande": 59.27,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 1.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a760ebda8f736988eafea879173c5be468ea68d0",
    "model_name_for_query": "L-R/LLmRa-1.3B_V2",
    "link": "https://huggingface.co/L-R/LLmRa-1.3B_V2",
    "author": "L-R"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v2-1_5b",
    "average": 34.2,
    "arc": 32.59,
    "hellaswag": 53.98,
    "mmlu": 24.93,
    "truthfulqa": 38.77,
    "winogrande": 54.7,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.56,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "97440ff1b6ef749423758e3495cdce1b5e68ee92",
    "model_name_for_query": "aisquared/dlite-v2-1_5b",
    "link": "https://huggingface.co/aisquared/dlite-v2-1_5b",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardCoder-Guanaco-15B-V1.1",
    "average": 34.19,
    "arc": 32.59,
    "hellaswag": 45.42,
    "mmlu": 25.88,
    "truthfulqa": 42.33,
    "winogrande": 56.04,
    "gsm8k": 2.88,
    "model_type": "fine-tuned",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": ["apache-2.0"],
    "params": 15.52,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "979531c84ec0b4e1712d6a5cec6907126a21e605",
    "model_name_for_query": "LoupGarou/WizardCoder-Guanaco-15B-V1.1",
    "link": "https://huggingface.co/LoupGarou/WizardCoder-Guanaco-15B-V1.1",
    "author": "LoupGarou"
  },
  {
    "T": "\ud83d\udd36",
    "model": "starcoder-gpteacher-code-instruct",
    "average": 34.15,
    "arc": 32.68,
    "hellaswag": 47.6,
    "mmlu": 28.63,
    "truthfulqa": 40.41,
    "winogrande": 55.56,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": "bigcode-openrail-m",
    "params": 15.52,
    "likes": 74.0,
    "still_on_hub": true,
    "revision": "d866b68daa719239dc44979dbf39a608ed6f7bce",
    "model_name_for_query": "GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct",
    "link": "https://huggingface.co/GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct",
    "author": "GeorgiaTechResearchInstitute"
  },
  {
    "T": "\u2b55",
    "model": "gpt2-xl_lima",
    "average": 34.12,
    "arc": 31.14,
    "hellaswag": 51.28,
    "mmlu": 25.43,
    "truthfulqa": 38.74,
    "winogrande": 57.22,
    "gsm8k": 0.91,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7db5b1db521abd7578b95138e737637e0037ca5",
    "model_name_for_query": "lgaalves/gpt2-xl_lima",
    "link": "https://huggingface.co/lgaalves/gpt2-xl_lima",
    "author": "lgaalves"
  },
  {
    "T": "\u2b55",
    "model": "Walter-Falcon-1B",
    "average": 34.07,
    "arc": 31.06,
    "hellaswag": 54.92,
    "mmlu": 24.58,
    "truthfulqa": 38.47,
    "winogrande": 55.41,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9cc302810282152eea488e8649e45dbc332313e3",
    "model_name_for_query": "KnutJaegersberg/Walter-Falcon-1B",
    "link": "https://huggingface.co/KnutJaegersberg/Walter-Falcon-1B",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1",
    "average": 34.04,
    "arc": 30.55,
    "hellaswag": 53.7,
    "mmlu": 26.07,
    "truthfulqa": 35.85,
    "winogrande": 58.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "152436a0dd6ca1603b3993bbf08a227ea131f85d",
    "model_name_for_query": "habanoz/TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1",
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1",
    "author": "habanoz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "stablelm-tuned-alpha-7b",
    "average": 34.04,
    "arc": 31.91,
    "hellaswag": 53.59,
    "mmlu": 24.41,
    "truthfulqa": 40.37,
    "winogrande": 53.12,
    "gsm8k": 0.83,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 7.56,
    "likes": 350.0,
    "still_on_hub": true,
    "revision": "25071b093c15c0d1cb2b2876c6deb621b764fcf5",
    "model_name_for_query": "stabilityai/stablelm-tuned-alpha-7b",
    "link": "https://huggingface.co/stabilityai/stablelm-tuned-alpha-7b",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "opt-1.3b-rlhf",
    "average": 33.99,
    "arc": 28.92,
    "hellaswag": 52.77,
    "mmlu": 25.39,
    "truthfulqa": 37.44,
    "winogrande": 58.96,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5b12df71b21b6b7d76ca9d56de6751f25022e854",
    "model_name_for_query": "jzjiao/opt-1.3b-rlhf",
    "link": "https://huggingface.co/jzjiao/opt-1.3b-rlhf",
    "author": "jzjiao"
  },
  {
    "T": "?",
    "model": "bloom-1b7",
    "average": 33.98,
    "arc": 30.63,
    "hellaswag": 47.6,
    "mmlu": 27.48,
    "truthfulqa": 41.31,
    "winogrande": 56.04,
    "gsm8k": 0.83,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 1.72,
    "likes": 100.0,
    "still_on_hub": true,
    "revision": "cc72a88036c2fb937d65efeacc57a0c2ef5d6fe5",
    "model_name_for_query": "bigscience/bloom-1b7",
    "link": "https://huggingface.co/bigscience/bloom-1b7",
    "author": "bigscience"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-2.7b",
    "average": 33.98,
    "arc": 32.76,
    "hellaswag": 54.13,
    "mmlu": 23.28,
    "truthfulqa": 37.17,
    "winogrande": 56.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "creativeml-openrail-m",
    "params": 2.65,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "9533805293bc48e8ddfe9dc1940d8cbc5662113e",
    "model_name_for_query": "PygmalionAI/pygmalion-2.7b",
    "link": "https://huggingface.co/PygmalionAI/pygmalion-2.7b",
    "author": "PygmalionAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardCoder-Guanaco-15B-V1.0",
    "average": 33.96,
    "arc": 30.46,
    "hellaswag": 45.59,
    "mmlu": 26.79,
    "truthfulqa": 46.39,
    "winogrande": 53.12,
    "gsm8k": 1.44,
    "model_type": "fine-tuned",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": ["apache-2.0"],
    "params": 15.52,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "ab5ea678d63eb2324658dcc8cfae267eabc366ef",
    "model_name_for_query": "LoupGarou/WizardCoder-Guanaco-15B-V1.0",
    "link": "https://huggingface.co/LoupGarou/WizardCoder-Guanaco-15B-V1.0",
    "author": "LoupGarou"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gogpt-3b-bloom",
    "average": 33.96,
    "arc": 31.91,
    "hellaswag": 50.32,
    "mmlu": 25.2,
    "truthfulqa": 41.79,
    "winogrande": 54.38,
    "gsm8k": 0.15,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.0,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "fe942d5d0faca8156eaf456ecdf569993eab8062",
    "model_name_for_query": "golaxy/gogpt-3b-bloom",
    "link": "https://huggingface.co/golaxy/gogpt-3b-bloom",
    "author": "golaxy"
  },
  {
    "T": "\u2b55",
    "model": "gpt-2-xl_camel-ai-physics",
    "average": 33.96,
    "arc": 29.52,
    "hellaswag": 50.62,
    "mmlu": 26.79,
    "truthfulqa": 39.12,
    "winogrande": 57.54,
    "gsm8k": 0.15,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 1.56,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e20cf5a8c89441f4dc15fd2af12dbe72b7df8e60",
    "model_name_for_query": "lgaalves/gpt-2-xl_camel-ai-physics",
    "link": "https://huggingface.co/lgaalves/gpt-2-xl_camel-ai-physics",
    "author": "lgaalves"
  },
  {
    "T": "?",
    "model": "WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
    "average": 33.78,
    "arc": 28.41,
    "hellaswag": 26.05,
    "mmlu": 24.71,
    "truthfulqa": 49.54,
    "winogrande": 68.67,
    "gsm8k": 5.31,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 35.58,
    "likes": 69.0,
    "still_on_hub": true,
    "revision": "cd07cc7c55b46524f61214012653c25226d24c0d",
    "model_name_for_query": "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyLlama-1.1B-intermediate-step-240k-503b",
    "average": 33.72,
    "arc": 29.27,
    "hellaswag": 49.71,
    "mmlu": 26.26,
    "truthfulqa": 40.17,
    "winogrande": 56.59,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "213ebf60d7fdd3258fa5574840b06c97a7e8cf5d",
    "model_name_for_query": "PY007/TinyLlama-1.1B-intermediate-step-240k-503b",
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-intermediate-step-240k-503b",
    "author": "PY007"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-neo-1.3B",
    "average": 33.58,
    "arc": 31.23,
    "hellaswag": 48.47,
    "mmlu": 24.82,
    "truthfulqa": 39.63,
    "winogrande": 56.91,
    "gsm8k": 0.45,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 1.37,
    "likes": 206.0,
    "still_on_hub": true,
    "revision": "8282180b53cba30a1575e49de1530019e5931739",
    "model_name_for_query": "EleutherAI/gpt-neo-1.3B",
    "link": "https://huggingface.co/EleutherAI/gpt-neo-1.3B",
    "author": "EleutherAI"
  },
  {
    "T": "\u2b55",
    "model": "rwkv-raven-1b5",
    "average": 33.56,
    "arc": 31.83,
    "hellaswag": 52.6,
    "mmlu": 25.96,
    "truthfulqa": 37.09,
    "winogrande": 53.91,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.41,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "571a3bd891ce33f2ee3fc6de09218178edb0dae2",
    "model_name_for_query": "RWKV/rwkv-raven-1b5",
    "link": "https://huggingface.co/RWKV/rwkv-raven-1b5",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Cerebras-GPT-2.7B-Alpaca-SP",
    "average": 33.5,
    "arc": 30.8,
    "hellaswag": 48.88,
    "mmlu": 25.12,
    "truthfulqa": 40.24,
    "winogrande": 55.41,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "ae7f22e90cb968b0a73355aa2001d6bc7df28477",
    "model_name_for_query": "lxe/Cerebras-GPT-2.7B-Alpaca-SP",
    "link": "https://huggingface.co/lxe/Cerebras-GPT-2.7B-Alpaca-SP",
    "author": "lxe"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyLlama-1.1bee",
    "average": 33.38,
    "arc": 30.55,
    "hellaswag": 51.8,
    "mmlu": 24.25,
    "truthfulqa": 39.01,
    "winogrande": 54.46,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5889ec467cf80a83c4092b55686f8121e81bf001",
    "model_name_for_query": "BEE-spoke-data/TinyLlama-1.1bee",
    "link": "https://huggingface.co/BEE-spoke-data/TinyLlama-1.1bee",
    "author": "BEE-spoke-data"
  },
  {
    "T": "?",
    "model": "llama2-3b-distilled-layla-v1",
    "average": 33.36,
    "arc": 30.46,
    "hellaswag": 46.05,
    "mmlu": 23.91,
    "truthfulqa": 42.14,
    "winogrande": 57.38,
    "gsm8k": 0.23,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 3.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "a1ba0a65e5262bc134dbc562a9faf80865b0a72f",
    "model_name_for_query": "l3utterfly/llama2-3b-distilled-layla-v1",
    "link": "https://huggingface.co/l3utterfly/llama2-3b-distilled-layla-v1",
    "author": "l3utterfly"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v1-1_5b",
    "average": 33.35,
    "arc": 31.66,
    "hellaswag": 49.69,
    "mmlu": 25.62,
    "truthfulqa": 37.08,
    "winogrande": 55.96,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.56,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4ac21faec255e3544e96aeb3591c27bdee5ebf45",
    "model_name_for_query": "aisquared/dlite-v1-1_5b",
    "link": "https://huggingface.co/aisquared/dlite-v1-1_5b",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "polyglot-ko-12.8b",
    "average": 33.33,
    "arc": 27.05,
    "hellaswag": 51.68,
    "mmlu": 26.64,
    "truthfulqa": 34.69,
    "winogrande": 59.75,
    "gsm8k": 0.15,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.06,
    "likes": 59.0,
    "still_on_hub": true,
    "revision": "09dfc839067bf44e7f52976eca8adbc17f04e1b0",
    "model_name_for_query": "EleutherAI/polyglot-ko-12.8b",
    "link": "https://huggingface.co/EleutherAI/polyglot-ko-12.8b",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-xl-sft",
    "average": 33.31,
    "arc": 30.03,
    "hellaswag": 49.17,
    "mmlu": 25.56,
    "truthfulqa": 38.78,
    "winogrande": 55.56,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.56,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "53250831436460254b7ee9afc4014d4d3156b372",
    "model_name_for_query": "MrNJK/gpt2-xl-sft",
    "link": "https://huggingface.co/MrNJK/gpt2-xl-sft",
    "author": "MrNJK"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Quokka_2.7b",
    "average": 33.26,
    "arc": 31.06,
    "hellaswag": 47.72,
    "mmlu": 24.8,
    "truthfulqa": 40.14,
    "winogrande": 55.49,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.79,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "abe5e0f574d32f3234035b6e8c5d68bbb201e03c",
    "model_name_for_query": "Corianas/Quokka_2.7b",
    "link": "https://huggingface.co/Corianas/Quokka_2.7b",
    "author": "Corianas"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Cerebras-GPT-2.7B",
    "average": 33.25,
    "arc": 29.1,
    "hellaswag": 49.29,
    "mmlu": 25.17,
    "truthfulqa": 41.37,
    "winogrande": 54.14,
    "gsm8k": 0.45,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 2.65,
    "likes": 41.0,
    "still_on_hub": true,
    "revision": "4383dfd80aafdbcfd0876419d246de51e6cbf7c1",
    "model_name_for_query": "cerebras/Cerebras-GPT-2.7B",
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-2.7B",
    "author": "cerebras"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "rwkv-4-1b5-pile",
    "average": 33.25,
    "arc": 31.83,
    "hellaswag": 52.25,
    "mmlu": 25.77,
    "truthfulqa": 35.8,
    "winogrande": 53.83,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.41,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "643585471eaf5821d94dfcb498ab5b94a36b42cf",
    "model_name_for_query": "RWKV/rwkv-4-1b5-pile",
    "link": "https://huggingface.co/RWKV/rwkv-4-1b5-pile",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Sparse0.5_OPT-1.3",
    "average": 33.19,
    "arc": 27.13,
    "hellaswag": 48.69,
    "mmlu": 25.6,
    "truthfulqa": 39.11,
    "winogrande": 58.56,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "06249d582b0cfefac537dd6bee2e578002ffff00",
    "model_name_for_query": "shaohang/Sparse0.5_OPT-1.3",
    "link": "https://huggingface.co/shaohang/Sparse0.5_OPT-1.3",
    "author": "shaohang"
  },
  {
    "T": "?",
    "model": "SparseOPT-1.3B",
    "average": 33.19,
    "arc": 27.13,
    "hellaswag": 48.69,
    "mmlu": 25.6,
    "truthfulqa": 39.11,
    "winogrande": 58.56,
    "gsm8k": 0.08,
    "model_type": "",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "06249d582b0cfefac537dd6bee2e578002ffff00",
    "model_name_for_query": "shaohang/SparseOPT-1.3B",
    "link": "https://huggingface.co/shaohang/SparseOPT-1.3B",
    "author": "shaohang"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt3-finnish-13B",
    "average": 32.95,
    "arc": 24.66,
    "hellaswag": 46.76,
    "mmlu": 23.49,
    "truthfulqa": 44.47,
    "winogrande": 58.01,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "BloomModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.26,
    "likes": 10.0,
    "still_on_hub": true,
    "revision": "ade35fd78ac2c29f7a56ffd3087321d297bb97a9",
    "model_name_for_query": "TurkuNLP/gpt3-finnish-13B",
    "link": "https://huggingface.co/TurkuNLP/gpt3-finnish-13B",
    "author": "TurkuNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v2-774m",
    "average": 32.86,
    "arc": 30.12,
    "hellaswag": 47.68,
    "mmlu": 25.37,
    "truthfulqa": 40.0,
    "winogrande": 53.99,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.77,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "0ea894a33e491912cd1a65dde47b4af03f03c4f2",
    "model_name_for_query": "aisquared/dlite-v2-774m",
    "link": "https://huggingface.co/aisquared/dlite-v2-774m",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-1b-deduped",
    "average": 32.78,
    "arc": 29.1,
    "hellaswag": 49.65,
    "mmlu": 24.27,
    "truthfulqa": 38.94,
    "winogrande": 53.59,
    "gsm8k": 1.14,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.08,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "7199d8fc61a6d565cd1f3c62bf11525b563e13b2",
    "model_name_for_query": "EleutherAI/pythia-1b-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-1b-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096",
    "average": 32.68,
    "arc": 30.63,
    "hellaswag": 52.63,
    "mmlu": 25.04,
    "truthfulqa": 34.96,
    "winogrande": 52.8,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.41,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "657e40fe890c2baa1705b45084a93a70b98842eb",
    "model_name_for_query": "KnutJaegersberg/RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096",
    "link": "https://huggingface.co/KnutJaegersberg/RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "b1ade-1b",
    "average": 32.59,
    "arc": 28.58,
    "hellaswag": 46.08,
    "mmlu": 25.11,
    "truthfulqa": 41.34,
    "winogrande": 53.83,
    "gsm8k": 0.61,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 0.91,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b4b0fd71589e6590089e1ec14a840ecab10894ae",
    "model_name_for_query": "w601sxs/b1ade-1b",
    "link": "https://huggingface.co/w601sxs/b1ade-1b",
    "author": "w601sxs"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-neo-1.3B-4bit-alpaca",
    "average": 32.58,
    "arc": 28.24,
    "hellaswag": 46.35,
    "mmlu": 25.19,
    "truthfulqa": 39.26,
    "winogrande": 56.2,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "4bit",
    "license": "?",
    "params": 1.3,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "137d483d1dc757c81c59bd190016f7c5df01f978",
    "model_name_for_query": "TFLai/gpt-neo-1.3B-4bit-alpaca",
    "link": "https://huggingface.co/TFLai/gpt-neo-1.3B-4bit-alpaca",
    "author": "TFLai"
  },
  {
    "T": "?",
    "model": "bloom-1b1",
    "average": 32.47,
    "arc": 28.33,
    "hellaswag": 42.78,
    "mmlu": 26.7,
    "truthfulqa": 41.8,
    "winogrande": 55.01,
    "gsm8k": 0.23,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 1.06,
    "likes": 41.0,
    "still_on_hub": true,
    "revision": "6f4195539db0eef1c9d010289f32e0645d9a2354",
    "model_name_for_query": "bigscience/bloom-1b1",
    "link": "https://huggingface.co/bigscience/bloom-1b1",
    "author": "bigscience"
  },
  {
    "T": "\u2b55",
    "model": "bilingual-gpt-neox-4b-instruction-sft",
    "average": 32.46,
    "arc": 28.07,
    "hellaswag": 47.5,
    "mmlu": 23.12,
    "truthfulqa": 43.76,
    "winogrande": 52.33,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 3.8,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "c20e42bd49a3b1b0d0a07151899a322c4760e871",
    "model_name_for_query": "rinna/bilingual-gpt-neox-4b-instruction-sft",
    "link": "https://huggingface.co/rinna/bilingual-gpt-neox-4b-instruction-sft",
    "author": "rinna"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pile-7b-250b-tokens",
    "average": 32.44,
    "arc": 29.27,
    "hellaswag": 46.29,
    "mmlu": 25.25,
    "truthfulqa": 40.49,
    "winogrande": 52.8,
    "gsm8k": 0.53,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 5.87,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "caefdf7a7c177905b0b16fbe9d4c7ba08def97c2",
    "model_name_for_query": "Kunhao/pile-7b-250b-tokens",
    "link": "https://huggingface.co/Kunhao/pile-7b-250b-tokens",
    "author": "Kunhao"
  },
  {
    "T": "?",
    "model": "LaMini-GPT-774M",
    "average": 32.43,
    "arc": 27.65,
    "hellaswag": 43.81,
    "mmlu": 26.3,
    "truthfulqa": 40.26,
    "winogrande": 56.59,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.77,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "4f3bd4b37d249e6aa335be677afd39f417e05b5d",
    "model_name_for_query": "MBZUAI/LaMini-GPT-774M",
    "link": "https://huggingface.co/MBZUAI/LaMini-GPT-774M",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "codegen-6B-multi",
    "average": 32.43,
    "arc": 27.22,
    "hellaswag": 41.11,
    "mmlu": 25.71,
    "truthfulqa": 45.65,
    "winogrande": 53.91,
    "gsm8k": 0.99,
    "model_type": "pretrained",
    "architecture": "CodeGenForCausalLM",
    "precision": "float16",
    "license": "bsd-3-clause",
    "params": 6.85,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "2d58b1e73791e8f0be7ea59c2720dccb6f4d0f06",
    "model_name_for_query": "Salesforce/codegen-6B-multi",
    "link": "https://huggingface.co/Salesforce/codegen-6B-multi",
    "author": "Salesforce"
  },
  {
    "T": "?",
    "model": "Bloom_1b_Quantized",
    "average": 32.41,
    "arc": 27.73,
    "hellaswag": 42.83,
    "mmlu": 26.28,
    "truthfulqa": 41.82,
    "winogrande": 55.64,
    "gsm8k": 0.15,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 1.06,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f31188966c6735bd894edacfee8371a6eaf7dbc7",
    "model_name_for_query": "FabbriSimo01/Bloom_1b_Quantized",
    "link": "https://huggingface.co/FabbriSimo01/Bloom_1b_Quantized",
    "author": "FabbriSimo01"
  },
  {
    "T": "\u2b55",
    "model": "deepseek-coder-1.3b-instruct",
    "average": 32.4,
    "arc": 28.58,
    "hellaswag": 39.87,
    "mmlu": 28.47,
    "truthfulqa": 44.02,
    "winogrande": 52.41,
    "gsm8k": 1.06,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 1.3,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "e04e04028d6345ab3225644cd615e2573ffb9b8c",
    "model_name_for_query": "deepseek-ai/deepseek-coder-1.3b-instruct",
    "link": "https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct",
    "author": "deepseek-ai"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "gpt2-large-conversational",
    "average": 32.33,
    "arc": 26.96,
    "hellaswag": 44.98,
    "mmlu": 26.33,
    "truthfulqa": 39.6,
    "winogrande": 56.04,
    "gsm8k": 0.08,
    "model_type": "RL-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "openrail",
    "params": 0.77,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "6674ad1ed9f518054561b866172eb88b7a769413",
    "model_name_for_query": "Locutusque/gpt2-large-conversational",
    "link": "https://huggingface.co/Locutusque/gpt2-large-conversational",
    "author": "Locutusque"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "bilingual-gpt-neox-4b-8k",
    "average": 32.23,
    "arc": 28.58,
    "hellaswag": 43.94,
    "mmlu": 25.38,
    "truthfulqa": 47.48,
    "winogrande": 47.99,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 3.95,
    "likes": 22.0,
    "still_on_hub": true,
    "revision": "ad56d7fc86db4ad5a7036bc9f80e11cd6f435a60",
    "model_name_for_query": "rinna/bilingual-gpt-neox-4b-8k",
    "link": "https://huggingface.co/rinna/bilingual-gpt-neox-4b-8k",
    "author": "rinna"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-xl-alpaca",
    "average": 32.21,
    "arc": 26.79,
    "hellaswag": 43.85,
    "mmlu": 26.31,
    "truthfulqa": 39.4,
    "winogrande": 56.91,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 1.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a1a19acc0ef161bfa35f460c15ed3015595714d8",
    "model_name_for_query": "Rachneet/gpt2-xl-alpaca",
    "link": "https://huggingface.co/Rachneet/gpt2-xl-alpaca",
    "author": "Rachneet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test-3b",
    "average": 32.2,
    "arc": 27.65,
    "hellaswag": 44.79,
    "mmlu": 23.53,
    "truthfulqa": 41.42,
    "winogrande": 55.49,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 3.5,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b81c038ee2fa2addd285acde08b1a7ca3cb2854d",
    "model_name_for_query": "Devio/test-3b",
    "link": "https://huggingface.co/Devio/test-3b",
    "author": "Devio"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "bilingual-gpt-neox-4b",
    "average": 32.14,
    "arc": 29.18,
    "hellaswag": 43.73,
    "mmlu": 23.1,
    "truthfulqa": 45.0,
    "winogrande": 51.85,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 3.95,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "f02f6f3c8da0093f3c1ce59220409bc2fa9fbb17",
    "model_name_for_query": "rinna/bilingual-gpt-neox-4b",
    "link": "https://huggingface.co/rinna/bilingual-gpt-neox-4b",
    "author": "rinna"
  },
  {
    "T": "\ud83d\udd36",
    "model": "stablelm-tuned-alpha-3b",
    "average": 32.14,
    "arc": 27.82,
    "hellaswag": 44.06,
    "mmlu": 23.08,
    "truthfulqa": 42.33,
    "winogrande": 55.01,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": ["cc-by-nc-sa-4.0"],
    "params": 3.43,
    "likes": 106.0,
    "still_on_hub": true,
    "revision": "d1c03d2114451d562416b9efe4281d319ceff99e",
    "model_name_for_query": "stabilityai/stablelm-tuned-alpha-3b",
    "link": "https://huggingface.co/stabilityai/stablelm-tuned-alpha-3b",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Medical-ChatBot",
    "average": 32.13,
    "arc": 30.55,
    "hellaswag": 38.63,
    "mmlu": 25.98,
    "truthfulqa": 41.25,
    "winogrande": 55.41,
    "gsm8k": 0.99,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "8bit",
    "license": "mit",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9e2d5d7a6189762164690a2fe714b00ce497b253",
    "model_name_for_query": "Mohammed-Altaf/Medical-ChatBot",
    "link": "https://huggingface.co/Mohammed-Altaf/Medical-ChatBot",
    "author": "Mohammed-Altaf"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Medical-ChatBot",
    "average": 31.98,
    "arc": 30.46,
    "hellaswag": 38.6,
    "mmlu": 25.96,
    "truthfulqa": 41.04,
    "winogrande": 54.85,
    "gsm8k": 0.99,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9e2d5d7a6189762164690a2fe714b00ce497b253",
    "model_name_for_query": "Mohammed-Altaf/Medical-ChatBot",
    "link": "https://huggingface.co/Mohammed-Altaf/Medical-ChatBot",
    "author": "Mohammed-Altaf"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Medical-ChatBot",
    "average": 31.87,
    "arc": 30.46,
    "hellaswag": 38.55,
    "mmlu": 25.91,
    "truthfulqa": 41.02,
    "winogrande": 54.22,
    "gsm8k": 1.06,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "mit",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9e2d5d7a6189762164690a2fe714b00ce497b253",
    "model_name_for_query": "Mohammed-Altaf/Medical-ChatBot",
    "link": "https://huggingface.co/Mohammed-Altaf/Medical-ChatBot",
    "author": "Mohammed-Altaf"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyLlama-1.1B-step-50K-105b",
    "average": 31.86,
    "arc": 25.85,
    "hellaswag": 44.1,
    "mmlu": 26.78,
    "truthfulqa": 39.51,
    "winogrande": 54.38,
    "gsm8k": 0.53,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.1,
    "likes": 102.0,
    "still_on_hub": true,
    "revision": "c1f1ef67c12e4bb85fe0bdf1747c645a202cc118",
    "model_name_for_query": "PY007/TinyLlama-1.1B-step-50K-105b",
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-step-50K-105b",
    "author": "PY007"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-large-lora-sft",
    "average": 31.82,
    "arc": 26.79,
    "hellaswag": 44.15,
    "mmlu": 25.82,
    "truthfulqa": 39.06,
    "winogrande": 55.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.77,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "1c0c5a686f3c83692e033416197155557e4d3a0d",
    "model_name_for_query": "Mikivis/gpt2-large-lora-sft",
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-sft",
    "author": "Mikivis"
  },
  {
    "T": "\ud83d\udd36",
    "model": "firefly-bloom-2b6-v2",
    "average": 31.82,
    "arc": 27.65,
    "hellaswag": 39.23,
    "mmlu": 25.24,
    "truthfulqa": 42.27,
    "winogrande": 54.78,
    "gsm8k": 1.74,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 2.48,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "8334b22c39937c0404e09dd22a867e2e2a6fc9e0",
    "model_name_for_query": "YeungNLP/firefly-bloom-2b6-v2",
    "link": "https://huggingface.co/YeungNLP/firefly-bloom-2b6-v2",
    "author": "YeungNLP"
  },
  {
    "T": "\u2b55",
    "model": "llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
    "average": 31.77,
    "arc": 26.88,
    "hellaswag": 44.78,
    "mmlu": 23.12,
    "truthfulqa": 45.19,
    "winogrande": 50.67,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "68282fe744c69ea2e4420a4a6833c0b9168215eb",
    "model_name_for_query": "llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
    "link": "https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
    "author": "llm-jp"
  },
  {
    "T": "?",
    "model": "orca_mini_13B-GPTQ",
    "average": 31.73,
    "arc": 27.3,
    "hellaswag": 25.85,
    "mmlu": 25.31,
    "truthfulqa": 48.06,
    "winogrande": 63.77,
    "gsm8k": 0.08,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 16.22,
    "likes": 43.0,
    "still_on_hub": true,
    "revision": "8ec18e5c597da86fa123c08b6e6bef7da6ec7440",
    "model_name_for_query": "TheBloke/orca_mini_13B-GPTQ",
    "link": "https://huggingface.co/TheBloke/orca_mini_13B-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "llm-jp-13b-instruct-full-jaster-v1.0",
    "average": 31.63,
    "arc": 27.22,
    "hellaswag": 44.7,
    "mmlu": 23.12,
    "truthfulqa": 44.69,
    "winogrande": 50.04,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 13.0,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "b44eac954eac7ddbceba4f510325fd710c977eab",
    "model_name_for_query": "llm-jp/llm-jp-13b-instruct-full-jaster-v1.0",
    "link": "https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-jaster-v1.0",
    "author": "llm-jp"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fairseq-dense-355M",
    "average": 31.58,
    "arc": 25.43,
    "hellaswag": 46.67,
    "mmlu": 25.3,
    "truthfulqa": 39.19,
    "winogrande": 52.88,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.4,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "24da1ea670f0638c2df911596e95c764bcd5fb44",
    "model_name_for_query": "KoboldAI/fairseq-dense-355M",
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-355M",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-410m",
    "average": 31.55,
    "arc": 26.19,
    "hellaswag": 40.85,
    "mmlu": 27.25,
    "truthfulqa": 41.22,
    "winogrande": 53.12,
    "gsm8k": 0.68,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.51,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "9879c9b5f8bea9051dcb0e68dff21493d67e9d4f",
    "model_name_for_query": "EleutherAI/pythia-410m",
    "link": "https://huggingface.co/EleutherAI/pythia-410m",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-chat-longlora-32k-sft",
    "average": 31.54,
    "arc": 26.54,
    "hellaswag": 26.1,
    "mmlu": 23.12,
    "truthfulqa": 49.16,
    "winogrande": 64.33,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 13.02,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "6f2924e354c3ab035aa2ff7c7e28d0e5327e2667",
    "model_name_for_query": "Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "link": "https://huggingface.co/Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "author": "Yukang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v1-774m",
    "average": 31.51,
    "arc": 28.07,
    "hellaswag": 44.35,
    "mmlu": 25.91,
    "truthfulqa": 36.11,
    "winogrande": 54.62,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.77,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d3f5401d07965fb13c2cb8b458ffaed9a5a79c2d",
    "model_name_for_query": "aisquared/dlite-v1-774m",
    "link": "https://huggingface.co/aisquared/dlite-v1-774m",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-large-lora-stf4",
    "average": 31.5,
    "arc": 26.88,
    "hellaswag": 42.17,
    "mmlu": 25.53,
    "truthfulqa": 40.84,
    "winogrande": 53.59,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.77,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "82eff3a62116fd589ad7319c9d75ff6b12f42f72",
    "model_name_for_query": "Mikivis/gpt2-large-lora-stf4",
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-stf4",
    "author": "Mikivis"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "stablelm-base-alpha-3b",
    "average": 31.5,
    "arc": 26.45,
    "hellaswag": 42.24,
    "mmlu": 25.43,
    "truthfulqa": 40.5,
    "winogrande": 53.91,
    "gsm8k": 0.45,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": ["cc-by-sa-4.0"],
    "params": 3.43,
    "likes": 82.0,
    "still_on_hub": true,
    "revision": "99567ccfe45fabe467c71393aa6716106edb83c2",
    "model_name_for_query": "stabilityai/stablelm-base-alpha-3b",
    "link": "https://huggingface.co/stabilityai/stablelm-base-alpha-3b",
    "author": "stabilityai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-chat-longlora-32k-sft",
    "average": 31.43,
    "arc": 26.11,
    "hellaswag": 26.17,
    "mmlu": 23.12,
    "truthfulqa": 49.07,
    "winogrande": 64.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 13.02,
    "likes": 19.0,
    "still_on_hub": true,
    "revision": "6f2924e354c3ab035aa2ff7c7e28d0e5327e2667",
    "model_name_for_query": "Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "link": "https://huggingface.co/Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "author": "Yukang"
  },
  {
    "T": "?",
    "model": "xglm-1.7B",
    "average": 31.42,
    "arc": 25.85,
    "hellaswag": 45.68,
    "mmlu": 25.1,
    "truthfulqa": 37.21,
    "winogrande": 53.91,
    "gsm8k": 0.76,
    "model_type": "",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 1.73,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "d23a5e8e2164af31a84a26756b9b17f925143050",
    "model_name_for_query": "facebook/xglm-1.7B",
    "link": "https://huggingface.co/facebook/xglm-1.7B",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-large-lora-sft2",
    "average": 31.33,
    "arc": 26.62,
    "hellaswag": 42.68,
    "mmlu": 24.72,
    "truthfulqa": 40.31,
    "winogrande": 53.67,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.77,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1244efb5d20765beb54f6b4a4e1426cf6d5daf44",
    "model_name_for_query": "Mikivis/gpt2-large-lora-sft2",
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-sft2",
    "author": "Mikivis"
  },
  {
    "T": "\u2b55",
    "model": "Aira-2-774M",
    "average": 31.33,
    "arc": 28.75,
    "hellaswag": 40.8,
    "mmlu": 25.1,
    "truthfulqa": 41.33,
    "winogrande": 52.01,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.77,
    "likes": 2.0,
    "still_on_hub": false,
    "revision": "f43044cfe7bf0827a176f0d319c63251c2b29373",
    "model_name_for_query": "nicholasKluge/Aira-2-774M",
    "link": "https://huggingface.co/nicholasKluge/Aira-2-774M",
    "author": "nicholasKluge"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-2-xl-EvolInstruct",
    "average": 31.32,
    "arc": 27.39,
    "hellaswag": 38.46,
    "mmlu": 25.67,
    "truthfulqa": 42.76,
    "winogrande": 53.51,
    "gsm8k": 0.15,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3e68735b9bfbca5c2e6a8e4367f003ab3d3c1512",
    "model_name_for_query": "KnutJaegersberg/gpt-2-xl-EvolInstruct",
    "link": "https://huggingface.co/KnutJaegersberg/gpt-2-xl-EvolInstruct",
    "author": "KnutJaegersberg"
  },
  {
    "T": "?",
    "model": "Cerebras_1.3b_Quantized",
    "average": 31.31,
    "arc": 25.94,
    "hellaswag": 38.56,
    "mmlu": 26.79,
    "truthfulqa": 42.67,
    "winogrande": 53.51,
    "gsm8k": 0.38,
    "model_type": "",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 1.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e2126a42a1c8a938553dd513e4adafec41cb793e",
    "model_name_for_query": "FabbriSimo01/Cerebras_1.3b_Quantized",
    "link": "https://huggingface.co/FabbriSimo01/Cerebras_1.3b_Quantized",
    "author": "FabbriSimo01"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Cerebras-GPT-1.3B",
    "average": 31.3,
    "arc": 26.28,
    "hellaswag": 38.54,
    "mmlu": 26.59,
    "truthfulqa": 42.7,
    "winogrande": 53.43,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.32,
    "likes": 43.0,
    "still_on_hub": true,
    "revision": "5b95400ee8d1e3cc9f79f0dec7182ed9c1009c34",
    "model_name_for_query": "cerebras/Cerebras-GPT-1.3B",
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-1.3B",
    "author": "cerebras"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-410m-deduped",
    "average": 31.29,
    "arc": 24.83,
    "hellaswag": 41.29,
    "mmlu": 25.99,
    "truthfulqa": 40.95,
    "winogrande": 54.38,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.51,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "c4fc8d586d62df497f1f9b69d66d3ca419992d3e",
    "model_name_for_query": "EleutherAI/pythia-410m-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-410m-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v2-355m",
    "average": 31.2,
    "arc": 28.33,
    "hellaswag": 40.54,
    "mmlu": 26.77,
    "truthfulqa": 38.76,
    "winogrande": 52.8,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.36,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "f51d310aebc16a9fe0d999d2a437b5faff635716",
    "model_name_for_query": "aisquared/dlite-v2-355m",
    "link": "https://huggingface.co/aisquared/dlite-v2-355m",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udd36",
    "model": "basilisk-4b",
    "average": 31.15,
    "arc": 25.85,
    "hellaswag": 39.6,
    "mmlu": 24.61,
    "truthfulqa": 43.74,
    "winogrande": 53.12,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 3.37,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "b91c2e5389f4f0ce2d6042fdce5927343d8dcb06",
    "model_name_for_query": "winglian/basilisk-4b",
    "link": "https://huggingface.co/winglian/basilisk-4b",
    "author": "winglian"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-1.3b",
    "average": 31.14,
    "arc": 28.07,
    "hellaswag": 46.96,
    "mmlu": 24.12,
    "truthfulqa": 37.64,
    "winogrande": 50.04,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "agpl-3.0",
    "params": 1.52,
    "likes": 51.0,
    "still_on_hub": true,
    "revision": "bef2c90128c00ff6f16c0f397463423b7d988e17",
    "model_name_for_query": "PygmalionAI/pygmalion-1.3b",
    "link": "https://huggingface.co/PygmalionAI/pygmalion-1.3b",
    "author": "PygmalionAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-large-lora-sft1",
    "average": 31.01,
    "arc": 24.66,
    "hellaswag": 42.67,
    "mmlu": 24.89,
    "truthfulqa": 39.37,
    "winogrande": 54.46,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.77,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8e26a8d2dc1661d87a8652c75f00b805d63e7330",
    "model_name_for_query": "Mikivis/gpt2-large-lora-sft1",
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-sft1",
    "author": "Mikivis"
  },
  {
    "T": "\u2b55",
    "model": "Aira-2-355M",
    "average": 31.0,
    "arc": 27.56,
    "hellaswag": 38.92,
    "mmlu": 27.26,
    "truthfulqa": 38.53,
    "winogrande": 53.75,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.36,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "2479f5b1bb62251ec88e60182ba81390a4c19cf9",
    "model_name_for_query": "nicholasKluge/Aira-2-355M",
    "link": "https://huggingface.co/nicholasKluge/Aira-2-355M",
    "author": "nicholasKluge"
  },
  {
    "T": null,
    "model": "<p>Baseline</p>",
    "average": 31.0,
    "arc": 25.0,
    "hellaswag": 25.0,
    "mmlu": 25.0,
    "truthfulqa": 25.0,
    "winogrande": 50.0,
    "gsm8k": 0.21,
    "model_type": "",
    "architecture": null,
    "precision": null,
    "license": null,
    "params": null,
    "likes": null,
    "still_on_hub": null,
    "revision": "N/A",
    "model_name_for_query": "baseline",
    "link": null,
    "author": null
  },
  {
    "T": "\u2b55",
    "model": "GPTNeo350M-Instruct-SFT",
    "average": 31.0,
    "arc": 25.94,
    "hellaswag": 38.55,
    "mmlu": 25.76,
    "truthfulqa": 45.25,
    "winogrande": 50.2,
    "gsm8k": 0.3,
    "model_type": "instruction-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.46,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5e41660ced3edf13c47e933112efd280b710b977",
    "model_name_for_query": "SummerSigh/GPTNeo350M-Instruct-SFT",
    "link": "https://huggingface.co/SummerSigh/GPTNeo350M-Instruct-SFT",
    "author": "SummerSigh"
  },
  {
    "T": "\ud83d\udd36",
    "model": "emailgen-pythia-410m-deduped",
    "average": 30.93,
    "arc": 27.9,
    "hellaswag": 40.04,
    "mmlu": 27.35,
    "truthfulqa": 38.2,
    "winogrande": 52.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.51,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e0208b02990c49138350da791f0b6fcb8a65e738",
    "model_name_for_query": "postbot/emailgen-pythia-410m-deduped",
    "link": "https://huggingface.co/postbot/emailgen-pythia-410m-deduped",
    "author": "postbot"
  },
  {
    "T": "\u2b55",
    "model": "gpt-sw3-356m-instruct",
    "average": 30.93,
    "arc": 26.96,
    "hellaswag": 38.01,
    "mmlu": 25.53,
    "truthfulqa": 40.74,
    "winogrande": 52.57,
    "gsm8k": 1.74,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 0.47,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "85615b7c700ca7f38c32db8c7efabfa97668f1c2",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-356m-instruct",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-356m-instruct",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Quokka_1.3b",
    "average": 30.86,
    "arc": 27.73,
    "hellaswag": 37.91,
    "mmlu": 26.66,
    "truthfulqa": 40.14,
    "winogrande": 52.72,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.42,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8a8d738e841a524d658897d89b9e39e7b9272ed8",
    "model_name_for_query": "Corianas/Quokka_1.3b",
    "link": "https://huggingface.co/Corianas/Quokka_1.3b",
    "author": "Corianas"
  },
  {
    "T": "?",
    "model": "1.3b",
    "average": 30.76,
    "arc": 27.3,
    "hellaswag": 38.3,
    "mmlu": 26.77,
    "truthfulqa": 39.02,
    "winogrande": 53.04,
    "gsm8k": 0.15,
    "model_type": "",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.42,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "9831f95df82155ef95ff46a505506bf6194b131a",
    "model_name_for_query": "Corianas/1.3b",
    "link": "https://huggingface.co/Corianas/1.3b",
    "author": "Corianas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bloomz-560m-sft-chat",
    "average": 30.72,
    "arc": 27.47,
    "hellaswag": 37.05,
    "mmlu": 23.93,
    "truthfulqa": 42.35,
    "winogrande": 53.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "bfloat16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 0.56,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "e2bbcbdd534c7d75b7d2f9408e74f6682cf3a05e",
    "model_name_for_query": "cmarkea/bloomz-560m-sft-chat",
    "link": "https://huggingface.co/cmarkea/bloomz-560m-sft-chat",
    "author": "cmarkea"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolphinette",
    "average": 30.65,
    "arc": 24.91,
    "hellaswag": 37.33,
    "mmlu": 25.37,
    "truthfulqa": 42.08,
    "winogrande": 54.22,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.56,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "20529d47b0a82343014727edd1639a9a6a6b09e6",
    "model_name_for_query": "player1537/dolphinette",
    "link": "https://huggingface.co/player1537/dolphinette",
    "author": "player1537"
  },
  {
    "T": "?",
    "model": "bloomz-560m",
    "average": 30.63,
    "arc": 23.55,
    "hellaswag": 36.31,
    "mmlu": 25.1,
    "truthfulqa": 45.69,
    "winogrande": 53.12,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 0.56,
    "likes": 81.0,
    "still_on_hub": true,
    "revision": "a2845d7e13dd12efae154a9f1c63fcc2e0cc4b05",
    "model_name_for_query": "bigscience/bloomz-560m",
    "link": "https://huggingface.co/bigscience/bloomz-560m",
    "author": "bigscience"
  },
  {
    "T": "?",
    "model": "medalpaca-13B-GPTQ-4bit",
    "average": 30.62,
    "arc": 29.35,
    "hellaswag": 26.32,
    "mmlu": 25.44,
    "truthfulqa": 49.51,
    "winogrande": 53.12,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 16.22,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "12190f743a19e91dfe1f5c77abc0c1bf486073dd",
    "model_name_for_query": "TheBloke/medalpaca-13B-GPTQ-4bit",
    "link": "https://huggingface.co/TheBloke/medalpaca-13B-GPTQ-4bit",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v1-355m",
    "average": 30.54,
    "arc": 27.13,
    "hellaswag": 39.07,
    "mmlu": 27.12,
    "truthfulqa": 37.13,
    "winogrande": 52.8,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.36,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c5f4b5a61e6a66a5c7613164d99a70db5bf7e9a2",
    "model_name_for_query": "aisquared/dlite-v1-355m",
    "link": "https://huggingface.co/aisquared/dlite-v1-355m",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PT_GPTNEO350_ATG",
    "average": 30.46,
    "arc": 25.43,
    "hellaswag": 37.59,
    "mmlu": 24.79,
    "truthfulqa": 43.05,
    "winogrande": 51.46,
    "gsm8k": 0.45,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.36,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "56ab08aaa6802d0f830d42c352d5d536be72811d",
    "model_name_for_query": "xhyi/PT_GPTNEO350_ATG",
    "link": "https://huggingface.co/xhyi/PT_GPTNEO350_ATG",
    "author": "xhyi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DiffMerge-DollyGPT-Pygmalion",
    "average": 30.45,
    "arc": 23.63,
    "hellaswag": 34.38,
    "mmlu": 24.41,
    "truthfulqa": 46.48,
    "winogrande": 53.83,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 5.84,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "6a00b371146d4bd2903890814485ee1b775162e7",
    "model_name_for_query": "TehVenom/DiffMerge-DollyGPT-Pygmalion",
    "link": "https://huggingface.co/TehVenom/DiffMerge-DollyGPT-Pygmalion",
    "author": "TehVenom"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "rwkv-4-430m-pile",
    "average": 30.45,
    "arc": 26.71,
    "hellaswag": 40.01,
    "mmlu": 24.85,
    "truthfulqa": 39.58,
    "winogrande": 51.14,
    "gsm8k": 0.38,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.38,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "a4f6ec80438d4262d1bbc8f385feb2ef1a4a9d6b",
    "model_name_for_query": "RWKV/rwkv-4-430m-pile",
    "link": "https://huggingface.co/RWKV/rwkv-4-430m-pile",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "bloom-560m-RLHF-v2",
    "average": 30.43,
    "arc": 26.45,
    "hellaswag": 37.67,
    "mmlu": 23.95,
    "truthfulqa": 43.51,
    "winogrande": 50.91,
    "gsm8k": 0.08,
    "model_type": "RL-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.56,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "7128cbfcdaf67f1eff27e45d875c35e7b47618db",
    "model_name_for_query": "TheTravellingEngineer/bloom-560m-RLHF-v2",
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-560m-RLHF-v2",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-sw3-356m",
    "average": 30.41,
    "arc": 23.63,
    "hellaswag": 37.05,
    "mmlu": 25.93,
    "truthfulqa": 42.55,
    "winogrande": 53.04,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 0.47,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "15ba8a812d3eb265342f62cb0ee9ab6a45fdbd89",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-356m",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-356m",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "megatron-gpt2-345m",
    "average": 30.4,
    "arc": 24.23,
    "hellaswag": 39.18,
    "mmlu": 24.32,
    "truthfulqa": 41.51,
    "winogrande": 52.96,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.38,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "b39f8d00fb9f33da4271be2035da848da896a23b",
    "model_name_for_query": "robowaifudev/megatron-gpt2-345m",
    "link": "https://huggingface.co/robowaifudev/megatron-gpt2-345m",
    "author": "robowaifudev"
  },
  {
    "T": "\u2b55",
    "model": "speechless-codellama-orca-airoboros-13b-0.10e",
    "average": 30.36,
    "arc": 29.44,
    "hellaswag": 25.71,
    "mmlu": 25.43,
    "truthfulqa": 49.64,
    "winogrande": 51.93,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dbd1d1f7ad7b6b359f8246141650b25ca0bb8cbb",
    "model_name_for_query": "uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "author": "uukuguy"
  },
  {
    "T": "\u2b55",
    "model": "megatron-gpt2-345m-evol_instruct_v2",
    "average": 30.31,
    "arc": 26.37,
    "hellaswag": 38.39,
    "mmlu": 23.6,
    "truthfulqa": 41.19,
    "winogrande": 52.33,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.36,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "2866eeaaf62014a7a6e939d18b6e27f44df48428",
    "model_name_for_query": "KnutJaegersberg/megatron-gpt2-345m-evol_instruct_v2",
    "link": "https://huggingface.co/KnutJaegersberg/megatron-gpt2-345m-evol_instruct_v2",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-sf",
    "average": 30.22,
    "arc": 29.52,
    "hellaswag": 26.49,
    "mmlu": 25.98,
    "truthfulqa": 48.97,
    "winogrande": 50.36,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "06253ee259e6b205c4734ab6ec3fa850737b2110",
    "model_name_for_query": "porkorbeef/Llama-2-13b-sf",
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b-sf",
    "author": "porkorbeef"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-orca-airoboros-13b-0.10e",
    "average": 30.22,
    "arc": 29.27,
    "hellaswag": 25.74,
    "mmlu": 25.69,
    "truthfulqa": 49.61,
    "winogrande": 50.99,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "dbd1d1f7ad7b6b359f8246141650b25ca0bb8cbb",
    "model_name_for_query": "uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "fbopt-350m-8bit",
    "average": 30.21,
    "arc": 23.55,
    "hellaswag": 36.6,
    "mmlu": 26.22,
    "truthfulqa": 40.97,
    "winogrande": 52.64,
    "gsm8k": 1.29,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "8bit",
    "license": "unknown",
    "params": 0.33,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "305f804054d75a406a85a568ea99dca17cfc998d",
    "model_name_for_query": "yec019/fbopt-350m-8bit",
    "link": "https://huggingface.co/yec019/fbopt-350m-8bit",
    "author": "yec019"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
    "average": 30.18,
    "arc": 26.02,
    "hellaswag": 40.39,
    "mmlu": 24.45,
    "truthfulqa": 37.57,
    "winogrande": 52.41,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.38,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e31777c9d3b8c5c9f803b23f49550c009cbdcf6d",
    "model_name_for_query": "KnutJaegersberg/RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
    "link": "https://huggingface.co/KnutJaegersberg/RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "llama2_xs_460M_experimental",
    "average": 30.17,
    "arc": 24.91,
    "hellaswag": 38.47,
    "mmlu": 26.17,
    "truthfulqa": 41.59,
    "winogrande": 49.88,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.41,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "c8db281477559f5c969a9be794ce236f8a99e1a0",
    "model_name_for_query": "ahxt/llama2_xs_460M_experimental",
    "link": "https://huggingface.co/ahxt/llama2_xs_460M_experimental",
    "author": "ahxt"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Orca-2-7b-f16",
    "average": 30.15,
    "arc": 29.61,
    "hellaswag": 25.62,
    "mmlu": 26.7,
    "truthfulqa": 48.36,
    "winogrande": 50.59,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "llama2",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f6b2f717467dc12b2b19cad90ed4362153863ad9",
    "model_name_for_query": "uukuguy/Orca-2-7b-f16",
    "link": "https://huggingface.co/uukuguy/Orca-2-7b-f16",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-350M-Erebus",
    "average": 30.14,
    "arc": 23.81,
    "hellaswag": 34.35,
    "mmlu": 26.23,
    "truthfulqa": 43.58,
    "winogrande": 52.57,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.33,
    "likes": 11.0,
    "still_on_hub": true,
    "revision": "83ce2f4e78d308968cf7ecd03d86a1f64aea8336",
    "model_name_for_query": "KoboldAI/OPT-350M-Erebus",
    "link": "https://huggingface.co/KoboldAI/OPT-350M-Erebus",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "bloom-1b1-RLHF",
    "average": 30.14,
    "arc": 27.99,
    "hellaswag": 26.19,
    "mmlu": 26.86,
    "truthfulqa": 48.88,
    "winogrande": 50.91,
    "gsm8k": 0.0,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "65bd72580520a1d4a0c19fcb23f68c1f28464e1b",
    "model_name_for_query": "TheTravellingEngineer/bloom-1b1-RLHF",
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-1b1-RLHF",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "?",
    "model": "bloom-560m",
    "average": 30.13,
    "arc": 24.74,
    "hellaswag": 37.15,
    "mmlu": 24.22,
    "truthfulqa": 42.44,
    "winogrande": 51.93,
    "gsm8k": 0.3,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 0.56,
    "likes": 263.0,
    "still_on_hub": true,
    "revision": "4f42c91d806a19ae1a46af6c3fb5f4990d884cd6",
    "model_name_for_query": "bigscience/bloom-560m",
    "link": "https://huggingface.co/bigscience/bloom-560m",
    "author": "bigscience"
  },
  {
    "T": "\ud83d\udd36",
    "model": "med-orca-instruct-33b",
    "average": 30.12,
    "arc": 28.84,
    "hellaswag": 25.63,
    "mmlu": 26.5,
    "truthfulqa": 49.26,
    "winogrande": 50.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaModel",
    "precision": "bfloat16",
    "license": "?",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1d636881854338e571825226c712180da06be72c",
    "model_name_for_query": "yhyhy3/med-orca-instruct-33b",
    "link": "https://huggingface.co/yhyhy3/med-orca-instruct-33b",
    "author": "yhyhy3"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b",
    "average": 30.11,
    "arc": 29.35,
    "hellaswag": 26.35,
    "mmlu": 24.94,
    "truthfulqa": 48.32,
    "winogrande": 51.7,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "06253ee259e6b205c4734ab6ec3fa850737b2110",
    "model_name_for_query": "porkorbeef/Llama-2-13b",
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b",
    "author": "porkorbeef"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Healix-410M",
    "average": 30.1,
    "arc": 25.09,
    "hellaswag": 32.02,
    "mmlu": 24.94,
    "truthfulqa": 44.42,
    "winogrande": 54.14,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "bfloat16",
    "license": "?",
    "params": 0.35,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "df5a3cec54a0bdd22e1644bfe576c7b58eca6bfd",
    "model_name_for_query": "health360/Healix-410M",
    "link": "https://huggingface.co/health360/Healix-410M",
    "author": "health360"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-7B-LaMini-80K",
    "average": 30.09,
    "arc": 28.75,
    "hellaswag": 26.13,
    "mmlu": 24.46,
    "truthfulqa": 49.71,
    "winogrande": 51.46,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ea7a283403ec1a40570bfc25f2c4b8fcb089b6bb",
    "model_name_for_query": "marcchew/Marcoroni-7B-LaMini-80K",
    "link": "https://huggingface.co/marcchew/Marcoroni-7B-LaMini-80K",
    "author": "marcchew"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test5",
    "average": 30.06,
    "arc": 28.41,
    "hellaswag": 26.63,
    "mmlu": 25.36,
    "truthfulqa": 47.34,
    "winogrande": 52.64,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b0dae937b7137790d8946794375e1affd51c760a",
    "model_name_for_query": "doas/test5",
    "link": "https://huggingface.co/doas/test5",
    "author": "doas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lamini-cerebras-1.3b",
    "average": 30.05,
    "arc": 26.88,
    "hellaswag": 37.96,
    "mmlu": 28.43,
    "truthfulqa": 36.45,
    "winogrande": 50.59,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 1.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "502e70081df53edc8a9156acf5a26a11a9dad8fb",
    "model_name_for_query": "MBZUAI/lamini-cerebras-1.3b",
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-1.3b",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "megatron-GPT-2-345m-EvolInstruct",
    "average": 30.01,
    "arc": 24.06,
    "hellaswag": 35.12,
    "mmlu": 24.48,
    "truthfulqa": 41.25,
    "winogrande": 54.78,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.38,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "dc95fda9f1e51d94870e28751e35410c66563d18",
    "model_name_for_query": "KnutJaegersberg/megatron-GPT-2-345m-EvolInstruct",
    "link": "https://huggingface.co/KnutJaegersberg/megatron-GPT-2-345m-EvolInstruct",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "opt-350m",
    "average": 30.01,
    "arc": 23.55,
    "hellaswag": 36.73,
    "mmlu": 26.02,
    "truthfulqa": 40.83,
    "winogrande": 52.64,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.33,
    "likes": 75.0,
    "still_on_hub": true,
    "revision": "cb32f77e905cccbca1d970436fb0f5e6b58ee3c5",
    "model_name_for_query": "facebook/opt-350m",
    "link": "https://huggingface.co/facebook/opt-350m",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test_llama2_ko_7b",
    "average": 29.99,
    "arc": 29.95,
    "hellaswag": 26.94,
    "mmlu": 25.62,
    "truthfulqa": 49.03,
    "winogrande": 48.38,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.67,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "45901e1d6ccb22f5ed8aec3f9dd366823fdd1c33",
    "model_name_for_query": "yeen214/test_llama2_ko_7b",
    "link": "https://huggingface.co/yeen214/test_llama2_ko_7b",
    "author": "yeen214"
  },
  {
    "T": "\ud83d\udd36",
    "model": "phi2",
    "average": 29.98,
    "arc": 22.87,
    "hellaswag": 30.7,
    "mmlu": 27.55,
    "truthfulqa": 46.1,
    "winogrande": 52.01,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9fd01ce09da870fc66af88616d43e53db642ef46",
    "model_name_for_query": "vikp/phi2",
    "link": "https://huggingface.co/vikp/phi2",
    "author": "vikp"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-codellama-orca-platypus-13b-0.10e",
    "average": 29.96,
    "arc": 28.92,
    "hellaswag": 25.76,
    "mmlu": 25.28,
    "truthfulqa": 49.22,
    "winogrande": 50.59,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "119abfc73f9ce541a40779f167fe21e95faed4e8",
    "model_name_for_query": "uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Ziya-LLaMA-13B-Pretrain-v1",
    "average": 29.96,
    "arc": 27.99,
    "hellaswag": 26.0,
    "mmlu": 27.04,
    "truthfulqa": 48.59,
    "winogrande": 50.12,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 12.89,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "826e83e411df32f358893ab21f5eae680499ae9a",
    "model_name_for_query": "IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1",
    "link": "https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1",
    "author": "IDEA-CCNL"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pygmalion-350m",
    "average": 29.95,
    "arc": 25.0,
    "hellaswag": 37.8,
    "mmlu": 25.68,
    "truthfulqa": 40.41,
    "winogrande": 50.28,
    "gsm8k": 0.53,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.33,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "d65832d913f6b396e2ffb64c373d9383c9da9303",
    "model_name_for_query": "PygmalionAI/pygmalion-350m",
    "link": "https://huggingface.co/PygmalionAI/pygmalion-350m",
    "author": "PygmalionAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "proofGPT-v0.1",
    "average": 29.94,
    "arc": 22.87,
    "hellaswag": 28.66,
    "mmlu": 25.96,
    "truthfulqa": 51.64,
    "winogrande": 50.43,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 1.31,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "1e4dd330ca90c0ef6d77ca71bd49cbe3d71f26b8",
    "model_name_for_query": "hoskinson-center/proofGPT-v0.1",
    "link": "https://huggingface.co/hoskinson-center/proofGPT-v0.1",
    "author": "hoskinson-center"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LaMini-40k-Platypus2-7B",
    "average": 29.91,
    "arc": 28.5,
    "hellaswag": 26.32,
    "mmlu": 27.04,
    "truthfulqa": 47.39,
    "winogrande": 50.2,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e8c03e43eab479a216b5f4f182a711c3624f38bd",
    "model_name_for_query": "marcchew/LaMini-40k-Platypus2-7B",
    "link": "https://huggingface.co/marcchew/LaMini-40k-Platypus2-7B",
    "author": "marcchew"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-350M-Nerys-v2",
    "average": 29.9,
    "arc": 23.63,
    "hellaswag": 35.49,
    "mmlu": 25.91,
    "truthfulqa": 42.08,
    "winogrande": 51.62,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.33,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "59b1019c35ab17a7d77ea1ad32b45a8375ba6e89",
    "model_name_for_query": "KoboldAI/OPT-350M-Nerys-v2",
    "link": "https://huggingface.co/KoboldAI/OPT-350M-Nerys-v2",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-medium-emailgen",
    "average": 29.87,
    "arc": 26.45,
    "hellaswag": 34.31,
    "mmlu": 24.1,
    "truthfulqa": 43.96,
    "winogrande": 50.43,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": ["apache-2.0"],
    "params": 0.38,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "1b9b03d00b2b300d3c04c37fe3782c180ef51a27",
    "model_name_for_query": "postbot/gpt2-medium-emailgen",
    "link": "https://huggingface.co/postbot/gpt2-medium-emailgen",
    "author": "postbot"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "cutie",
    "average": 29.87,
    "arc": 26.96,
    "hellaswag": 27.02,
    "mmlu": 24.17,
    "truthfulqa": 48.42,
    "winogrande": 52.64,
    "gsm8k": 0.0,
    "model_type": "RL-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "eab22794d6cf39c945f7dc326c9785a5abf88ddd",
    "model_name_for_query": "rishiraj/cutie",
    "link": "https://huggingface.co/rishiraj/cutie",
    "author": "rishiraj"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test2",
    "average": 29.87,
    "arc": 29.61,
    "hellaswag": 26.65,
    "mmlu": 24.34,
    "truthfulqa": 48.49,
    "winogrande": 50.12,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f08d224deae510ebf1408ce38bc2610b1e4c77eb",
    "model_name_for_query": "doas/test2",
    "link": "https://huggingface.co/doas/test2",
    "author": "doas"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "bloom-560m-RLHF",
    "average": 29.86,
    "arc": 24.4,
    "hellaswag": 36.96,
    "mmlu": 23.63,
    "truthfulqa": 40.76,
    "winogrande": 53.12,
    "gsm8k": 0.3,
    "model_type": "RL-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.56,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "b1769e92f325d8a28e7db1c21f133e6c85b84e78",
    "model_name_for_query": "TheTravellingEngineer/bloom-560m-RLHF",
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-560m-RLHF",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "?",
    "model": "WizardLM-7B-uncensored-GPTQ",
    "average": 29.86,
    "arc": 28.5,
    "hellaswag": 25.37,
    "mmlu": 24.85,
    "truthfulqa": 50.86,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 9.04,
    "likes": 150.0,
    "still_on_hub": true,
    "revision": "cc30c031fd795ee3d3a50312ab4549415bfbdb46",
    "model_name_for_query": "TheBloke/WizardLM-7B-uncensored-GPTQ",
    "link": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GPTQ",
    "author": "TheBloke"
  },
  {
    "T": "\u2b55",
    "model": "speechless-codellama-orca-platypus-13b-0.10e",
    "average": 29.83,
    "arc": 28.75,
    "hellaswag": 25.88,
    "mmlu": 25.36,
    "truthfulqa": 49.27,
    "winogrande": 49.72,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "119abfc73f9ce541a40779f167fe21e95faed4e8",
    "model_name_for_query": "uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "author": "uukuguy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Ziya-LLaMA-13B-v1",
    "average": 29.82,
    "arc": 27.73,
    "hellaswag": 25.96,
    "mmlu": 27.04,
    "truthfulqa": 48.65,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "gpl-3.0",
    "params": 12.89,
    "likes": 251.0,
    "still_on_hub": true,
    "revision": "fccf34387d2c9f2f95ff59ae380e6de3718e41ff",
    "model_name_for_query": "IDEA-CCNL/Ziya-LLaMA-13B-v1",
    "link": "https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1",
    "author": "IDEA-CCNL"
  },
  {
    "T": "?",
    "model": "WizardLM-33B-V1.0-Uncensored-SuperHOT-8k",
    "average": 29.81,
    "arc": 25.43,
    "hellaswag": 31.97,
    "mmlu": 23.43,
    "truthfulqa": 47.0,
    "winogrande": 51.07,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "b6d0002b10d43ab48aa14e365d9e7b40655ec160",
    "model_name_for_query": "Panchovix/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k",
    "link": "https://huggingface.co/Panchovix/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k",
    "author": "Panchovix"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Marcoroni-7B-LaMini-40K",
    "average": 29.78,
    "arc": 27.65,
    "hellaswag": 26.23,
    "mmlu": 26.92,
    "truthfulqa": 47.4,
    "winogrande": 50.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "27868e4faed5d68d059c8c57dbd3e24e4933ca28",
    "model_name_for_query": "marcchew/Marcoroni-7B-LaMini-40K",
    "link": "https://huggingface.co/marcchew/Marcoroni-7B-LaMini-40K",
    "author": "marcchew"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FinOPT-Franklin",
    "average": 29.78,
    "arc": 27.73,
    "hellaswag": 24.91,
    "mmlu": 23.12,
    "truthfulqa": 52.4,
    "winogrande": 50.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 1.32,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "1b13331834190bfe49a176f1661ba4d8309a5051",
    "model_name_for_query": "MayaPH/FinOPT-Franklin",
    "link": "https://huggingface.co/MayaPH/FinOPT-Franklin",
    "author": "MayaPH"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mental-alpaca",
    "average": 29.77,
    "arc": 28.58,
    "hellaswag": 26.02,
    "mmlu": 27.04,
    "truthfulqa": 48.61,
    "winogrande": 48.38,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f5f24d4a11ed52b4a224f365b6a694cf4e27c1bc",
    "model_name_for_query": "NEU-HAI/mental-alpaca",
    "link": "https://huggingface.co/NEU-HAI/mental-alpaca",
    "author": "NEU-HAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "PM_modelV2",
    "average": 29.77,
    "arc": 25.09,
    "hellaswag": 26.45,
    "mmlu": 26.14,
    "truthfulqa": 51.36,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4edde209eea33af491206f8651c0c47e70e08289",
    "model_name_for_query": "BreadAi/PM_modelV2",
    "link": "https://huggingface.co/BreadAi/PM_modelV2",
    "author": "BreadAi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "proofGPT-v0.1-6.7B",
    "average": 29.72,
    "arc": 23.29,
    "hellaswag": 28.45,
    "mmlu": 24.57,
    "truthfulqa": 50.87,
    "winogrande": 51.14,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 6.65,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "02f405f08ca0e5b1aaa90a7c3b11303b5f245102",
    "model_name_for_query": "hoskinson-center/proofGPT-v0.1-6.7B",
    "link": "https://huggingface.co/hoskinson-center/proofGPT-v0.1-6.7B",
    "author": "hoskinson-center"
  },
  {
    "T": "\ud83d\udd36",
    "model": "neuralfalcon-1b-v1",
    "average": 29.72,
    "arc": 26.79,
    "hellaswag": 26.56,
    "mmlu": 26.22,
    "truthfulqa": 48.93,
    "winogrande": 49.57,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "FalconForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f788af66f22a933ad60e732ebaede3dfb5679bd4",
    "model_name_for_query": "vihangd/neuralfalcon-1b-v1",
    "link": "https://huggingface.co/vihangd/neuralfalcon-1b-v1",
    "author": "vihangd"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gorani-100k-llama2-13b-instruct",
    "average": 29.69,
    "arc": 28.07,
    "hellaswag": 26.3,
    "mmlu": 25.17,
    "truthfulqa": 48.96,
    "winogrande": 49.64,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f7d38ee654e505ad7a454f192d5e3d85cb60b3b8",
    "model_name_for_query": "danielpark/gorani-100k-llama2-13b-instruct",
    "link": "https://huggingface.co/danielpark/gorani-100k-llama2-13b-instruct",
    "author": "danielpark"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-turkish-uncased",
    "average": 29.68,
    "arc": 24.49,
    "hellaswag": 25.08,
    "mmlu": 26.59,
    "truthfulqa": 52.3,
    "winogrande": 49.64,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "4807e7df1dfb9d60c6d98e3cfeff62cb6b9a1579",
    "model_name_for_query": "TFLai/gpt2-turkish-uncased",
    "link": "https://huggingface.co/TFLai/gpt2-turkish-uncased",
    "author": "TFLai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-12_153950",
    "average": 29.68,
    "arc": 28.58,
    "hellaswag": 26.58,
    "mmlu": 20.79,
    "truthfulqa": 49.03,
    "winogrande": 53.12,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ee9b0cf26f521b5cb2322d743880e8b6bfadb0b7",
    "model_name_for_query": "porkorbeef/Llama-2-13b-12_153950",
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b-12_153950",
    "author": "porkorbeef"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Platypus-2-7B-LaMini-14K",
    "average": 29.64,
    "arc": 29.52,
    "hellaswag": 26.15,
    "mmlu": 23.13,
    "truthfulqa": 48.29,
    "winogrande": 50.75,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "50199ba51c4d002cc86cf3fb2ac921ec52bf4828",
    "model_name_for_query": "marcchew/Platypus-2-7B-LaMini-14K",
    "link": "https://huggingface.co/marcchew/Platypus-2-7B-LaMini-14K",
    "author": "marcchew"
  },
  {
    "T": "\ud83d\udd36",
    "model": "UltraRM-13b",
    "average": 29.58,
    "arc": 28.16,
    "hellaswag": 26.13,
    "mmlu": 25.96,
    "truthfulqa": 47.91,
    "winogrande": 49.33,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaRewardModel",
    "precision": "float16",
    "license": "mit",
    "params": 12.85,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "4b231ae58c15244e6e15f0d2f4e26ec37b846229",
    "model_name_for_query": "openbmb/UltraRM-13b",
    "link": "https://huggingface.co/openbmb/UltraRM-13b",
    "author": "openbmb"
  },
  {
    "T": "\ud83d\udd36",
    "model": "alpaca-7b",
    "average": 29.57,
    "arc": 28.07,
    "hellaswag": 25.83,
    "mmlu": 25.31,
    "truthfulqa": 48.49,
    "winogrande": 49.72,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "7f22882125208d1f54765c21abf84fd162aa454a",
    "model_name_for_query": "vicgalle/alpaca-7b",
    "link": "https://huggingface.co/vicgalle/alpaca-7b",
    "author": "vicgalle"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Cerebras-GPT-111M-instruction",
    "average": 29.57,
    "arc": 24.4,
    "hellaswag": 26.05,
    "mmlu": 25.87,
    "truthfulqa": 49.46,
    "winogrande": 51.62,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.11,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "09f1ec782ae2243fc605b24eb13ec8d5e4fd2734",
    "model_name_for_query": "SebastianSchramm/Cerebras-GPT-111M-instruction",
    "link": "https://huggingface.co/SebastianSchramm/Cerebras-GPT-111M-instruction",
    "author": "SebastianSchramm"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gogpt-560m",
    "average": 29.56,
    "arc": 26.37,
    "hellaswag": 31.86,
    "mmlu": 25.29,
    "truthfulqa": 43.12,
    "winogrande": 50.75,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.56,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "82bd8b88b95068eee614a35b790388c5d2415705",
    "model_name_for_query": "golaxy/gogpt-560m",
    "link": "https://huggingface.co/golaxy/gogpt-560m",
    "author": "golaxy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-70m-deduped-cleansharegpt",
    "average": 29.56,
    "arc": 25.68,
    "hellaswag": 25.4,
    "mmlu": 23.12,
    "truthfulqa": 51.15,
    "winogrande": 52.01,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.07,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6ea42abd94cb0017918f6fe5e71d78bcb7c75548",
    "model_name_for_query": "HWERI/pythia-70m-deduped-cleansharegpt",
    "link": "https://huggingface.co/HWERI/pythia-70m-deduped-cleansharegpt",
    "author": "HWERI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "xglm-564M",
    "average": 29.55,
    "arc": 24.57,
    "hellaswag": 34.64,
    "mmlu": 25.18,
    "truthfulqa": 40.43,
    "winogrande": 52.25,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 0.56,
    "likes": 28.0,
    "still_on_hub": true,
    "revision": "f3059f01b98ccc877c673149e0178c0e957660f9",
    "model_name_for_query": "facebook/xglm-564M",
    "link": "https://huggingface.co/facebook/xglm-564M",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "juniper-certificate-Llama-2-7b-chat-hf",
    "average": 29.55,
    "arc": 29.1,
    "hellaswag": 27.63,
    "mmlu": 24.02,
    "truthfulqa": 48.23,
    "winogrande": 48.3,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "90ed388e5503c02f5e6ba8dbc7286687a85ce1c1",
    "model_name_for_query": "Abe13/juniper-certificate-Llama-2-7b-chat-hf",
    "link": "https://huggingface.co/Abe13/juniper-certificate-Llama-2-7b-chat-hf",
    "author": "Abe13"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Llama-2-3b-hf",
    "average": 29.53,
    "arc": 26.96,
    "hellaswag": 26.52,
    "mmlu": 23.33,
    "truthfulqa": 50.71,
    "winogrande": 49.64,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 3.37,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "293f071b223efd7959f9e1fac66285369aaa959d",
    "model_name_for_query": "winglian/Llama-2-3b-hf",
    "link": "https://huggingface.co/winglian/Llama-2-3b-hf",
    "author": "winglian"
  },
  {
    "T": "\ud83d\udd36",
    "model": "rugpt3large_based_on_gpt2",
    "average": 29.53,
    "arc": 22.61,
    "hellaswag": 32.84,
    "mmlu": 24.9,
    "truthfulqa": 43.39,
    "winogrande": 53.12,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.76,
    "likes": 60.0,
    "still_on_hub": true,
    "revision": "8201db0de8deb68f25e7309db04d163b71970494",
    "model_name_for_query": "ai-forever/rugpt3large_based_on_gpt2",
    "link": "https://huggingface.co/ai-forever/rugpt3large_based_on_gpt2",
    "author": "ai-forever"
  },
  {
    "T": "\ud83d\udd36",
    "model": "santacoder",
    "average": 29.51,
    "arc": 26.28,
    "hellaswag": 25.6,
    "mmlu": 25.89,
    "truthfulqa": 51.24,
    "winogrande": 48.07,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadCustomModel",
    "precision": "float16",
    "license": "bigcode-openrail-m",
    "params": 1.31,
    "likes": 300.0,
    "still_on_hub": true,
    "revision": "132eb6b6cedaf579c2f333f1ecd78a16d7e45978",
    "model_name_for_query": "bigcode/santacoder",
    "link": "https://huggingface.co/bigcode/santacoder",
    "author": "bigcode"
  },
  {
    "T": "?",
    "model": "bloom-820m-chat",
    "average": 29.5,
    "arc": 23.38,
    "hellaswag": 34.16,
    "mmlu": 25.98,
    "truthfulqa": 40.32,
    "winogrande": 53.2,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 0.75,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "f98b1f9c1bd358dd837d05d443d992c495497606",
    "model_name_for_query": "WangZeJun/bloom-820m-chat",
    "link": "https://huggingface.co/WangZeJun/bloom-820m-chat",
    "author": "WangZeJun"
  },
  {
    "T": "\ud83d\udd36",
    "model": "supermario-v1",
    "average": 29.49,
    "arc": 27.73,
    "hellaswag": 25.83,
    "mmlu": 27.04,
    "truthfulqa": 47.27,
    "winogrande": 49.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "22a88e62529dc2cc95991478cd87e6c588237258",
    "model_name_for_query": "janhq/supermario-v1",
    "link": "https://huggingface.co/janhq/supermario-v1",
    "author": "janhq"
  },
  {
    "T": "\ud83d\udd36",
    "model": "bladeecity-jerma985",
    "average": 29.49,
    "arc": 22.87,
    "hellaswag": 30.53,
    "mmlu": 26.56,
    "truthfulqa": 44.99,
    "winogrande": 52.01,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9bf3a0db7f6bc960c51f2c0dc6fb66ed982b0180",
    "model_name_for_query": "huggingtweets/bladeecity-jerma985",
    "link": "https://huggingface.co/huggingtweets/bladeecity-jerma985",
    "author": "huggingtweets"
  },
  {
    "T": "?",
    "model": "airoboros-33b-gpt4-1.2-SuperHOT-8k",
    "average": 29.48,
    "arc": 24.66,
    "hellaswag": 31.23,
    "mmlu": 23.13,
    "truthfulqa": 47.44,
    "winogrande": 50.43,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 32.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "47c14f699cbbc9bd24458edd86eb70d87552b623",
    "model_name_for_query": "Panchovix/airoboros-33b-gpt4-1.2-SuperHOT-8k",
    "link": "https://huggingface.co/Panchovix/airoboros-33b-gpt4-1.2-SuperHOT-8k",
    "author": "Panchovix"
  },
  {
    "T": "\ud83d\udd36",
    "model": "test1",
    "average": 29.48,
    "arc": 27.65,
    "hellaswag": 26.17,
    "mmlu": 24.55,
    "truthfulqa": 48.33,
    "winogrande": 50.2,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "8bit",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "7444355ad764584ef05805f58ccf174bb03e0f46",
    "model_name_for_query": "marcchew/test1",
    "link": "https://huggingface.co/marcchew/test1",
    "author": "marcchew"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "codeparrot",
    "average": 29.48,
    "arc": 21.67,
    "hellaswag": 28.34,
    "mmlu": 25.55,
    "truthfulqa": 50.87,
    "winogrande": 50.2,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 1.53,
    "likes": 87.0,
    "still_on_hub": true,
    "revision": "065248a99f051da363b1c2cbf05da943c8b6211b",
    "model_name_for_query": "codeparrot/codeparrot",
    "link": "https://huggingface.co/codeparrot/codeparrot",
    "author": "codeparrot"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-neo-125m",
    "average": 29.47,
    "arc": 22.95,
    "hellaswag": 30.26,
    "mmlu": 25.97,
    "truthfulqa": 45.58,
    "winogrande": 51.78,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 0.15,
    "likes": 132.0,
    "still_on_hub": true,
    "revision": "6cb0d322a3a484e99667e7cb240e22f1ac036b99",
    "model_name_for_query": "EleutherAI/gpt-neo-125m",
    "link": "https://huggingface.co/EleutherAI/gpt-neo-125m",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "KoAlpaca-Polyglot-5.8B",
    "average": 29.46,
    "arc": 27.65,
    "hellaswag": 35.58,
    "mmlu": 24.72,
    "truthfulqa": 39.74,
    "winogrande": 49.01,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.0,
    "likes": 48.0,
    "still_on_hub": true,
    "revision": "1051dacf82ca9fba0ba4a4ff67f1d98a81ef7a2e",
    "model_name_for_query": "beomi/KoAlpaca-Polyglot-5.8B",
    "link": "https://huggingface.co/beomi/KoAlpaca-Polyglot-5.8B",
    "author": "beomi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MusePy-1-2",
    "average": 29.46,
    "arc": 25.77,
    "hellaswag": 25.94,
    "mmlu": 25.22,
    "truthfulqa": 49.33,
    "winogrande": 50.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.04,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6c1725158a74a41a10f21696a48510d45b4b425b",
    "model_name_for_query": "BreadAi/MusePy-1-2",
    "link": "https://huggingface.co/BreadAi/MusePy-1-2",
    "author": "BreadAi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-public",
    "average": 29.45,
    "arc": 29.95,
    "hellaswag": 26.65,
    "mmlu": 22.74,
    "truthfulqa": 49.01,
    "winogrande": 48.38,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e1b32a8fcfc0f37fd5f50cf765151897574c73c7",
    "model_name_for_query": "porkorbeef/Llama-2-13b-public",
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b-public",
    "author": "porkorbeef"
  },
  {
    "T": "\ud83d\udd36",
    "model": "UltraLM-13b",
    "average": 29.45,
    "arc": 29.44,
    "hellaswag": 25.99,
    "mmlu": 23.12,
    "truthfulqa": 48.61,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 67.0,
    "still_on_hub": true,
    "revision": "2c732c2899fc329036d97e5c6f0a61eaff19d97d",
    "model_name_for_query": "openbmb/UltraLM-13b",
    "link": "https://huggingface.co/openbmb/UltraLM-13b",
    "author": "openbmb"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lamini-neo-125m",
    "average": 29.44,
    "arc": 24.57,
    "hellaswag": 30.22,
    "mmlu": 26.74,
    "truthfulqa": 42.85,
    "winogrande": 52.25,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.12,
    "likes": 13.0,
    "still_on_hub": true,
    "revision": "f01e73ba67da96f6645be3067158cc493b0cbbcb",
    "model_name_for_query": "MBZUAI/lamini-neo-125m",
    "link": "https://huggingface.co/MBZUAI/lamini-neo-125m",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fairseq-dense-125M",
    "average": 29.41,
    "arc": 24.06,
    "hellaswag": 34.14,
    "mmlu": 23.98,
    "truthfulqa": 43.72,
    "winogrande": 50.59,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "XGLMForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "c8fb975220512b34e7b4a9fc570ca333ddcaf9b5",
    "model_name_for_query": "KoboldAI/fairseq-dense-125M",
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-125M",
    "author": "KoboldAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "tiny_starcoder_py",
    "average": 29.41,
    "arc": 20.99,
    "hellaswag": 28.77,
    "mmlu": 26.79,
    "truthfulqa": 47.68,
    "winogrande": 51.22,
    "gsm8k": 0.99,
    "model_type": "pretrained",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": "bigcode-openrail-m",
    "params": 0.16,
    "likes": 57.0,
    "still_on_hub": true,
    "revision": "8547527bef0bc927268c1653cce6948c5c242dd1",
    "model_name_for_query": "bigcode/tiny_starcoder_py",
    "link": "https://huggingface.co/bigcode/tiny_starcoder_py",
    "author": "bigcode"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Cerebras-GPT-256M",
    "average": 29.38,
    "arc": 22.01,
    "hellaswag": 28.99,
    "mmlu": 26.83,
    "truthfulqa": 45.98,
    "winogrande": 52.49,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.26,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "d77812ac95aece1f1edef6745ae2a1b325ad01a4",
    "model_name_for_query": "cerebras/Cerebras-GPT-256M",
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-256M",
    "author": "cerebras"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-160m-deduped",
    "average": 29.38,
    "arc": 24.06,
    "hellaswag": 31.39,
    "mmlu": 24.86,
    "truthfulqa": 44.34,
    "winogrande": 51.38,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.21,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "582159a2dfe3e712a8d47ae83dec95ae3bde8e7e",
    "model_name_for_query": "EleutherAI/pythia-160m-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-160m-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "dough-instruct-base-001",
    "average": 29.37,
    "arc": 23.89,
    "hellaswag": 24.76,
    "mmlu": 23.13,
    "truthfulqa": 53.4,
    "winogrande": 51.07,
    "gsm8k": 0.0,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.19,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3e1b0bf0a887feeb342982eee4f6d8041772a7dd",
    "model_name_for_query": "breadlicker45/dough-instruct-base-001",
    "link": "https://huggingface.co/breadlicker45/dough-instruct-base-001",
    "author": "breadlicker45"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dough-base-001",
    "average": 29.37,
    "arc": 23.89,
    "hellaswag": 24.76,
    "mmlu": 23.13,
    "truthfulqa": 53.4,
    "winogrande": 51.07,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.15,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e42b65191f97d786eadaba450f1d34baea470734",
    "model_name_for_query": "breadlicker45/dough-base-001",
    "link": "https://huggingface.co/breadlicker45/dough-base-001",
    "author": "breadlicker45"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "DeciCoder-1b",
    "average": 29.37,
    "arc": 21.16,
    "hellaswag": 31.09,
    "mmlu": 24.34,
    "truthfulqa": 47.05,
    "winogrande": 50.83,
    "gsm8k": 1.74,
    "model_type": "pretrained",
    "architecture": "DeciLlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.11,
    "likes": 221.0,
    "still_on_hub": true,
    "revision": "af2ef45ef8cbe82eb7eb4074f260412bc14c7b11",
    "model_name_for_query": "Deci/DeciCoder-1b",
    "link": "https://huggingface.co/Deci/DeciCoder-1b",
    "author": "Deci"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "zephyr-smol_llama-100m-dpo-full",
    "average": 29.37,
    "arc": 25.0,
    "hellaswag": 28.54,
    "mmlu": 25.18,
    "truthfulqa": 45.75,
    "winogrande": 51.07,
    "gsm8k": 0.68,
    "model_type": "RL-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "be3400c89d66ed66f0aa96f1b8131604c118b67b",
    "model_name_for_query": "amazingvince/zephyr-smol_llama-100m-dpo-full",
    "link": "https://huggingface.co/amazingvince/zephyr-smol_llama-100m-dpo-full",
    "author": "amazingvince"
  },
  {
    "T": "?",
    "model": "med-orca-instruct-33b",
    "average": 29.36,
    "arc": 27.39,
    "hellaswag": 25.89,
    "mmlu": 25.37,
    "truthfulqa": 49.6,
    "winogrande": 47.91,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "?",
    "params": 32.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1d636881854338e571825226c712180da06be72c",
    "model_name_for_query": "yhyhy3/med-orca-instruct-33b",
    "link": "https://huggingface.co/yhyhy3/med-orca-instruct-33b",
    "author": "yhyhy3"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-r",
    "average": 29.34,
    "arc": 21.59,
    "hellaswag": 30.18,
    "mmlu": 26.13,
    "truthfulqa": 45.38,
    "winogrande": 52.17,
    "gsm8k": 0.61,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.69,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6bdde9a227da60c2db803024d5b2e3a53a41cf0b",
    "model_name_for_query": "FINDA-FIT/llama-r",
    "link": "https://huggingface.co/FINDA-FIT/llama-r",
    "author": "FINDA-FIT"
  },
  {
    "T": "\u2b55",
    "model": "Aira-2-1B1",
    "average": 29.32,
    "arc": 23.21,
    "hellaswag": 26.97,
    "mmlu": 24.86,
    "truthfulqa": 50.63,
    "winogrande": 50.28,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.1,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a53eb20b72ae86441566f99acc204d9bb527bf32",
    "model_name_for_query": "nicholasKluge/Aira-2-1B1",
    "link": "https://huggingface.co/nicholasKluge/Aira-2-1B1",
    "author": "nicholasKluge"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "test-model",
    "average": 29.31,
    "arc": 24.4,
    "hellaswag": 30.17,
    "mmlu": 25.88,
    "truthfulqa": 44.59,
    "winogrande": 50.83,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3ea8330f61a47f16861415359f09ff0c6a210f27",
    "model_name_for_query": "yyjjtt/test-model",
    "link": "https://huggingface.co/yyjjtt/test-model",
    "author": "yyjjtt"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Flash-Llama-30M-20001",
    "average": 29.31,
    "arc": 23.89,
    "hellaswag": 25.76,
    "mmlu": 24.09,
    "truthfulqa": 51.29,
    "winogrande": 50.83,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6ff84442217565875450bd7a0457121dcedf6b0b",
    "model_name_for_query": "TaylorAI/Flash-Llama-30M-20001",
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-30M-20001",
    "author": "TaylorAI"
  },
  {
    "T": "\u2b55",
    "model": "LaMini-Neo-1.3B-Mental-Health_lora",
    "average": 29.3,
    "arc": 25.77,
    "hellaswag": 25.67,
    "mmlu": 27.0,
    "truthfulqa": 48.21,
    "winogrande": 49.17,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "9f1c45d5ce88a8eaf7ec03b760a4adfb5fda07eb",
    "model_name_for_query": "Harshvir/LaMini-Neo-1.3B-Mental-Health_lora",
    "link": "https://huggingface.co/Harshvir/LaMini-Neo-1.3B-Mental-Health_lora",
    "author": "Harshvir"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-160m-deduped-step92k-193bt",
    "average": 29.3,
    "arc": 24.23,
    "hellaswag": 32.33,
    "mmlu": 24.54,
    "truthfulqa": 43.49,
    "winogrande": 50.83,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9eac24dad1bd7194e38ce8083a0197cee456456c",
    "model_name_for_query": "klosax/pythia-160m-deduped-step92k-193bt",
    "link": "https://huggingface.co/klosax/pythia-160m-deduped-step92k-193bt",
    "author": "klosax"
  },
  {
    "T": "\u2b55",
    "model": "llama2-13b-platypus-ckpt-1000",
    "average": 29.28,
    "arc": 28.16,
    "hellaswag": 26.55,
    "mmlu": 23.17,
    "truthfulqa": 48.79,
    "winogrande": 49.01,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaModel",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "d9f3e490df2134784afc3a86f5c617a9bab8db4d",
    "model_name_for_query": "bsp-albz/llama2-13b-platypus-ckpt-1000",
    "link": "https://huggingface.co/bsp-albz/llama2-13b-platypus-ckpt-1000",
    "author": "bsp-albz"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DialoGPT-large",
    "average": 29.27,
    "arc": 23.38,
    "hellaswag": 25.77,
    "mmlu": 23.81,
    "truthfulqa": 50.27,
    "winogrande": 52.41,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.77,
    "likes": 203.0,
    "still_on_hub": true,
    "revision": "04e3e47b52dadbcf7688aa61a7ed0438ecf9184c",
    "model_name_for_query": "microsoft/DialoGPT-large",
    "link": "https://huggingface.co/microsoft/DialoGPT-large",
    "author": "microsoft"
  },
  {
    "T": "\u2b55",
    "model": "changpt-bart",
    "average": 29.27,
    "arc": 28.67,
    "hellaswag": 26.41,
    "mmlu": 23.12,
    "truthfulqa": 47.94,
    "winogrande": 49.49,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "BartForConditionalGeneration",
    "precision": "float16",
    "license": "?",
    "params": 0.18,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e3d26f736b8b47d5275421be6133b81bef84db7d",
    "model_name_for_query": "voidful/changpt-bart",
    "link": "https://huggingface.co/voidful/changpt-bart",
    "author": "voidful"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FinOPT-Lincoln",
    "average": 29.27,
    "arc": 26.71,
    "hellaswag": 25.6,
    "mmlu": 23.0,
    "truthfulqa": 50.59,
    "winogrande": 49.72,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 0.33,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "7ddc381fa3968df22f72acb6cf03b75d3ac49661",
    "model_name_for_query": "MayaPH/FinOPT-Lincoln",
    "link": "https://huggingface.co/MayaPH/FinOPT-Lincoln",
    "author": "MayaPH"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-13B-1.0",
    "average": 29.27,
    "arc": 28.5,
    "hellaswag": 25.97,
    "mmlu": 23.12,
    "truthfulqa": 48.61,
    "winogrande": 49.41,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 66.0,
    "still_on_hub": true,
    "revision": "2ea86d3c02ca0c2abb086a2145e1e85eaea4a23e",
    "model_name_for_query": "victor123/WizardLM-13B-1.0",
    "link": "https://huggingface.co/victor123/WizardLM-13B-1.0",
    "author": "victor123"
  },
  {
    "T": "?",
    "model": "pythia-160m-hq-emails",
    "average": 29.26,
    "arc": 23.12,
    "hellaswag": 30.05,
    "mmlu": 26.58,
    "truthfulqa": 45.51,
    "winogrande": 50.28,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 0.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6eeded627780b47b5221ed72ebea436514621964",
    "model_name_for_query": "postbot/pythia-160m-hq-emails",
    "link": "https://huggingface.co/postbot/pythia-160m-hq-emails",
    "author": "postbot"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "NanoLlama-GQA-L10-A32_KV8-v13-KI",
    "average": 29.23,
    "arc": 23.81,
    "hellaswag": 29.39,
    "mmlu": 25.37,
    "truthfulqa": 44.77,
    "winogrande": 51.14,
    "gsm8k": 0.91,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.22,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "29fc3a802ee639be914d2a54fa6d9f595036ecf2",
    "model_name_for_query": "BEE-spoke-data/NanoLlama-GQA-L10-A32_KV8-v13-KI",
    "link": "https://huggingface.co/BEE-spoke-data/NanoLlama-GQA-L10-A32_KV8-v13-KI",
    "author": "BEE-spoke-data"
  },
  {
    "T": "?",
    "model": "GPT_Large_Quantized",
    "average": 29.21,
    "arc": 27.05,
    "hellaswag": 26.29,
    "mmlu": 24.12,
    "truthfulqa": 48.46,
    "winogrande": 49.33,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "unknown",
    "params": 0.77,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c2df1904aa18de22d03ba0fee925e831d8468898",
    "model_name_for_query": "FabbriSimo01/GPT_Large_Quantized",
    "link": "https://huggingface.co/FabbriSimo01/GPT_Large_Quantized",
    "author": "FabbriSimo01"
  },
  {
    "T": "\u2b55",
    "model": "gpt2-dolly",
    "average": 29.21,
    "arc": 22.7,
    "hellaswag": 30.15,
    "mmlu": 25.81,
    "truthfulqa": 44.97,
    "winogrande": 51.46,
    "gsm8k": 0.15,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "4bit",
    "license": "mit",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "7e75e6f4626437305e4d3e7b2aa36f617c517247",
    "model_name_for_query": "lgaalves/gpt2-dolly",
    "link": "https://huggingface.co/lgaalves/gpt2-dolly",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Pythia-70M-ChatSalad",
    "average": 29.2,
    "arc": 20.99,
    "hellaswag": 27.28,
    "mmlu": 24.78,
    "truthfulqa": 49.74,
    "winogrande": 52.41,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.1,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "692289413c47c219cf83b1596783a8e9223541eb",
    "model_name_for_query": "concedo/Pythia-70M-ChatSalad",
    "link": "https://huggingface.co/concedo/Pythia-70M-ChatSalad",
    "author": "concedo"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-longlora-32k-ft",
    "average": 29.2,
    "arc": 27.9,
    "hellaswag": 25.61,
    "mmlu": 23.08,
    "truthfulqa": 49.57,
    "winogrande": 49.01,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "ab48674ffc55568ffe2a1207ef0e711c2febbaaf",
    "model_name_for_query": "Yukang/Llama-2-7b-longlora-32k-ft",
    "link": "https://huggingface.co/Yukang/Llama-2-7b-longlora-32k-ft",
    "author": "Yukang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DialoGPT-small",
    "average": 29.19,
    "arc": 25.77,
    "hellaswag": 25.79,
    "mmlu": 25.81,
    "truthfulqa": 47.49,
    "winogrande": 50.28,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.18,
    "likes": 55.0,
    "still_on_hub": true,
    "revision": "97d0fec744c2cb4d48f5db51d17e3258e185858e",
    "model_name_for_query": "microsoft/DialoGPT-small",
    "link": "https://huggingface.co/microsoft/DialoGPT-small",
    "author": "microsoft"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-13b-longlora-16k-ft",
    "average": 29.17,
    "arc": 25.85,
    "hellaswag": 27.6,
    "mmlu": 23.1,
    "truthfulqa": 48.89,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 12.85,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5f0cfdef590fc9bd7642042fb5f1ed9679260b93",
    "model_name_for_query": "Yukang/Llama-2-13b-longlora-16k-ft",
    "link": "https://huggingface.co/Yukang/Llama-2-13b-longlora-16k-ft",
    "author": "Yukang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "CodeGPT-small-py",
    "average": 29.17,
    "arc": 22.7,
    "hellaswag": 27.26,
    "mmlu": 25.05,
    "truthfulqa": 51.23,
    "winogrande": 48.78,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 18.0,
    "still_on_hub": true,
    "revision": "e5f31df92bfb7b7a808ea8d1c7557488e1bdff7f",
    "model_name_for_query": "microsoft/CodeGPT-small-py",
    "link": "https://huggingface.co/microsoft/CodeGPT-small-py",
    "author": "microsoft"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-31m-KI_v1-2048-scratch",
    "average": 29.15,
    "arc": 23.12,
    "hellaswag": 25.23,
    "mmlu": 23.12,
    "truthfulqa": 51.67,
    "winogrande": 51.78,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.03,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b29a3229f8d5317adeabafeb20677ec7bea9d703",
    "model_name_for_query": "pszemraj/pythia-31m-KI_v1-2048-scratch",
    "link": "https://huggingface.co/pszemraj/pythia-31m-KI_v1-2048-scratch",
    "author": "pszemraj"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "opt-125m",
    "average": 29.15,
    "arc": 22.87,
    "hellaswag": 31.47,
    "mmlu": 26.02,
    "truthfulqa": 42.87,
    "winogrande": 51.62,
    "gsm8k": 0.08,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.12,
    "likes": 81.0,
    "still_on_hub": true,
    "revision": "3d2b5f275bdf882b8775f902e1bfdb790e2cfc32",
    "model_name_for_query": "facebook/opt-125m",
    "link": "https://huggingface.co/facebook/opt-125m",
    "author": "facebook"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-neo-125m-neurallinguisticpioneers",
    "average": 29.15,
    "arc": 22.44,
    "hellaswag": 30.36,
    "mmlu": 25.14,
    "truthfulqa": 45.64,
    "winogrande": 51.22,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "515fd7753c5fecbf4a2951f7cebb2846d91324b3",
    "model_name_for_query": "ogimgio/gpt-neo-125m-neurallinguisticpioneers",
    "link": "https://huggingface.co/ogimgio/gpt-neo-125m-neurallinguisticpioneers",
    "author": "ogimgio"
  },
  {
    "T": "?",
    "model": "Cerebras-GPT-590M",
    "average": 29.14,
    "arc": 23.72,
    "hellaswag": 32.4,
    "mmlu": 25.97,
    "truthfulqa": 44.15,
    "winogrande": 48.15,
    "gsm8k": 0.45,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.59,
    "likes": 17.0,
    "still_on_hub": true,
    "revision": "67a653304fd782a34906d59f3795a37f9e053397",
    "model_name_for_query": "cerebras/Cerebras-GPT-590M",
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-590M",
    "author": "cerebras"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyStories-1M",
    "average": 29.14,
    "arc": 23.46,
    "hellaswag": 25.23,
    "mmlu": 24.57,
    "truthfulqa": 49.4,
    "winogrande": 52.17,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.0,
    "likes": 20.0,
    "still_on_hub": true,
    "revision": "8cd14d5339178f1b285f55baee14a0deff7103ac",
    "model_name_for_query": "roneneldan/TinyStories-1M",
    "link": "https://huggingface.co/roneneldan/TinyStories-1M",
    "author": "roneneldan"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-Chat-AWQ",
    "average": 29.14,
    "arc": 27.22,
    "hellaswag": 25.48,
    "mmlu": 24.67,
    "truthfulqa": 49.95,
    "winogrande": 47.51,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "llama2",
    "params": 1.13,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "a065961fd627aa3b3e6dde21e77fd5e20f712189",
    "model_name_for_query": "TheBloke/Llama-2-7b-Chat-AWQ",
    "link": "https://huggingface.co/TheBloke/Llama-2-7b-Chat-AWQ",
    "author": "TheBloke"
  },
  {
    "T": "\ud83d\udd36",
    "model": "tulu-7b-instruct-pl-lora_unload",
    "average": 29.11,
    "arc": 28.67,
    "hellaswag": 26.05,
    "mmlu": 23.12,
    "truthfulqa": 48.61,
    "winogrande": 48.22,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "962d4e5d8da5a4ec0ec047b6f8f08f1bb9e509fe",
    "model_name_for_query": "Aspik101/tulu-7b-instruct-pl-lora_unload",
    "link": "https://huggingface.co/Aspik101/tulu-7b-instruct-pl-lora_unload",
    "author": "Aspik101"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt3-finnish-large",
    "average": 29.11,
    "arc": 21.76,
    "hellaswag": 32.88,
    "mmlu": 24.11,
    "truthfulqa": 44.35,
    "winogrande": 51.54,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "BloomModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.88,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "b9a3dd97387fc70d07010d469888a918842d3449",
    "model_name_for_query": "TurkuNLP/gpt3-finnish-large",
    "link": "https://huggingface.co/TurkuNLP/gpt3-finnish-large",
    "author": "TurkuNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-neox-122m-minipile-digits",
    "average": 29.1,
    "arc": 20.73,
    "hellaswag": 27.03,
    "mmlu": 25.31,
    "truthfulqa": 49.19,
    "winogrande": 52.33,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc0-1.0",
    "params": 0.17,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "3e9187385d31234b04021ddc8b03cbd5cfef9fb4",
    "model_name_for_query": "euclaise/gpt-neox-122m-minipile-digits",
    "link": "https://huggingface.co/euclaise/gpt-neox-122m-minipile-digits",
    "author": "euclaise"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-longlora-100k-ft",
    "average": 29.08,
    "arc": 28.16,
    "hellaswag": 25.43,
    "mmlu": 23.48,
    "truthfulqa": 49.06,
    "winogrande": 48.38,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 37.0,
    "still_on_hub": true,
    "revision": "242c6469cab41b41d30826e850afa4687e422f24",
    "model_name_for_query": "Yukang/Llama-2-7b-longlora-100k-ft",
    "link": "https://huggingface.co/Yukang/Llama-2-7b-longlora-100k-ft",
    "author": "Yukang"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mpt-1b-redpajama-200b",
    "average": 29.05,
    "arc": 25.77,
    "hellaswag": 26.08,
    "mmlu": 24.5,
    "truthfulqa": 47.57,
    "winogrande": 50.36,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "MosaicGPT",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.0,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "fc98636655efb7c091bbe5d8014eb138ddfc5471",
    "model_name_for_query": "anas-awadalla/mpt-1b-redpajama-200b",
    "link": "https://huggingface.co/anas-awadalla/mpt-1b-redpajama-200b",
    "author": "anas-awadalla"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-YA-1-1_160M",
    "average": 29.03,
    "arc": 22.95,
    "hellaswag": 27.29,
    "mmlu": 26.25,
    "truthfulqa": 47.02,
    "winogrande": 50.67,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b9b3577df726f7984721e4d73741296db50fa782",
    "model_name_for_query": "BreadAi/gpt-YA-1-1_160M",
    "link": "https://huggingface.co/BreadAi/gpt-YA-1-1_160M",
    "author": "BreadAi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "medical_transcription_generator",
    "average": 29.03,
    "arc": 22.78,
    "hellaswag": 30.6,
    "mmlu": 23.84,
    "truthfulqa": 46.5,
    "winogrande": 50.43,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.14,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f622239151c89c2db0f1cef495d1b42afd16ce64",
    "model_name_for_query": "alibidaran/medical_transcription_generator",
    "link": "https://huggingface.co/alibidaran/medical_transcription_generator",
    "author": "alibidaran"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-160m",
    "average": 29.02,
    "arc": 22.78,
    "hellaswag": 30.34,
    "mmlu": 24.95,
    "truthfulqa": 44.26,
    "winogrande": 51.54,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.21,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "50f5173d932e8e61f858120bcb800b97af589f46",
    "model_name_for_query": "EleutherAI/pythia-160m",
    "link": "https://huggingface.co/EleutherAI/pythia-160m",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-conversational-or-qa",
    "average": 29.01,
    "arc": 21.42,
    "hellaswag": 27.61,
    "mmlu": 26.51,
    "truthfulqa": 47.31,
    "winogrande": 51.14,
    "gsm8k": 0.08,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "openrail",
    "params": 0.14,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f881c740c82ee9bc3191b886ad53f18d741960ea",
    "model_name_for_query": "Locutusque/gpt2-conversational-or-qa",
    "link": "https://huggingface.co/Locutusque/gpt2-conversational-or-qa",
    "author": "Locutusque"
  },
  {
    "T": "\ud83d\udd36",
    "model": "hepu-o4zf-ravz-7-0",
    "average": 29.01,
    "arc": 24.49,
    "hellaswag": 25.36,
    "mmlu": 23.27,
    "truthfulqa": 51.67,
    "winogrande": 49.25,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 7.24,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b73d869edfc259dea27c15d06cf65ee08ec3c2c7",
    "model_name_for_query": "abhishek/hepu-o4zf-ravz-7-0",
    "link": "https://huggingface.co/abhishek/hepu-o4zf-ravz-7-0",
    "author": "abhishek"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-70m-deduped-step44k-92bt",
    "average": 29.0,
    "arc": 22.1,
    "hellaswag": 28.21,
    "mmlu": 26.03,
    "truthfulqa": 46.12,
    "winogrande": 51.54,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.04,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aac86fff08965d84d8bfc3e7c14559d48b8c4c99",
    "model_name_for_query": "klosax/pythia-70m-deduped-step44k-92bt",
    "link": "https://huggingface.co/klosax/pythia-70m-deduped-step44k-92bt",
    "author": "klosax"
  },
  {
    "T": "\ud83d\udd36",
    "model": "jerma985",
    "average": 28.97,
    "arc": 21.67,
    "hellaswag": 30.91,
    "mmlu": 26.57,
    "truthfulqa": 44.01,
    "winogrande": 50.67,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "816206ad02a397161be78dcb70eeda67e0c53132",
    "model_name_for_query": "huggingtweets/jerma985",
    "link": "https://huggingface.co/huggingtweets/jerma985",
    "author": "huggingtweets"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "smol_llama-101M-GQA",
    "average": 28.97,
    "arc": 23.55,
    "hellaswag": 28.77,
    "mmlu": 24.24,
    "truthfulqa": 45.76,
    "winogrande": 50.67,
    "gsm8k": 0.83,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.1,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cac68b3377fd0a1eb1aca92a2e661d81f59d8b08",
    "model_name_for_query": "BEE-spoke-data/smol_llama-101M-GQA",
    "link": "https://huggingface.co/BEE-spoke-data/smol_llama-101M-GQA",
    "author": "BEE-spoke-data"
  },
  {
    "T": "\ud83d\udd36",
    "model": "smol_llama-101M-GQA",
    "average": 28.96,
    "arc": 23.46,
    "hellaswag": 28.73,
    "mmlu": 24.35,
    "truthfulqa": 45.8,
    "winogrande": 50.67,
    "gsm8k": 0.76,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.1,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cac68b3377fd0a1eb1aca92a2e661d81f59d8b08",
    "model_name_for_query": "BEE-spoke-data/smol_llama-101M-GQA",
    "link": "https://huggingface.co/BEE-spoke-data/smol_llama-101M-GQA",
    "author": "BEE-spoke-data"
  },
  {
    "T": "\u2b55",
    "model": "WizardLM-30B-V1.0",
    "average": 28.96,
    "arc": 27.39,
    "hellaswag": 25.94,
    "mmlu": 23.12,
    "truthfulqa": 48.61,
    "winogrande": 48.7,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "?",
    "params": 32.32,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "815e2dd7daabe446c429f3c9f70ef01582528f81",
    "model_name_for_query": "WizardLM/WizardLM-30B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardLM-30B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OPT-19M-ChatSalad",
    "average": 28.96,
    "arc": 24.4,
    "hellaswag": 25.15,
    "mmlu": 23.12,
    "truthfulqa": 51.36,
    "winogrande": 49.72,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "other",
    "params": 0.02,
    "likes": 15.0,
    "still_on_hub": true,
    "revision": "3930ca6bf3976e9b603815403cb373398ae509e5",
    "model_name_for_query": "concedo/OPT-19M-ChatSalad",
    "link": "https://huggingface.co/concedo/OPT-19M-ChatSalad",
    "author": "concedo"
  },
  {
    "T": "\ud83d\udd36",
    "model": "WizardLM-30B-V1.0",
    "average": 28.95,
    "arc": 27.39,
    "hellaswag": 25.94,
    "mmlu": 23.12,
    "truthfulqa": 48.61,
    "winogrande": 48.62,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "?",
    "params": 32.32,
    "likes": 70.0,
    "still_on_hub": true,
    "revision": "815e2dd7daabe446c429f3c9f70ef01582528f81",
    "model_name_for_query": "WizardLM/WizardLM-30B-V1.0",
    "link": "https://huggingface.co/WizardLM/WizardLM-30B-V1.0",
    "author": "WizardLM"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DiscordPy",
    "average": 28.94,
    "arc": 23.29,
    "hellaswag": 26.15,
    "mmlu": 25.04,
    "truthfulqa": 48.16,
    "winogrande": 50.99,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.26,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a5405585aec0b60c5de7d942ccd58421fe9239be",
    "model_name_for_query": "BreadAi/DiscordPy",
    "link": "https://huggingface.co/BreadAi/DiscordPy",
    "author": "BreadAi"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-70m",
    "average": 28.93,
    "arc": 21.59,
    "hellaswag": 27.29,
    "mmlu": 25.9,
    "truthfulqa": 47.06,
    "winogrande": 51.46,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.1,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "2ab25ed47af79376eed2baaf8bbb7a192a0c73ff",
    "model_name_for_query": "EleutherAI/pythia-70m",
    "link": "https://huggingface.co/EleutherAI/pythia-70m",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-j-tiny-random",
    "average": 28.92,
    "arc": 26.37,
    "hellaswag": 25.76,
    "mmlu": 24.46,
    "truthfulqa": 47.44,
    "winogrande": 49.49,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTJForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.05,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "feea91564dac0081f73aeb6744979c6cfe553fff",
    "model_name_for_query": "anton-l/gpt-j-tiny-random",
    "link": "https://huggingface.co/anton-l/gpt-j-tiny-random",
    "author": "anton-l"
  },
  {
    "T": "?",
    "model": "590m",
    "average": 28.88,
    "arc": 24.15,
    "hellaswag": 31.91,
    "mmlu": 26.61,
    "truthfulqa": 42.19,
    "winogrande": 48.38,
    "gsm8k": 0.08,
    "model_type": "",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.67,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ec721c97ef0e6ebfc578ab98b3ff6e2bd19b3e27",
    "model_name_for_query": "Corianas/590m",
    "link": "https://huggingface.co/Corianas/590m",
    "author": "Corianas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-YA-1-1_70M",
    "average": 28.88,
    "arc": 22.53,
    "hellaswag": 27.37,
    "mmlu": 25.38,
    "truthfulqa": 47.09,
    "winogrande": 50.91,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.04,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "218e8da522cf6fb5566314f37624f27412ae2259",
    "model_name_for_query": "BreadAi/gpt-YA-1-1_70M",
    "link": "https://huggingface.co/BreadAi/gpt-YA-1-1_70M",
    "author": "BreadAi"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "open-calm-large",
    "average": 28.88,
    "arc": 20.73,
    "hellaswag": 29.56,
    "mmlu": 25.23,
    "truthfulqa": 46.52,
    "winogrande": 51.14,
    "gsm8k": 0.08,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 0.76,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "f9b7a3222967b15169a09bcc86b118ac68a1ad62",
    "model_name_for_query": "cyberagent/open-calm-large",
    "link": "https://huggingface.co/cyberagent/open-calm-large",
    "author": "cyberagent"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DialoGPT-medium",
    "average": 28.86,
    "arc": 24.49,
    "hellaswag": 26.21,
    "mmlu": 25.84,
    "truthfulqa": 47.06,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.36,
    "likes": 240.0,
    "still_on_hub": true,
    "revision": "9d5c5fadcc072b693fb5a5e29416bbf3f503c26c",
    "model_name_for_query": "microsoft/DialoGPT-medium",
    "link": "https://huggingface.co/microsoft/DialoGPT-medium",
    "author": "microsoft"
  },
  {
    "T": "\ud83d\udd36",
    "model": "easyTermsSummerizer",
    "average": 28.86,
    "arc": 25.77,
    "hellaswag": 25.81,
    "mmlu": 23.12,
    "truthfulqa": 47.69,
    "winogrande": 50.75,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "BartForConditionalGeneration",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.41,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8df9f96cc14be8f681c40bd1672b3f3540b70e31",
    "model_name_for_query": "Quake24/easyTermsSummerizer",
    "link": "https://huggingface.co/Quake24/easyTermsSummerizer",
    "author": "Quake24"
  },
  {
    "T": "\ud83d\udd36",
    "model": "FinOPT-Washington",
    "average": 28.85,
    "arc": 25.17,
    "hellaswag": 26.25,
    "mmlu": 24.83,
    "truthfulqa": 45.8,
    "winogrande": 51.07,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "cdd8a6cde7902de39757cf31d73af1f51df0d8e8",
    "model_name_for_query": "MayaPH/FinOPT-Washington",
    "link": "https://huggingface.co/MayaPH/FinOPT-Washington",
    "author": "MayaPH"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-31m-goodwiki-deduped-2048-scratch",
    "average": 28.85,
    "arc": 23.12,
    "hellaswag": 25.66,
    "mmlu": 23.11,
    "truthfulqa": 51.32,
    "winogrande": 49.88,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.03,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "01a3cd918dd7c233bc0c3c0c948a9a462a5359d1",
    "model_name_for_query": "pszemraj/pythia-31m-goodwiki-deduped-2048-scratch",
    "link": "https://huggingface.co/pszemraj/pythia-31m-goodwiki-deduped-2048-scratch",
    "author": "pszemraj"
  },
  {
    "T": "\ud83d\udd36",
    "model": "StoryPy",
    "average": 28.85,
    "arc": 22.35,
    "hellaswag": 26.19,
    "mmlu": 24.37,
    "truthfulqa": 49.1,
    "winogrande": 51.07,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.1,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5c32081bd3bc1404c2f5b8dbb6f888048bcb7cd7",
    "model_name_for_query": "BreadAi/StoryPy",
    "link": "https://huggingface.co/BreadAi/StoryPy",
    "author": "BreadAi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "distilgpt2-emailgen",
    "average": 28.84,
    "arc": 21.76,
    "hellaswag": 27.52,
    "mmlu": 25.97,
    "truthfulqa": 46.17,
    "winogrande": 51.62,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.09,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "fe96d63cc2edcbd1ae444ada293cc59d1e01a6ad",
    "model_name_for_query": "postbot/distilgpt2-emailgen",
    "link": "https://huggingface.co/postbot/distilgpt2-emailgen",
    "author": "postbot"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-31m",
    "average": 28.81,
    "arc": 21.84,
    "hellaswag": 27.0,
    "mmlu": 24.97,
    "truthfulqa": 49.1,
    "winogrande": 49.72,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.03,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "eeea0b6b80603d162fe7de4e80a5bf4a8e9c6207",
    "model_name_for_query": "ethzanalytics/pythia-31m",
    "link": "https://huggingface.co/ethzanalytics/pythia-31m",
    "author": "ethzanalytics"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-7b-longlora-16k-ft",
    "average": 28.81,
    "arc": 26.37,
    "hellaswag": 26.37,
    "mmlu": 23.75,
    "truthfulqa": 47.76,
    "winogrande": 48.62,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c86de31b80866d047e680e08dbd3572e2965d4c5",
    "model_name_for_query": "Yukang/Llama-2-7b-longlora-16k-ft",
    "link": "https://huggingface.co/Yukang/Llama-2-7b-longlora-16k-ft",
    "author": "Yukang"
  },
  {
    "T": "?",
    "model": "Yi-8B-Llama",
    "average": 28.78,
    "arc": 25.68,
    "hellaswag": 26.79,
    "mmlu": 24.14,
    "truthfulqa": 47.79,
    "winogrande": 48.3,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "other",
    "params": 8.73,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "4f3f4d73ff3962487d1c51702b02d795bf1f33a4",
    "model_name_for_query": "ByteWave/Yi-8B-Llama",
    "link": "https://huggingface.co/ByteWave/Yi-8B-Llama",
    "author": "ByteWave"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-owt2-70m-100k",
    "average": 28.78,
    "arc": 20.9,
    "hellaswag": 28.34,
    "mmlu": 25.02,
    "truthfulqa": 45.12,
    "winogrande": 53.28,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.07,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "b288893319b6cdce499148f4482043c350116560",
    "model_name_for_query": "nthngdy/pythia-owt2-70m-100k",
    "link": "https://huggingface.co/nthngdy/pythia-owt2-70m-100k",
    "author": "nthngdy"
  },
  {
    "T": "\ud83d\udd36",
    "model": "fiction_story_generator",
    "average": 28.77,
    "arc": 23.29,
    "hellaswag": 28.68,
    "mmlu": 26.72,
    "truthfulqa": 43.79,
    "winogrande": 50.12,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "377b080cf96e10d50289aa3e1fd79c330265f45a",
    "model_name_for_query": "Tincando/fiction_story_generator",
    "link": "https://huggingface.co/Tincando/fiction_story_generator",
    "author": "Tincando"
  },
  {
    "T": "\ud83d\udd36",
    "model": "256_5epoch",
    "average": 28.76,
    "arc": 22.27,
    "hellaswag": 28.99,
    "mmlu": 26.62,
    "truthfulqa": 41.71,
    "winogrande": 52.72,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 0.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "b1fe75844a07832acd405a4d989a26f6ab7b1c00",
    "model_name_for_query": "Corianas/256_5epoch",
    "link": "https://huggingface.co/Corianas/256_5epoch",
    "author": "Corianas"
  },
  {
    "T": "\ud83d\udd36",
    "model": "DialoGPT-sarcastic-medium",
    "average": 28.73,
    "arc": 23.29,
    "hellaswag": 25.93,
    "mmlu": 23.76,
    "truthfulqa": 46.04,
    "winogrande": 53.35,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.14,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "292596e120591887383011c4520bc5b57e7e8993",
    "model_name_for_query": "abhiramtirumala/DialoGPT-sarcastic-medium",
    "link": "https://huggingface.co/abhiramtirumala/DialoGPT-sarcastic-medium",
    "author": "abhiramtirumala"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-owt2-70m-50k",
    "average": 28.71,
    "arc": 21.5,
    "hellaswag": 28.15,
    "mmlu": 25.7,
    "truthfulqa": 44.5,
    "winogrande": 52.41,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "?",
    "params": 0.07,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "9fce9b8252f7891dbd50299a8c3bd71cd25454db",
    "model_name_for_query": "nthngdy/pythia-owt2-70m-50k",
    "link": "https://huggingface.co/nthngdy/pythia-owt2-70m-50k",
    "author": "nthngdy"
  },
  {
    "T": "?",
    "model": "distilgpt2",
    "average": 28.71,
    "arc": 22.27,
    "hellaswag": 27.58,
    "mmlu": 24.81,
    "truthfulqa": 44.49,
    "winogrande": 53.12,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.09,
    "likes": 262.0,
    "still_on_hub": true,
    "revision": "38cc92ec43315abd5136313225e95acc5986876c",
    "model_name_for_query": "distilgpt2",
    "link": "https://huggingface.co/distilgpt2",
    "author": "distilgpt2"
  },
  {
    "T": "\ud83d\udd36",
    "model": "pythia-70m-deduped-cleansharegpt-en",
    "average": 28.71,
    "arc": 21.16,
    "hellaswag": 27.16,
    "mmlu": 25.24,
    "truthfulqa": 48.57,
    "winogrande": 50.12,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.04,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "a97ff56bc68a81a9f6147f1590e53511246d1040",
    "model_name_for_query": "HWERI/pythia-70m-deduped-cleansharegpt-en",
    "link": "https://huggingface.co/HWERI/pythia-70m-deduped-cleansharegpt-en",
    "author": "HWERI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "verysmol_llama-v11-KIx2",
    "average": 28.7,
    "arc": 22.7,
    "hellaswag": 27.6,
    "mmlu": 25.28,
    "truthfulqa": 44.75,
    "winogrande": 51.54,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.06,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1cd271d3d62a9e1dc4b7c2978e54806d74705439",
    "model_name_for_query": "BEE-spoke-data/verysmol_llama-v11-KIx2",
    "link": "https://huggingface.co/BEE-spoke-data/verysmol_llama-v11-KIx2",
    "author": "BEE-spoke-data"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "rwkv-4-169m-pile",
    "average": 28.64,
    "arc": 23.63,
    "hellaswag": 31.74,
    "mmlu": 23.18,
    "truthfulqa": 41.92,
    "winogrande": 50.91,
    "gsm8k": 0.45,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.13,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "46bdc280eb97b6141d5d51a935e0c4870ecaefcc",
    "model_name_for_query": "RWKV/rwkv-4-169m-pile",
    "link": "https://huggingface.co/RWKV/rwkv-4-169m-pile",
    "author": "RWKV"
  },
  {
    "T": "\ud83d\udd36",
    "model": "distilgpt2-emailgen-V2",
    "average": 28.64,
    "arc": 20.99,
    "hellaswag": 26.78,
    "mmlu": 25.53,
    "truthfulqa": 46.51,
    "winogrande": 52.01,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.09,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "9750ba00e79a02e1bf98d3faa3d49b8ae0f8ae63",
    "model_name_for_query": "postbot/distilgpt2-emailgen-V2",
    "link": "https://huggingface.co/postbot/distilgpt2-emailgen-V2",
    "author": "postbot"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-31m-simplewiki-scratch-bf16",
    "average": 28.61,
    "arc": 22.78,
    "hellaswag": 25.61,
    "mmlu": 23.12,
    "truthfulqa": 49.65,
    "winogrande": 50.51,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.03,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4eaec0542e7609fd3f364cb34491f05d7c61a3d0",
    "model_name_for_query": "pszemraj/pythia-31m-simplewiki-scratch-bf16",
    "link": "https://huggingface.co/pszemraj/pythia-31m-simplewiki-scratch-bf16",
    "author": "pszemraj"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-31m-simplepile-lite-2048-scratch-2e",
    "average": 28.6,
    "arc": 21.59,
    "hellaswag": 25.79,
    "mmlu": 24.99,
    "truthfulqa": 50.62,
    "winogrande": 48.62,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.03,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "91f011eb99502e667ebc2803f354ce5f5209ccf1",
    "model_name_for_query": "pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e",
    "link": "https://huggingface.co/pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e",
    "author": "pszemraj"
  },
  {
    "T": "\u2b55",
    "model": "gpt2_open-platypus",
    "average": 28.58,
    "arc": 22.18,
    "hellaswag": 31.29,
    "mmlu": 26.19,
    "truthfulqa": 40.35,
    "winogrande": 51.3,
    "gsm8k": 0.15,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "745c1864b752525789cad2b75166c519a327325e",
    "model_name_for_query": "lgaalves/gpt2_open-platypus",
    "link": "https://huggingface.co/lgaalves/gpt2_open-platypus",
    "author": "lgaalves"
  },
  {
    "T": "\u2b55",
    "model": "KoAlpaca-KoRWKV-6B",
    "average": 28.57,
    "arc": 23.46,
    "hellaswag": 31.65,
    "mmlu": 24.89,
    "truthfulqa": 39.83,
    "winogrande": 51.62,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.53,
    "likes": 7.0,
    "still_on_hub": true,
    "revision": "427ee72c4350f26de1b287a0c07b842e7d168dbc",
    "model_name_for_query": "beomi/KoAlpaca-KoRWKV-6B",
    "link": "https://huggingface.co/beomi/KoAlpaca-KoRWKV-6B",
    "author": "beomi"
  },
  {
    "T": "\ud83d\udd36",
    "model": "RWKV-4-PilePlus-169M-20230520-done-ctx4096",
    "average": 28.57,
    "arc": 23.98,
    "hellaswag": 32.25,
    "mmlu": 23.37,
    "truthfulqa": 42.29,
    "winogrande": 49.17,
    "gsm8k": 0.38,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.13,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1134d31db1aee9fc970d3e9dc4e7314fb8bba500",
    "model_name_for_query": "KnutJaegersberg/RWKV-4-PilePlus-169M-20230520-done-ctx4096",
    "link": "https://huggingface.co/KnutJaegersberg/RWKV-4-PilePlus-169M-20230520-done-ctx4096",
    "author": "KnutJaegersberg"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama2_7b_small_tuning_v1",
    "average": 28.56,
    "arc": 22.44,
    "hellaswag": 25.0,
    "mmlu": 25.51,
    "truthfulqa": 48.7,
    "winogrande": 49.72,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 6.61,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "3f9b43b4db2da4fe3785071dd52c9fc92aa0801d",
    "model_name_for_query": "yeen214/llama2_7b_small_tuning_v1",
    "link": "https://huggingface.co/yeen214/llama2_7b_small_tuning_v1",
    "author": "yeen214"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt2",
    "average": 28.55,
    "arc": 21.93,
    "hellaswag": 31.59,
    "mmlu": 25.84,
    "truthfulqa": 40.73,
    "winogrande": 50.51,
    "gsm8k": 0.68,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 1422.0,
    "still_on_hub": true,
    "revision": "11c5a3d5811f50298f278a704980280950aedb10",
    "model_name_for_query": "gpt2",
    "link": "https://huggingface.co/gpt2",
    "author": "gpt2"
  },
  {
    "T": "\ud83d\udd36",
    "model": "My_GPT2",
    "average": 28.55,
    "arc": 21.93,
    "hellaswag": 31.59,
    "mmlu": 25.84,
    "truthfulqa": 40.73,
    "winogrande": 50.51,
    "gsm8k": 0.68,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "4145e280b85ec619906dfc5a624e17cde8ffbea6",
    "model_name_for_query": "qiyinmiss/My_GPT2",
    "link": "https://huggingface.co/qiyinmiss/My_GPT2",
    "author": "qiyinmiss"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Quokka_590m",
    "average": 28.53,
    "arc": 24.4,
    "hellaswag": 31.61,
    "mmlu": 25.36,
    "truthfulqa": 39.59,
    "winogrande": 50.2,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.67,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ae0ac41e9be016f6dceac06821fbf6ebacc7edb9",
    "model_name_for_query": "Corianas/Quokka_590m",
    "link": "https://huggingface.co/Corianas/Quokka_590m",
    "author": "Corianas"
  },
  {
    "T": "\u2b55",
    "model": "gpt2_guanaco-dolly-platypus",
    "average": 28.52,
    "arc": 23.55,
    "hellaswag": 31.03,
    "mmlu": 26.4,
    "truthfulqa": 40.02,
    "winogrande": 50.12,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "6bf0a8146cf255c829ec2ad83926c8b80945b431",
    "model_name_for_query": "lgaalves/gpt2_guanaco-dolly-platypus",
    "link": "https://huggingface.co/lgaalves/gpt2_guanaco-dolly-platypus",
    "author": "lgaalves"
  },
  {
    "T": "\u2b55",
    "model": "gpt2_platypus-dolly-guanaco",
    "average": 28.51,
    "arc": 23.21,
    "hellaswag": 31.04,
    "mmlu": 26.16,
    "truthfulqa": 40.31,
    "winogrande": 50.36,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "bfa144d3eb087e54f1798fd2e2fb17e894cc39d3",
    "model_name_for_query": "lgaalves/gpt2_platypus-dolly-guanaco",
    "link": "https://huggingface.co/lgaalves/gpt2_platypus-dolly-guanaco",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt_bigcode-santacoder",
    "average": 28.49,
    "arc": 21.16,
    "hellaswag": 30.84,
    "mmlu": 24.97,
    "truthfulqa": 45.64,
    "winogrande": 47.83,
    "gsm8k": 0.53,
    "model_type": "pretrained",
    "architecture": "GPTBigCodeForCausalLM",
    "precision": "float16",
    "license": "openrail",
    "params": 1.12,
    "likes": 21.0,
    "still_on_hub": true,
    "revision": "291931872cae83498cf984b16319f47f5e9e7a07",
    "model_name_for_query": "bigcode/gpt_bigcode-santacoder",
    "link": "https://huggingface.co/bigcode/gpt_bigcode-santacoder",
    "author": "bigcode"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lamini-cerebras-256m",
    "average": 28.49,
    "arc": 21.76,
    "hellaswag": 28.7,
    "mmlu": 26.66,
    "truthfulqa": 41.81,
    "winogrande": 52.01,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.26,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "72df0b6d62d64002575687ea2edbb0df05712678",
    "model_name_for_query": "MBZUAI/lamini-cerebras-256m",
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-256m",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt-sw3-126m",
    "average": 28.49,
    "arc": 22.18,
    "hellaswag": 29.54,
    "mmlu": 24.43,
    "truthfulqa": 44.03,
    "winogrande": 50.67,
    "gsm8k": 0.08,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 0.19,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "9272f5a996cf785b8ab706a27d1e7dff1228dc70",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-126m",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-126m",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\ud83d\udd36",
    "model": "TinyStories-Alpaca",
    "average": 28.46,
    "arc": 23.98,
    "hellaswag": 24.92,
    "mmlu": 23.35,
    "truthfulqa": 46.68,
    "winogrande": 51.85,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.07,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "18e0bde7e72e477757832f0624a0410efc066216",
    "model_name_for_query": "blueapple8259/TinyStories-Alpaca",
    "link": "https://huggingface.co/blueapple8259/TinyStories-Alpaca",
    "author": "blueapple8259"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt-Youtube",
    "average": 28.46,
    "arc": 23.29,
    "hellaswag": 26.34,
    "mmlu": 23.54,
    "truthfulqa": 48.63,
    "winogrande": 48.93,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "de88554a0212c16fdfeda030afb58f831ebcd895",
    "model_name_for_query": "BreadAi/gpt-Youtube",
    "link": "https://huggingface.co/BreadAi/gpt-Youtube",
    "author": "BreadAi"
  },
  {
    "T": "?",
    "model": "Llama-Flan-XL2base",
    "average": 28.44,
    "arc": 20.65,
    "hellaswag": 25.33,
    "mmlu": 23.19,
    "truthfulqa": 50.58,
    "winogrande": 50.91,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 2.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "5ffcaeaf5645d96c3f04ed632a820590d3f87c6c",
    "model_name_for_query": "Sayan01/Llama-Flan-XL2base",
    "link": "https://huggingface.co/Sayan01/Llama-Flan-XL2base",
    "author": "Sayan01"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyStories-28M",
    "average": 28.44,
    "arc": 22.78,
    "hellaswag": 25.83,
    "mmlu": 23.53,
    "truthfulqa": 48.08,
    "winogrande": 50.43,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.05,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "52dabea9997faf578489d619249616926e54ed18",
    "model_name_for_query": "roneneldan/TinyStories-28M",
    "link": "https://huggingface.co/roneneldan/TinyStories-28M",
    "author": "roneneldan"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-70m-deduped",
    "average": 28.44,
    "arc": 21.08,
    "hellaswag": 27.17,
    "mmlu": 25.26,
    "truthfulqa": 47.51,
    "winogrande": 49.64,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.1,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "e93a9faa9c77e5d09219f6c868bfc7a1bd65593c",
    "model_name_for_query": "EleutherAI/pythia-70m-deduped",
    "link": "https://huggingface.co/EleutherAI/pythia-70m-deduped",
    "author": "EleutherAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "boomer-1b",
    "average": 28.44,
    "arc": 22.78,
    "hellaswag": 31.58,
    "mmlu": 25.66,
    "truthfulqa": 39.17,
    "winogrande": 50.51,
    "gsm8k": 0.91,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.94,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "f8f24b5480fa43f23d858f0eb8d1af1b7ad0af59",
    "model_name_for_query": "budecosystem/boomer-1b",
    "link": "https://huggingface.co/budecosystem/boomer-1b",
    "author": "budecosystem"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyStories-33M",
    "average": 28.41,
    "arc": 24.23,
    "hellaswag": 25.69,
    "mmlu": 23.82,
    "truthfulqa": 47.64,
    "winogrande": 49.09,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.07,
    "likes": 61.0,
    "still_on_hub": true,
    "revision": "190d22e37cba4b12ddae57d6738a0c65f6ab1aa5",
    "model_name_for_query": "roneneldan/TinyStories-33M",
    "link": "https://huggingface.co/roneneldan/TinyStories-33M",
    "author": "roneneldan"
  },
  {
    "T": "\u2b55",
    "model": "gpt2_platypus-camel_physics",
    "average": 28.41,
    "arc": 23.04,
    "hellaswag": 31.32,
    "mmlu": 26.91,
    "truthfulqa": 39.56,
    "winogrande": 49.64,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "66165ff32ed8de6c39f3524a810f5e97ba6d3347",
    "model_name_for_query": "lgaalves/gpt2_platypus-camel_physics",
    "link": "https://huggingface.co/lgaalves/gpt2_platypus-camel_physics",
    "author": "lgaalves"
  },
  {
    "T": "\u2b55",
    "model": "gpt2_camel_physics-platypus",
    "average": 28.41,
    "arc": 23.04,
    "hellaswag": 31.32,
    "mmlu": 26.91,
    "truthfulqa": 39.56,
    "winogrande": 49.64,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "66165ff32ed8de6c39f3524a810f5e97ba6d3347",
    "model_name_for_query": "lgaalves/gpt2_camel_physics-platypus",
    "link": "https://huggingface.co/lgaalves/gpt2_camel_physics-platypus",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt2_test",
    "average": 28.4,
    "arc": 21.84,
    "hellaswag": 31.6,
    "mmlu": 25.86,
    "truthfulqa": 40.67,
    "winogrande": 50.12,
    "gsm8k": 0.3,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ef61310a16ffda93bf8f6132e02658482ffc2bcc",
    "model_name_for_query": "SaylorTwift/gpt2_test",
    "link": "https://huggingface.co/SaylorTwift/gpt2_test",
    "author": "SaylorTwift"
  },
  {
    "T": "\ud83d\udd36",
    "model": "finetuned-gpt2-tiny",
    "average": 28.4,
    "arc": 21.84,
    "hellaswag": 31.6,
    "mmlu": 25.86,
    "truthfulqa": 40.67,
    "winogrande": 50.12,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "379e02101b4dccba48e7ae792708d2fe7f0bbca2",
    "model_name_for_query": "dpv/finetuned-gpt2-tiny",
    "link": "https://huggingface.co/dpv/finetuned-gpt2-tiny",
    "author": "dpv"
  },
  {
    "T": "\u2b55",
    "model": "gpt2_platypus-camel_physics",
    "average": 28.4,
    "arc": 22.78,
    "hellaswag": 31.24,
    "mmlu": 25.87,
    "truthfulqa": 38.95,
    "winogrande": 51.54,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "cd4d700d13b3bc9371bf45616ef74ac20d165c3d",
    "model_name_for_query": "behnamsh/gpt2_platypus-camel_physics",
    "link": "https://huggingface.co/behnamsh/gpt2_platypus-camel_physics",
    "author": "behnamsh"
  },
  {
    "T": "?",
    "model": "lamini-cerebras-590m",
    "average": 28.38,
    "arc": 24.32,
    "hellaswag": 31.58,
    "mmlu": 25.57,
    "truthfulqa": 40.72,
    "winogrande": 47.91,
    "gsm8k": 0.15,
    "model_type": "",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.59,
    "likes": 5.0,
    "still_on_hub": true,
    "revision": "bab37eb7ba63f6ff9f0eb36a85727146b82ae5ed",
    "model_name_for_query": "MBZUAI/lamini-cerebras-590m",
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-590m",
    "author": "MBZUAI"
  },
  {
    "T": "?",
    "model": "SGPT-1.3B-insurance-epoch10",
    "average": 28.37,
    "arc": 24.57,
    "hellaswag": 24.25,
    "mmlu": 25.23,
    "truthfulqa": 45.24,
    "winogrande": 50.91,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.27,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "df685c0bbf838f0627383c28f48e577ee901ba68",
    "model_name_for_query": "mncai/SGPT-1.3B-insurance-epoch10",
    "link": "https://huggingface.co/mncai/SGPT-1.3B-insurance-epoch10",
    "author": "mncai"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-alpaca-gpt4",
    "average": 28.34,
    "arc": 22.61,
    "hellaswag": 31.17,
    "mmlu": 25.76,
    "truthfulqa": 38.04,
    "winogrande": 52.17,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "282e9bd56f0cab5d48e6954793647eecaa0871d9",
    "model_name_for_query": "vicgalle/gpt2-alpaca-gpt4",
    "link": "https://huggingface.co/vicgalle/gpt2-alpaca-gpt4",
    "author": "vicgalle"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Quokka_256m",
    "average": 28.32,
    "arc": 22.87,
    "hellaswag": 28.84,
    "mmlu": 26.48,
    "truthfulqa": 39.47,
    "winogrande": 52.25,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.32,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "d4e69f714d360d39979eb7b8cbc9decdb7190c88",
    "model_name_for_query": "Corianas/Quokka_256m",
    "link": "https://huggingface.co/Corianas/Quokka_256m",
    "author": "Corianas"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyStories-8M",
    "average": 28.31,
    "arc": 24.66,
    "hellaswag": 25.03,
    "mmlu": 23.33,
    "truthfulqa": 46.54,
    "winogrande": 50.28,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.02,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "8612e3b15c66ffa94eaa6ee0de5c96edd2d630af",
    "model_name_for_query": "roneneldan/TinyStories-8M",
    "link": "https://huggingface.co/roneneldan/TinyStories-8M",
    "author": "roneneldan"
  },
  {
    "T": "\u2b55",
    "model": "GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
    "average": 28.3,
    "arc": 24.57,
    "hellaswag": 29.43,
    "mmlu": 25.82,
    "truthfulqa": 38.84,
    "winogrande": 49.01,
    "gsm8k": 2.12,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "e12dbd27ee148ce4af6faf742aa936d38c26536f",
    "model_name_for_query": "xzuyn/GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
    "link": "https://huggingface.co/xzuyn/GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
    "author": "xzuyn"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-31m",
    "average": 28.3,
    "arc": 19.97,
    "hellaswag": 26.34,
    "mmlu": 24.27,
    "truthfulqa": 50.12,
    "winogrande": 49.09,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.03,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "8a3c2f1555de8a3c53d67d73b5d0d53a66a6c6c2",
    "model_name_for_query": "ethzanalytics/pythia-31m",
    "link": "https://huggingface.co/ethzanalytics/pythia-31m",
    "author": "ethzanalytics"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v2-124m",
    "average": 28.3,
    "arc": 23.98,
    "hellaswag": 31.1,
    "mmlu": 25.29,
    "truthfulqa": 38.98,
    "winogrande": 50.43,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.12,
    "likes": 4.0,
    "still_on_hub": true,
    "revision": "bc719f990748ea72be4b6c270df34fc3d37291dc",
    "model_name_for_query": "aisquared/dlite-v2-124m",
    "link": "https://huggingface.co/aisquared/dlite-v2-124m",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gladosystem",
    "average": 28.29,
    "arc": 24.4,
    "hellaswag": 29.71,
    "mmlu": 23.18,
    "truthfulqa": 41.78,
    "winogrande": 50.67,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "02a1bbcee7b584ace743b2fe4885cc0eaf2179ac",
    "model_name_for_query": "huggingtweets/gladosystem",
    "link": "https://huggingface.co/huggingtweets/gladosystem",
    "author": "huggingtweets"
  },
  {
    "T": "\ud83d\udd36",
    "model": "lamini-cerebras-111m",
    "average": 28.29,
    "arc": 22.1,
    "hellaswag": 27.12,
    "mmlu": 25.51,
    "truthfulqa": 43.79,
    "winogrande": 51.22,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.11,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "e8e347b02f9305e4bc144eb9be2821c518d43183",
    "model_name_for_query": "MBZUAI/lamini-cerebras-111m",
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-111m",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt2",
    "average": 28.28,
    "arc": 21.59,
    "hellaswag": 31.58,
    "mmlu": 25.4,
    "truthfulqa": 41.15,
    "winogrande": 49.57,
    "gsm8k": 0.38,
    "model_type": "pretrained",
    "architecture": "GPT2LMHeadModel",
    "precision": "8bit",
    "license": "mit",
    "params": 0.14,
    "likes": 1504.0,
    "still_on_hub": true,
    "revision": "11c5a3d5811f50298f278a704980280950aedb10",
    "model_name_for_query": "gpt2",
    "link": "https://huggingface.co/gpt2",
    "author": "gpt2"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "pythia-31m-simplewiki-2048",
    "average": 28.27,
    "arc": 22.18,
    "hellaswag": 25.55,
    "mmlu": 23.12,
    "truthfulqa": 49.37,
    "winogrande": 49.41,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.03,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "95d47818055661250b55144c7d9beaf05dc126d8",
    "model_name_for_query": "pszemraj/pythia-31m-simplewiki-2048",
    "link": "https://huggingface.co/pszemraj/pythia-31m-simplewiki-2048",
    "author": "pszemraj"
  },
  {
    "T": "\ud83d\udd36",
    "model": "open-calm-7b",
    "average": 28.21,
    "arc": 20.48,
    "hellaswag": 30.65,
    "mmlu": 25.22,
    "truthfulqa": 44.15,
    "winogrande": 48.54,
    "gsm8k": 0.23,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-sa-4.0",
    "params": 6.66,
    "likes": 188.0,
    "still_on_hub": true,
    "revision": "276a5fb67510554e11ef191a2da44c919acccdf5",
    "model_name_for_query": "cyberagent/open-calm-7b",
    "link": "https://huggingface.co/cyberagent/open-calm-7b",
    "author": "cyberagent"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2023",
    "average": 28.2,
    "arc": 21.93,
    "hellaswag": 31.11,
    "mmlu": 25.05,
    "truthfulqa": 40.71,
    "winogrande": 50.12,
    "gsm8k": 0.3,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "e3620b53d164529575db66d9d4f4382311dd713c",
    "model_name_for_query": "crumb/gpt2023",
    "link": "https://huggingface.co/crumb/gpt2023",
    "author": "crumb"
  },
  {
    "T": "\u2b55",
    "model": "gpt-sw3-126m-instruct",
    "average": 28.2,
    "arc": 23.38,
    "hellaswag": 29.88,
    "mmlu": 23.78,
    "truthfulqa": 42.65,
    "winogrande": 48.54,
    "gsm8k": 0.99,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "other",
    "params": 0.19,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "5f353e1eb1b579ef62e10302b7c0bb843ee8eba9",
    "model_name_for_query": "AI-Sweden-Models/gpt-sw3-126m-instruct",
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-126m-instruct",
    "author": "AI-Sweden-Models"
  },
  {
    "T": "\u2b55",
    "model": "TinyMistral-248M-SFT-v4",
    "average": 28.2,
    "arc": 24.91,
    "hellaswag": 28.15,
    "mmlu": 26.04,
    "truthfulqa": 39.56,
    "winogrande": 50.51,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.25,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "ec0ff201527cd9b50eb9b4fc754d6c08f1242ea1",
    "model_name_for_query": "Felladrin/TinyMistral-248M-SFT-v4",
    "link": "https://huggingface.co/Felladrin/TinyMistral-248M-SFT-v4",
    "author": "Felladrin"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "KoRWKV-6B",
    "average": 28.19,
    "arc": 22.1,
    "hellaswag": 32.18,
    "mmlu": 24.69,
    "truthfulqa": 39.05,
    "winogrande": 51.14,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "RwkvForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 6.53,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "541600070459baf0f1be9560181d5ceb77794085",
    "model_name_for_query": "beomi/KoRWKV-6B",
    "link": "https://huggingface.co/beomi/KoRWKV-6B",
    "author": "beomi"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyStories-3M",
    "average": 28.19,
    "arc": 22.01,
    "hellaswag": 25.58,
    "mmlu": 24.99,
    "truthfulqa": 47.33,
    "winogrande": 49.25,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "GPTNeoForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 0.01,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "cfaf26ec85ecdfc1bd7c2638104cce55cb67f894",
    "model_name_for_query": "roneneldan/TinyStories-3M",
    "link": "https://huggingface.co/roneneldan/TinyStories-3M",
    "author": "roneneldan"
  },
  {
    "T": "\u2b55",
    "model": "TinyMistral-248M-Instruct",
    "average": 28.19,
    "arc": 24.32,
    "hellaswag": 27.52,
    "mmlu": 25.18,
    "truthfulqa": 41.94,
    "winogrande": 50.2,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.25,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "32a9317176bd8562bbb6497eef43a95f2c0261c3",
    "model_name_for_query": "Locutusque/TinyMistral-248M-Instruct",
    "link": "https://huggingface.co/Locutusque/TinyMistral-248M-Instruct",
    "author": "Locutusque"
  },
  {
    "T": "\ud83d\udd36",
    "model": "distilgpt2-HC3",
    "average": 28.18,
    "arc": 24.66,
    "hellaswag": 27.99,
    "mmlu": 23.95,
    "truthfulqa": 42.1,
    "winogrande": 50.36,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.09,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "6f9ad473a3793d0271df34a55882ad30846a6788",
    "model_name_for_query": "pszemraj/distilgpt2-HC3",
    "link": "https://huggingface.co/pszemraj/distilgpt2-HC3",
    "author": "pszemraj"
  },
  {
    "T": "\u2b55",
    "model": "gpt2-dolly",
    "average": 28.18,
    "arc": 21.76,
    "hellaswag": 30.77,
    "mmlu": 24.66,
    "truthfulqa": 42.22,
    "winogrande": 49.57,
    "gsm8k": 0.08,
    "model_type": "instruction-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "52fcf61a8eef255a981be6efde187481086e1a48",
    "model_name_for_query": "lgaalves/gpt2-dolly",
    "link": "https://huggingface.co/lgaalves/gpt2-dolly",
    "author": "lgaalves"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "smol_llama-81M-tied",
    "average": 28.17,
    "arc": 22.18,
    "hellaswag": 29.33,
    "mmlu": 24.06,
    "truthfulqa": 43.97,
    "winogrande": 49.25,
    "gsm8k": 0.23,
    "model_type": "pretrained",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 0.08,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "096e543bd36d067a819ea867c66f14d946849053",
    "model_name_for_query": "BEE-spoke-data/smol_llama-81M-tied",
    "link": "https://huggingface.co/BEE-spoke-data/smol_llama-81M-tied",
    "author": "BEE-spoke-data"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LaMini-GPT-124M",
    "average": 28.01,
    "arc": 24.32,
    "hellaswag": 30.82,
    "mmlu": 24.99,
    "truthfulqa": 36.57,
    "winogrande": 51.38,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 0.12,
    "likes": 14.0,
    "still_on_hub": true,
    "revision": "5c67c8c03c08e82d6138ce2a1eddf5317fac3a6b",
    "model_name_for_query": "MBZUAI/LaMini-GPT-124M",
    "link": "https://huggingface.co/MBZUAI/LaMini-GPT-124M",
    "author": "MBZUAI"
  },
  {
    "T": "\ud83d\udd36",
    "model": "LocutusqueXFelladrin-TinyMistral248M-Instruct",
    "average": 27.98,
    "arc": 24.74,
    "hellaswag": 27.79,
    "mmlu": 26.12,
    "truthfulqa": 40.12,
    "winogrande": 49.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.25,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "646fc1eaf46fcd7f1f9141da8a259715ff7528be",
    "model_name_for_query": "Locutusque/LocutusqueXFelladrin-TinyMistral248M-Instruct",
    "link": "https://huggingface.co/Locutusque/LocutusqueXFelladrin-TinyMistral248M-Instruct",
    "author": "Locutusque"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "gpt3-finnish-small",
    "average": 27.95,
    "arc": 20.48,
    "hellaswag": 28.09,
    "mmlu": 24.47,
    "truthfulqa": 46.47,
    "winogrande": 48.22,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "BloomModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.19,
    "likes": 9.0,
    "still_on_hub": true,
    "revision": "20a19af481bf59f38610a2977b2b513e9df51e3a",
    "model_name_for_query": "TurkuNLP/gpt3-finnish-small",
    "link": "https://huggingface.co/TurkuNLP/gpt3-finnish-small",
    "author": "TurkuNLP"
  },
  {
    "T": "\ud83d\udd36",
    "model": "xuanxuan",
    "average": 27.88,
    "arc": 23.46,
    "hellaswag": 31.12,
    "mmlu": 26.27,
    "truthfulqa": 35.97,
    "winogrande": 50.43,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "ba6ae2b347bc613ae38980e059ec8c5ec8b26038",
    "model_name_for_query": "Mikivis/xuanxuan",
    "link": "https://huggingface.co/Mikivis/xuanxuan",
    "author": "Mikivis"
  },
  {
    "T": "\ud83d\udd36",
    "model": "gpt2-alpaca",
    "average": 27.86,
    "arc": 22.87,
    "hellaswag": 31.14,
    "mmlu": 26.26,
    "truthfulqa": 36.22,
    "winogrande": 50.67,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "mit",
    "params": 0.14,
    "likes": 8.0,
    "still_on_hub": true,
    "revision": "e06875a588f7b3386c18a6efdc8cc7583d95b21b",
    "model_name_for_query": "vicgalle/gpt2-alpaca",
    "link": "https://huggingface.co/vicgalle/gpt2-alpaca",
    "author": "vicgalle"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dlite-v1-124m",
    "average": 27.86,
    "arc": 24.32,
    "hellaswag": 31.16,
    "mmlu": 25.08,
    "truthfulqa": 36.38,
    "winogrande": 50.2,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.12,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f6fd5f3960f31881e6cee23f5a872ecc80b40283",
    "model_name_for_query": "aisquared/dlite-v1-124m",
    "link": "https://huggingface.co/aisquared/dlite-v1-124m",
    "author": "aisquared"
  },
  {
    "T": "\ud83d\udd36",
    "model": "kogpt",
    "average": 27.83,
    "arc": 21.16,
    "hellaswag": 28.11,
    "mmlu": 26.56,
    "truthfulqa": 42.06,
    "winogrande": 49.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.39,
    "likes": 3.0,
    "still_on_hub": true,
    "revision": "4c02d48f548103ba53a5e481b8aa81bf7a259287",
    "model_name_for_query": "psyche/kogpt",
    "link": "https://huggingface.co/psyche/kogpt",
    "author": "psyche"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Cerebras-GPT-111M",
    "average": 27.75,
    "arc": 20.22,
    "hellaswag": 26.73,
    "mmlu": 25.51,
    "truthfulqa": 46.31,
    "winogrande": 47.75,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.11,
    "likes": 62.0,
    "still_on_hub": true,
    "revision": "d2b54d7af419055f204690fe0385959616a1723e",
    "model_name_for_query": "cerebras/Cerebras-GPT-111M",
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-111M",
    "author": "cerebras"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "TinyMistral-248m",
    "average": 27.73,
    "arc": 22.87,
    "hellaswag": 28.02,
    "mmlu": 23.15,
    "truthfulqa": 42.52,
    "winogrande": 49.8,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.25,
    "likes": 6.0,
    "still_on_hub": true,
    "revision": "8f03f72bca0542aa164c29ba41f02cba6f9d7748",
    "model_name_for_query": "Locutusque/TinyMistral-248m",
    "link": "https://huggingface.co/Locutusque/TinyMistral-248m",
    "author": "Locutusque"
  },
  {
    "T": "\ud83d\udd36",
    "model": "testmodel",
    "average": 27.6,
    "arc": 19.71,
    "hellaswag": 26.68,
    "mmlu": 25.28,
    "truthfulqa": 43.72,
    "winogrande": 50.2,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 0.15,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "1ac5d244402e2433b6abfcff1fe65e84af15766b",
    "model_name_for_query": "huashiyiqike/testmodel",
    "link": "https://huggingface.co/huashiyiqike/testmodel",
    "author": "huashiyiqike"
  },
  {
    "T": "\ud83d\udd36",
    "model": "111m",
    "average": 27.6,
    "arc": 19.71,
    "hellaswag": 26.68,
    "mmlu": 25.28,
    "truthfulqa": 43.72,
    "winogrande": 50.2,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "cc-by-nc-sa-4.0",
    "params": 0.15,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "ee58d79e27f8b9e3984aab29235c5851d2be01d4",
    "model_name_for_query": "Corianas/111m",
    "link": "https://huggingface.co/Corianas/111m",
    "author": "Corianas"
  },
  {
    "T": "\u2b55",
    "model": "TinyMistral-248M-SFT-v3",
    "average": 27.45,
    "arc": 21.93,
    "hellaswag": 28.26,
    "mmlu": 22.91,
    "truthfulqa": 40.03,
    "winogrande": 51.54,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.25,
    "likes": 12.0,
    "still_on_hub": true,
    "revision": "7a4787dfed21a432924d24575e6c65a97e1dd98a",
    "model_name_for_query": "Felladrin/TinyMistral-248M-SFT-v3",
    "link": "https://huggingface.co/Felladrin/TinyMistral-248M-SFT-v3",
    "author": "Felladrin"
  },
  {
    "T": "\ud83d\udd36",
    "model": "dolly-v2-3b",
    "average": 22.83,
    "arc": 25.26,
    "hellaswag": 26.55,
    "mmlu": 24.7,
    "truthfulqa": 0.0,
    "winogrande": 59.43,
    "gsm8k": 1.06,
    "model_type": "fine-tuned",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 2.65,
    "likes": 232.0,
    "still_on_hub": true,
    "revision": "f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df",
    "model_name_for_query": "databricks/dolly-v2-3b",
    "link": "https://huggingface.co/databricks/dolly-v2-3b",
    "author": "databricks"
  },
  {
    "T": "\ud83d\udd36",
    "model": "v1olet_marcoroni-go-bruins-7B",
    "average": 22.43,
    "arc": 29.1,
    "hellaswag": 28.3,
    "mmlu": 25.09,
    "truthfulqa": 0.0,
    "winogrande": 52.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "05868b30f81600b703a1029c4806683f7f5a89fc",
    "model_name_for_query": "v1olet/v1olet_marcoroni-go-bruins-7B",
    "link": "https://huggingface.co/v1olet/v1olet_marcoroni-go-bruins-7B",
    "author": "v1olet"
  },
  {
    "T": "\u2b55",
    "model": "v1olet_mistral_7B",
    "average": 22.16,
    "arc": 29.18,
    "hellaswag": 28.13,
    "mmlu": 26.24,
    "truthfulqa": 0.0,
    "winogrande": 49.41,
    "gsm8k": 0.0,
    "model_type": "instruction-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": false,
    "revision": "aaf2184ac642ce0171d2703bdb3db8fde855e4c9",
    "model_name_for_query": "v1olet/v1olet_mistral_7B",
    "link": "https://huggingface.co/v1olet/v1olet_mistral_7B",
    "author": "v1olet"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "Facebook_opt_1.3b_Quantized",
    "average": 21.78,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 59.67,
    "gsm8k": 0.15,
    "model_type": "pretrained",
    "architecture": "OPTForCausalLM",
    "precision": "float16",
    "license": "mit",
    "params": 1.32,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "7ef72ccee9d91d06967809e4e63ffbef62a9ad4a",
    "model_name_for_query": "FabbriSimo01/Facebook_opt_1.3b_Quantized",
    "link": "https://huggingface.co/FabbriSimo01/Facebook_opt_1.3b_Quantized",
    "author": "FabbriSimo01"
  },
  {
    "T": "\ud83d\udd36",
    "model": "mistral-class-bio-tutor",
    "average": 21.59,
    "arc": 28.07,
    "hellaswag": 28.02,
    "mmlu": 23.79,
    "truthfulqa": 0.0,
    "winogrande": 49.64,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "MistralModel",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 7.11,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "c0e782c571209e1238e3a3170dcd187f9a436df2",
    "model_name_for_query": "KevinNi/mistral-class-bio-tutor",
    "link": "https://huggingface.co/KevinNi/mistral-class-bio-tutor",
    "author": "KevinNi"
  },
  {
    "T": "?",
    "model": "bloom-560m-finetuned-fraud",
    "average": 21.37,
    "arc": 26.96,
    "hellaswag": 28.87,
    "mmlu": 24.03,
    "truthfulqa": 0.0,
    "winogrande": 48.38,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "bigscience-bloom-rail-1.0",
    "params": 0.56,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "5571f87f557b909e863005c6e3870bc2e77341a7",
    "model_name_for_query": "jslin09/bloom-560m-finetuned-fraud",
    "link": "https://huggingface.co/jslin09/bloom-560m-finetuned-fraud",
    "author": "jslin09"
  },
  {
    "T": "\ud83d\udd36",
    "model": "OpenOrca-AYT-13B",
    "average": 21.35,
    "arc": 27.22,
    "hellaswag": 26.03,
    "mmlu": 25.11,
    "truthfulqa": 0.0,
    "winogrande": 49.72,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "bfloat16",
    "license": "llama2",
    "params": 13.02,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "1357abceda30e8389007a023907824cc3a11e397",
    "model_name_for_query": "ahnyeonchan/OpenOrca-AYT-13B",
    "link": "https://huggingface.co/ahnyeonchan/OpenOrca-AYT-13B",
    "author": "ahnyeonchan"
  },
  {
    "T": "?",
    "model": "YetAnother_Open-Llama-3B-LoRA",
    "average": 21.29,
    "arc": 25.94,
    "hellaswag": 25.76,
    "mmlu": 24.65,
    "truthfulqa": 0.0,
    "winogrande": 51.38,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "52c5cb0178831908ed0571f1750fcb0f0fb125f9",
    "model_name_for_query": "Andron00e/YetAnother_Open-Llama-3B-LoRA",
    "link": "https://huggingface.co/Andron00e/YetAnother_Open-Llama-3B-LoRA",
    "author": "Andron00e"
  },
  {
    "T": "\ud83d\udd36",
    "model": "YetAnother_Open-Llama-3B-LoRA-OpenOrca",
    "average": 21.2,
    "arc": 25.94,
    "hellaswag": 25.76,
    "mmlu": 24.65,
    "truthfulqa": 0.0,
    "winogrande": 50.83,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 3.43,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "07d9d32cd091148295d4e13802ba63486599aff4",
    "model_name_for_query": "Andron00e/YetAnother_Open-Llama-3B-LoRA-OpenOrca",
    "link": "https://huggingface.co/Andron00e/YetAnother_Open-Llama-3B-LoRA-OpenOrca",
    "author": "Andron00e"
  },
  {
    "T": "?",
    "model": "Dante-2.8B",
    "average": 21.12,
    "arc": 25.09,
    "hellaswag": 26.05,
    "mmlu": 24.51,
    "truthfulqa": 0.0,
    "winogrande": 51.07,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "GPTNeoXForCausalLM",
    "precision": "float16",
    "license": "cc-by-nc-4.0",
    "params": 2.65,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "fb2a8f95c0286f957c830af640fd5c989081e8e4",
    "model_name_for_query": "Dampish/Dante-2.8B",
    "link": "https://huggingface.co/Dampish/Dante-2.8B",
    "author": "Dampish"
  },
  {
    "T": "\ud83d\udd36",
    "model": "MuseCan",
    "average": 21.06,
    "arc": 28.07,
    "hellaswag": 25.0,
    "mmlu": 24.19,
    "truthfulqa": 0.0,
    "winogrande": 49.09,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "GPT2LMHeadModel",
    "precision": "float16",
    "license": "?",
    "params": 0.07,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "f441866d78feaead3dede6efd9e23990bb74c21e",
    "model_name_for_query": "BreadAi/MuseCan",
    "link": "https://huggingface.co/BreadAi/MuseCan",
    "author": "BreadAi"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "mptk-1b",
    "average": 20.84,
    "arc": 22.7,
    "hellaswag": 25.48,
    "mmlu": 27.11,
    "truthfulqa": 0.0,
    "winogrande": 49.72,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "MptForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 1.31,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "aea467410ae0cead4fded6b98a3575e92b22862f",
    "model_name_for_query": "team-lucid/mptk-1b",
    "link": "https://huggingface.co/team-lucid/mptk-1b",
    "author": "team-lucid"
  },
  {
    "T": "\ud83d\udfe6",
    "model": "bloom-1b1-RLHF-v2",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "RL-tuned",
    "architecture": "BloomForCausalLM",
    "precision": "float16",
    "license": "?",
    "params": 1.06,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "05f7f0fd82fb3a5798d4bb284b6c10dd9d380f22",
    "model_name_for_query": "TheTravellingEngineer/bloom-1b1-RLHF-v2",
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-1b1-RLHF-v2",
    "author": "TheTravellingEngineer"
  },
  {
    "T": "\ud83d\udd36",
    "model": "panda-coder-13B",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "4bit",
    "license": "apache-2.0",
    "params": 12.85,
    "likes": 2.0,
    "still_on_hub": true,
    "revision": "823a8320224cdac88e927aee00338ffa79395faa",
    "model_name_for_query": "aiplanet/panda-coder-13B",
    "link": "https://huggingface.co/aiplanet/panda-coder-13B",
    "author": "aiplanet"
  },
  {
    "T": "\ud83d\udd36",
    "model": "caigun-lora-model-33B",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "8bit",
    "license": "cc-by-nc-nd-4.0",
    "params": 18.25,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "43789c7afafa495cbcb75185c8f48b11488c0408",
    "model_name_for_query": "APMIC/caigun-lora-model-33B",
    "link": "https://huggingface.co/APMIC/caigun-lora-model-33B",
    "author": "APMIC"
  },
  {
    "T": "\ud83d\udd36",
    "model": "Llama-2-ft-instruct-es",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "LlamaForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 6.61,
    "likes": 16.0,
    "still_on_hub": true,
    "revision": "42f07d6a86fac5574febb7b8fa13c3b1e14fcebd",
    "model_name_for_query": "clibrain/Llama-2-ft-instruct-es",
    "link": "https://huggingface.co/clibrain/Llama-2-ft-instruct-es",
    "author": "clibrain"
  },
  {
    "T": "\ud83d\udd36",
    "model": "llama-2-13b-dolphin-peft",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "?",
    "precision": "float16",
    "license": "llama2",
    "params": 13.0,
    "likes": 10.0,
    "still_on_hub": false,
    "revision": "5d17f6b5f394f0745bd4377c8a1290c68051e351",
    "model_name_for_query": "dfurman/llama-2-13b-dolphin-peft",
    "link": "https://huggingface.co/dfurman/llama-2-13b-dolphin-peft",
    "author": "dfurman"
  },
  {
    "T": "\ud83d\udd36",
    "model": "speechless-mistral-six-in-one-7b-orth-1.0",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "fine-tuned",
    "architecture": "MistralForCausalLM",
    "precision": "bfloat16",
    "license": "apache-2.0",
    "params": 7.0,
    "likes": 0.0,
    "still_on_hub": true,
    "revision": "e500285ba420cb3865d72aa0cc3b1fb9cc0bfee8",
    "model_name_for_query": "uukuguy/speechless-mistral-six-in-one-7b-orth-1.0",
    "link": "https://huggingface.co/uukuguy/speechless-mistral-six-in-one-7b-orth-1.0",
    "author": "uukuguy"
  },
  {
    "T": "?",
    "model": "Panther_v1",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "",
    "architecture": "?",
    "precision": "float16",
    "license": "other",
    "params": 6.61,
    "likes": 1.0,
    "still_on_hub": false,
    "revision": "",
    "model_name_for_query": "Rardilit/Panther_v1",
    "link": "https://huggingface.co/Rardilit/Panther_v1",
    "author": "Rardilit"
  },
  {
    "T": "\ud83d\udfe2",
    "model": "mpt-125m-c4",
    "average": 20.07,
    "arc": 22.7,
    "hellaswag": 25.04,
    "mmlu": 23.12,
    "truthfulqa": 0.0,
    "winogrande": 49.57,
    "gsm8k": 0.0,
    "model_type": "pretrained",
    "architecture": "MPTForCausalLM",
    "precision": "float16",
    "license": "apache-2.0",
    "params": 0.12,
    "likes": 1.0,
    "still_on_hub": true,
    "revision": "55f8f1874aa8bf4fc28c0abc92c7fbd1271ff7d7",
    "model_name_for_query": "wtang06/mpt-125m-c4",
    "link": "https://huggingface.co/wtang06/mpt-125m-c4",
    "author": "wtang06"
  }
]
