[
  {
    "name": "go-bruins-v2.1.1",
    "author": "rwitz2",
    "query_name": "rwitz2/go-bruins-v2.1.1",
    "score": 74.95,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz2/go-bruins-v2.1.1",
    "still_on_hub": true
  },
  {
    "name": "quantum-dpo-v0.1",
    "author": "quantumaikr",
    "query_name": "quantumaikr/quantum-dpo-v0.1",
    "score": 74.87,
    "likes": 0.0,
    "link": "https://huggingface.co/quantumaikr/quantum-dpo-v0.1",
    "still_on_hub": true
  },
  {
    "name": "trinity-v1",
    "author": "janai-hq",
    "query_name": "janai-hq/trinity-v1",
    "score": 74.8,
    "likes": 0.0,
    "link": "https://huggingface.co/janai-hq/trinity-v1",
    "still_on_hub": true
  },
  {
    "name": "trinity-v1",
    "author": "jan-hq",
    "query_name": "jan-hq/trinity-v1",
    "score": 74.8,
    "likes": 2.0,
    "link": "https://huggingface.co/jan-hq/trinity-v1",
    "still_on_hub": true
  },
  {
    "name": "GreenNodeLM-v3olet-7B",
    "author": "GreenNode",
    "query_name": "GreenNode/GreenNodeLM-v3olet-7B",
    "score": 74.75,
    "likes": 0.0,
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-v3olet-7B",
    "still_on_hub": true
  },
  {
    "name": "LeoScorpius-GreenNode-Alpaca-7B-v1",
    "author": "ignos",
    "query_name": "ignos/LeoScorpius-GreenNode-Alpaca-7B-v1",
    "score": 74.74,
    "likes": 0.0,
    "link": "https://huggingface.co/ignos/LeoScorpius-GreenNode-Alpaca-7B-v1",
    "still_on_hub": true
  },
  {
    "name": "LeoScorpius-GreenNode-7B-v1",
    "author": "Toten5",
    "query_name": "Toten5/LeoScorpius-GreenNode-7B-v1",
    "score": 74.74,
    "likes": 0.0,
    "link": "https://huggingface.co/Toten5/LeoScorpius-GreenNode-7B-v1",
    "still_on_hub": false
  },
  {
    "name": "quantum-trinity-v0.1",
    "author": "quantumaikr",
    "query_name": "quantumaikr/quantum-trinity-v0.1",
    "score": 74.67,
    "likes": 0.0,
    "link": "https://huggingface.co/quantumaikr/quantum-trinity-v0.1",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-dpo-merge-v1.1",
    "author": "mncai",
    "query_name": "mncai/mistral-7b-dpo-merge-v1.1",
    "score": 74.53,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/mistral-7b-dpo-merge-v1.1",
    "still_on_hub": true
  },
  {
    "name": "go-bruins-v2.1",
    "author": "rwitz2",
    "query_name": "rwitz2/go-bruins-v2.1",
    "score": 74.5,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz2/go-bruins-v2.1",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-dpo-v6",
    "author": "mncai",
    "query_name": "mncai/mistral-7b-dpo-v6",
    "score": 74.5,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/mistral-7b-dpo-v6",
    "still_on_hub": true
  },
  {
    "name": "SOLAR-10.7B-Instruct-v1.0",
    "author": "upstage",
    "query_name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "score": 74.2,
    "likes": 0.0,
    "link": "https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0",
    "still_on_hub": true
  },
  {
    "name": "GreenNodeLM-7B-v4leo",
    "author": "GreenNode",
    "query_name": "GreenNode/GreenNodeLM-7B-v4leo",
    "score": 74.18,
    "likes": 0.0,
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-7B-v4leo",
    "still_on_hub": true
  },
  {
    "name": "una-xaberius-34b-v1beta has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/444\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #444</a>",
    "author": "fblgit",
    "query_name": "fblgit/una-xaberius-34b-v1beta",
    "score": 74.18,
    "likes": 0.0,
    "link": "https://huggingface.co/fblgit/una-xaberius-34b-v1beta",
    "still_on_hub": true
  },
  {
    "name": "una-cybertron-7b-v3-OMA",
    "author": "fblgit",
    "query_name": "fblgit/una-cybertron-7b-v3-OMA",
    "score": 74.01,
    "likes": 0.0,
    "link": "https://huggingface.co/fblgit/una-cybertron-7b-v3-OMA",
    "still_on_hub": true
  },
  {
    "name": "meow",
    "author": "rishiraj",
    "query_name": "rishiraj/meow",
    "score": 73.94,
    "likes": 1.0,
    "link": "https://huggingface.co/rishiraj/meow",
    "still_on_hub": true
  },
  {
    "name": "LeoScorpius-7B-Chat-DPO",
    "author": "viethq188",
    "query_name": "viethq188/LeoScorpius-7B-Chat-DPO",
    "score": 73.92,
    "likes": 0.0,
    "link": "https://huggingface.co/viethq188/LeoScorpius-7B-Chat-DPO",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-dpo-v5",
    "author": "mncai",
    "query_name": "mncai/mistral-7b-dpo-v5",
    "score": 73.87,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/mistral-7b-dpo-v5",
    "still_on_hub": true
  },
  {
    "name": "ShiningValiant",
    "author": "ValiantLabs",
    "query_name": "ValiantLabs/ShiningValiant",
    "score": 73.78,
    "likes": 63.0,
    "link": "https://huggingface.co/ValiantLabs/ShiningValiant",
    "still_on_hub": true
  },
  {
    "name": "SunsetBoulevard",
    "author": "sequelbox",
    "query_name": "sequelbox/SunsetBoulevard",
    "score": 73.78,
    "likes": 1.0,
    "link": "https://huggingface.co/sequelbox/SunsetBoulevard",
    "still_on_hub": true
  },
  {
    "name": "v1olet_merged_dpo_7B_v3",
    "author": "v1olet",
    "query_name": "v1olet/v1olet_merged_dpo_7B_v3",
    "score": 73.68,
    "likes": 0.0,
    "link": "https://huggingface.co/v1olet/v1olet_merged_dpo_7B_v3",
    "still_on_hub": true
  },
  {
    "name": "GreenNodeLM-7B-v1olet",
    "author": "GreenNode",
    "query_name": "GreenNode/GreenNodeLM-7B-v1olet",
    "score": 73.68,
    "likes": 3.0,
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-7B-v1olet",
    "still_on_hub": true
  },
  {
    "name": "Qwen-72B",
    "author": "Qwen",
    "query_name": "Qwen/Qwen-72B",
    "score": 73.6,
    "likes": 168.0,
    "link": "https://huggingface.co/Qwen/Qwen-72B",
    "still_on_hub": true
  },
  {
    "name": "BruinHermes",
    "author": "cookinai",
    "query_name": "cookinai/BruinHermes",
    "score": 73.42,
    "likes": 0.0,
    "link": "https://huggingface.co/cookinai/BruinHermes",
    "still_on_hub": true
  },
  {
    "name": "GreenNodeLM-7B-v2leo",
    "author": "GreenNode",
    "query_name": "GreenNode/GreenNodeLM-7B-v2leo",
    "score": 73.29,
    "likes": 0.0,
    "link": "https://huggingface.co/GreenNode/GreenNodeLM-7B-v2leo",
    "still_on_hub": false
  },
  {
    "name": "SUS-Chat-34B",
    "author": "SUSTech",
    "query_name": "SUSTech/SUS-Chat-34B",
    "score": 73.22,
    "likes": 51.0,
    "link": "https://huggingface.co/SUSTech/SUS-Chat-34B",
    "still_on_hub": true
  },
  {
    "name": "Pandora-10.7B-v1",
    "author": "jan-ai",
    "query_name": "jan-ai/Pandora-10.7B-v1",
    "score": 72.93,
    "likes": 0.0,
    "link": "https://huggingface.co/jan-ai/Pandora-10.7B-v1",
    "still_on_hub": true
  },
  {
    "name": "v1olet_marcoroni-go-bruins-merge-7B",
    "author": "v1olet",
    "query_name": "v1olet/v1olet_marcoroni-go-bruins-merge-7B",
    "score": 72.81,
    "likes": 0.0,
    "link": "https://huggingface.co/v1olet/v1olet_marcoroni-go-bruins-merge-7B",
    "still_on_hub": true
  },
  {
    "name": "Mixtral-8x7B-Instruct-v0.1",
    "author": "mistralai",
    "query_name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "score": 72.62,
    "likes": 383.0,
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "still_on_hub": true
  },
  {
    "name": "Marcoroni-7B-v3",
    "author": "AIDC-ai-business",
    "query_name": "AIDC-ai-business/Marcoroni-7B-v3",
    "score": 72.53,
    "likes": 0.0,
    "link": "https://huggingface.co/AIDC-ai-business/Marcoroni-7B-v3",
    "still_on_hub": true
  },
  {
    "name": "Marcoroni-v3-neural-chat-v3-3-Slerp",
    "author": "Toten5",
    "query_name": "Toten5/Marcoroni-v3-neural-chat-v3-3-Slerp",
    "score": 72.51,
    "likes": 0.0,
    "link": "https://huggingface.co/Toten5/Marcoroni-v3-neural-chat-v3-3-Slerp",
    "still_on_hub": true
  },
  {
    "name": "pee",
    "author": "rwitz2",
    "query_name": "rwitz2/pee",
    "score": 72.5,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz2/pee",
    "still_on_hub": true
  },
  {
    "name": "Marcoroni-neural-chat-7B-v2",
    "author": "Toten5",
    "query_name": "Toten5/Marcoroni-neural-chat-7B-v2",
    "score": 72.5,
    "likes": 1.0,
    "link": "https://huggingface.co/Toten5/Marcoroni-neural-chat-7B-v2",
    "still_on_hub": true
  },
  {
    "name": "Marcoroni-8x7B-v3-MoE",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Marcoroni-8x7B-v3-MoE",
    "score": 72.45,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Marcoroni-8x7B-v3-MoE",
    "still_on_hub": true
  },
  {
    "name": "mindy-7b",
    "author": "mindy-labs",
    "query_name": "mindy-labs/mindy-7b",
    "score": 72.34,
    "likes": 1.0,
    "link": "https://huggingface.co/mindy-labs/mindy-7b",
    "still_on_hub": true
  },
  {
    "name": "supermario-v2",
    "author": "janhq",
    "query_name": "janhq/supermario-v2",
    "score": 72.34,
    "likes": 0.0,
    "link": "https://huggingface.co/janhq/supermario-v2",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-deepseek-67b-v15.2",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-deepseek-67b-v15.2",
    "score": 72.33,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-deepseek-67b-v15.2",
    "still_on_hub": true
  },
  {
    "name": "supermario-slerp",
    "author": "janhq",
    "query_name": "janhq/supermario-slerp",
    "score": 72.32,
    "likes": 0.0,
    "link": "https://huggingface.co/janhq/supermario-slerp",
    "still_on_hub": true
  },
  {
    "name": "CatPPT",
    "author": "rishiraj",
    "query_name": "rishiraj/CatPPT",
    "score": 72.32,
    "likes": 0.0,
    "link": "https://huggingface.co/rishiraj/CatPPT",
    "still_on_hub": true
  },
  {
    "name": "Solar-10.7B-SLERP",
    "author": "jan-ai",
    "query_name": "jan-ai/Solar-10.7B-SLERP",
    "score": 72.31,
    "likes": 0.0,
    "link": "https://huggingface.co/jan-ai/Solar-10.7B-SLERP",
    "still_on_hub": true
  },
  {
    "name": "yi-34B-v3",
    "author": "mncai",
    "query_name": "mncai/yi-34B-v3",
    "score": 72.26,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/yi-34B-v3",
    "still_on_hub": true
  },
  {
    "name": "LeoScorpius-7B",
    "author": "viethq188",
    "query_name": "viethq188/LeoScorpius-7B",
    "score": 72.21,
    "likes": 0.0,
    "link": "https://huggingface.co/viethq188/LeoScorpius-7B",
    "still_on_hub": true
  },
  {
    "name": "grindin",
    "author": "rwitz2",
    "query_name": "rwitz2/grindin",
    "score": 72.18,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz2/grindin",
    "still_on_hub": false
  },
  {
    "name": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
    "author": "brucethemoose",
    "query_name": "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
    "score": 72.15,
    "likes": 0.0,
    "link": "https://huggingface.co/brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity",
    "still_on_hub": true
  },
  {
    "name": "yi-34B-v2",
    "author": "mncai",
    "query_name": "mncai/yi-34B-v2",
    "score": 72.12,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/yi-34B-v2",
    "still_on_hub": true
  },
  {
    "name": "72B-preview",
    "author": "CausalLM",
    "query_name": "CausalLM/72B-preview",
    "score": 72.12,
    "likes": 47.0,
    "link": "https://huggingface.co/CausalLM/72B-preview",
    "still_on_hub": true
  },
  {
    "name": "go-bruins-v2",
    "author": "rwitz",
    "query_name": "rwitz/go-bruins-v2",
    "score": 72.07,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz/go-bruins-v2",
    "still_on_hub": true
  },
  {
    "name": "72B-preview",
    "author": "CausalLM",
    "query_name": "CausalLM/72B-preview",
    "score": 72.06,
    "likes": 57.0,
    "link": "https://huggingface.co/CausalLM/72B-preview",
    "still_on_hub": true
  },
  {
    "name": "dec10",
    "author": "rwitz",
    "query_name": "rwitz/dec10",
    "score": 72.05,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz/dec10",
    "still_on_hub": true
  },
  {
    "name": "dec10",
    "author": "rwitz",
    "query_name": "rwitz/dec10",
    "score": 72.01,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz/dec10",
    "still_on_hub": true
  },
  {
    "name": "go-bruins-v2",
    "author": "rwitz",
    "query_name": "rwitz/go-bruins-v2",
    "score": 71.95,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz/go-bruins-v2",
    "still_on_hub": true
  },
  {
    "name": "COKAL-v1-70B",
    "author": "DopeorNope",
    "query_name": "DopeorNope/COKAL-v1-70B",
    "score": 71.87,
    "likes": 0.0,
    "link": "https://huggingface.co/DopeorNope/COKAL-v1-70B",
    "still_on_hub": true
  },
  {
    "name": "Seraph-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Seraph-7B",
    "score": 71.86,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Seraph-7B",
    "still_on_hub": true
  },
  {
    "name": "go-bruins",
    "author": "rwitz",
    "query_name": "rwitz/go-bruins",
    "score": 71.81,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz/go-bruins",
    "still_on_hub": true
  },
  {
    "name": "deepseek-llm-67b-chat",
    "author": "deepseek-ai",
    "query_name": "deepseek-ai/deepseek-llm-67b-chat",
    "score": 71.79,
    "likes": 58.0,
    "link": "https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat",
    "still_on_hub": true
  },
  {
    "name": "go-bruins",
    "author": "rwitz",
    "query_name": "rwitz/go-bruins",
    "score": 71.79,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz/go-bruins",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-deepseek-67b-v15.1",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-deepseek-67b-v15.1",
    "score": 71.76,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-deepseek-67b-v15.1",
    "still_on_hub": true
  },
  {
    "name": "Tess-M-Creative-v1.0",
    "author": "migtissera",
    "query_name": "migtissera/Tess-M-Creative-v1.0",
    "score": 71.73,
    "likes": 30.0,
    "link": "https://huggingface.co/migtissera/Tess-M-Creative-v1.0",
    "still_on_hub": true
  },
  {
    "name": "platypus-yi-34b",
    "author": "bhenrym14",
    "query_name": "bhenrym14/platypus-yi-34b",
    "score": 71.69,
    "likes": 0.0,
    "link": "https://huggingface.co/bhenrym14/platypus-yi-34b",
    "still_on_hub": true
  },
  {
    "name": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
    "author": "brucethemoose",
    "query_name": "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
    "score": 71.57,
    "likes": 0.0,
    "link": "https://huggingface.co/brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity",
    "still_on_hub": true
  },
  {
    "name": "Deacon-34b-qlora-adapter",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Deacon-34b-qlora-adapter",
    "score": 71.39,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/Deacon-34b-qlora-adapter",
    "still_on_hub": false
  },
  {
    "name": "OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "author": "PulsarAI",
    "query_name": "PulsarAI/OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "score": 71.38,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "still_on_hub": true
  },
  {
    "name": "DiscoLM-70b",
    "author": "DiscoResearch",
    "query_name": "DiscoResearch/DiscoLM-70b",
    "score": 71.37,
    "likes": 0.0,
    "link": "https://huggingface.co/DiscoResearch/DiscoLM-70b",
    "still_on_hub": true
  },
  {
    "name": "MoMo-70B-LoRA-V1.2_1",
    "author": "leejunhyeok",
    "query_name": "leejunhyeok/MoMo-70B-LoRA-V1.2_1",
    "score": 71.36,
    "likes": 0.0,
    "link": "https://huggingface.co/leejunhyeok/MoMo-70B-LoRA-V1.2_1",
    "still_on_hub": false
  },
  {
    "name": "supermario-slerp-v2",
    "author": "janhq",
    "query_name": "janhq/supermario-slerp-v2",
    "score": 71.35,
    "likes": 0.0,
    "link": "https://huggingface.co/janhq/supermario-slerp-v2",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-Cybertron-Starling",
    "author": "Q-bert",
    "query_name": "Q-bert/MetaMath-Cybertron-Starling",
    "score": 71.35,
    "likes": 1.0,
    "link": "https://huggingface.co/Q-bert/MetaMath-Cybertron-Starling",
    "still_on_hub": true
  },
  {
    "name": "CapyTessBorosYi-34B-200K-DARE-Ties",
    "author": "brucethemoose",
    "query_name": "brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties",
    "score": 71.31,
    "likes": 3.0,
    "link": "https://huggingface.co/brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties",
    "still_on_hub": true
  },
  {
    "name": "ipo-test",
    "author": "rwitz2",
    "query_name": "rwitz2/ipo-test",
    "score": 71.29,
    "likes": 0.0,
    "link": "https://huggingface.co/rwitz2/ipo-test",
    "still_on_hub": false
  },
  {
    "name": "MetaMath-Cybertron-Starling",
    "author": "Q-bert",
    "query_name": "Q-bert/MetaMath-Cybertron-Starling",
    "score": 71.25,
    "likes": 2.0,
    "link": "https://huggingface.co/Q-bert/MetaMath-Cybertron-Starling",
    "still_on_hub": true
  },
  {
    "name": "sheep-duck-llama-2-70b-v1.1",
    "author": "Riiid",
    "query_name": "Riiid/sheep-duck-llama-2-70b-v1.1",
    "score": 71.22,
    "likes": 17.0,
    "link": "https://huggingface.co/Riiid/sheep-duck-llama-2-70b-v1.1",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-3-Slerp",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3-3-Slerp",
    "score": 71.19,
    "likes": 1.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-3-Slerp",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-v3-3-8x7b-MoE",
    "author": "perlthoughts",
    "query_name": "perlthoughts/neural-chat-v3-3-8x7b-MoE",
    "score": 71.17,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/neural-chat-v3-3-8x7b-MoE",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-Llama-Q",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-Llama-Q",
    "score": 71.13,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q",
    "still_on_hub": true
  },
  {
    "name": "shark_tank_ai_7_b",
    "author": "NExtNewChattingAI",
    "query_name": "NExtNewChattingAI/shark_tank_ai_7_b",
    "score": 71.1,
    "likes": 0.0,
    "link": "https://huggingface.co/NExtNewChattingAI/shark_tank_ai_7_b",
    "still_on_hub": true
  },
  {
    "name": "Yi-34B-200K-AEZAKMI-v2",
    "author": "adamo1139",
    "query_name": "adamo1139/Yi-34B-200K-AEZAKMI-v2",
    "score": 71.0,
    "likes": 0.0,
    "link": "https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2",
    "still_on_hub": true
  },
  {
    "name": "Yi-34B-Llama",
    "author": "chargoddard",
    "query_name": "chargoddard/Yi-34B-Llama",
    "score": 70.95,
    "likes": 36.0,
    "link": "https://huggingface.co/chargoddard/Yi-34B-Llama",
    "still_on_hub": true
  },
  {
    "name": "Marcoroni-7B-v2",
    "author": "AIDC-ai-business",
    "query_name": "AIDC-ai-business/Marcoroni-7B-v2",
    "score": 70.92,
    "likes": 0.0,
    "link": "https://huggingface.co/AIDC-ai-business/Marcoroni-7B-v2",
    "still_on_hub": true
  },
  {
    "name": "Yi-34B-200K",
    "author": "01-ai",
    "query_name": "01-ai/Yi-34B-200K",
    "score": 70.81,
    "likes": 153.0,
    "link": "https://huggingface.co/01-ai/Yi-34B-200K",
    "still_on_hub": true
  },
  {
    "name": "Terminis-7B",
    "author": "Q-bert",
    "query_name": "Q-bert/Terminis-7B",
    "score": 70.73,
    "likes": 1.0,
    "link": "https://huggingface.co/Q-bert/Terminis-7B",
    "still_on_hub": true
  },
  {
    "name": "Nyxene-v3-11B",
    "author": "beberik",
    "query_name": "beberik/Nyxene-v3-11B",
    "score": 70.72,
    "likes": 0.0,
    "link": "https://huggingface.co/beberik/Nyxene-v3-11B",
    "still_on_hub": true
  },
  {
    "name": "una-neural-chat-v3-3-P2-OMA",
    "author": "one-man-army",
    "query_name": "one-man-army/una-neural-chat-v3-3-P2-OMA",
    "score": 70.72,
    "likes": 0.0,
    "link": "https://huggingface.co/one-man-army/una-neural-chat-v3-3-P2-OMA",
    "still_on_hub": true
  },
  {
    "name": "Merged-AGI-7B",
    "author": "Q-bert",
    "query_name": "Q-bert/Merged-AGI-7B",
    "score": 70.68,
    "likes": 0.0,
    "link": "https://huggingface.co/Q-bert/Merged-AGI-7B",
    "still_on_hub": true
  },
  {
    "name": "dolphin-2.2-70b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-2.2-70b",
    "score": 70.6,
    "likes": 23.0,
    "link": "https://huggingface.co/ehartford/dolphin-2.2-70b",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-Cybertron",
    "author": "Q-bert",
    "query_name": "Q-bert/MetaMath-Cybertron",
    "score": 70.6,
    "likes": 1.0,
    "link": "https://huggingface.co/Q-bert/MetaMath-Cybertron",
    "still_on_hub": true
  },
  {
    "name": "Capybara-Tess-Yi-34B-200K",
    "author": "brucethemoose",
    "query_name": "brucethemoose/Capybara-Tess-Yi-34B-200K",
    "score": 70.57,
    "likes": 0.0,
    "link": "https://huggingface.co/brucethemoose/Capybara-Tess-Yi-34B-200K",
    "still_on_hub": true
  },
  {
    "name": "una-neural-chat-v3-3-P2-OMA",
    "author": "one-man-army",
    "query_name": "one-man-army/una-neural-chat-v3-3-P2-OMA",
    "score": 70.55,
    "likes": 0.0,
    "link": "https://huggingface.co/one-man-army/una-neural-chat-v3-3-P2-OMA",
    "still_on_hub": true
  },
  {
    "name": "kaori-70b-v1",
    "author": "KaeriJenti",
    "query_name": "KaeriJenti/kaori-70b-v1",
    "score": 70.54,
    "likes": 0.0,
    "link": "https://huggingface.co/KaeriJenti/kaori-70b-v1",
    "still_on_hub": true
  },
  {
    "name": "Pallas-0.2",
    "author": "Mihaiii",
    "query_name": "Mihaiii/Pallas-0.2",
    "score": 70.51,
    "likes": 0.0,
    "link": "https://huggingface.co/Mihaiii/Pallas-0.2",
    "still_on_hub": true
  },
  {
    "name": "Pallas-0.2",
    "author": "Mihaiii",
    "query_name": "Mihaiii/Pallas-0.2",
    "score": 70.49,
    "likes": 0.0,
    "link": "https://huggingface.co/Mihaiii/Pallas-0.2",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-7B-v2.01",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-7B-v2.01",
    "score": 70.43,
    "likes": 1.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.01",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-8x7B-MoE",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-8x7B-MoE",
    "score": 70.4,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-8x7B-MoE",
    "still_on_hub": true
  },
  {
    "name": "Tulpar-7b-v2",
    "author": "HyperbeeAI",
    "query_name": "HyperbeeAI/Tulpar-7b-v2",
    "score": 70.36,
    "likes": 0.0,
    "link": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v2",
    "still_on_hub": true
  },
  {
    "name": "Falkor-7b",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Falkor-7b",
    "score": 70.33,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Falkor-7b",
    "still_on_hub": true
  },
  {
    "name": "una-neural-chat-v3-3-P1-OMA",
    "author": "one-man-army",
    "query_name": "one-man-army/una-neural-chat-v3-3-P1-OMA",
    "score": 70.32,
    "likes": 0.0,
    "link": "https://huggingface.co/one-man-army/una-neural-chat-v3-3-P1-OMA",
    "still_on_hub": false
  },
  {
    "name": "v1olet_merged_dpo_7B",
    "author": "v1olet",
    "query_name": "v1olet/v1olet_merged_dpo_7B",
    "score": 70.26,
    "likes": 0.0,
    "link": "https://huggingface.co/v1olet/v1olet_merged_dpo_7B",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-Chupacabra-7B-v2.01-Slerp",
    "author": "PulsarAI",
    "query_name": "PulsarAI/MetaMath-Chupacabra-7B-v2.01-Slerp",
    "score": 70.21,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/MetaMath-Chupacabra-7B-v2.01-Slerp",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-Tulpar-7b-v2-Slerp",
    "author": "PulsarAI",
    "query_name": "PulsarAI/MetaMath-Tulpar-7b-v2-Slerp",
    "score": 70.2,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/MetaMath-Tulpar-7b-v2-Slerp",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-2.5-neural-chat-v3-2-Slerp",
    "author": "PulsarAI",
    "query_name": "PulsarAI/OpenHermes-2.5-neural-chat-v3-2-Slerp",
    "score": 70.2,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/OpenHermes-2.5-neural-chat-v3-2-Slerp",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-Merge-14-v0",
    "author": "EmbeddedLLM",
    "query_name": "EmbeddedLLM/Mistral-7B-Merge-14-v0",
    "score": 70.17,
    "likes": 0.0,
    "link": "https://huggingface.co/EmbeddedLLM/Mistral-7B-Merge-14-v0",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "author": "PulsarAI",
    "query_name": "PulsarAI/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "score": 70.11,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp",
    "still_on_hub": true
  },
  {
    "name": "Tess-34B-v1.4",
    "author": "migtissera",
    "query_name": "migtissera/Tess-34B-v1.4",
    "score": 70.11,
    "likes": 0.0,
    "link": "https://huggingface.co/migtissera/Tess-34B-v1.4",
    "still_on_hub": true
  },
  {
    "name": "SOLAR-0-70b-16bit",
    "author": "upstage",
    "query_name": "upstage/SOLAR-0-70b-16bit",
    "score": 70.11,
    "likes": 214.0,
    "link": "https://huggingface.co/upstage/SOLAR-0-70b-16bit",
    "still_on_hub": true
  },
  {
    "name": "FashionGPT-70B-V1.1",
    "author": "ICBU-NPU",
    "query_name": "ICBU-NPU/FashionGPT-70B-V1.1",
    "score": 70.05,
    "likes": 38.0,
    "link": "https://huggingface.co/ICBU-NPU/FashionGPT-70B-V1.1",
    "still_on_hub": true
  },
  {
    "name": "BruinsV2-OpHermesNeu-11B",
    "author": "Ba2han",
    "query_name": "Ba2han/BruinsV2-OpHermesNeu-11B",
    "score": 69.88,
    "likes": 0.0,
    "link": "https://huggingface.co/Ba2han/BruinsV2-OpHermesNeu-11B",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-Q",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-Q",
    "score": 69.86,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Q",
    "still_on_hub": true
  },
  {
    "name": "StellarBright",
    "author": "sequelbox",
    "query_name": "sequelbox/StellarBright",
    "score": 69.86,
    "likes": 8.0,
    "link": "https://huggingface.co/sequelbox/StellarBright",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-3",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3-3",
    "score": 69.83,
    "likes": 0.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-3",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-7B-v2.02",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-7B-v2.02",
    "score": 69.82,
    "likes": 2.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.02",
    "still_on_hub": true
  },
  {
    "name": "Tess-M-v1.1",
    "author": "migtissera",
    "query_name": "migtissera/Tess-M-v1.1",
    "score": 69.79,
    "likes": 0.0,
    "link": "https://huggingface.co/migtissera/Tess-M-v1.1",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-neural-chat-7b-v3-2-Slerp",
    "author": "Weyaxi",
    "query_name": "Weyaxi/MetaMath-neural-chat-7b-v3-2-Slerp",
    "score": 69.79,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/MetaMath-neural-chat-7b-v3-2-Slerp",
    "still_on_hub": true
  },
  {
    "name": "Tess-M-v1.3",
    "author": "migtissera",
    "query_name": "migtissera/Tess-M-v1.3",
    "score": 69.71,
    "likes": 6.0,
    "link": "https://huggingface.co/migtissera/Tess-M-v1.3",
    "still_on_hub": true
  },
  {
    "name": "Rabbit-7B-DPO-Chat",
    "author": "viethq188",
    "query_name": "viethq188/Rabbit-7B-DPO-Chat",
    "score": 69.69,
    "likes": 0.0,
    "link": "https://huggingface.co/viethq188/Rabbit-7B-DPO-Chat",
    "still_on_hub": true
  },
  {
    "name": "una-cybertron-7b-v2-bf16",
    "author": "fblgit",
    "query_name": "fblgit/una-cybertron-7b-v2-bf16",
    "score": 69.67,
    "likes": 0.0,
    "link": "https://huggingface.co/fblgit/una-cybertron-7b-v2-bf16",
    "still_on_hub": true
  },
  {
    "name": "Pandora-13B-v1",
    "author": "jan-ai",
    "query_name": "jan-ai/Pandora-13B-v1",
    "score": 69.59,
    "likes": 0.0,
    "link": "https://huggingface.co/jan-ai/Pandora-13B-v1",
    "still_on_hub": true
  },
  {
    "name": "DPOpenHermes-7B-v2",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/DPOpenHermes-7B-v2",
    "score": 69.58,
    "likes": 0.0,
    "link": "https://huggingface.co/openaccess-ai-collective/DPOpenHermes-7B-v2",
    "still_on_hub": true
  },
  {
    "name": "una-cybertron-7b-v1-fp16",
    "author": "fblgit",
    "query_name": "fblgit/una-cybertron-7b-v1-fp16",
    "score": 69.49,
    "likes": 0.0,
    "link": "https://huggingface.co/fblgit/una-cybertron-7b-v1-fp16",
    "still_on_hub": true
  },
  {
    "name": "GodziLLa2-70B",
    "author": "MayaPH",
    "query_name": "MayaPH/GodziLLa2-70B",
    "score": 69.46,
    "likes": 17.0,
    "link": "https://huggingface.co/MayaPH/GodziLLa2-70B",
    "still_on_hub": true
  },
  {
    "name": "Yi-34B",
    "author": "01-ai",
    "query_name": "01-ai/Yi-34B",
    "score": 69.42,
    "likes": 15.0,
    "link": "https://huggingface.co/01-ai/Yi-34B",
    "still_on_hub": true
  },
  {
    "name": "deepseek-llm-67b-base",
    "author": "deepseek-ai",
    "query_name": "deepseek-ai/deepseek-llm-67b-base",
    "score": 69.38,
    "likes": 0.0,
    "link": "https://huggingface.co/deepseek-ai/deepseek-llm-67b-base",
    "still_on_hub": true
  },
  {
    "name": "Rabbit-7B-v2-DPO-Chat",
    "author": "viethq188",
    "query_name": "viethq188/Rabbit-7B-v2-DPO-Chat",
    "score": 69.36,
    "likes": 0.0,
    "link": "https://huggingface.co/viethq188/Rabbit-7B-v2-DPO-Chat",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-deepseek-67b-v15-base",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-deepseek-67b-v15-base",
    "score": 69.34,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-deepseek-67b-v15-base",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-70B-instruct",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Platypus2-70B-instruct",
    "score": 69.3,
    "likes": 148.0,
    "link": "https://huggingface.co/garage-bAInd/Platypus2-70B-instruct",
    "still_on_hub": true
  },
  {
    "name": "Synatra-MCS-7B-v0.3-RP-Slerp",
    "author": "PistachioAlt",
    "query_name": "PistachioAlt/Synatra-MCS-7B-v0.3-RP-Slerp",
    "score": 69.18,
    "likes": 0.0,
    "link": "https://huggingface.co/PistachioAlt/Synatra-MCS-7B-v0.3-RP-Slerp",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-70b-2.2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-70b-2.2.1",
    "score": 69.13,
    "likes": 6.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-2.2.1",
    "still_on_hub": true
  },
  {
    "name": "piano-medley-7b",
    "author": "chargoddard",
    "query_name": "chargoddard/piano-medley-7b",
    "score": 69.1,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/piano-medley-7b",
    "still_on_hub": true
  },
  {
    "name": "Optimus-7B",
    "author": "Q-bert",
    "query_name": "Q-bert/Optimus-7B",
    "score": 69.09,
    "likes": 1.0,
    "link": "https://huggingface.co/Q-bert/Optimus-7B",
    "still_on_hub": true
  },
  {
    "name": "loyal-piano-m7-cdpo",
    "author": "chargoddard",
    "query_name": "chargoddard/loyal-piano-m7-cdpo",
    "score": 69.08,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/loyal-piano-m7-cdpo",
    "still_on_hub": true
  },
  {
    "name": "Neural-una-cybertron-7b",
    "author": "PulsarAI",
    "query_name": "PulsarAI/Neural-una-cybertron-7b",
    "score": 69.05,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/Neural-una-cybertron-7b",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v3_70b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_v3_70b",
    "score": 69.02,
    "likes": 16.0,
    "link": "https://huggingface.co/psmathur/orca_mini_v3_70b",
    "still_on_hub": true
  },
  {
    "name": "loyal-piano-m7-cdpo",
    "author": "chargoddard",
    "query_name": "chargoddard/loyal-piano-m7-cdpo",
    "score": 69.0,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/loyal-piano-m7-cdpo",
    "still_on_hub": true
  },
  {
    "name": "servile-harpsichord-cdpo",
    "author": "chargoddard",
    "query_name": "chargoddard/servile-harpsichord-cdpo",
    "score": 68.98,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/servile-harpsichord-cdpo",
    "still_on_hub": true
  },
  {
    "name": "LeoScorpius-GreenNode-Platypus-7B-v1",
    "author": "ignos",
    "query_name": "ignos/LeoScorpius-GreenNode-Platypus-7B-v1",
    "score": 68.96,
    "likes": 0.0,
    "link": "https://huggingface.co/ignos/LeoScorpius-GreenNode-Platypus-7B-v1",
    "still_on_hub": true
  },
  {
    "name": "openchat-3.5-1210",
    "author": "openchat",
    "query_name": "openchat/openchat-3.5-1210",
    "score": 68.89,
    "likes": 36.0,
    "link": "https://huggingface.co/openchat/openchat-3.5-1210",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-una-cybertron-v2-bf16-Ties",
    "author": "Weyaxi",
    "query_name": "Weyaxi/MetaMath-una-cybertron-v2-bf16-Ties",
    "score": 68.88,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/MetaMath-una-cybertron-v2-bf16-Ties",
    "still_on_hub": true
  },
  {
    "name": "Marcoroni-70B-v1",
    "author": "AIDC-ai-business",
    "query_name": "AIDC-ai-business/Marcoroni-70B-v1",
    "score": 68.83,
    "likes": 16.0,
    "link": "https://huggingface.co/AIDC-ai-business/Marcoroni-70B-v1",
    "still_on_hub": true
  },
  {
    "name": "A11P",
    "author": "AA051610",
    "query_name": "AA051610/A11P",
    "score": 68.73,
    "likes": 0.0,
    "link": "https://huggingface.co/AA051610/A11P",
    "still_on_hub": false
  },
  {
    "name": "pic_7B_mistral_Full_v0.2",
    "author": "TokenBender",
    "query_name": "TokenBender/pic_7B_mistral_Full_v0.2",
    "score": 68.72,
    "likes": 0.0,
    "link": "https://huggingface.co/TokenBender/pic_7B_mistral_Full_v0.2",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-2.5-neural-chat-7b-v3-2-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-2-7B",
    "score": 68.71,
    "likes": 11.0,
    "link": "https://huggingface.co/Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-2-7B",
    "still_on_hub": true
  },
  {
    "name": "Yi-34B-AEZAKMI-v1",
    "author": "adamo1139",
    "query_name": "adamo1139/Yi-34B-AEZAKMI-v1",
    "score": 68.67,
    "likes": 0.0,
    "link": "https://huggingface.co/adamo1139/Yi-34B-AEZAKMI-v1",
    "still_on_hub": true
  },
  {
    "name": "loyal-piano-m7",
    "author": "chargoddard",
    "query_name": "chargoddard/loyal-piano-m7",
    "score": 68.67,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/loyal-piano-m7",
    "still_on_hub": true
  },
  {
    "name": "A12P",
    "author": "AA051610",
    "query_name": "AA051610/A12P",
    "score": 68.64,
    "likes": 0.0,
    "link": "https://huggingface.co/AA051610/A12P",
    "still_on_hub": false
  },
  {
    "name": "agiin-13.6B-v0.0",
    "author": "mncai",
    "query_name": "mncai/agiin-13.6B-v0.0",
    "score": 68.63,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/agiin-13.6B-v0.0",
    "still_on_hub": true
  },
  {
    "name": "spicyboros-70b-2.2",
    "author": "jondurbin",
    "query_name": "jondurbin/spicyboros-70b-2.2",
    "score": 68.62,
    "likes": 7.0,
    "link": "https://huggingface.co/jondurbin/spicyboros-70b-2.2",
    "still_on_hub": true
  },
  {
    "name": "CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
    "author": "brucethemoose",
    "query_name": "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
    "score": 68.57,
    "likes": 0.0,
    "link": "https://huggingface.co/brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties",
    "still_on_hub": true
  },
  {
    "name": "model_007",
    "author": "psmathur",
    "query_name": "psmathur/model_007",
    "score": 68.56,
    "likes": 19.0,
    "link": "https://huggingface.co/psmathur/model_007",
    "still_on_hub": true
  },
  {
    "name": "model_009",
    "author": "psmathur",
    "query_name": "psmathur/model_009",
    "score": 68.53,
    "likes": 1.0,
    "link": "https://huggingface.co/psmathur/model_009",
    "still_on_hub": true
  },
  {
    "name": "Instruct-v0.2-Seraph-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Instruct-v0.2-Seraph-7B",
    "score": 68.48,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Instruct-v0.2-Seraph-7B",
    "still_on_hub": true
  },
  {
    "name": "model_101",
    "author": "psmathur",
    "query_name": "psmathur/model_101",
    "score": 68.46,
    "likes": 0.0,
    "link": "https://huggingface.co/psmathur/model_101",
    "still_on_hub": true
  },
  {
    "name": "Mixtral-8x7B-v0.1",
    "author": "mistralai",
    "query_name": "mistralai/Mixtral-8x7B-v0.1",
    "score": 68.42,
    "likes": 194.0,
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-v0.1",
    "still_on_hub": true
  },
  {
    "name": "agiin-13.6B-v0.1",
    "author": "mncai",
    "query_name": "mncai/agiin-13.6B-v0.1",
    "score": 68.4,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/agiin-13.6B-v0.1",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-Llama",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-Llama",
    "score": 68.37,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama",
    "still_on_hub": false
  },
  {
    "name": "genz-70b",
    "author": "budecosystem",
    "query_name": "budecosystem/genz-70b",
    "score": 68.35,
    "likes": 26.0,
    "link": "https://huggingface.co/budecosystem/genz-70b",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-Llama-Q-FastChat",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-Llama-Q-FastChat",
    "score": 68.31,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q-FastChat",
    "still_on_hub": false
  },
  {
    "name": "Falkor-8x7B-MoE",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Falkor-8x7B-MoE",
    "score": 68.31,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Falkor-8x7B-MoE",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-2",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3-2",
    "score": 68.29,
    "likes": 5.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-2",
    "still_on_hub": true
  },
  {
    "name": "chronos007-70b",
    "author": "elinas",
    "query_name": "elinas/chronos007-70b",
    "score": 68.25,
    "likes": 2.0,
    "link": "https://huggingface.co/elinas/chronos007-70b",
    "still_on_hub": true
  },
  {
    "name": "NeuralHermes-2.5-Mistral-7B",
    "author": "mlabonne",
    "query_name": "mlabonne/NeuralHermes-2.5-Mistral-7B",
    "score": 68.22,
    "likes": 10.0,
    "link": "https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "OrionStar-Yi-34B-Chat-Llama",
    "author": "OrionStarAI",
    "query_name": "OrionStarAI/OrionStar-Yi-34B-Chat-Llama",
    "score": 68.17,
    "likes": 1.0,
    "link": "https://huggingface.co/OrionStarAI/OrionStar-Yi-34B-Chat-Llama",
    "still_on_hub": true
  },
  {
    "name": "blossom-v3_1-yi-34b",
    "author": "Azure99",
    "query_name": "Azure99/blossom-v3_1-yi-34b",
    "score": 68.16,
    "likes": 0.0,
    "link": "https://huggingface.co/Azure99/blossom-v3_1-yi-34b",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama2-70b-v10.1-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-llama2-70b-v10.1-bf16",
    "score": 68.16,
    "likes": 41.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-70b-v10.1-bf16",
    "still_on_hub": true
  },
  {
    "name": "AZG",
    "author": "AA051610",
    "query_name": "AA051610/AZG",
    "score": 68.16,
    "likes": 0.0,
    "link": "https://huggingface.co/AA051610/AZG",
    "still_on_hub": false
  },
  {
    "name": "OpenZephyrChat",
    "author": "Fredithefish",
    "query_name": "Fredithefish/OpenZephyrChat",
    "score": 68.12,
    "likes": 0.0,
    "link": "https://huggingface.co/Fredithefish/OpenZephyrChat",
    "still_on_hub": true
  },
  {
    "name": "agiin-11.1B-v0.0",
    "author": "mncai",
    "query_name": "mncai/agiin-11.1B-v0.0",
    "score": 68.1,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/agiin-11.1B-v0.0",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-LoRA",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-LoRA",
    "score": 68.1,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-LoRA",
    "still_on_hub": true
  },
  {
    "name": "Merged-DPO-7B",
    "author": "GreenNode",
    "query_name": "GreenNode/Merged-DPO-7B",
    "score": 68.06,
    "likes": 0.0,
    "link": "https://huggingface.co/GreenNode/Merged-DPO-7B",
    "still_on_hub": false
  },
  {
    "name": "lil-c3po",
    "author": "deepnight-research",
    "query_name": "deepnight-research/lil-c3po",
    "score": 68.03,
    "likes": 0.0,
    "link": "https://huggingface.co/deepnight-research/lil-c3po",
    "still_on_hub": true
  },
  {
    "name": "bagel-dpo-7b-v0.1",
    "author": "jondurbin",
    "query_name": "jondurbin/bagel-dpo-7b-v0.1",
    "score": 67.95,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/bagel-dpo-7b-v0.1",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-Llama-Q-v2",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-Llama-Q-v2",
    "score": 67.88,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q-v2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-70b-hf",
    "author": "meta-llama",
    "query_name": "meta-llama/Llama-2-70b-hf",
    "score": 67.87,
    "likes": 623.0,
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-hf",
    "still_on_hub": false
  },
  {
    "name": "PlatYi-34B-200k-Q-FastChat",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-200k-Q-FastChat",
    "score": 67.85,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-200k-Q-FastChat",
    "still_on_hub": true
  },
  {
    "name": "falcon-180B",
    "author": "tiiuae",
    "query_name": "tiiuae/falcon-180B",
    "score": 67.85,
    "likes": 830.0,
    "link": "https://huggingface.co/tiiuae/falcon-180B",
    "still_on_hub": false
  },
  {
    "name": "Nyxene-v2-11B",
    "author": "beberik",
    "query_name": "beberik/Nyxene-v2-11B",
    "score": 67.84,
    "likes": 0.0,
    "link": "https://huggingface.co/beberik/Nyxene-v2-11B",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-2.5-neural-chat-7b-v3-1-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B",
    "score": 67.84,
    "likes": 1.0,
    "link": "https://huggingface.co/Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-7B",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-7B",
    "score": 67.76,
    "likes": 4.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B",
    "still_on_hub": true
  },
  {
    "name": "Bumblebee-7B",
    "author": "Q-bert",
    "query_name": "Q-bert/Bumblebee-7B",
    "score": 67.73,
    "likes": 1.0,
    "link": "https://huggingface.co/Q-bert/Bumblebee-7B",
    "still_on_hub": true
  },
  {
    "name": "Nyxene-11B",
    "author": "beberik",
    "query_name": "beberik/Nyxene-11B",
    "score": 67.72,
    "likes": 0.0,
    "link": "https://huggingface.co/beberik/Nyxene-11B",
    "still_on_hub": true
  },
  {
    "name": "Euryale-1.3-L2-70B",
    "author": "Sao10K",
    "query_name": "Sao10K/Euryale-1.3-L2-70B",
    "score": 67.66,
    "likes": 4.0,
    "link": "https://huggingface.co/Sao10K/Euryale-1.3-L2-70B",
    "still_on_hub": true
  },
  {
    "name": "NeuralOrca-7B-v1",
    "author": "mrfakename",
    "query_name": "mrfakename/NeuralOrca-7B-v1",
    "score": 67.64,
    "likes": 0.0,
    "link": "https://huggingface.co/mrfakename/NeuralOrca-7B-v1",
    "still_on_hub": true
  },
  {
    "name": "DPOpenHermes-7B",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/DPOpenHermes-7B",
    "score": 67.63,
    "likes": 0.0,
    "link": "https://huggingface.co/openaccess-ai-collective/DPOpenHermes-7B",
    "still_on_hub": true
  },
  {
    "name": "ORCA_LLaMA_70B_QLoRA",
    "author": "fangloveskari",
    "query_name": "fangloveskari/ORCA_LLaMA_70B_QLoRA",
    "score": 67.6,
    "likes": 49.0,
    "link": "https://huggingface.co/fangloveskari/ORCA_LLaMA_70B_QLoRA",
    "still_on_hub": true
  },
  {
    "name": "Nyxene-v1-11B",
    "author": "beberik",
    "query_name": "beberik/Nyxene-v1-11B",
    "score": 67.58,
    "likes": 0.0,
    "link": "https://huggingface.co/beberik/Nyxene-v1-11B",
    "still_on_hub": true
  },
  {
    "name": "DPOpenHermes-7B",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/DPOpenHermes-7B",
    "score": 67.58,
    "likes": 0.0,
    "link": "https://huggingface.co/openaccess-ai-collective/DPOpenHermes-7B",
    "still_on_hub": true
  },
  {
    "name": "Platypus_QLoRA_LLaMA_70b",
    "author": "fangloveskari",
    "query_name": "fangloveskari/Platypus_QLoRA_LLaMA_70b",
    "score": 67.57,
    "likes": 3.0,
    "link": "https://huggingface.co/fangloveskari/Platypus_QLoRA_LLaMA_70b",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-neural-chat-7b-v3-2-Ties",
    "author": "Weyaxi",
    "query_name": "Weyaxi/MetaMath-neural-chat-7b-v3-2-Ties",
    "score": 67.54,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/MetaMath-neural-chat-7b-v3-2-Ties",
    "still_on_hub": true
  },
  {
    "name": "MoMo-70B-LoRA-V1.1",
    "author": "bongchoi",
    "query_name": "bongchoi/MoMo-70B-LoRA-V1.1",
    "score": 67.53,
    "likes": 0.0,
    "link": "https://huggingface.co/bongchoi/MoMo-70B-LoRA-V1.1",
    "still_on_hub": false
  },
  {
    "name": "FashionGPT-70B-V1",
    "author": "ICBU-NPU",
    "query_name": "ICBU-NPU/FashionGPT-70B-V1",
    "score": 67.47,
    "likes": 4.0,
    "link": "https://huggingface.co/ICBU-NPU/FashionGPT-70B-V1",
    "still_on_hub": true
  },
  {
    "name": "juanako-7b-UNA",
    "author": "fblgit",
    "query_name": "fblgit/juanako-7b-UNA",
    "score": 67.46,
    "likes": 1.0,
    "link": "https://huggingface.co/fblgit/juanako-7b-UNA",
    "still_on_hub": true
  },
  {
    "name": "Samantha-1.1-70b",
    "author": "ehartford",
    "query_name": "ehartford/Samantha-1.1-70b",
    "score": 67.43,
    "likes": 4.0,
    "link": "https://huggingface.co/ehartford/Samantha-1.1-70b",
    "still_on_hub": true
  },
  {
    "name": "StableBeluga2",
    "author": "stabilityai",
    "query_name": "stabilityai/StableBeluga2",
    "score": 67.42,
    "likes": 836.0,
    "link": "https://huggingface.co/stabilityai/StableBeluga2",
    "still_on_hub": true
  },
  {
    "name": "test_42_70b",
    "author": "psmathur",
    "query_name": "psmathur/test_42_70b",
    "score": 67.38,
    "likes": 4.0,
    "link": "https://huggingface.co/psmathur/test_42_70b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-70b-instruct",
    "author": "upstage",
    "query_name": "upstage/Llama-2-70b-instruct",
    "score": 67.38,
    "likes": 53.0,
    "link": "https://huggingface.co/upstage/Llama-2-70b-instruct",
    "still_on_hub": true
  },
  {
    "name": "SharpBalance",
    "author": "sequelbox",
    "query_name": "sequelbox/SharpBalance",
    "score": 67.36,
    "likes": 3.0,
    "link": "https://huggingface.co/sequelbox/SharpBalance",
    "still_on_hub": true
  },
  {
    "name": "Samantha-1.11-70b",
    "author": "ehartford",
    "query_name": "ehartford/Samantha-1.11-70b",
    "score": 67.28,
    "likes": 30.0,
    "link": "https://huggingface.co/ehartford/Samantha-1.11-70b",
    "still_on_hub": true
  },
  {
    "name": "Ana-v1-m7",
    "author": "Sao10K",
    "query_name": "Sao10K/Ana-v1-m7",
    "score": 67.24,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Ana-v1-m7",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-1-OpenHermes-2.5-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B",
    "score": 67.19,
    "likes": 2.0,
    "link": "https://huggingface.co/Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B",
    "still_on_hub": true
  },
  {
    "name": "FashionGPT-70B-V1.2",
    "author": "ICBU-NPU",
    "query_name": "ICBU-NPU/FashionGPT-70B-V1.2",
    "score": 67.17,
    "likes": 2.0,
    "link": "https://huggingface.co/ICBU-NPU/FashionGPT-70B-V1.2",
    "still_on_hub": true
  },
  {
    "name": "Starling-LM-7B-alpha",
    "author": "berkeley-nest",
    "query_name": "berkeley-nest/Starling-LM-7B-alpha",
    "score": 67.13,
    "likes": 170.0,
    "link": "https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha",
    "still_on_hub": true
  },
  {
    "name": "lzlv_70b_fp16_hf",
    "author": "lizpreciatior",
    "query_name": "lizpreciatior/lzlv_70b_fp16_hf",
    "score": 67.13,
    "likes": 23.0,
    "link": "https://huggingface.co/lizpreciatior/lzlv_70b_fp16_hf",
    "still_on_hub": true
  },
  {
    "name": "model_007_v2",
    "author": "psmathur",
    "query_name": "psmathur/model_007_v2",
    "score": 67.13,
    "likes": 1.0,
    "link": "https://huggingface.co/psmathur/model_007_v2",
    "still_on_hub": true
  },
  {
    "name": "MelangeB-70b",
    "author": "chargoddard",
    "query_name": "chargoddard/MelangeB-70b",
    "score": 67.12,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/MelangeB-70b",
    "still_on_hub": true
  },
  {
    "name": "Starling-LM-alpha-8x7B-MoE",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Starling-LM-alpha-8x7B-MoE",
    "score": 67.11,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Starling-LM-alpha-8x7B-MoE",
    "still_on_hub": true
  },
  {
    "name": "smol-7b",
    "author": "rishiraj",
    "query_name": "rishiraj/smol-7b",
    "score": 67.11,
    "likes": 0.0,
    "link": "https://huggingface.co/rishiraj/smol-7b",
    "still_on_hub": true
  },
  {
    "name": "Starling-LM-7B-alpha",
    "author": "berkeley-nest",
    "query_name": "berkeley-nest/Starling-LM-7B-alpha",
    "score": 67.05,
    "likes": 61.0,
    "link": "https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-7B-v2",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-7B-v2",
    "score": 67.04,
    "likes": 25.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
    "author": "Weyaxi",
    "query_name": "Weyaxi/MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
    "score": 67.03,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/MetaMath-NeuralHermes-2.5-Mistral-7B-Ties",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-70B-V1.0",
    "author": "meta-math",
    "query_name": "meta-math/MetaMath-70B-V1.0",
    "score": 67.02,
    "likes": 8.0,
    "link": "https://huggingface.co/meta-math/MetaMath-70B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "Synthia-70B-v1.2b",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-70B-v1.2b",
    "score": 67.0,
    "likes": 17.0,
    "link": "https://huggingface.co/migtissera/Synthia-70B-v1.2b",
    "still_on_hub": true
  },
  {
    "name": "Mixtral-SlimOrca-8x7B",
    "author": "Open-Orca",
    "query_name": "Open-Orca/Mixtral-SlimOrca-8x7B",
    "score": 66.97,
    "likes": 7.0,
    "link": "https://huggingface.co/Open-Orca/Mixtral-SlimOrca-8x7B",
    "still_on_hub": true
  },
  {
    "name": "Misted-7B",
    "author": "Walmart-the-bag",
    "query_name": "Walmart-the-bag/Misted-7B",
    "score": 66.94,
    "likes": 1.0,
    "link": "https://huggingface.co/Walmart-the-bag/Misted-7B",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7B-v3-2-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/neural-chat-7B-v3-2-GPTQ",
    "score": 66.93,
    "likes": 1.0,
    "link": "https://huggingface.co/TheBloke/neural-chat-7B-v3-2-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Synthia-70B-v1.2",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-70B-v1.2",
    "score": 66.9,
    "likes": 16.0,
    "link": "https://huggingface.co/migtissera/Synthia-70B-v1.2",
    "still_on_hub": true
  },
  {
    "name": "Synthia-70B-v1.1",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-70B-v1.1",
    "score": 66.81,
    "likes": 7.0,
    "link": "https://huggingface.co/migtissera/Synthia-70B-v1.1",
    "still_on_hub": true
  },
  {
    "name": "Synthia-70B",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-70B",
    "score": 66.72,
    "likes": 8.0,
    "link": "https://huggingface.co/migtissera/Synthia-70B",
    "still_on_hub": true
  },
  {
    "name": "Uni-TianYan",
    "author": "uni-tianyan",
    "query_name": "uni-tianyan/Uni-TianYan",
    "score": 66.61,
    "likes": 48.0,
    "link": "https://huggingface.co/uni-tianyan/Uni-TianYan",
    "still_on_hub": true
  },
  {
    "name": "HermesStar-OrcaWind-Synth-11B",
    "author": "Ba2han",
    "query_name": "Ba2han/HermesStar-OrcaWind-Synth-11B",
    "score": 66.59,
    "likes": 0.0,
    "link": "https://huggingface.co/Ba2han/HermesStar-OrcaWind-Synth-11B",
    "still_on_hub": true
  },
  {
    "name": "dpopenhermes-alpha-v0",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/dpopenhermes-alpha-v0",
    "score": 66.52,
    "likes": 3.0,
    "link": "https://huggingface.co/openaccess-ai-collective/dpopenhermes-alpha-v0",
    "still_on_hub": true
  },
  {
    "name": "LLaMA-2-Wizard-70B-QLoRA",
    "author": "v2ray",
    "query_name": "v2ray/LLaMA-2-Wizard-70B-QLoRA",
    "score": 66.47,
    "likes": 2.0,
    "link": "https://huggingface.co/v2ray/LLaMA-2-Wizard-70B-QLoRA",
    "still_on_hub": false
  },
  {
    "name": "A13",
    "author": "AA051610",
    "query_name": "AA051610/A13",
    "score": 66.45,
    "likes": 0.0,
    "link": "https://huggingface.co/AA051610/A13",
    "still_on_hub": false
  },
  {
    "name": "Math-OpenHermes-2.5-Mistral-7B",
    "author": "simonveitner",
    "query_name": "simonveitner/Math-OpenHermes-2.5-Mistral-7B",
    "score": 66.42,
    "likes": 0.0,
    "link": "https://huggingface.co/simonveitner/Math-OpenHermes-2.5-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "Instruct_Llama70B_Dolly15k",
    "author": "Brillibits",
    "query_name": "Brillibits/Instruct_Llama70B_Dolly15k",
    "score": 66.42,
    "likes": 0.0,
    "link": "https://huggingface.co/Brillibits/Instruct_Llama70B_Dolly15k",
    "still_on_hub": true
  },
  {
    "name": "openhermes-2_5-dpo-no-robots",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/openhermes-2_5-dpo-no-robots",
    "score": 66.4,
    "likes": 0.0,
    "link": "https://huggingface.co/openaccess-ai-collective/openhermes-2_5-dpo-no-robots",
    "still_on_hub": true
  },
  {
    "name": "qCammel70",
    "author": "augtoma",
    "query_name": "augtoma/qCammel70",
    "score": 66.31,
    "likes": 20.0,
    "link": "https://huggingface.co/augtoma/qCammel70",
    "still_on_hub": true
  },
  {
    "name": "qCammel-70",
    "author": "augtoma",
    "query_name": "augtoma/qCammel-70",
    "score": 66.31,
    "likes": 20.0,
    "link": "https://huggingface.co/augtoma/qCammel-70",
    "still_on_hub": true
  },
  {
    "name": "qCammel-70v1",
    "author": "augtoma",
    "query_name": "augtoma/qCammel-70v1",
    "score": 66.31,
    "likes": 20.0,
    "link": "https://huggingface.co/augtoma/qCammel-70v1",
    "still_on_hub": true
  },
  {
    "name": "qCammel-70-x",
    "author": "augtoma",
    "query_name": "augtoma/qCammel-70-x",
    "score": 66.31,
    "likes": 20.0,
    "link": "https://huggingface.co/augtoma/qCammel-70-x",
    "still_on_hub": true
  },
  {
    "name": "qCammel-70x",
    "author": "augtoma",
    "query_name": "augtoma/qCammel-70x",
    "score": 66.31,
    "likes": 20.0,
    "link": "https://huggingface.co/augtoma/qCammel-70x",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-70B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Platypus2-70B",
    "score": 66.28,
    "likes": 19.0,
    "link": "https://huggingface.co/garage-bAInd/Platypus2-70B",
    "still_on_hub": true
  },
  {
    "name": "mythospice-limarp-70b",
    "author": "Doctor-Shotgun",
    "query_name": "Doctor-Shotgun/mythospice-limarp-70b",
    "score": 66.27,
    "likes": 0.0,
    "link": "https://huggingface.co/Doctor-Shotgun/mythospice-limarp-70b",
    "still_on_hub": true
  },
  {
    "name": "Xwin-LM-70B-V0.1",
    "author": "Xwin-LM",
    "query_name": "Xwin-LM/Xwin-LM-70B-V0.1",
    "score": 66.2,
    "likes": 159.0,
    "link": "https://huggingface.co/Xwin-LM/Xwin-LM-70B-V0.1",
    "still_on_hub": true
  },
  {
    "name": "mythospice-70b",
    "author": "Doctor-Shotgun",
    "query_name": "Doctor-Shotgun/mythospice-70b",
    "score": 66.17,
    "likes": 1.0,
    "link": "https://huggingface.co/Doctor-Shotgun/mythospice-70b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-70b-fb16-orca-chat-10k",
    "author": "quantumaikr",
    "query_name": "quantumaikr/llama-2-70b-fb16-orca-chat-10k",
    "score": 66.16,
    "likes": 2.0,
    "link": "https://huggingface.co/quantumaikr/llama-2-70b-fb16-orca-chat-10k",
    "still_on_hub": true
  },
  {
    "name": "where-llambo-7b",
    "author": "amazingvince",
    "query_name": "amazingvince/where-llambo-7b",
    "score": 66.08,
    "likes": 0.0,
    "link": "https://huggingface.co/amazingvince/where-llambo-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-70b-Guanaco-QLoRA-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/llama-2-70b-Guanaco-QLoRA-fp16",
    "score": 66.05,
    "likes": 53.0,
    "link": "https://huggingface.co/TheBloke/llama-2-70b-Guanaco-QLoRA-fp16",
    "still_on_hub": true
  },
  {
    "name": "SOLAR-10.7B-v1.0",
    "author": "upstage",
    "query_name": "upstage/SOLAR-10.7B-v1.0",
    "score": 66.04,
    "likes": 0.0,
    "link": "https://huggingface.co/upstage/SOLAR-10.7B-v1.0",
    "still_on_hub": true
  },
  {
    "name": "pic_7B_mistral_Full_v0.1",
    "author": "TokenBender",
    "query_name": "TokenBender/pic_7B_mistral_Full_v0.1",
    "score": 66.0,
    "likes": 0.0,
    "link": "https://huggingface.co/TokenBender/pic_7B_mistral_Full_v0.1",
    "still_on_hub": false
  },
  {
    "name": "medllama-2-70b-qlora-1.1",
    "author": "s1ghhh",
    "query_name": "s1ghhh/medllama-2-70b-qlora-1.1",
    "score": 65.99,
    "likes": 1.0,
    "link": "https://huggingface.co/s1ghhh/medllama-2-70b-qlora-1.1",
    "still_on_hub": false
  },
  {
    "name": "model_51",
    "author": "psmathur",
    "query_name": "psmathur/model_51",
    "score": 65.96,
    "likes": 1.0,
    "link": "https://huggingface.co/psmathur/model_51",
    "still_on_hub": true
  },
  {
    "name": "14B-DPO-alpha",
    "author": "CausalLM",
    "query_name": "CausalLM/14B-DPO-alpha",
    "score": 65.91,
    "likes": 64.0,
    "link": "https://huggingface.co/CausalLM/14B-DPO-alpha",
    "still_on_hub": false
  },
  {
    "name": "Qwen-14B",
    "author": "Qwen",
    "query_name": "Qwen/Qwen-14B",
    "score": 65.86,
    "likes": 162.0,
    "link": "https://huggingface.co/Qwen/Qwen-14B",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-falcon-180b-v13-preview0",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-falcon-180b-v13-preview0",
    "score": 65.85,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-falcon-180b-v13-preview0",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-7B-v2.03-128k",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-7B-v2.03-128k",
    "score": 65.83,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.03-128k",
    "still_on_hub": true
  },
  {
    "name": "Mixtral-8x7B-v0.1",
    "author": "mistralai",
    "query_name": "mistralai/Mixtral-8x7B-v0.1",
    "score": 65.81,
    "likes": 0.0,
    "link": "https://huggingface.co/mistralai/Mixtral-8x7B-v0.1",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-Mistral-7B",
    "author": "meta-math",
    "query_name": "meta-math/MetaMath-Mistral-7B",
    "score": 65.78,
    "likes": 32.0,
    "link": "https://huggingface.co/meta-math/MetaMath-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "model_420",
    "author": "psmathur",
    "query_name": "psmathur/model_420",
    "score": 65.76,
    "likes": 1.0,
    "link": "https://huggingface.co/psmathur/model_420",
    "still_on_hub": true
  },
  {
    "name": "llama-2-70b-dolphin-peft",
    "author": "dfurman",
    "query_name": "dfurman/llama-2-70b-dolphin-peft",
    "score": 65.72,
    "likes": 12.0,
    "link": "https://huggingface.co/dfurman/llama-2-70b-dolphin-peft",
    "still_on_hub": false
  },
  {
    "name": "Mistral-7B-Instruct-v0.2",
    "author": "mistralai",
    "query_name": "mistralai/Mistral-7B-Instruct-v0.2",
    "score": 65.71,
    "likes": 19.0,
    "link": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2",
    "still_on_hub": true
  },
  {
    "name": "Mixtral-8x7B-v0.1-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Mixtral-8x7B-v0.1-GPTQ",
    "score": 65.7,
    "likes": 0.0,
    "link": "https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "LLaMA-2-Jannie-70B-QLoRA",
    "author": "v2ray",
    "query_name": "v2ray/LLaMA-2-Jannie-70B-QLoRA",
    "score": 65.6,
    "likes": 14.0,
    "link": "https://huggingface.co/v2ray/LLaMA-2-Jannie-70B-QLoRA",
    "still_on_hub": false
  },
  {
    "name": "Camel-Platypus2-70B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Camel-Platypus2-70B",
    "score": 65.59,
    "likes": 12.0,
    "link": "https://huggingface.co/garage-bAInd/Camel-Platypus2-70B",
    "still_on_hub": true
  },
  {
    "name": "Yee-34B-200K-Chat",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/Yee-34B-200K-Chat",
    "score": 65.56,
    "likes": 0.0,
    "link": "https://huggingface.co/JosephusCheung/Yee-34B-200K-Chat",
    "still_on_hub": false
  },
  {
    "name": "neural-chat-11b-v3-2",
    "author": "NurtureAI",
    "query_name": "NurtureAI/neural-chat-11b-v3-2",
    "score": 65.52,
    "likes": 0.0,
    "link": "https://huggingface.co/NurtureAI/neural-chat-11b-v3-2",
    "still_on_hub": true
  },
  {
    "name": "model_42_70b",
    "author": "psmathur",
    "query_name": "psmathur/model_42_70b",
    "score": 65.51,
    "likes": 4.0,
    "link": "https://huggingface.co/psmathur/model_42_70b",
    "still_on_hub": true
  },
  {
    "name": "Lima_Unchained_70b",
    "author": "pankajmathur",
    "query_name": "pankajmathur/Lima_Unchained_70b",
    "score": 65.51,
    "likes": 4.0,
    "link": "https://huggingface.co/pankajmathur/Lima_Unchained_70b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-70b-oasst-1-200",
    "author": "jordiclive",
    "query_name": "jordiclive/Llama-2-70b-oasst-1-200",
    "score": 65.5,
    "likes": 2.0,
    "link": "https://huggingface.co/jordiclive/Llama-2-70b-oasst-1-200",
    "still_on_hub": true
  },
  {
    "name": "bagel-7b-v0.1",
    "author": "jondurbin",
    "query_name": "jondurbin/bagel-7b-v0.1",
    "score": 65.49,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/bagel-7b-v0.1",
    "still_on_hub": true
  },
  {
    "name": "fiction.live-Kimiko-V2-70B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/fiction.live-Kimiko-V2-70B-fp16",
    "score": 65.48,
    "likes": 3.0,
    "link": "https://huggingface.co/TheBloke/fiction.live-Kimiko-V2-70B-fp16",
    "still_on_hub": true
  },
  {
    "name": "falcon-180B",
    "author": "tiiuae",
    "query_name": "tiiuae/falcon-180B",
    "score": 65.46,
    "likes": 830.0,
    "link": "https://huggingface.co/tiiuae/falcon-180B",
    "still_on_hub": false
  },
  {
    "name": "Metis-0.3",
    "author": "Mihaiii",
    "query_name": "Mihaiii/Metis-0.3",
    "score": 65.44,
    "likes": 0.0,
    "link": "https://huggingface.co/Mihaiii/Metis-0.3",
    "still_on_hub": true
  },
  {
    "name": "Camel-Platypus2-70B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Camel-Platypus2-70B",
    "score": 65.39,
    "likes": 12.0,
    "link": "https://huggingface.co/garage-bAInd/Camel-Platypus2-70B",
    "still_on_hub": true
  },
  {
    "name": "lemur-70b-chat-v1",
    "author": "OpenLemur",
    "query_name": "OpenLemur/lemur-70b-chat-v1",
    "score": 65.38,
    "likes": 46.0,
    "link": "https://huggingface.co/OpenLemur/lemur-70b-chat-v1",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-7B-v2.03",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-7B-v2.03",
    "score": 65.34,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-7B-v2.03",
    "still_on_hub": true
  },
  {
    "name": "Yi-34B-Chat",
    "author": "01-ai",
    "query_name": "01-ai/Yi-34B-Chat",
    "score": 65.32,
    "likes": 21.0,
    "link": "https://huggingface.co/01-ai/Yi-34B-Chat",
    "still_on_hub": true
  },
  {
    "name": "llama2-70B-qlora-gpt4",
    "author": "liuxiang886",
    "query_name": "liuxiang886/llama2-70B-qlora-gpt4",
    "score": 65.29,
    "likes": 0.0,
    "link": "https://huggingface.co/liuxiang886/llama2-70B-qlora-gpt4",
    "still_on_hub": true
  },
  {
    "name": "Writing_Partner_Mistral_7B",
    "author": "FPHam",
    "query_name": "FPHam/Writing_Partner_Mistral_7B",
    "score": 65.29,
    "likes": 14.0,
    "link": "https://huggingface.co/FPHam/Writing_Partner_Mistral_7B",
    "still_on_hub": true
  },
  {
    "name": "MadMix-v0.1",
    "author": "Fredithefish",
    "query_name": "Fredithefish/MadMix-v0.1",
    "score": 65.26,
    "likes": 0.0,
    "link": "https://huggingface.co/Fredithefish/MadMix-v0.1",
    "still_on_hub": true
  },
  {
    "name": "MathHermes-2.5-Mistral-7B",
    "author": "simonveitner",
    "query_name": "simonveitner/MathHermes-2.5-Mistral-7B",
    "score": 65.24,
    "likes": 0.0,
    "link": "https://huggingface.co/simonveitner/MathHermes-2.5-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-70b-fb16-korean",
    "author": "quantumaikr",
    "query_name": "quantumaikr/llama-2-70b-fb16-korean",
    "score": 65.23,
    "likes": 28.0,
    "link": "https://huggingface.co/quantumaikr/llama-2-70b-fb16-korean",
    "still_on_hub": true
  },
  {
    "name": "OpenOrca-Zephyr-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/OpenOrca-Zephyr-7B",
    "score": 64.97,
    "likes": 2.0,
    "link": "https://huggingface.co/Weyaxi/OpenOrca-Zephyr-7B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-70b-gpt4-1.4.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-70b-gpt4-1.4.1",
    "score": 64.97,
    "likes": 46.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-1.4.1",
    "still_on_hub": true
  },
  {
    "name": "dolphin-2.2.1-mistral-7b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-2.2.1-mistral-7b",
    "score": 64.93,
    "likes": 105.0,
    "link": "https://huggingface.co/ehartford/dolphin-2.2.1-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "Nous-Puffin-70B",
    "author": "NousResearch",
    "query_name": "NousResearch/Nous-Puffin-70B",
    "score": 64.91,
    "likes": 16.0,
    "link": "https://huggingface.co/NousResearch/Nous-Puffin-70B",
    "still_on_hub": true
  },
  {
    "name": "llama2_70b_chat_uncensored",
    "author": "jarradh",
    "query_name": "jarradh/llama2_70b_chat_uncensored",
    "score": 64.88,
    "likes": 37.0,
    "link": "https://huggingface.co/jarradh/llama2_70b_chat_uncensored",
    "still_on_hub": true
  },
  {
    "name": "llama-2-70B-LoRA-assemble-v2",
    "author": "oh-yeontaek",
    "query_name": "oh-yeontaek/llama-2-70B-LoRA-assemble-v2",
    "score": 64.73,
    "likes": 2.0,
    "link": "https://huggingface.co/oh-yeontaek/llama-2-70B-LoRA-assemble-v2",
    "still_on_hub": true
  },
  {
    "name": "speechless-mistral-7b-dare-0.85",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-mistral-7b-dare-0.85",
    "score": 64.69,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-mistral-7b-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "Euryale-L2-70B",
    "author": "Sao10K",
    "query_name": "Sao10K/Euryale-L2-70B",
    "score": 64.66,
    "likes": 8.0,
    "link": "https://huggingface.co/Sao10K/Euryale-L2-70B",
    "still_on_hub": true
  },
  {
    "name": "PiVoT-0.1-early",
    "author": "maywell",
    "query_name": "maywell/PiVoT-0.1-early",
    "score": 64.58,
    "likes": 0.0,
    "link": "https://huggingface.co/maywell/PiVoT-0.1-early",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-70b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-70b-gpt4-m2.0",
    "score": 64.56,
    "likes": 10.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-70B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Llama-2-70B-fp16",
    "score": 64.52,
    "likes": 40.0,
    "link": "https://huggingface.co/TheBloke/Llama-2-70B-fp16",
    "still_on_hub": true
  },
  {
    "name": "llama-65b-instruct",
    "author": "upstage",
    "query_name": "upstage/llama-65b-instruct",
    "score": 64.51,
    "likes": 9.0,
    "link": "https://huggingface.co/upstage/llama-65b-instruct",
    "still_on_hub": true
  },
  {
    "name": "SauerkrautLM-7b-HerO",
    "author": "VAGOsolutions",
    "query_name": "VAGOsolutions/SauerkrautLM-7b-HerO",
    "score": 64.49,
    "likes": 16.0,
    "link": "https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama-65b-v8-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-llama-65b-v8-bf16",
    "score": 64.47,
    "likes": 8.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama-65b-v8-bf16",
    "still_on_hub": true
  },
  {
    "name": "llama2-70b-oasst-sft-v10",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/llama2-70b-oasst-sft-v10",
    "score": 64.47,
    "likes": 64.0,
    "link": "https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10",
    "still_on_hub": true
  },
  {
    "name": "Starling-LM-11B-alpha-v1",
    "author": "NurtureAI",
    "query_name": "NurtureAI/Starling-LM-11B-alpha-v1",
    "score": 64.44,
    "likes": 0.0,
    "link": "https://huggingface.co/NurtureAI/Starling-LM-11B-alpha-v1",
    "still_on_hub": false
  },
  {
    "name": "OpenHermes-7B-Symbolic",
    "author": "hedronstone",
    "query_name": "hedronstone/OpenHermes-7B-Symbolic",
    "score": 64.44,
    "likes": 0.0,
    "link": "https://huggingface.co/hedronstone/OpenHermes-7B-Symbolic",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-7B-Reasoner",
    "author": "hedronstone",
    "query_name": "hedronstone/OpenHermes-7B-Reasoner",
    "score": 64.44,
    "likes": 0.0,
    "link": "https://huggingface.co/hedronstone/OpenHermes-7B-Reasoner",
    "still_on_hub": true
  },
  {
    "name": "medilora-mistral-7b",
    "author": "Medilora",
    "query_name": "Medilora/medilora-mistral-7b",
    "score": 64.41,
    "likes": 0.0,
    "link": "https://huggingface.co/Medilora/medilora-mistral-7b",
    "still_on_hub": false
  },
  {
    "name": "chronos-70b-v2",
    "author": "elinas",
    "query_name": "elinas/chronos-70b-v2",
    "score": 64.41,
    "likes": 9.0,
    "link": "https://huggingface.co/elinas/chronos-70b-v2",
    "still_on_hub": true
  },
  {
    "name": "Mistral-dpo-v1",
    "author": "xxyyy123",
    "query_name": "xxyyy123/Mistral-dpo-v1",
    "score": 64.39,
    "likes": 0.0,
    "link": "https://huggingface.co/xxyyy123/Mistral-dpo-v1",
    "still_on_hub": false
  },
  {
    "name": "v1olet_merged_dpo_7B_v4",
    "author": "v1olet",
    "query_name": "v1olet/v1olet_merged_dpo_7B_v4",
    "score": 64.3,
    "likes": 0.0,
    "link": "https://huggingface.co/v1olet/v1olet_merged_dpo_7B_v4",
    "still_on_hub": true
  },
  {
    "name": "PiVoT-10.7B-Mistral-v0.2",
    "author": "maywell",
    "query_name": "maywell/PiVoT-10.7B-Mistral-v0.2",
    "score": 64.25,
    "likes": 1.0,
    "link": "https://huggingface.co/maywell/PiVoT-10.7B-Mistral-v0.2",
    "still_on_hub": true
  },
  {
    "name": "model_420_preview",
    "author": "psmathur",
    "query_name": "psmathur/model_420_preview",
    "score": 64.22,
    "likes": 0.0,
    "link": "https://huggingface.co/psmathur/model_420_preview",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-70b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-70b-gpt4-2.0",
    "score": 64.14,
    "likes": 12.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "llama-65b-hf",
    "author": "Enoch",
    "query_name": "Enoch/llama-65b-hf",
    "score": 63.99,
    "likes": 3.0,
    "link": "https://huggingface.co/Enoch/llama-65b-hf",
    "still_on_hub": true
  },
  {
    "name": "UltraLM-65b",
    "author": "openbmb",
    "query_name": "openbmb/UltraLM-65b",
    "score": 63.82,
    "likes": 6.0,
    "link": "https://huggingface.co/openbmb/UltraLM-65b",
    "still_on_hub": false
  },
  {
    "name": "14B",
    "author": "CausalLM",
    "query_name": "CausalLM/14B",
    "score": 63.81,
    "likes": 220.0,
    "link": "https://huggingface.co/CausalLM/14B",
    "still_on_hub": false
  },
  {
    "name": "medilora-qwen-14b",
    "author": "Medilora",
    "query_name": "Medilora/medilora-qwen-14b",
    "score": 63.81,
    "likes": 0.0,
    "link": "https://huggingface.co/Medilora/medilora-qwen-14b",
    "still_on_hub": false
  },
  {
    "name": "CausalLM-Platypus-14B",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/CausalLM-Platypus-14B",
    "score": 63.8,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/CausalLM-Platypus-14B",
    "still_on_hub": true
  },
  {
    "name": "tigerbot-70b-base",
    "author": "TigerResearch",
    "query_name": "TigerResearch/tigerbot-70b-base",
    "score": 63.71,
    "likes": 11.0,
    "link": "https://huggingface.co/TigerResearch/tigerbot-70b-base",
    "still_on_hub": true
  },
  {
    "name": "Starling-LM-11B-alpha",
    "author": "Delcos",
    "query_name": "Delcos/Starling-LM-11B-alpha",
    "score": 63.66,
    "likes": 1.0,
    "link": "https://huggingface.co/Delcos/Starling-LM-11B-alpha",
    "still_on_hub": true
  },
  {
    "name": "gpt4-alpaca-lora_mlp-65B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/gpt4-alpaca-lora_mlp-65B-HF",
    "score": 63.66,
    "likes": 7.0,
    "link": "https://huggingface.co/TheBloke/gpt4-alpaca-lora_mlp-65B-HF",
    "still_on_hub": true
  },
  {
    "name": "openinstruct-mistral-7b",
    "author": "monology",
    "query_name": "monology/openinstruct-mistral-7b",
    "score": 63.64,
    "likes": 0.0,
    "link": "https://huggingface.co/monology/openinstruct-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "speechless-code-mistral-7b-v1.0",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-code-mistral-7b-v1.0",
    "score": 63.6,
    "likes": 7.0,
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-7b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "higgs-llama-vicuna-ep25-70b",
    "author": "luffycodes",
    "query_name": "luffycodes/higgs-llama-vicuna-ep25-70b",
    "score": 63.6,
    "likes": 1.0,
    "link": "https://huggingface.co/luffycodes/higgs-llama-vicuna-ep25-70b",
    "still_on_hub": true
  },
  {
    "name": "Falkor-16b",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Falkor-16b",
    "score": 63.52,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Falkor-16b",
    "still_on_hub": true
  },
  {
    "name": "notus-7b-v1",
    "author": "argilla",
    "query_name": "argilla/notus-7b-v1",
    "score": 63.49,
    "likes": 11.0,
    "link": "https://huggingface.co/argilla/notus-7b-v1",
    "still_on_hub": true
  },
  {
    "name": "Mistral7B_adaptor_v1",
    "author": "xxyyy123",
    "query_name": "xxyyy123/Mistral7B_adaptor_v1",
    "score": 63.42,
    "likes": 0.0,
    "link": "https://huggingface.co/xxyyy123/Mistral7B_adaptor_v1",
    "still_on_hub": false
  },
  {
    "name": "Chupacabra-16B-v2.01",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-16B-v2.01",
    "score": 63.42,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-16B-v2.01",
    "still_on_hub": true
  },
  {
    "name": "tora-70b-v1.0",
    "author": "llm-agents",
    "query_name": "llm-agents/tora-70b-v1.0",
    "score": 63.39,
    "likes": 8.0,
    "link": "https://huggingface.co/llm-agents/tora-70b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "Mini_Synatra_SFT",
    "author": "maywell",
    "query_name": "maywell/Mini_Synatra_SFT",
    "score": 63.39,
    "likes": 0.0,
    "link": "https://huggingface.co/maywell/Mini_Synatra_SFT",
    "still_on_hub": true
  },
  {
    "name": "1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
    "author": "xxyyy123",
    "query_name": "xxyyy123/1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
    "score": 63.37,
    "likes": 0.0,
    "link": "https://huggingface.co/xxyyy123/1701221123_Ads_Mistral7B-slimorca_all-Lqv-r4b128",
    "still_on_hub": false
  },
  {
    "name": "DeciLM-7B-instruct",
    "author": "Deci",
    "query_name": "Deci/DeciLM-7B-instruct",
    "score": 63.19,
    "likes": 3.0,
    "link": "https://huggingface.co/Deci/DeciLM-7B-instruct",
    "still_on_hub": true
  },
  {
    "name": "Yi-34B-Chat",
    "author": "01-ai",
    "query_name": "01-ai/Yi-34B-Chat",
    "score": 63.17,
    "likes": 18.0,
    "link": "https://huggingface.co/01-ai/Yi-34B-Chat",
    "still_on_hub": true
  },
  {
    "name": "testllm-c2",
    "author": "Kiddyz",
    "query_name": "Kiddyz/testllm-c2",
    "score": 63.13,
    "likes": 0.0,
    "link": "https://huggingface.co/Kiddyz/testllm-c2",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-falcon-180b-v12-preview0",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-falcon-180b-v12-preview0",
    "score": 63.06,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-falcon-180b-v12-preview0",
    "still_on_hub": true
  },
  {
    "name": "LLaMA_2_13B_SFT_v1",
    "author": "adonlee",
    "query_name": "adonlee/LLaMA_2_13B_SFT_v1",
    "score": 63.04,
    "likes": 0.0,
    "link": "https://huggingface.co/adonlee/LLaMA_2_13B_SFT_v1",
    "still_on_hub": true
  },
  {
    "name": "Airoboros-L2-70B-2.1-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Airoboros-L2-70B-2.1-GPTQ",
    "score": 63.04,
    "likes": 14.0,
    "link": "https://huggingface.co/TheBloke/Airoboros-L2-70B-2.1-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "blossom-v3-mistral-7b",
    "author": "Azure99",
    "query_name": "Azure99/blossom-v3-mistral-7b",
    "score": 62.95,
    "likes": 0.0,
    "link": "https://huggingface.co/Azure99/blossom-v3-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "CollectiveCognition-v1.1-Mistral-7B",
    "author": "teknium",
    "query_name": "teknium/CollectiveCognition-v1.1-Mistral-7B",
    "score": 62.92,
    "likes": 45.0,
    "link": "https://huggingface.co/teknium/CollectiveCognition-v1.1-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "MelangeA-70b",
    "author": "chargoddard",
    "query_name": "chargoddard/MelangeA-70b",
    "score": 62.82,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/MelangeA-70b",
    "still_on_hub": true
  },
  {
    "name": "llama-65b",
    "author": "huggyllama",
    "query_name": "huggyllama/llama-65b",
    "score": 62.79,
    "likes": 64.0,
    "link": "https://huggingface.co/huggyllama/llama-65b",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-1-dare-0.85",
    "author": "uukuguy",
    "query_name": "uukuguy/neural-chat-7b-v3-1-dare-0.85",
    "score": 62.74,
    "likes": 1.0,
    "link": "https://huggingface.co/uukuguy/neural-chat-7b-v3-1-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "ARIA-70B-V3",
    "author": "Faradaylab",
    "query_name": "Faradaylab/ARIA-70B-V3",
    "score": 62.73,
    "likes": 0.0,
    "link": "https://huggingface.co/Faradaylab/ARIA-70B-V3",
    "still_on_hub": true
  },
  {
    "name": "SG-Raccoon-Yi-200k-2.0",
    "author": "mlinmg",
    "query_name": "mlinmg/SG-Raccoon-Yi-200k-2.0",
    "score": 62.72,
    "likes": 0.0,
    "link": "https://huggingface.co/mlinmg/SG-Raccoon-Yi-200k-2.0",
    "still_on_hub": true
  },
  {
    "name": "MadMix-v0.2",
    "author": "Fredithefish",
    "query_name": "Fredithefish/MadMix-v0.2",
    "score": 62.72,
    "likes": 0.0,
    "link": "https://huggingface.co/Fredithefish/MadMix-v0.2",
    "still_on_hub": true
  },
  {
    "name": "guanaco-65B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/guanaco-65B-HF",
    "score": 62.67,
    "likes": 26.0,
    "link": "https://huggingface.co/TheBloke/guanaco-65B-HF",
    "still_on_hub": true
  },
  {
    "name": "Tess-XS-v1-3-yarn-128K",
    "author": "migtissera",
    "query_name": "migtissera/Tess-XS-v1-3-yarn-128K",
    "score": 62.66,
    "likes": 6.0,
    "link": "https://huggingface.co/migtissera/Tess-XS-v1-3-yarn-128K",
    "still_on_hub": true
  },
  {
    "name": "llama-2-70b-IA3-guanaco",
    "author": "yeontaek",
    "query_name": "yeontaek/llama-2-70b-IA3-guanaco",
    "score": 62.61,
    "likes": 1.0,
    "link": "https://huggingface.co/yeontaek/llama-2-70b-IA3-guanaco",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-70b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-70b-gpt4-2.0",
    "score": 62.6,
    "likes": 12.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-70b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "VicUnlocked-alpaca-65B-QLoRA-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16",
    "score": 62.58,
    "likes": 9.0,
    "link": "https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-fp16",
    "still_on_hub": true
  },
  {
    "name": "blossom-v3_1-mistral-7b",
    "author": "Azure99",
    "query_name": "Azure99/blossom-v3_1-mistral-7b",
    "score": 62.53,
    "likes": 0.0,
    "link": "https://huggingface.co/Azure99/blossom-v3_1-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "Tess-XS-v1-3-yarn-128K",
    "author": "migtissera",
    "query_name": "migtissera/Tess-XS-v1-3-yarn-128K",
    "score": 62.49,
    "likes": 7.0,
    "link": "https://huggingface.co/migtissera/Tess-XS-v1-3-yarn-128K",
    "still_on_hub": true
  },
  {
    "name": "ShiningValiantXS",
    "author": "ValiantLabs",
    "query_name": "ValiantLabs/ShiningValiantXS",
    "score": 62.48,
    "likes": 4.0,
    "link": "https://huggingface.co/ValiantLabs/ShiningValiantXS",
    "still_on_hub": true
  },
  {
    "name": "Kant-Test-0.1-Mistral-7B",
    "author": "Zardos",
    "query_name": "Zardos/Kant-Test-0.1-Mistral-7B",
    "score": 62.42,
    "likes": 0.0,
    "link": "https://huggingface.co/Zardos/Kant-Test-0.1-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-70b-chat-hf",
    "author": "meta-llama",
    "query_name": "meta-llama/Llama-2-70b-chat-hf",
    "score": 62.4,
    "likes": 1453.0,
    "link": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf",
    "still_on_hub": false
  },
  {
    "name": "ARIA-70B-French",
    "author": "willyninja30",
    "query_name": "willyninja30/ARIA-70B-French",
    "score": 62.37,
    "likes": 0.0,
    "link": "https://huggingface.co/willyninja30/ARIA-70B-French",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-1.2",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-1.2",
    "score": 62.36,
    "likes": 21.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.2",
    "still_on_hub": true
  },
  {
    "name": "zephyr-7b-alpha-dare-0.85",
    "author": "uukuguy",
    "query_name": "uukuguy/zephyr-7b-alpha-dare-0.85",
    "score": 62.35,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/zephyr-7b-alpha-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "Orca2-13B-selfmerge-39B",
    "author": "vmajor",
    "query_name": "vmajor/Orca2-13B-selfmerge-39B",
    "score": 62.24,
    "likes": 0.0,
    "link": "https://huggingface.co/vmajor/Orca2-13B-selfmerge-39B",
    "still_on_hub": true
  },
  {
    "name": "Orca2-13B-selfmerge-26B",
    "author": "vmajor",
    "query_name": "vmajor/Orca2-13B-selfmerge-26B",
    "score": 62.24,
    "likes": 0.0,
    "link": "https://huggingface.co/vmajor/Orca2-13B-selfmerge-26B",
    "still_on_hub": true
  },
  {
    "name": "Tess-7B-v1.4",
    "author": "migtissera",
    "query_name": "migtissera/Tess-7B-v1.4",
    "score": 62.19,
    "likes": 0.0,
    "link": "https://huggingface.co/migtissera/Tess-7B-v1.4",
    "still_on_hub": true
  },
  {
    "name": "Orca-2-13b-f16",
    "author": "uukuguy",
    "query_name": "uukuguy/Orca-2-13b-f16",
    "score": 62.14,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/Orca-2-13b-f16",
    "still_on_hub": true
  },
  {
    "name": "lemur-70b-v1",
    "author": "OpenLemur",
    "query_name": "OpenLemur/lemur-70b-v1",
    "score": 62.07,
    "likes": 31.0,
    "link": "https://huggingface.co/OpenLemur/lemur-70b-v1",
    "still_on_hub": true
  },
  {
    "name": "speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
    "score": 62.06,
    "likes": 1.0,
    "link": "https://huggingface.co/uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "Alpaca-elina-65b",
    "author": "Aeala",
    "query_name": "Aeala/Alpaca-elina-65b",
    "score": 62.03,
    "likes": 3.0,
    "link": "https://huggingface.co/Aeala/Alpaca-elina-65b",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-200K-Q",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-200K-Q",
    "score": 62.0,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-200K-Q",
    "still_on_hub": true
  },
  {
    "name": "Iambe-20b-DARE-v2",
    "author": "athirdpath",
    "query_name": "athirdpath/Iambe-20b-DARE-v2",
    "score": 61.99,
    "likes": 4.0,
    "link": "https://huggingface.co/athirdpath/Iambe-20b-DARE-v2",
    "still_on_hub": true
  },
  {
    "name": "zephyr-beta-math",
    "author": "abhishek",
    "query_name": "abhishek/zephyr-beta-math",
    "score": 61.99,
    "likes": 3.0,
    "link": "https://huggingface.co/abhishek/zephyr-beta-math",
    "still_on_hub": true
  },
  {
    "name": "Synthia-7B-v3.0",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-7B-v3.0",
    "score": 61.99,
    "likes": 13.0,
    "link": "https://huggingface.co/migtissera/Synthia-7B-v3.0",
    "still_on_hub": true
  },
  {
    "name": "MelangeC-70b",
    "author": "chargoddard",
    "query_name": "chargoddard/MelangeC-70b",
    "score": 61.96,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/MelangeC-70b",
    "still_on_hub": true
  },
  {
    "name": "ARIA-70B-V2",
    "author": "Faradaylab",
    "query_name": "Faradaylab/ARIA-70B-V2",
    "score": 61.93,
    "likes": 7.0,
    "link": "https://huggingface.co/Faradaylab/ARIA-70B-V2",
    "still_on_hub": true
  },
  {
    "name": "MythoMist-7b",
    "author": "Gryphe",
    "query_name": "Gryphe/MythoMist-7b",
    "score": 61.67,
    "likes": 0.0,
    "link": "https://huggingface.co/Gryphe/MythoMist-7b",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-finetuned-orca-dpo-v2",
    "author": "lvkaokao",
    "query_name": "lvkaokao/mistral-7b-finetuned-orca-dpo-v2",
    "score": 61.59,
    "likes": 0.0,
    "link": "https://huggingface.co/lvkaokao/mistral-7b-finetuned-orca-dpo-v2",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-1",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3-1",
    "score": 61.59,
    "likes": 12.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-1",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3-1",
    "score": 61.59,
    "likes": 12.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "still_on_hub": true
  },
  {
    "name": "NSFW_DPO_Noromaid-7b",
    "author": "athirdpath",
    "query_name": "athirdpath/NSFW_DPO_Noromaid-7b",
    "score": 61.59,
    "likes": 0.0,
    "link": "https://huggingface.co/athirdpath/NSFW_DPO_Noromaid-7b",
    "still_on_hub": true
  },
  {
    "name": "zephyr-7b-beta",
    "author": "HuggingFaceH4",
    "query_name": "HuggingFaceH4/zephyr-7b-beta",
    "score": 61.59,
    "likes": 976.0,
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "still_on_hub": true
  },
  {
    "name": "DeciLM-7B",
    "author": "Deci",
    "query_name": "Deci/DeciLM-7B",
    "score": 61.55,
    "likes": 3.0,
    "link": "https://huggingface.co/Deci/DeciLM-7B",
    "still_on_hub": true
  },
  {
    "name": "zephyr-7b-dpo-full-beta-0.2",
    "author": "tianlinliu0121",
    "query_name": "tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "score": 61.55,
    "likes": 0.0,
    "link": "https://huggingface.co/tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-1",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3-1",
    "score": 61.54,
    "likes": 12.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-2.5-Mistral-7B",
    "author": "teknium",
    "query_name": "teknium/OpenHermes-2.5-Mistral-7B",
    "score": 61.52,
    "likes": 125.0,
    "link": "https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "Noromaid-7b-v0.1.1",
    "author": "NeverSleep",
    "query_name": "NeverSleep/Noromaid-7b-v0.1.1",
    "score": 61.49,
    "likes": 3.0,
    "link": "https://huggingface.co/NeverSleep/Noromaid-7b-v0.1.1",
    "still_on_hub": true
  },
  {
    "name": "robin-65b-v2-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/robin-65b-v2-fp16",
    "score": 61.48,
    "likes": 3.0,
    "link": "https://huggingface.co/TheBloke/robin-65b-v2-fp16",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-2.5-Mistral-7B",
    "author": "teknium",
    "query_name": "teknium/OpenHermes-2.5-Mistral-7B",
    "score": 61.45,
    "likes": 115.0,
    "link": "https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "speechless-llama2-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-llama2-13b",
    "score": 61.36,
    "likes": 4.0,
    "link": "https://huggingface.co/uukuguy/speechless-llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "zephyr-7b-dpo-full-beta-0.2",
    "author": "tianlinliu0121",
    "query_name": "tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "score": 61.36,
    "likes": 0.0,
    "link": "https://huggingface.co/tianlinliu0121/zephyr-7b-dpo-full-beta-0.2",
    "still_on_hub": true
  },
  {
    "name": "alpaca-lora-65B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/alpaca-lora-65B-HF",
    "score": 61.33,
    "likes": 3.0,
    "link": "https://huggingface.co/TheBloke/alpaca-lora-65B-HF",
    "still_on_hub": true
  },
  {
    "name": "phi-2",
    "author": "microsoft",
    "query_name": "microsoft/phi-2",
    "score": 61.33,
    "likes": 13.0,
    "link": "https://huggingface.co/microsoft/phi-2",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
    "author": "NickyNicky",
    "query_name": "NickyNicky/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
    "score": 61.26,
    "likes": 3.0,
    "link": "https://huggingface.co/NickyNicky/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-70B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardLM-70B-V1.0",
    "score": 61.25,
    "likes": 112.0,
    "link": "https://huggingface.co/WizardLM/WizardLM-70B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "openchat_3.5",
    "author": "openchat",
    "query_name": "openchat/openchat_3.5",
    "score": 61.24,
    "likes": 517.0,
    "link": "https://huggingface.co/openchat/openchat_3.5",
    "still_on_hub": true
  },
  {
    "name": "Mini_DPO_test02",
    "author": "Minirecord",
    "query_name": "Minirecord/Mini_DPO_test02",
    "score": 61.23,
    "likes": 0.0,
    "link": "https://huggingface.co/Minirecord/Mini_DPO_test02",
    "still_on_hub": true
  },
  {
    "name": "openchat_3.5",
    "author": "openchat",
    "query_name": "openchat/openchat_3.5",
    "score": 61.22,
    "likes": 517.0,
    "link": "https://huggingface.co/openchat/openchat_3.5",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-2.0",
    "score": 61.2,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "llama-65b",
    "author": "huggingface",
    "query_name": "huggingface/llama-65b",
    "score": 61.19,
    "likes": 0.0,
    "link": "https://huggingface.co/huggingface/llama-65b",
    "still_on_hub": false
  },
  {
    "name": "mistral-7b-slimorcaboros",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/mistral-7b-slimorcaboros",
    "score": 61.18,
    "likes": 1.0,
    "link": "https://huggingface.co/openaccess-ai-collective/mistral-7b-slimorcaboros",
    "still_on_hub": true
  },
  {
    "name": "jackalope-7b",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/jackalope-7b",
    "score": 61.16,
    "likes": 16.0,
    "link": "https://huggingface.co/openaccess-ai-collective/jackalope-7b",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-ft-h4-no_robots_instructions",
    "author": "mrm8488",
    "query_name": "mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "score": 61.16,
    "likes": 9.0,
    "link": "https://huggingface.co/mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-ft-h4-no_robots_instructions",
    "author": "mrm8488",
    "query_name": "mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "score": 61.16,
    "likes": 9.0,
    "link": "https://huggingface.co/mrm8488/mistral-7b-ft-h4-no_robots_instructions",
    "still_on_hub": true
  },
  {
    "name": "PlatYi-34B-Llama-Q-v3",
    "author": "kyujinpy",
    "query_name": "kyujinpy/PlatYi-34B-Llama-Q-v3",
    "score": 61.15,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/PlatYi-34B-Llama-Q-v3",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-2.0",
    "score": 61.14,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "dolphin-2.1-mistral-7b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-2.1-mistral-7b",
    "score": 61.12,
    "likes": 54.0,
    "link": "https://huggingface.co/ehartford/dolphin-2.1-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "Kant-Test-0.1-Mistral-7B",
    "author": "Zardos",
    "query_name": "Zardos/Kant-Test-0.1-Mistral-7B",
    "score": 61.1,
    "likes": 0.0,
    "link": "https://huggingface.co/Zardos/Kant-Test-0.1-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "Dans-07YahooAnswers-7b",
    "author": "Dans-DiscountModels",
    "query_name": "Dans-DiscountModels/Dans-07YahooAnswers-7b",
    "score": 61.07,
    "likes": 1.0,
    "link": "https://huggingface.co/Dans-DiscountModels/Dans-07YahooAnswers-7b",
    "still_on_hub": true
  },
  {
    "name": "dolphin-2.1-mistral-7b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-2.1-mistral-7b",
    "score": 61.0,
    "likes": 54.0,
    "link": "https://huggingface.co/ehartford/dolphin-2.1-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-v0.1",
    "author": "mistralai",
    "query_name": "mistralai/Mistral-7B-v0.1",
    "score": 60.97,
    "likes": 1173.0,
    "link": "https://huggingface.co/mistralai/Mistral-7B-v0.1",
    "still_on_hub": true
  },
  {
    "name": "llama-30b-instruct-2048",
    "author": "upstage",
    "query_name": "upstage/llama-30b-instruct-2048",
    "score": 60.91,
    "likes": 102.0,
    "link": "https://huggingface.co/upstage/llama-30b-instruct-2048",
    "still_on_hub": true
  },
  {
    "name": "alpaca-lora-65b-en-pt-es-ca",
    "author": "HiTZ",
    "query_name": "HiTZ/alpaca-lora-65b-en-pt-es-ca",
    "score": 60.89,
    "likes": 2.0,
    "link": "https://huggingface.co/HiTZ/alpaca-lora-65b-en-pt-es-ca",
    "still_on_hub": false
  },
  {
    "name": "SlimOpenOrca-Mistral-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/SlimOpenOrca-Mistral-7B",
    "score": 60.84,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/SlimOpenOrca-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "30B-Epsilon",
    "author": "CalderaAI",
    "query_name": "CalderaAI/30B-Epsilon",
    "score": 60.8,
    "likes": 9.0,
    "link": "https://huggingface.co/CalderaAI/30B-Epsilon",
    "still_on_hub": true
  },
  {
    "name": "speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "score": 60.79,
    "likes": 7.0,
    "link": "https://huggingface.co/uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-m2.0",
    "score": 60.79,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama-30b-v7.1-bf16",
    "author": "OpenBuddyEA",
    "query_name": "OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "score": 60.76,
    "likes": 6.0,
    "link": "https://huggingface.co/OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "still_on_hub": true
  },
  {
    "name": "speechless-mistral-six-in-one-7b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-mistral-six-in-one-7b",
    "score": 60.76,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-mistral-six-in-one-7b",
    "still_on_hub": true
  },
  {
    "name": "GPT4-X-Alpasta-30b",
    "author": "MetaIX",
    "query_name": "MetaIX/GPT4-X-Alpasta-30b",
    "score": 60.76,
    "likes": 64.0,
    "link": "https://huggingface.co/MetaIX/GPT4-X-Alpasta-30b",
    "still_on_hub": true
  },
  {
    "name": "oasst-rlhf-2-llama-30b-7k-steps-hf",
    "author": "Yhyu13",
    "query_name": "Yhyu13/oasst-rlhf-2-llama-30b-7k-steps-hf",
    "score": 60.74,
    "likes": 6.0,
    "link": "https://huggingface.co/Yhyu13/oasst-rlhf-2-llama-30b-7k-steps-hf",
    "still_on_hub": true
  },
  {
    "name": "Venomia-m7",
    "author": "Sao10K",
    "query_name": "Sao10K/Venomia-m7",
    "score": 60.74,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Venomia-m7",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama-30b-v7.1-bf16",
    "author": "OpenBuddyEA",
    "query_name": "OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "score": 60.71,
    "likes": 6.0,
    "link": "https://huggingface.co/OpenBuddyEA/openbuddy-llama-30b-v7.1-bf16",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-m2.0",
    "score": 60.68,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-1.4-peft",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-1.4-peft",
    "score": 60.67,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.4-peft",
    "still_on_hub": false
  },
  {
    "name": "airoboros-65b-gpt4-1.4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-1.4",
    "score": 60.67,
    "likes": 16.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.4",
    "still_on_hub": true
  },
  {
    "name": "Zephyrus-L1-33B",
    "author": "Sao10K",
    "query_name": "Sao10K/Zephyrus-L1-33B",
    "score": 60.61,
    "likes": 2.0,
    "link": "https://huggingface.co/Sao10K/Zephyrus-L1-33B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-1.4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-1.4",
    "score": 60.59,
    "likes": 16.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.4",
    "still_on_hub": true
  },
  {
    "name": "Synatra-7B-v0.3-dpo",
    "author": "maywell",
    "query_name": "maywell/Synatra-7B-v0.3-dpo",
    "score": 60.55,
    "likes": 6.0,
    "link": "https://huggingface.co/maywell/Synatra-7B-v0.3-dpo",
    "still_on_hub": true
  },
  {
    "name": "dolphin-2.2.1-mistral-7b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-2.2.1-mistral-7b",
    "score": 60.54,
    "likes": 84.0,
    "link": "https://huggingface.co/ehartford/dolphin-2.2.1-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "Mistral-11B-TestBench9",
    "author": "Undi95",
    "query_name": "Undi95/Mistral-11B-TestBench9",
    "score": 60.52,
    "likes": 0.0,
    "link": "https://huggingface.co/Undi95/Mistral-11B-TestBench9",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-70B-V1.0-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-70B-V1.0-GPTQ",
    "score": 60.5,
    "likes": 26.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-70B-V1.0-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Dolphin2.1-OpenOrca-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Dolphin2.1-OpenOrca-7B",
    "score": 60.47,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Dolphin2.1-OpenOrca-7B",
    "still_on_hub": true
  },
  {
    "name": "oasst-sft-6-llama-33b-xor-MERGED-16bit",
    "author": "TehVenom",
    "query_name": "TehVenom/oasst-sft-6-llama-33b-xor-MERGED-16bit",
    "score": 60.45,
    "likes": 3.0,
    "link": "https://huggingface.co/TehVenom/oasst-sft-6-llama-33b-xor-MERGED-16bit",
    "still_on_hub": true
  },
  {
    "name": "GPT4-x-AlpacaDente-30b",
    "author": "Aeala",
    "query_name": "Aeala/GPT4-x-AlpacaDente-30b",
    "score": 60.43,
    "likes": 3.0,
    "link": "https://huggingface.co/Aeala/GPT4-x-AlpacaDente-30b",
    "still_on_hub": true
  },
  {
    "name": "WizardMath-70B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardMath-70B-V1.0",
    "score": 60.42,
    "likes": 95.0,
    "link": "https://huggingface.co/WizardLM/WizardMath-70B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "WizardMath-70B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardMath-70B-V1.0",
    "score": 60.41,
    "likes": 95.0,
    "link": "https://huggingface.co/WizardLM/WizardMath-70B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "SlimOrca-13B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/SlimOrca-13B",
    "score": 60.39,
    "likes": 1.0,
    "link": "https://huggingface.co/ajibawa-2023/SlimOrca-13B",
    "still_on_hub": true
  },
  {
    "name": "speechless-mistral-7b-dare-0.85",
    "author": "speechlessai",
    "query_name": "speechlessai/speechless-mistral-7b-dare-0.85",
    "score": 60.39,
    "likes": 0.0,
    "link": "https://huggingface.co/speechlessai/speechless-mistral-7b-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "Dolphin2.1-OpenOrca-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Dolphin2.1-OpenOrca-7B",
    "score": 60.38,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Dolphin2.1-OpenOrca-7B",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-SlimOrca",
    "author": "Open-Orca",
    "query_name": "Open-Orca/Mistral-7B-SlimOrca",
    "score": 60.37,
    "likes": 4.0,
    "link": "https://huggingface.co/Open-Orca/Mistral-7B-SlimOrca",
    "still_on_hub": true
  },
  {
    "name": "openchat_3.5",
    "author": "openchat",
    "query_name": "openchat/openchat_3.5",
    "score": 60.26,
    "likes": 535.0,
    "link": "https://huggingface.co/openchat/openchat_3.5",
    "still_on_hub": true
  },
  {
    "name": "SlimOpenOrca-Mistral-7B-v2",
    "author": "PulsarAI",
    "query_name": "PulsarAI/SlimOpenOrca-Mistral-7B-v2",
    "score": 60.25,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/SlimOpenOrca-Mistral-7B-v2",
    "still_on_hub": true
  },
  {
    "name": "Mistral-11B-TestBench11",
    "author": "Undi95",
    "query_name": "Undi95/Mistral-11B-TestBench11",
    "score": 60.25,
    "likes": 7.0,
    "link": "https://huggingface.co/Undi95/Mistral-11B-TestBench11",
    "still_on_hub": true
  },
  {
    "name": "wendigo-14b-alpha4",
    "author": "MisterRid",
    "query_name": "MisterRid/wendigo-14b-alpha4",
    "score": 60.25,
    "likes": 0.0,
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha4",
    "still_on_hub": true
  },
  {
    "name": "smartyplats-7b-v2",
    "author": "vihangd",
    "query_name": "vihangd/smartyplats-7b-v2",
    "score": 60.24,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/smartyplats-7b-v2",
    "still_on_hub": true
  },
  {
    "name": "GPlatty-30B",
    "author": "lilloukas",
    "query_name": "lilloukas/GPlatty-30B",
    "score": 60.23,
    "likes": 18.0,
    "link": "https://huggingface.co/lilloukas/GPlatty-30B",
    "still_on_hub": true
  },
  {
    "name": "notus-7b-v1",
    "author": "argilla",
    "query_name": "argilla/notus-7b-v1",
    "score": 60.22,
    "likes": 0.0,
    "link": "https://huggingface.co/argilla/notus-7b-v1",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-OpenOrca",
    "author": "Open-Orca",
    "query_name": "Open-Orca/Mistral-7B-OpenOrca",
    "score": 60.17,
    "likes": 314.0,
    "link": "https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca",
    "still_on_hub": true
  },
  {
    "name": "airoboros-65b-gpt4-1.3",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-65b-gpt4-1.3",
    "score": 60.15,
    "likes": 1.0,
    "link": "https://huggingface.co/jondurbin/airoboros-65b-gpt4-1.3",
    "still_on_hub": true
  },
  {
    "name": "wendigo-14b-alpha3",
    "author": "MisterRid",
    "query_name": "MisterRid/wendigo-14b-alpha3",
    "score": 60.1,
    "likes": 0.0,
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha3",
    "still_on_hub": true
  },
  {
    "name": "CollectiveCognition-v1-Mistral-7B",
    "author": "teknium",
    "query_name": "teknium/CollectiveCognition-v1-Mistral-7B",
    "score": 60.1,
    "likes": 4.0,
    "link": "https://huggingface.co/teknium/CollectiveCognition-v1-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "ccy0-2g7e-wqsa-0",
    "author": "abhishek",
    "query_name": "abhishek/ccy0-2g7e-wqsa-0",
    "score": 60.07,
    "likes": 0.0,
    "link": "https://huggingface.co/abhishek/ccy0-2g7e-wqsa-0",
    "still_on_hub": true
  },
  {
    "name": "llama-30b-2048-instruct-PL-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/llama-30b-2048-instruct-PL-lora_unload",
    "score": 60.03,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/llama-30b-2048-instruct-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "Metis-0.1",
    "author": "Mihaiii",
    "query_name": "Mihaiii/Metis-0.1",
    "score": 60.02,
    "likes": 0.0,
    "link": "https://huggingface.co/Mihaiii/Metis-0.1",
    "still_on_hub": true
  },
  {
    "name": "Velara",
    "author": "Delcos",
    "query_name": "Delcos/Velara",
    "score": 60.01,
    "likes": 0.0,
    "link": "https://huggingface.co/Delcos/Velara",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-33B-V1.0-Uncensored",
    "author": "ehartford",
    "query_name": "ehartford/WizardLM-33B-V1.0-Uncensored",
    "score": 59.99,
    "likes": 44.0,
    "link": "https://huggingface.co/ehartford/WizardLM-33B-V1.0-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "psyonic-cetacean-20B",
    "author": "jebcarter",
    "query_name": "jebcarter/psyonic-cetacean-20B",
    "score": 59.97,
    "likes": 4.0,
    "link": "https://huggingface.co/jebcarter/psyonic-cetacean-20B",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-1",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3-1",
    "score": 59.9,
    "likes": 12.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3-1",
    "still_on_hub": true
  },
  {
    "name": "samantha-1.2-mistral-7b",
    "author": "ehartford",
    "query_name": "ehartford/samantha-1.2-mistral-7b",
    "score": 59.83,
    "likes": 8.0,
    "link": "https://huggingface.co/ehartford/samantha-1.2-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-30b-instruct-2048-PL-lora",
    "author": "Aspik101",
    "query_name": "Aspik101/llama-30b-instruct-2048-PL-lora",
    "score": 59.82,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/llama-30b-instruct-2048-PL-lora",
    "still_on_hub": true
  },
  {
    "name": "WizardMath-70B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardMath-70B-V1.0",
    "score": 59.81,
    "likes": 95.0,
    "link": "https://huggingface.co/WizardLM/WizardMath-70B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-sft-beta",
    "author": "HuggingFaceH4",
    "query_name": "HuggingFaceH4/mistral-7b-sft-beta",
    "score": 59.78,
    "likes": 14.0,
    "link": "https://huggingface.co/HuggingFaceH4/mistral-7b-sft-beta",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-70B-chat-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Llama-2-70B-chat-GPTQ",
    "score": 59.75,
    "likes": 204.0,
    "link": "https://huggingface.co/TheBloke/Llama-2-70B-chat-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Synatra-RP-Orca-2-7b-v0.1",
    "author": "maywell",
    "query_name": "maywell/Synatra-RP-Orca-2-7b-v0.1",
    "score": 59.65,
    "likes": 2.0,
    "link": "https://huggingface.co/maywell/Synatra-RP-Orca-2-7b-v0.1",
    "still_on_hub": true
  },
  {
    "name": "Orca-2-13B-no_robots",
    "author": "Locutusque",
    "query_name": "Locutusque/Orca-2-13B-no_robots",
    "score": 59.63,
    "likes": 4.0,
    "link": "https://huggingface.co/Locutusque/Orca-2-13B-no_robots",
    "still_on_hub": true
  },
  {
    "name": "Yarn-Mistral-7b-64k",
    "author": "NousResearch",
    "query_name": "NousResearch/Yarn-Mistral-7b-64k",
    "score": 59.63,
    "likes": 32.0,
    "link": "https://huggingface.co/NousResearch/Yarn-Mistral-7b-64k",
    "still_on_hub": true
  },
  {
    "name": "SynthIA-7B-v1.5",
    "author": "migtissera",
    "query_name": "migtissera/SynthIA-7B-v1.5",
    "score": 59.59,
    "likes": 0.0,
    "link": "https://huggingface.co/migtissera/SynthIA-7B-v1.5",
    "still_on_hub": true
  },
  {
    "name": "internlm-20b",
    "author": "internlm",
    "query_name": "internlm/internlm-20b",
    "score": 59.55,
    "likes": 47.0,
    "link": "https://huggingface.co/internlm/internlm-20b",
    "still_on_hub": true
  },
  {
    "name": "Chupacabra-v3",
    "author": "perlthoughts",
    "query_name": "perlthoughts/Chupacabra-v3",
    "score": 59.52,
    "likes": 0.0,
    "link": "https://huggingface.co/perlthoughts/Chupacabra-v3",
    "still_on_hub": false
  },
  {
    "name": "WizardLM-30B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-30B-fp16",
    "score": 59.51,
    "likes": 10.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-30B-fp16",
    "still_on_hub": true
  },
  {
    "name": "gpt4-alpaca-lora-30b-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/gpt4-alpaca-lora-30b-HF",
    "score": 59.51,
    "likes": 9.0,
    "link": "https://huggingface.co/TheBloke/gpt4-alpaca-lora-30b-HF",
    "still_on_hub": true
  },
  {
    "name": "zephyr-7b-alpha",
    "author": "HuggingFaceH4",
    "query_name": "HuggingFaceH4/zephyr-7b-alpha",
    "score": 59.5,
    "likes": 377.0,
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha",
    "still_on_hub": true
  },
  {
    "name": "HelpSteer-filtered-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/HelpSteer-filtered-7B",
    "score": 59.49,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/HelpSteer-filtered-7B",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-30B-V1.0",
    "author": "LLMs",
    "query_name": "LLMs/WizardLM-30B-V1.0",
    "score": 59.45,
    "likes": 2.0,
    "link": "https://huggingface.co/LLMs/WizardLM-30B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "Yarn-Mistral-7b-128k",
    "author": "NousResearch",
    "query_name": "NousResearch/Yarn-Mistral-7b-128k",
    "score": 59.42,
    "likes": 462.0,
    "link": "https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k",
    "still_on_hub": true
  },
  {
    "name": "Tess-XS-v1.1",
    "author": "migtissera",
    "query_name": "migtissera/Tess-XS-v1.1",
    "score": 59.39,
    "likes": 0.0,
    "link": "https://huggingface.co/migtissera/Tess-XS-v1.1",
    "still_on_hub": true
  },
  {
    "name": "grendel",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/grendel",
    "score": 59.36,
    "likes": 0.0,
    "link": "https://huggingface.co/openaccess-ai-collective/grendel",
    "still_on_hub": false
  },
  {
    "name": "OpenAssistant-SFT-7-Llama-30B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/OpenAssistant-SFT-7-Llama-30B-HF",
    "score": 59.34,
    "likes": 13.0,
    "link": "https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-HF",
    "still_on_hub": true
  },
  {
    "name": "SynthIA-7B-v1.3",
    "author": "migtissera",
    "query_name": "migtissera/SynthIA-7B-v1.3",
    "score": 59.34,
    "likes": 115.0,
    "link": "https://huggingface.co/migtissera/SynthIA-7B-v1.3",
    "still_on_hub": true
  },
  {
    "name": "fin-llama-33b-merged",
    "author": "bavest",
    "query_name": "bavest/fin-llama-33b-merged",
    "score": 59.33,
    "likes": 11.0,
    "link": "https://huggingface.co/bavest/fin-llama-33b-merged",
    "still_on_hub": true
  },
  {
    "name": "MysticFusion-13B",
    "author": "Walmart-the-bag",
    "query_name": "Walmart-the-bag/MysticFusion-13B",
    "score": 59.31,
    "likes": 0.0,
    "link": "https://huggingface.co/Walmart-the-bag/MysticFusion-13B",
    "still_on_hub": true
  },
  {
    "name": "SuperPlatty-30B",
    "author": "ariellee",
    "query_name": "ariellee/SuperPlatty-30B",
    "score": 59.3,
    "likes": 9.0,
    "link": "https://huggingface.co/ariellee/SuperPlatty-30B",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-claude-instruct",
    "author": "Norquinal",
    "query_name": "Norquinal/Mistral-7B-claude-instruct",
    "score": 59.27,
    "likes": 2.0,
    "link": "https://huggingface.co/Norquinal/Mistral-7B-claude-instruct",
    "still_on_hub": true
  },
  {
    "name": "Venomia-1.1-m7",
    "author": "Sao10K",
    "query_name": "Sao10K/Venomia-1.1-m7",
    "score": 59.27,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Venomia-1.1-m7",
    "still_on_hub": true
  },
  {
    "name": "zephyrnotus-11b-alpha",
    "author": "mergedlm",
    "query_name": "mergedlm/zephyrnotus-11b-alpha",
    "score": 59.26,
    "likes": 0.0,
    "link": "https://huggingface.co/mergedlm/zephyrnotus-11b-alpha",
    "still_on_hub": true
  },
  {
    "name": "Synatra-7B-v0.3-RP",
    "author": "maywell",
    "query_name": "maywell/Synatra-7B-v0.3-RP",
    "score": 59.26,
    "likes": 6.0,
    "link": "https://huggingface.co/maywell/Synatra-7B-v0.3-RP",
    "still_on_hub": true
  },
  {
    "name": "zephyr-7b-beta",
    "author": "HuggingFaceH4",
    "query_name": "HuggingFaceH4/zephyr-7b-beta",
    "score": 59.23,
    "likes": 784.0,
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "still_on_hub": true
  },
  {
    "name": "gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
    "author": "gaodrew",
    "query_name": "gaodrew/gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
    "score": 59.22,
    "likes": 0.0,
    "link": "https://huggingface.co/gaodrew/gaodrew-llama-30b-instruct-2048-Open-Platypus-100steps",
    "still_on_hub": true
  },
  {
    "name": "Qwen-7B",
    "author": "Qwen",
    "query_name": "Qwen/Qwen-7B",
    "score": 59.19,
    "likes": 288.0,
    "link": "https://huggingface.co/Qwen/Qwen-7B",
    "still_on_hub": true
  },
  {
    "name": "vigostral-7b-chat",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigostral-7b-chat",
    "score": 59.18,
    "likes": 7.0,
    "link": "https://huggingface.co/bofenghuang/vigostral-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "PiVoT-0.1-Evil-a",
    "author": "maywell",
    "query_name": "maywell/PiVoT-0.1-Evil-a",
    "score": 59.16,
    "likes": 1.0,
    "link": "https://huggingface.co/maywell/PiVoT-0.1-Evil-a",
    "still_on_hub": true
  },
  {
    "name": "Karen_TheEditor_V2_STRICT_Mistral_7B",
    "author": "FPHam",
    "query_name": "FPHam/Karen_TheEditor_V2_STRICT_Mistral_7B",
    "score": 59.13,
    "likes": 1.0,
    "link": "https://huggingface.co/FPHam/Karen_TheEditor_V2_STRICT_Mistral_7B",
    "still_on_hub": true
  },
  {
    "name": "Mistral-v0.1-PeanutButter-v0.0.0-7B",
    "author": "PeanutJar",
    "query_name": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.0-7B",
    "score": 59.09,
    "likes": 0.0,
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.0-7B",
    "still_on_hub": true
  },
  {
    "name": "zephyr-7b-beta",
    "author": "HuggingFaceH4",
    "query_name": "HuggingFaceH4/zephyr-7b-beta",
    "score": 59.08,
    "likes": 784.0,
    "link": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "still_on_hub": true
  },
  {
    "name": "openchat_3.5-16k",
    "author": "NurtureAI",
    "query_name": "NurtureAI/openchat_3.5-16k",
    "score": 59.03,
    "likes": 22.0,
    "link": "https://huggingface.co/NurtureAI/openchat_3.5-16k",
    "still_on_hub": true
  },
  {
    "name": "Platypus-30B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Platypus-30B",
    "score": 59.03,
    "likes": 16.0,
    "link": "https://huggingface.co/garage-bAInd/Platypus-30B",
    "still_on_hub": true
  },
  {
    "name": "Platypus-30B",
    "author": "lilloukas",
    "query_name": "lilloukas/Platypus-30B",
    "score": 59.03,
    "likes": 16.0,
    "link": "https://huggingface.co/lilloukas/Platypus-30B",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v3_13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/orca_mini_v3_13B-GPTQ",
    "score": 59.01,
    "likes": 10.0,
    "link": "https://huggingface.co/TheBloke/orca_mini_v3_13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "zephyr-alpha-Nebula-v2-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/zephyr-alpha-Nebula-v2-7B",
    "score": 59.01,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/zephyr-alpha-Nebula-v2-7B",
    "still_on_hub": true
  },
  {
    "name": "wizard-mistral-v0.1",
    "author": "unaidedelf87777",
    "query_name": "unaidedelf87777/wizard-mistral-v0.1",
    "score": 59.01,
    "likes": 0.0,
    "link": "https://huggingface.co/unaidedelf87777/wizard-mistral-v0.1",
    "still_on_hub": true
  },
  {
    "name": "samantha-1.1-llama-33b",
    "author": "ehartford",
    "query_name": "ehartford/samantha-1.1-llama-33b",
    "score": 58.98,
    "likes": 13.0,
    "link": "https://huggingface.co/ehartford/samantha-1.1-llama-33b",
    "still_on_hub": true
  },
  {
    "name": "Tess-XS-v1.0",
    "author": "migtissera",
    "query_name": "migtissera/Tess-XS-v1.0",
    "score": 58.95,
    "likes": 0.0,
    "link": "https://huggingface.co/migtissera/Tess-XS-v1.0",
    "still_on_hub": true
  },
  {
    "name": "chronoboros-33B",
    "author": "Henk717",
    "query_name": "Henk717/chronoboros-33B",
    "score": 58.92,
    "likes": 9.0,
    "link": "https://huggingface.co/Henk717/chronoboros-33B",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-v0.1-Open-Platypus",
    "author": "akjindal53244",
    "query_name": "akjindal53244/Mistral-7B-v0.1-Open-Platypus",
    "score": 58.92,
    "likes": 2.0,
    "link": "https://huggingface.co/akjindal53244/Mistral-7B-v0.1-Open-Platypus",
    "still_on_hub": true
  },
  {
    "name": "llama-30b-instruct",
    "author": "upstage",
    "query_name": "upstage/llama-30b-instruct",
    "score": 58.91,
    "likes": 21.0,
    "link": "https://huggingface.co/upstage/llama-30b-instruct",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-OpenOrca-1k",
    "author": "mncai",
    "query_name": "mncai/Mistral-7B-OpenOrca-1k",
    "score": 58.9,
    "likes": 1.0,
    "link": "https://huggingface.co/mncai/Mistral-7B-OpenOrca-1k",
    "still_on_hub": true
  },
  {
    "name": "manticore-30b-chat-pyg-alpha",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/manticore-30b-chat-pyg-alpha",
    "score": 58.86,
    "likes": 13.0,
    "link": "https://huggingface.co/openaccess-ai-collective/manticore-30b-chat-pyg-alpha",
    "still_on_hub": true
  },
  {
    "name": "speechless-code-mistral-7b-v1.0",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-code-mistral-7b-v1.0",
    "score": 58.85,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-7b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "mistral_7b_norobots",
    "author": "qblocks",
    "query_name": "qblocks/mistral_7b_norobots",
    "score": 58.85,
    "likes": 0.0,
    "link": "https://huggingface.co/qblocks/mistral_7b_norobots",
    "still_on_hub": false
  },
  {
    "name": "airochronos-33B",
    "author": "Henk717",
    "query_name": "Henk717/airochronos-33B",
    "score": 58.84,
    "likes": 6.0,
    "link": "https://huggingface.co/Henk717/airochronos-33B",
    "still_on_hub": true
  },
  {
    "name": "Mistral-11B-SynthIAirOmniMix",
    "author": "NeverSleep",
    "query_name": "NeverSleep/Mistral-11B-SynthIAirOmniMix",
    "score": 58.84,
    "likes": 0.0,
    "link": "https://huggingface.co/NeverSleep/Mistral-11B-SynthIAirOmniMix",
    "still_on_hub": true
  },
  {
    "name": "Nebula-v2-7B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/Nebula-v2-7B",
    "score": 58.82,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/Nebula-v2-7B",
    "still_on_hub": true
  },
  {
    "name": "scarlett-33b",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/scarlett-33b",
    "score": 58.81,
    "likes": 19.0,
    "link": "https://huggingface.co/ajibawa-2023/scarlett-33b",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama-30b",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama-30b",
    "score": 58.77,
    "likes": 0.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama-30b",
    "still_on_hub": true
  },
  {
    "name": "airochronos-33B",
    "author": "Henk717",
    "query_name": "Henk717/airochronos-33B",
    "score": 58.75,
    "likes": 6.0,
    "link": "https://huggingface.co/Henk717/airochronos-33B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-m-7b-3.1.2",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-m-7b-3.1.2",
    "score": 58.75,
    "likes": 20.0,
    "link": "https://huggingface.co/jondurbin/airoboros-m-7b-3.1.2",
    "still_on_hub": true
  },
  {
    "name": "dromedary-65b-lora-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/dromedary-65b-lora-HF",
    "score": 58.73,
    "likes": 19.0,
    "link": "https://huggingface.co/TheBloke/dromedary-65b-lora-HF",
    "still_on_hub": true
  },
  {
    "name": "llama-30b-supercot",
    "author": "ausboss",
    "query_name": "ausboss/llama-30b-supercot",
    "score": 58.73,
    "likes": 124.0,
    "link": "https://huggingface.co/ausboss/llama-30b-supercot",
    "still_on_hub": true
  },
  {
    "name": "UltraLM-13b-v2.0",
    "author": "openbmb",
    "query_name": "openbmb/UltraLM-13b-v2.0",
    "score": 58.72,
    "likes": 2.0,
    "link": "https://huggingface.co/openbmb/UltraLM-13b-v2.0",
    "still_on_hub": true
  },
  {
    "name": "CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
    "author": "uukuguy",
    "query_name": "uukuguy/CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
    "score": 58.72,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/CollectiveCognition-v1.1-Mistral-7B-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "GPT4-x-AlpacaDente2-30b",
    "author": "Aeala",
    "query_name": "Aeala/GPT4-x-AlpacaDente2-30b",
    "score": 58.71,
    "likes": 30.0,
    "link": "https://huggingface.co/Aeala/GPT4-x-AlpacaDente2-30b",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-platypus-fp16",
    "author": "bhenrym14",
    "query_name": "bhenrym14/mistral-7b-platypus-fp16",
    "score": 58.71,
    "likes": 0.0,
    "link": "https://huggingface.co/bhenrym14/mistral-7b-platypus-fp16",
    "still_on_hub": true
  },
  {
    "name": "Dolphin-Nebula-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Dolphin-Nebula-7B",
    "score": 58.69,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Dolphin-Nebula-7B",
    "still_on_hub": true
  },
  {
    "name": "Mistral-v0.1-PeanutButter-v0.0.2-7B",
    "author": "PeanutJar",
    "query_name": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.2-7B",
    "score": 58.66,
    "likes": 0.0,
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.2-7B",
    "still_on_hub": true
  },
  {
    "name": "Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA",
    "author": "PeanutJar",
    "query_name": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA",
    "score": 58.65,
    "likes": 0.0,
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-DPO-7B-QLoRA",
    "still_on_hub": false
  },
  {
    "name": "Orca-2-13b",
    "author": "microsoft",
    "query_name": "microsoft/Orca-2-13b",
    "score": 58.64,
    "likes": 138.0,
    "link": "https://huggingface.co/microsoft/Orca-2-13b",
    "still_on_hub": true
  },
  {
    "name": "falcon-40b-openassistant-peft",
    "author": "dfurman",
    "query_name": "dfurman/falcon-40b-openassistant-peft",
    "score": 58.63,
    "likes": 38.0,
    "link": "https://huggingface.co/dfurman/falcon-40b-openassistant-peft",
    "still_on_hub": false
  },
  {
    "name": "SOLAR-Platypus-10.7B-v1",
    "author": "kyujinpy",
    "query_name": "kyujinpy/SOLAR-Platypus-10.7B-v1",
    "score": 58.62,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/SOLAR-Platypus-10.7B-v1",
    "still_on_hub": true
  },
  {
    "name": "QuantumLM-70B-hf",
    "author": "quantumaikr",
    "query_name": "quantumaikr/QuantumLM-70B-hf",
    "score": 58.61,
    "likes": 2.0,
    "link": "https://huggingface.co/quantumaikr/QuantumLM-70B-hf",
    "still_on_hub": true
  },
  {
    "name": "mamba-gpt-7b-v1",
    "author": "CobraMamba",
    "query_name": "CobraMamba/mamba-gpt-7b-v1",
    "score": 58.61,
    "likes": 0.0,
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-7b-v1",
    "still_on_hub": true
  },
  {
    "name": "koOpenChat-sft",
    "author": "maywell",
    "query_name": "maywell/koOpenChat-sft",
    "score": 58.61,
    "likes": 0.0,
    "link": "https://huggingface.co/maywell/koOpenChat-sft",
    "still_on_hub": true
  },
  {
    "name": "MegaMix-T1-13B",
    "author": "gradientputri",
    "query_name": "gradientputri/MegaMix-T1-13B",
    "score": 58.61,
    "likes": 0.0,
    "link": "https://huggingface.co/gradientputri/MegaMix-T1-13B",
    "still_on_hub": true
  },
  {
    "name": "dolphin-2.0-mistral-7b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-2.0-mistral-7b",
    "score": 58.58,
    "likes": 58.0,
    "link": "https://huggingface.co/ehartford/dolphin-2.0-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "zephyr-neural-chat-frankenmerge11b",
    "author": "S4sch",
    "query_name": "S4sch/zephyr-neural-chat-frankenmerge11b",
    "score": 58.57,
    "likes": 2.0,
    "link": "https://huggingface.co/S4sch/zephyr-neural-chat-frankenmerge11b",
    "still_on_hub": true
  },
  {
    "name": "vicuna-33b-v1.3",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-33b-v1.3",
    "score": 58.54,
    "likes": 230.0,
    "link": "https://huggingface.co/lmsys/vicuna-33b-v1.3",
    "still_on_hub": true
  },
  {
    "name": "MegaMix-A1-13B",
    "author": "gradientputri",
    "query_name": "gradientputri/MegaMix-A1-13B",
    "score": 58.52,
    "likes": 0.0,
    "link": "https://huggingface.co/gradientputri/MegaMix-A1-13B",
    "still_on_hub": true
  },
  {
    "name": "MLewd-ReMM-L2-Chat-20B",
    "author": "Undi95",
    "query_name": "Undi95/MLewd-ReMM-L2-Chat-20B",
    "score": 58.49,
    "likes": 6.0,
    "link": "https://huggingface.co/Undi95/MLewd-ReMM-L2-Chat-20B",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-30B-Uncensored-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ",
    "score": 58.47,
    "likes": 380.0,
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3",
    "author": "Intel",
    "query_name": "Intel/neural-chat-7b-v3",
    "score": 58.46,
    "likes": 2.0,
    "link": "https://huggingface.co/Intel/neural-chat-7b-v3",
    "still_on_hub": true
  },
  {
    "name": "Llama2-chat-AYB-13B",
    "author": "posicube",
    "query_name": "posicube/Llama2-chat-AYB-13B",
    "score": 58.45,
    "likes": 10.0,
    "link": "https://huggingface.co/posicube/Llama2-chat-AYB-13B",
    "still_on_hub": true
  },
  {
    "name": "trurl-2-13b-pl-instruct_unload has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/213\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #213</a>",
    "author": "Aspik101",
    "query_name": "Aspik101/trurl-2-13b-pl-instruct_unload",
    "score": 58.44,
    "likes": 5.0,
    "link": "https://huggingface.co/Aspik101/trurl-2-13b-pl-instruct_unload",
    "still_on_hub": true
  },
  {
    "name": "X-MythoChronos-13B",
    "author": "Undi95",
    "query_name": "Undi95/X-MythoChronos-13B",
    "score": 58.43,
    "likes": 10.0,
    "link": "https://huggingface.co/Undi95/X-MythoChronos-13B",
    "still_on_hub": true
  },
  {
    "name": "30B-Lazarus",
    "author": "CalderaAI",
    "query_name": "CalderaAI/30B-Lazarus",
    "score": 58.4,
    "likes": 116.0,
    "link": "https://huggingface.co/CalderaAI/30B-Lazarus",
    "still_on_hub": true
  },
  {
    "name": "Dans-PersonalityEngine-30b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-PersonalityEngine-30b",
    "score": 58.39,
    "likes": 4.0,
    "link": "https://huggingface.co/PocketDoc/Dans-PersonalityEngine-30b",
    "still_on_hub": true
  },
  {
    "name": "SynthIA-7B-v1.3-dare-0.85",
    "author": "uukuguy",
    "query_name": "uukuguy/SynthIA-7B-v1.3-dare-0.85",
    "score": 58.38,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/SynthIA-7B-v1.3-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "Uncensored-Frank-33B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Uncensored-Frank-33B",
    "score": 58.38,
    "likes": 2.0,
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Frank-33B",
    "still_on_hub": true
  },
  {
    "name": "Llama-chat-AY-13B",
    "author": "posicube",
    "query_name": "posicube/Llama-chat-AY-13B",
    "score": 58.34,
    "likes": 0.0,
    "link": "https://huggingface.co/posicube/Llama-chat-AY-13B",
    "still_on_hub": true
  },
  {
    "name": "SynthIA-v1.3-Nebula-v2-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/SynthIA-v1.3-Nebula-v2-7B",
    "score": 58.33,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/SynthIA-v1.3-Nebula-v2-7B",
    "still_on_hub": true
  },
  {
    "name": "mamba-gpt-7b-v2",
    "author": "CobraMamba",
    "query_name": "CobraMamba/mamba-gpt-7b-v2",
    "score": 58.31,
    "likes": 0.0,
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-7b-v2",
    "still_on_hub": true
  },
  {
    "name": "30B-Lazarus-instruct-PL-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/30B-Lazarus-instruct-PL-lora_unload",
    "score": 58.29,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/30B-Lazarus-instruct-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "Vicuzard-30B-Uncensored",
    "author": "concedo",
    "query_name": "concedo/Vicuzard-30B-Uncensored",
    "score": 58.26,
    "likes": 11.0,
    "link": "https://huggingface.co/concedo/Vicuzard-30B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
    "author": "PeanutJar",
    "query_name": "PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
    "score": 58.24,
    "likes": 0.0,
    "link": "https://huggingface.co/PeanutJar/Mistral-v0.1-PeanutButter-v0.0.5-SFT-7B-QLoRA",
    "still_on_hub": false
  },
  {
    "name": "airoboros-33b-gpt4-1.4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-1.4",
    "score": 58.2,
    "likes": 13.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.4",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-platypus1k",
    "author": "lgaalves",
    "query_name": "lgaalves/mistral-7b-platypus1k",
    "score": 58.19,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/mistral-7b-platypus1k",
    "still_on_hub": true
  },
  {
    "name": "sheep-duck-llama-2-13b",
    "author": "Riiid",
    "query_name": "Riiid/sheep-duck-llama-2-13b",
    "score": 58.19,
    "likes": 1.0,
    "link": "https://huggingface.co/Riiid/sheep-duck-llama-2-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-33B-instructed",
    "author": "Secbone",
    "query_name": "Secbone/llama-33B-instructed",
    "score": 58.18,
    "likes": 0.0,
    "link": "https://huggingface.co/Secbone/llama-33B-instructed",
    "still_on_hub": true
  },
  {
    "name": "sitebunny-13b",
    "author": "42MARU",
    "query_name": "42MARU/sitebunny-13b",
    "score": 58.17,
    "likes": 1.0,
    "link": "https://huggingface.co/42MARU/sitebunny-13b",
    "still_on_hub": true
  },
  {
    "name": "Dans-TotSirocco-7b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-TotSirocco-7b",
    "score": 58.16,
    "likes": 4.0,
    "link": "https://huggingface.co/PocketDoc/Dans-TotSirocco-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-megamerge-dare-13b",
    "author": "martyn",
    "query_name": "martyn/llama-megamerge-dare-13b",
    "score": 58.15,
    "likes": 0.0,
    "link": "https://huggingface.co/martyn/llama-megamerge-dare-13b",
    "still_on_hub": true
  },
  {
    "name": "Dans-TotSirocco-7b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-TotSirocco-7b",
    "score": 58.15,
    "likes": 4.0,
    "link": "https://huggingface.co/PocketDoc/Dans-TotSirocco-7b",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-OpenOrca-lora",
    "author": "uukuguy",
    "query_name": "uukuguy/Mistral-7B-OpenOrca-lora",
    "score": 58.14,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/Mistral-7B-OpenOrca-lora",
    "still_on_hub": false
  },
  {
    "name": "mistral-guanaco1k-ep2",
    "author": "caisarl76",
    "query_name": "caisarl76/mistral-guanaco1k-ep2",
    "score": 58.13,
    "likes": 2.0,
    "link": "https://huggingface.co/caisarl76/mistral-guanaco1k-ep2",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-guanaco1k-ep2",
    "author": "caisarl76",
    "query_name": "caisarl76/Mistral-7B-guanaco1k-ep2",
    "score": 58.13,
    "likes": 2.0,
    "link": "https://huggingface.co/caisarl76/Mistral-7B-guanaco1k-ep2",
    "still_on_hub": true
  },
  {
    "name": "Stheno-1.8-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-1.8-L2-13B",
    "score": 58.12,
    "likes": 1.0,
    "link": "https://huggingface.co/Sao10K/Stheno-1.8-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "2x-LoRA-Assemble-13B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/2x-LoRA-Assemble-13B",
    "score": 58.1,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/2x-LoRA-Assemble-13B",
    "still_on_hub": true
  },
  {
    "name": "Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
    "score": 58.09,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/Vicuzard-30B-Uncensored-instruct-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "vigogne-33b-instruct",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-33b-instruct",
    "score": 58.08,
    "likes": 5.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-33b-instruct",
    "still_on_hub": true
  },
  {
    "name": "falcon-40b",
    "author": "tiiuae",
    "query_name": "tiiuae/falcon-40b",
    "score": 58.07,
    "likes": 1099.0,
    "link": "https://huggingface.co/tiiuae/falcon-40b",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-openplatypus-1k",
    "author": "mncai",
    "query_name": "mncai/Mistral-7B-openplatypus-1k",
    "score": 58.07,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/Mistral-7B-openplatypus-1k",
    "still_on_hub": true
  },
  {
    "name": "CAMEL-33B-Combined-Data",
    "author": "camel-ai",
    "query_name": "camel-ai/CAMEL-33B-Combined-Data",
    "score": 58.06,
    "likes": 3.0,
    "link": "https://huggingface.co/camel-ai/CAMEL-33B-Combined-Data",
    "still_on_hub": true
  },
  {
    "name": "hippogriff-30b-chat",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/hippogriff-30b-chat",
    "score": 58.05,
    "likes": 21.0,
    "link": "https://huggingface.co/openaccess-ai-collective/hippogriff-30b-chat",
    "still_on_hub": true
  },
  {
    "name": "airoboros-m-7b-3.1.2-dare-0.85",
    "author": "uukuguy",
    "query_name": "uukuguy/airoboros-m-7b-3.1.2-dare-0.85",
    "score": 58.03,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/airoboros-m-7b-3.1.2-dare-0.85",
    "still_on_hub": true
  },
  {
    "name": "DaringFortitude",
    "author": "sequelbox",
    "query_name": "sequelbox/DaringFortitude",
    "score": 58.01,
    "likes": 2.0,
    "link": "https://huggingface.co/sequelbox/DaringFortitude",
    "still_on_hub": true
  },
  {
    "name": "Luban-Marcoroni-13B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Luban-Marcoroni-13B",
    "score": 57.98,
    "likes": 1.0,
    "link": "https://huggingface.co/Weyaxi/Luban-Marcoroni-13B",
    "still_on_hub": true
  },
  {
    "name": "samantha-mistral-7b",
    "author": "ehartford",
    "query_name": "ehartford/samantha-mistral-7b",
    "score": 57.96,
    "likes": 17.0,
    "link": "https://huggingface.co/ehartford/samantha-mistral-7b",
    "still_on_hub": true
  },
  {
    "name": "llama2-megamerge-dare-13b-v2",
    "author": "martyn",
    "query_name": "martyn/llama2-megamerge-dare-13b-v2",
    "score": 57.94,
    "likes": 0.0,
    "link": "https://huggingface.co/martyn/llama2-megamerge-dare-13b-v2",
    "still_on_hub": true
  },
  {
    "name": "Luban-Marcoroni-13B-v3",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Luban-Marcoroni-13B-v3",
    "score": 57.94,
    "likes": 4.0,
    "link": "https://huggingface.co/Weyaxi/Luban-Marcoroni-13B-v3",
    "still_on_hub": true
  },
  {
    "name": "Llamix2-Xwin-MoE-4x13B",
    "author": "Undi95",
    "query_name": "Undi95/Llamix2-Xwin-MoE-4x13B",
    "score": 57.93,
    "likes": 0.0,
    "link": "https://huggingface.co/Undi95/Llamix2-Xwin-MoE-4x13B",
    "still_on_hub": false
  },
  {
    "name": "Luban-Marcoroni-13B-v2",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Luban-Marcoroni-13B-v2",
    "score": 57.92,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Luban-Marcoroni-13B-v2",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-OpenOrca-Guanaco-accu16",
    "author": "caisarl76",
    "query_name": "caisarl76/Mistral-7B-OpenOrca-Guanaco-accu16",
    "score": 57.91,
    "likes": 0.0,
    "link": "https://huggingface.co/caisarl76/Mistral-7B-OpenOrca-Guanaco-accu16",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13B-LoRA-assemble",
    "author": "oh-yeontaek",
    "query_name": "oh-yeontaek/llama-2-13B-LoRA-assemble",
    "score": 57.91,
    "likes": 7.0,
    "link": "https://huggingface.co/oh-yeontaek/llama-2-13B-LoRA-assemble",
    "still_on_hub": true
  },
  {
    "name": "Enterredaas-33b",
    "author": "Aeala",
    "query_name": "Aeala/Enterredaas-33b",
    "score": 57.9,
    "likes": 0.0,
    "link": "https://huggingface.co/Aeala/Enterredaas-33b",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-30B-Uncensored",
    "author": "ehartford",
    "query_name": "ehartford/Wizard-Vicuna-30B-Uncensored",
    "score": 57.89,
    "likes": 72.0,
    "link": "https://huggingface.co/ehartford/Wizard-Vicuna-30B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-30B-Uncensored-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Wizard-Vicuna-30B-Uncensored-fp16",
    "score": 57.89,
    "likes": 16.0,
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-fp16",
    "still_on_hub": true
  },
  {
    "name": "Llama2-chat-AYT-13B",
    "author": "posicube",
    "query_name": "posicube/Llama2-chat-AYT-13B",
    "score": 57.88,
    "likes": 12.0,
    "link": "https://huggingface.co/posicube/Llama2-chat-AYT-13B",
    "still_on_hub": true
  },
  {
    "name": "VicUnlocked-alpaca-30b",
    "author": "Aeala",
    "query_name": "Aeala/VicUnlocked-alpaca-30b",
    "score": 57.86,
    "likes": 7.0,
    "link": "https://huggingface.co/Aeala/VicUnlocked-alpaca-30b",
    "still_on_hub": true
  },
  {
    "name": "Chat-AYB-Nova-13B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/Chat-AYB-Nova-13B",
    "score": 57.84,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/Chat-AYB-Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "mistral_7b_2epoch_norobots",
    "author": "souvik0306",
    "query_name": "souvik0306/mistral_7b_2epoch_norobots",
    "score": 57.84,
    "likes": 0.0,
    "link": "https://huggingface.co/souvik0306/mistral_7b_2epoch_norobots",
    "still_on_hub": false
  },
  {
    "name": "Stheno-v2-Delta-fp16",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-v2-Delta-fp16",
    "score": 57.81,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Stheno-v2-Delta-fp16",
    "still_on_hub": true
  },
  {
    "name": "Stheno-V2-Delta-fp16",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-V2-Delta-fp16",
    "score": 57.81,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Stheno-V2-Delta-fp16",
    "still_on_hub": true
  },
  {
    "name": "ChatAYT-Lora-Assamble-Marcoroni",
    "author": "Weyaxi",
    "query_name": "Weyaxi/ChatAYT-Lora-Assamble-Marcoroni",
    "score": 57.76,
    "likes": 1.0,
    "link": "https://huggingface.co/Weyaxi/ChatAYT-Lora-Assamble-Marcoroni",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama2-13b-v8.1-fp16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-llama2-13b-v8.1-fp16",
    "score": 57.76,
    "likes": 62.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v8.1-fp16",
    "still_on_hub": true
  },
  {
    "name": "OpenOrcaxOpenChat-Preview2-13B",
    "author": "Open-Orca",
    "query_name": "Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "score": 57.76,
    "likes": 94.0,
    "link": "https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "still_on_hub": true
  },
  {
    "name": "MLewd-L2-Chat-13B",
    "author": "Undi95",
    "query_name": "Undi95/MLewd-L2-Chat-13B",
    "score": 57.75,
    "likes": 13.0,
    "link": "https://huggingface.co/Undi95/MLewd-L2-Chat-13B",
    "still_on_hub": true
  },
  {
    "name": "Pwen-14B-Chat-20_30",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/Pwen-14B-Chat-20_30",
    "score": 57.74,
    "likes": 0.0,
    "link": "https://huggingface.co/JosephusCheung/Pwen-14B-Chat-20_30",
    "still_on_hub": false
  },
  {
    "name": "Luban-13B",
    "author": "ai-business",
    "query_name": "ai-business/Luban-13B",
    "score": 57.73,
    "likes": 13.0,
    "link": "https://huggingface.co/ai-business/Luban-13B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-1.2",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-1.2",
    "score": 57.69,
    "likes": 8.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.2",
    "still_on_hub": true
  },
  {
    "name": "Alpacino30b",
    "author": "digitous",
    "query_name": "digitous/Alpacino30b",
    "score": 57.67,
    "likes": 67.0,
    "link": "https://huggingface.co/digitous/Alpacino30b",
    "still_on_hub": true
  },
  {
    "name": "magpie-13b",
    "author": "boomerchan",
    "query_name": "boomerchan/magpie-13b",
    "score": 57.64,
    "likes": 6.0,
    "link": "https://huggingface.co/boomerchan/magpie-13b",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-v0.1-layla-v2",
    "author": "l3utterfly",
    "query_name": "l3utterfly/mistral-7b-v0.1-layla-v2",
    "score": 57.6,
    "likes": 0.0,
    "link": "https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v2",
    "still_on_hub": false
  },
  {
    "name": "Orca-2-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Orca-2-13B-GPTQ",
    "score": 57.6,
    "likes": 2.0,
    "link": "https://huggingface.co/TheBloke/Orca-2-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "MelloGPT",
    "author": "steve-cse",
    "query_name": "steve-cse/MelloGPT",
    "score": 57.59,
    "likes": 0.0,
    "link": "https://huggingface.co/steve-cse/MelloGPT",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b-v0.1-layla-v1",
    "author": "l3utterfly",
    "query_name": "l3utterfly/mistral-7b-v0.1-layla-v1",
    "score": 57.56,
    "likes": 0.0,
    "link": "https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v1",
    "still_on_hub": true
  },
  {
    "name": "tulu-30B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/tulu-30B-fp16",
    "score": 57.53,
    "likes": 5.0,
    "link": "https://huggingface.co/TheBloke/tulu-30B-fp16",
    "still_on_hub": true
  },
  {
    "name": "speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "score": 57.52,
    "likes": 24.0,
    "link": "https://huggingface.co/uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-1.3",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-1.3",
    "score": 57.49,
    "likes": 2.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.3",
    "still_on_hub": true
  },
  {
    "name": "Unholy-v1-12L-13B",
    "author": "Undi95",
    "query_name": "Undi95/Unholy-v1-12L-13B",
    "score": 57.47,
    "likes": 25.0,
    "link": "https://huggingface.co/Undi95/Unholy-v1-12L-13B",
    "still_on_hub": true
  },
  {
    "name": "Dans-AdventurousWinds-7b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-AdventurousWinds-7b",
    "score": 57.46,
    "likes": 7.0,
    "link": "https://huggingface.co/PocketDoc/Dans-AdventurousWinds-7b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-1.3",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-1.3",
    "score": 57.43,
    "likes": 2.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-1.3",
    "still_on_hub": true
  },
  {
    "name": "MXLewd-L2-20B",
    "author": "Undi95",
    "query_name": "Undi95/MXLewd-L2-20B",
    "score": 57.43,
    "likes": 7.0,
    "link": "https://huggingface.co/Undi95/MXLewd-L2-20B",
    "still_on_hub": true
  },
  {
    "name": "speechless-llama2-luban-orca-platypus-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-llama2-luban-orca-platypus-13b",
    "score": 57.42,
    "likes": 3.0,
    "link": "https://huggingface.co/uukuguy/speechless-llama2-luban-orca-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "chinese-alpaca-2-13b",
    "author": "hfl",
    "query_name": "hfl/chinese-alpaca-2-13b",
    "score": 57.41,
    "likes": 74.0,
    "link": "https://huggingface.co/hfl/chinese-alpaca-2-13b",
    "still_on_hub": true
  },
  {
    "name": "Mistralic-7B-1",
    "author": "SkunkworksAI",
    "query_name": "SkunkworksAI/Mistralic-7B-1",
    "score": 57.4,
    "likes": 17.0,
    "link": "https://huggingface.co/SkunkworksAI/Mistralic-7B-1",
    "still_on_hub": true
  },
  {
    "name": "llama-polyglot-13b",
    "author": "chargoddard",
    "query_name": "chargoddard/llama-polyglot-13b",
    "score": 57.36,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/llama-polyglot-13b",
    "still_on_hub": true
  },
  {
    "name": "digital-socrates-13b",
    "author": "allenai",
    "query_name": "allenai/digital-socrates-13b",
    "score": 57.34,
    "likes": 1.0,
    "link": "https://huggingface.co/allenai/digital-socrates-13b",
    "still_on_hub": true
  },
  {
    "name": "VicUnlocked-30B-LoRA-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/VicUnlocked-30B-LoRA-HF",
    "score": 57.33,
    "likes": 1.0,
    "link": "https://huggingface.co/TheBloke/VicUnlocked-30B-LoRA-HF",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4",
    "score": 57.32,
    "likes": 7.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4",
    "still_on_hub": true
  },
  {
    "name": "BrainDerp2",
    "author": "Sao10K",
    "query_name": "Sao10K/BrainDerp2",
    "score": 57.32,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/BrainDerp2",
    "still_on_hub": true
  },
  {
    "name": "OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
    "score": 57.31,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "LLaMA_2_13B_SFT_v0",
    "author": "adonlee",
    "query_name": "adonlee/LLaMA_2_13B_SFT_v0",
    "score": 57.31,
    "likes": 0.0,
    "link": "https://huggingface.co/adonlee/LLaMA_2_13B_SFT_v0",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-34b-Instruct-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-34b-Instruct-hf",
    "score": 57.29,
    "likes": 215.0,
    "link": "https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf",
    "still_on_hub": true
  },
  {
    "name": "OpenOrca-Platypus2-13B",
    "author": "Open-Orca",
    "query_name": "Open-Orca/OpenOrca-Platypus2-13B",
    "score": 57.28,
    "likes": 204.0,
    "link": "https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B",
    "still_on_hub": true
  },
  {
    "name": "2x-LoRA-Assemble-Nova-13B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/2x-LoRA-Assemble-Nova-13B",
    "score": 57.26,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/2x-LoRA-Assemble-Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "MLewd-ReMM-L2-Chat-20B-Inverted",
    "author": "Undi95",
    "query_name": "Undi95/MLewd-ReMM-L2-Chat-20B-Inverted",
    "score": 57.25,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/MLewd-ReMM-L2-Chat-20B-Inverted",
    "still_on_hub": true
  },
  {
    "name": "Giraffe-13b-32k-v3",
    "author": "abacusai",
    "query_name": "abacusai/Giraffe-13b-32k-v3",
    "score": 57.24,
    "likes": 1.0,
    "link": "https://huggingface.co/abacusai/Giraffe-13b-32k-v3",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v3_13b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_v3_13b",
    "score": 57.24,
    "likes": 27.0,
    "link": "https://huggingface.co/psmathur/orca_mini_v3_13b",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v3_13b",
    "author": "pankajmathur",
    "query_name": "pankajmathur/orca_mini_v3_13b",
    "score": 57.24,
    "likes": 27.0,
    "link": "https://huggingface.co/pankajmathur/orca_mini_v3_13b",
    "still_on_hub": true
  },
  {
    "name": "MLewd-Chat-v2-13B",
    "author": "Undi95",
    "query_name": "Undi95/MLewd-Chat-v2-13B",
    "score": 57.23,
    "likes": 7.0,
    "link": "https://huggingface.co/Undi95/MLewd-Chat-v2-13B",
    "still_on_hub": true
  },
  {
    "name": "Athena-v4",
    "author": "IkariDev",
    "query_name": "IkariDev/Athena-v4",
    "score": 57.23,
    "likes": 11.0,
    "link": "https://huggingface.co/IkariDev/Athena-v4",
    "still_on_hub": true
  },
  {
    "name": "speechless-llama2-hermes-orca-platypus-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-llama2-hermes-orca-platypus-13b",
    "score": 57.17,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-llama2-hermes-orca-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-2.1",
    "score": 57.16,
    "likes": 8.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-2.1",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-m2.0",
    "score": 57.16,
    "likes": 1.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "BrainDerp3",
    "author": "Sao10K",
    "query_name": "Sao10K/BrainDerp3",
    "score": 57.13,
    "likes": 1.0,
    "link": "https://huggingface.co/Sao10K/BrainDerp3",
    "still_on_hub": true
  },
  {
    "name": "CalliopeDS-v2-L2-13B",
    "author": "Doctor-Shotgun",
    "query_name": "Doctor-Shotgun/CalliopeDS-v2-L2-13B",
    "score": 57.12,
    "likes": 1.0,
    "link": "https://huggingface.co/Doctor-Shotgun/CalliopeDS-v2-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "MegaMix-S1-13B",
    "author": "gradientputri",
    "query_name": "gradientputri/MegaMix-S1-13B",
    "score": 57.12,
    "likes": 0.0,
    "link": "https://huggingface.co/gradientputri/MegaMix-S1-13B",
    "still_on_hub": true
  },
  {
    "name": "BrainDerp",
    "author": "Sao10K",
    "query_name": "Sao10K/BrainDerp",
    "score": 57.11,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/BrainDerp",
    "still_on_hub": true
  },
  {
    "name": "ReMM-v2.2-L2-13B",
    "author": "Undi95",
    "query_name": "Undi95/ReMM-v2.2-L2-13B",
    "score": 57.1,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/ReMM-v2.2-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "Athena-v3",
    "author": "IkariDev",
    "query_name": "IkariDev/Athena-v3",
    "score": 57.09,
    "likes": 8.0,
    "link": "https://huggingface.co/IkariDev/Athena-v3",
    "still_on_hub": true
  },
  {
    "name": "vicuna-33b-coder",
    "author": "FelixChao",
    "query_name": "FelixChao/vicuna-33b-coder",
    "score": 57.07,
    "likes": 1.0,
    "link": "https://huggingface.co/FelixChao/vicuna-33b-coder",
    "still_on_hub": true
  },
  {
    "name": "Emerhyst-20B",
    "author": "Undi95",
    "query_name": "Undi95/Emerhyst-20B",
    "score": 57.07,
    "likes": 16.0,
    "link": "https://huggingface.co/Undi95/Emerhyst-20B",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-orca-v1",
    "author": "circulus",
    "query_name": "circulus/Llama-2-13b-orca-v1",
    "score": 57.05,
    "likes": 5.0,
    "link": "https://huggingface.co/circulus/Llama-2-13b-orca-v1",
    "still_on_hub": true
  },
  {
    "name": "StableBeluga-13B",
    "author": "stabilityai",
    "query_name": "stabilityai/StableBeluga-13B",
    "score": 57.05,
    "likes": 107.0,
    "link": "https://huggingface.co/stabilityai/StableBeluga-13B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-m2.0",
    "score": 57.03,
    "likes": 1.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "zephyr-beta-Nebula-v2-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/zephyr-beta-Nebula-v2-7B",
    "score": 57.03,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/zephyr-beta-Nebula-v2-7B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-2.0",
    "score": 57.02,
    "likes": 3.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "wendigo-14b-alpha2",
    "author": "MisterRid",
    "query_name": "MisterRid/wendigo-14b-alpha2",
    "score": 57.02,
    "likes": 0.0,
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha2",
    "still_on_hub": true
  },
  {
    "name": "synapsellm-7b-mistral-v0.3-preview",
    "author": "WebraftAI",
    "query_name": "WebraftAI/synapsellm-7b-mistral-v0.3-preview",
    "score": 57.01,
    "likes": 0.0,
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.3-preview",
    "still_on_hub": true
  },
  {
    "name": "wendigo-14b-alpha1",
    "author": "MisterRid",
    "query_name": "MisterRid/wendigo-14b-alpha1",
    "score": 57.01,
    "likes": 0.0,
    "link": "https://huggingface.co/MisterRid/wendigo-14b-alpha1",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-2.0",
    "score": 57.01,
    "likes": 3.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "YuLan-Chat-2-13b-fp16",
    "author": "yulan-team",
    "query_name": "yulan-team/YuLan-Chat-2-13b-fp16",
    "score": 57.01,
    "likes": 7.0,
    "link": "https://huggingface.co/yulan-team/YuLan-Chat-2-13b-fp16",
    "still_on_hub": true
  },
  {
    "name": "ReMM-v2-L2-13B",
    "author": "Undi95",
    "query_name": "Undi95/ReMM-v2-L2-13B",
    "score": 56.99,
    "likes": 2.0,
    "link": "https://huggingface.co/Undi95/ReMM-v2-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "OpenOrca-Platypus2-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/OpenOrca-Platypus2-13B-GPTQ",
    "score": 56.98,
    "likes": 49.0,
    "link": "https://huggingface.co/TheBloke/OpenOrca-Platypus2-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "GenAI-Nova-13B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/GenAI-Nova-13B",
    "score": 56.98,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/GenAI-Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-33b-gpt4-m2.0",
    "score": 56.97,
    "likes": 1.0,
    "link": "https://huggingface.co/jondurbin/airoboros-33b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "llama-30b",
    "author": "huggyllama",
    "query_name": "huggyllama/llama-30b",
    "score": 56.96,
    "likes": 37.0,
    "link": "https://huggingface.co/huggyllama/llama-30b",
    "still_on_hub": true
  },
  {
    "name": "llama-30b",
    "author": "huggingface",
    "query_name": "huggingface/llama-30b",
    "score": 56.94,
    "likes": 0.0,
    "link": "https://huggingface.co/huggingface/llama-30b",
    "still_on_hub": false
  },
  {
    "name": "llama-30B-hf-openassitant",
    "author": "Yhyu13",
    "query_name": "Yhyu13/llama-30B-hf-openassitant",
    "score": 56.94,
    "likes": 1.0,
    "link": "https://huggingface.co/Yhyu13/llama-30B-hf-openassitant",
    "still_on_hub": true
  },
  {
    "name": "UndiMix-v4-13B",
    "author": "Undi95",
    "query_name": "Undi95/UndiMix-v4-13B",
    "score": 56.93,
    "likes": 3.0,
    "link": "https://huggingface.co/Undi95/UndiMix-v4-13B",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-megacode2_min100",
    "author": "andreaskoepf",
    "query_name": "andreaskoepf/llama2-13b-megacode2_min100",
    "score": 56.92,
    "likes": 0.0,
    "link": "https://huggingface.co/andreaskoepf/llama2-13b-megacode2_min100",
    "still_on_hub": true
  },
  {
    "name": "LosslessMegaCoder-llama2-13b-mini",
    "author": "rombodawg",
    "query_name": "rombodawg/LosslessMegaCoder-llama2-13b-mini",
    "score": 56.92,
    "likes": 7.0,
    "link": "https://huggingface.co/rombodawg/LosslessMegaCoder-llama2-13b-mini",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-orca-v1",
    "author": "circulus",
    "query_name": "circulus/Llama-2-13b-orca-v1",
    "score": 56.91,
    "likes": 5.0,
    "link": "https://huggingface.co/circulus/Llama-2-13b-orca-v1",
    "still_on_hub": true
  },
  {
    "name": "Emerald-13B",
    "author": "Undi95",
    "query_name": "Undi95/Emerald-13B",
    "score": 56.89,
    "likes": 0.0,
    "link": "https://huggingface.co/Undi95/Emerald-13B",
    "still_on_hub": true
  },
  {
    "name": "ReMM-Mistral-13B",
    "author": "Undi95",
    "query_name": "Undi95/ReMM-Mistral-13B",
    "score": 56.89,
    "likes": 4.0,
    "link": "https://huggingface.co/Undi95/ReMM-Mistral-13B",
    "still_on_hub": false
  },
  {
    "name": "OpenOrcaxOpenChat-Preview2-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/OpenOrcaxOpenChat-Preview2-13B-GPTQ",
    "score": 56.84,
    "likes": 21.0,
    "link": "https://huggingface.co/TheBloke/OpenOrcaxOpenChat-Preview2-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "alpaca-cleaned-llama-30b-bf16",
    "author": "dsvv-cair",
    "query_name": "dsvv-cair/alpaca-cleaned-llama-30b-bf16",
    "score": 56.82,
    "likes": 3.0,
    "link": "https://huggingface.co/dsvv-cair/alpaca-cleaned-llama-30b-bf16",
    "still_on_hub": true
  },
  {
    "name": "Orca-2-13b-SFT_v5",
    "author": "Locutusque",
    "query_name": "Locutusque/Orca-2-13b-SFT_v5",
    "score": 56.77,
    "likes": 1.0,
    "link": "https://huggingface.co/Locutusque/Orca-2-13b-SFT_v5",
    "still_on_hub": true
  },
  {
    "name": "Yi-6B-200K",
    "author": "01-ai",
    "query_name": "01-ai/Yi-6B-200K",
    "score": 56.76,
    "likes": 108.0,
    "link": "https://huggingface.co/01-ai/Yi-6B-200K",
    "still_on_hub": true
  },
  {
    "name": "Platypus2xOpenOrca-13B-IA3-v3",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2xOpenOrca-13B-IA3-v3",
    "score": 56.74,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3-v3",
    "still_on_hub": true
  },
  {
    "name": "Orca-Nova-13B",
    "author": "TFLai",
    "query_name": "TFLai/Orca-Nova-13B",
    "score": 56.72,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Orca-Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "ReMM-v2.1-L2-13B",
    "author": "Undi95",
    "query_name": "Undi95/ReMM-v2.1-L2-13B",
    "score": 56.71,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/ReMM-v2.1-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "OpenOrcaxOpenChat-Preview2-13B",
    "author": "Open-Orca",
    "query_name": "Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "score": 56.7,
    "likes": 94.0,
    "link": "https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B",
    "still_on_hub": true
  },
  {
    "name": "Yi-6B-200K",
    "author": "01-ai",
    "query_name": "01-ai/Yi-6B-200K",
    "score": 56.69,
    "likes": 116.0,
    "link": "https://huggingface.co/01-ai/Yi-6B-200K",
    "still_on_hub": true
  },
  {
    "name": "Platypus2xOpenOrca-13B-IA3",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2xOpenOrca-13B-IA3",
    "score": 56.65,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3",
    "still_on_hub": true
  },
  {
    "name": "storytime-13b",
    "author": "chargoddard",
    "query_name": "chargoddard/storytime-13b",
    "score": 56.64,
    "likes": 12.0,
    "link": "https://huggingface.co/chargoddard/storytime-13b",
    "still_on_hub": true
  },
  {
    "name": "unraveled-7b-a1",
    "author": "ZoidBB",
    "query_name": "ZoidBB/unraveled-7b-a1",
    "score": 56.63,
    "likes": 0.0,
    "link": "https://huggingface.co/ZoidBB/unraveled-7b-a1",
    "still_on_hub": true
  },
  {
    "name": "duplicitous-slurpbeast-13b",
    "author": "chargoddard",
    "query_name": "chargoddard/duplicitous-slurpbeast-13b",
    "score": 56.62,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/duplicitous-slurpbeast-13b",
    "still_on_hub": true
  },
  {
    "name": "Amethyst-13B-Mistral",
    "author": "Undi95",
    "query_name": "Undi95/Amethyst-13B-Mistral",
    "score": 56.62,
    "likes": 3.0,
    "link": "https://huggingface.co/Undi95/Amethyst-13B-Mistral",
    "still_on_hub": false
  },
  {
    "name": "Amethyst-13B",
    "author": "Undi95",
    "query_name": "Undi95/Amethyst-13B",
    "score": 56.62,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/Amethyst-13B",
    "still_on_hub": true
  },
  {
    "name": "BELLE-Llama2-13B-chat-0.4M",
    "author": "BELLE-2",
    "query_name": "BELLE-2/BELLE-Llama2-13B-chat-0.4M",
    "score": 56.62,
    "likes": 27.0,
    "link": "https://huggingface.co/BELLE-2/BELLE-Llama2-13B-chat-0.4M",
    "still_on_hub": true
  },
  {
    "name": "Clover3-17B",
    "author": "Undi95",
    "query_name": "Undi95/Clover3-17B",
    "score": 56.61,
    "likes": 0.0,
    "link": "https://huggingface.co/Undi95/Clover3-17B",
    "still_on_hub": true
  },
  {
    "name": "chronos-33b",
    "author": "elinas",
    "query_name": "elinas/chronos-33b",
    "score": 56.59,
    "likes": 23.0,
    "link": "https://huggingface.co/elinas/chronos-33b",
    "still_on_hub": true
  },
  {
    "name": "LlongOrca-13B-16k",
    "author": "Open-Orca",
    "query_name": "Open-Orca/LlongOrca-13B-16k",
    "score": 56.59,
    "likes": 11.0,
    "link": "https://huggingface.co/Open-Orca/LlongOrca-13B-16k",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-megacode2-oasst",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/llama2-13b-megacode2-oasst",
    "score": 56.59,
    "likes": 9.0,
    "link": "https://huggingface.co/OpenAssistant/llama2-13b-megacode2-oasst",
    "still_on_hub": true
  },
  {
    "name": "Slerpeno",
    "author": "Brouz",
    "query_name": "Brouz/Slerpeno",
    "score": 56.59,
    "likes": 4.0,
    "link": "https://huggingface.co/Brouz/Slerpeno",
    "still_on_hub": true
  },
  {
    "name": "NyakuraV2.1-m7",
    "author": "Sao10K",
    "query_name": "Sao10K/NyakuraV2.1-m7",
    "score": 56.57,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/NyakuraV2.1-m7",
    "still_on_hub": true
  },
  {
    "name": "duplicitous-mammal-13b",
    "author": "chargoddard",
    "query_name": "chargoddard/duplicitous-mammal-13b",
    "score": 56.57,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/duplicitous-mammal-13b",
    "still_on_hub": true
  },
  {
    "name": "OpenRP-13B",
    "author": "Undi95",
    "query_name": "Undi95/OpenRP-13B",
    "score": 56.57,
    "likes": 2.0,
    "link": "https://huggingface.co/Undi95/OpenRP-13B",
    "still_on_hub": true
  },
  {
    "name": "MM-ReMM-L2-20B",
    "author": "Undi95",
    "query_name": "Undi95/MM-ReMM-L2-20B",
    "score": 56.55,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/MM-ReMM-L2-20B",
    "still_on_hub": true
  },
  {
    "name": "BerrySauce-L2-13b",
    "author": "sauce1337",
    "query_name": "sauce1337/BerrySauce-L2-13b",
    "score": 56.55,
    "likes": 0.0,
    "link": "https://huggingface.co/sauce1337/BerrySauce-L2-13b",
    "still_on_hub": true
  },
  {
    "name": "MLewdBoros-L2-13B",
    "author": "Undi95",
    "query_name": "Undi95/MLewdBoros-L2-13B",
    "score": 56.51,
    "likes": 11.0,
    "link": "https://huggingface.co/Undi95/MLewdBoros-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "Platypus2xOpenOrca-13B-IA3-v4",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2xOpenOrca-13B-IA3-v4",
    "score": 56.49,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3-v4",
    "still_on_hub": true
  },
  {
    "name": "EnsembleV5-Nova-13B",
    "author": "TFLai",
    "query_name": "TFLai/EnsembleV5-Nova-13B",
    "score": 56.49,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/EnsembleV5-Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "EnsembleV5-Nova-13B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/EnsembleV5-Nova-13B",
    "score": 56.49,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/EnsembleV5-Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "mythalion-13b",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/mythalion-13b",
    "score": 56.48,
    "likes": 58.0,
    "link": "https://huggingface.co/PygmalionAI/mythalion-13b",
    "still_on_hub": true
  },
  {
    "name": "speechless-code-mistral-7b-v2.0",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-code-mistral-7b-v2.0",
    "score": 56.47,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-7b-v2.0",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-30B-Uncensored",
    "author": "ehartford",
    "query_name": "ehartford/WizardLM-30B-Uncensored",
    "score": 56.46,
    "likes": 118.0,
    "link": "https://huggingface.co/ehartford/WizardLM-30B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "SciPhi-Self-RAG-Mistral-7B-32k",
    "author": "SciPhi",
    "query_name": "SciPhi/SciPhi-Self-RAG-Mistral-7B-32k",
    "score": 56.46,
    "likes": 38.0,
    "link": "https://huggingface.co/SciPhi/SciPhi-Self-RAG-Mistral-7B-32k",
    "still_on_hub": true
  },
  {
    "name": "Pygmalion-2-13b-SuperCOT",
    "author": "royallab",
    "query_name": "royallab/Pygmalion-2-13b-SuperCOT",
    "score": 56.46,
    "likes": 7.0,
    "link": "https://huggingface.co/royallab/Pygmalion-2-13b-SuperCOT",
    "still_on_hub": true
  },
  {
    "name": "Stheno-Inverted-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-Inverted-L2-13B",
    "score": 56.44,
    "likes": 1.0,
    "link": "https://huggingface.co/Sao10K/Stheno-Inverted-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "Nova-13B",
    "author": "TFLai",
    "query_name": "TFLai/Nova-13B",
    "score": 56.44,
    "likes": 1.0,
    "link": "https://huggingface.co/TFLai/Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "Stheno-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-L2-13B",
    "score": 56.43,
    "likes": 7.0,
    "link": "https://huggingface.co/Sao10K/Stheno-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "Mythical-Destroyer-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Mythical-Destroyer-L2-13B",
    "score": 56.39,
    "likes": 2.0,
    "link": "https://huggingface.co/Sao10K/Mythical-Destroyer-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "llama2_7b_merge_orcafamily",
    "author": "yeen214",
    "query_name": "yeen214/llama2_7b_merge_orcafamily",
    "score": 56.38,
    "likes": 0.0,
    "link": "https://huggingface.co/yeen214/llama2_7b_merge_orcafamily",
    "still_on_hub": true
  },
  {
    "name": "Dans-AdventurousWinds-Mk2-7b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-AdventurousWinds-Mk2-7b",
    "score": 56.38,
    "likes": 0.0,
    "link": "https://huggingface.co/PocketDoc/Dans-AdventurousWinds-Mk2-7b",
    "still_on_hub": true
  },
  {
    "name": "MLewd-v2.4-13B",
    "author": "Undi95",
    "query_name": "Undi95/MLewd-v2.4-13B",
    "score": 56.37,
    "likes": 8.0,
    "link": "https://huggingface.co/Undi95/MLewd-v2.4-13B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-13b-2.2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-13b-2.2.1",
    "score": 56.36,
    "likes": 3.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-2.2.1",
    "still_on_hub": true
  },
  {
    "name": "openchat_v3.1",
    "author": "openchat",
    "query_name": "openchat/openchat_v3.1",
    "score": 56.36,
    "likes": 5.0,
    "link": "https://huggingface.co/openchat/openchat_v3.1",
    "still_on_hub": true
  },
  {
    "name": "CalliopeDS-L2-13B",
    "author": "Doctor-Shotgun",
    "query_name": "Doctor-Shotgun/CalliopeDS-L2-13B",
    "score": 56.34,
    "likes": 4.0,
    "link": "https://huggingface.co/Doctor-Shotgun/CalliopeDS-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "LLAMA-13B-test-finetuning",
    "author": "iGenius-AI-Team",
    "query_name": "iGenius-AI-Team/LLAMA-13B-test-finetuning",
    "score": 56.34,
    "likes": 0.0,
    "link": "https://huggingface.co/iGenius-AI-Team/LLAMA-13B-test-finetuning",
    "still_on_hub": true
  },
  {
    "name": "MythoMix-L2-13b",
    "author": "Gryphe",
    "query_name": "Gryphe/MythoMix-L2-13b",
    "score": 56.31,
    "likes": 15.0,
    "link": "https://huggingface.co/Gryphe/MythoMix-L2-13b",
    "still_on_hub": true
  },
  {
    "name": "mistral-7b_open_platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/mistral-7b_open_platypus",
    "score": 56.29,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/mistral-7b_open_platypus",
    "still_on_hub": true
  },
  {
    "name": "Platypus2xOpenOrca-13B-IA3-v2.1",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2xOpenOrca-13B-IA3-v2.1",
    "score": 56.29,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-IA3-v2.1",
    "still_on_hub": true
  },
  {
    "name": "Uncensored-Jordan-13B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Uncensored-Jordan-13B",
    "score": 56.27,
    "likes": 3.0,
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Jordan-13B",
    "still_on_hub": true
  },
  {
    "name": "speechless-code-mistral-orca-7b-v1.0",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-code-mistral-orca-7b-v1.0",
    "score": 56.24,
    "likes": 4.0,
    "link": "https://huggingface.co/uukuguy/speechless-code-mistral-orca-7b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "StableBeluga-13B-instruct-PL-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/StableBeluga-13B-instruct-PL-lora_unload",
    "score": 56.24,
    "likes": 1.0,
    "link": "https://huggingface.co/Aspik101/StableBeluga-13B-instruct-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "MythoLogic-L2-13b",
    "author": "Gryphe",
    "query_name": "Gryphe/MythoLogic-L2-13b",
    "score": 56.19,
    "likes": 15.0,
    "link": "https://huggingface.co/Gryphe/MythoLogic-L2-13b",
    "still_on_hub": true
  },
  {
    "name": "Synatra-11B-Testbench",
    "author": "maywell",
    "query_name": "maywell/Synatra-11B-Testbench",
    "score": 56.17,
    "likes": 0.0,
    "link": "https://huggingface.co/maywell/Synatra-11B-Testbench",
    "still_on_hub": false
  },
  {
    "name": "Stheno-1.2-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-1.2-L2-13B",
    "score": 56.15,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Stheno-1.2-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "SpeechlessV1-Nova-13B",
    "author": "TFLai",
    "query_name": "TFLai/SpeechlessV1-Nova-13B",
    "score": 56.14,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/SpeechlessV1-Nova-13B",
    "still_on_hub": true
  },
  {
    "name": "NewHope_HF_not_official",
    "author": "WhoTookMyAmogusNickname",
    "query_name": "WhoTookMyAmogusNickname/NewHope_HF_not_official",
    "score": 56.11,
    "likes": 0.0,
    "link": "https://huggingface.co/WhoTookMyAmogusNickname/NewHope_HF_not_official",
    "still_on_hub": true
  },
  {
    "name": "chronos-hermes-13b-v2",
    "author": "Austism",
    "query_name": "Austism/chronos-hermes-13b-v2",
    "score": 56.1,
    "likes": 11.0,
    "link": "https://huggingface.co/Austism/chronos-hermes-13b-v2",
    "still_on_hub": true
  },
  {
    "name": "Nebula-7B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/Nebula-7B",
    "score": 56.1,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/Nebula-7B",
    "still_on_hub": true
  },
  {
    "name": "prometheus-13b-v1.0",
    "author": "kaist-ai",
    "query_name": "kaist-ai/prometheus-13b-v1.0",
    "score": 56.09,
    "likes": 29.0,
    "link": "https://huggingface.co/kaist-ai/prometheus-13b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "qCammel-13",
    "author": "augtoma",
    "query_name": "augtoma/qCammel-13",
    "score": 56.05,
    "likes": 7.0,
    "link": "https://huggingface.co/augtoma/qCammel-13",
    "still_on_hub": true
  },
  {
    "name": "Huginn-13b-v1.2",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Huginn-13b-v1.2",
    "score": 56.03,
    "likes": 10.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-v1.2",
    "still_on_hub": true
  },
  {
    "name": "ReMM-SLERP-L2-13B",
    "author": "Undi95",
    "query_name": "Undi95/ReMM-SLERP-L2-13B",
    "score": 56.03,
    "likes": 8.0,
    "link": "https://huggingface.co/Undi95/ReMM-SLERP-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "carl-33b",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/carl-33b",
    "score": 56.03,
    "likes": 8.0,
    "link": "https://huggingface.co/ajibawa-2023/carl-33b",
    "still_on_hub": true
  },
  {
    "name": "synapsellm-7b-mistral-v0.5-preview",
    "author": "WebraftAI",
    "query_name": "WebraftAI/synapsellm-7b-mistral-v0.5-preview",
    "score": 56.03,
    "likes": 0.0,
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.5-preview",
    "still_on_hub": true
  },
  {
    "name": "neural-chat-7b-v3-1-Nebula-v2-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/neural-chat-7b-v3-1-Nebula-v2-7B",
    "score": 56.01,
    "likes": 1.0,
    "link": "https://huggingface.co/Weyaxi/neural-chat-7b-v3-1-Nebula-v2-7B",
    "still_on_hub": true
  },
  {
    "name": "MythoMax-L2-13b",
    "author": "Gryphe",
    "query_name": "Gryphe/MythoMax-L2-13b",
    "score": 56.0,
    "likes": 119.0,
    "link": "https://huggingface.co/Gryphe/MythoMax-L2-13b",
    "still_on_hub": true
  },
  {
    "name": "huginnv1.2",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/huginnv1.2",
    "score": 55.98,
    "likes": 10.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/huginnv1.2",
    "still_on_hub": true
  },
  {
    "name": "Nous-Hermes-Llama2-13b",
    "author": "NousResearch",
    "query_name": "NousResearch/Nous-Hermes-Llama2-13b",
    "score": 55.97,
    "likes": 221.0,
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "Samantha-1.11-13b",
    "author": "ehartford",
    "query_name": "ehartford/Samantha-1.11-13b",
    "score": 55.97,
    "likes": 6.0,
    "link": "https://huggingface.co/ehartford/Samantha-1.11-13b",
    "still_on_hub": true
  },
  {
    "name": "Walter-SOLAR-11B",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Walter-SOLAR-11B",
    "score": 55.95,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/Walter-SOLAR-11B",
    "still_on_hub": true
  },
  {
    "name": "Nous-Hermes-13B-Code",
    "author": "Undi95",
    "query_name": "Undi95/Nous-Hermes-13B-Code",
    "score": 55.93,
    "likes": 3.0,
    "link": "https://huggingface.co/Undi95/Nous-Hermes-13B-Code",
    "still_on_hub": true
  },
  {
    "name": "Chat-AYB-Platypus2-13B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/Chat-AYB-Platypus2-13B",
    "score": 55.93,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/Chat-AYB-Platypus2-13B",
    "still_on_hub": true
  },
  {
    "name": "synapsellm-7b-mistral-v0.4-preview2",
    "author": "WebraftAI",
    "query_name": "WebraftAI/synapsellm-7b-mistral-v0.4-preview2",
    "score": 55.93,
    "likes": 0.0,
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.4-preview2",
    "still_on_hub": true
  },
  {
    "name": "synapsellm-7b-mistral-v0.5-preview2",
    "author": "WebraftAI",
    "query_name": "WebraftAI/synapsellm-7b-mistral-v0.5-preview2",
    "score": 55.93,
    "likes": 0.0,
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.5-preview2",
    "still_on_hub": true
  },
  {
    "name": "AppleSauce-L2-13b",
    "author": "sauce1337",
    "query_name": "sauce1337/AppleSauce-L2-13b",
    "score": 55.91,
    "likes": 0.0,
    "link": "https://huggingface.co/sauce1337/AppleSauce-L2-13b",
    "still_on_hub": true
  },
  {
    "name": "Synthia-13B-v1.2",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-13B-v1.2",
    "score": 55.9,
    "likes": 6.0,
    "link": "https://huggingface.co/migtissera/Synthia-13B-v1.2",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama2-34b-v11.1-bf16",
    "author": "openBuddy",
    "query_name": "openBuddy/openbuddy-llama2-34b-v11.1-bf16",
    "score": 55.88,
    "likes": 6.0,
    "link": "https://huggingface.co/openBuddy/openbuddy-llama2-34b-v11.1-bf16",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-codellama2-34b-v11.1-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-codellama2-34b-v11.1-bf16",
    "score": 55.88,
    "likes": 6.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-codellama2-34b-v11.1-bf16",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama2-13b-v1.2",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama2-13b-v1.2",
    "score": 55.87,
    "likes": 2.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b-v1.2",
    "still_on_hub": true
  },
  {
    "name": "Synatra-V0.1-7B-Instruct",
    "author": "maywell",
    "query_name": "maywell/Synatra-V0.1-7B-Instruct",
    "score": 55.86,
    "likes": 12.0,
    "link": "https://huggingface.co/maywell/Synatra-V0.1-7B-Instruct",
    "still_on_hub": true
  },
  {
    "name": "Synatra-V0.1-7B",
    "author": "maywell",
    "query_name": "maywell/Synatra-V0.1-7B",
    "score": 55.86,
    "likes": 12.0,
    "link": "https://huggingface.co/maywell/Synatra-V0.1-7B",
    "still_on_hub": true
  },
  {
    "name": "7B-DPO-alpha",
    "author": "CausalLM",
    "query_name": "CausalLM/7B-DPO-alpha",
    "score": 55.84,
    "likes": 46.0,
    "link": "https://huggingface.co/CausalLM/7B-DPO-alpha",
    "still_on_hub": false
  },
  {
    "name": "Mistral-7B-Instruct-v0.2-DARE",
    "author": "janhq",
    "query_name": "janhq/Mistral-7B-Instruct-v0.2-DARE",
    "score": 55.84,
    "likes": 0.0,
    "link": "https://huggingface.co/janhq/Mistral-7B-Instruct-v0.2-DARE",
    "still_on_hub": true
  },
  {
    "name": "Barcenas-13b",
    "author": "Danielbrdz",
    "query_name": "Danielbrdz/Barcenas-13b",
    "score": 55.83,
    "likes": 0.0,
    "link": "https://huggingface.co/Danielbrdz/Barcenas-13b",
    "still_on_hub": true
  },
  {
    "name": "Metamath-reproduce-7b",
    "author": "feidfoe",
    "query_name": "feidfoe/Metamath-reproduce-7b",
    "score": 55.81,
    "likes": 0.0,
    "link": "https://huggingface.co/feidfoe/Metamath-reproduce-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-OpenOrca_5w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-OpenOrca_5w",
    "score": 55.8,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-OpenOrca_5w",
    "still_on_hub": true
  },
  {
    "name": "neu-sai-it1",
    "author": "CoruNethron",
    "query_name": "CoruNethron/neu-sai-it1",
    "score": 55.78,
    "likes": 0.0,
    "link": "https://huggingface.co/CoruNethron/neu-sai-it1",
    "still_on_hub": false
  },
  {
    "name": "Nous-Hermes-Llama2-13b",
    "author": "NousResearch",
    "query_name": "NousResearch/Nous-Hermes-Llama2-13b",
    "score": 55.75,
    "likes": 221.0,
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "Stable-Platypus2-13B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Stable-Platypus2-13B",
    "score": 55.75,
    "likes": 19.0,
    "link": "https://huggingface.co/garage-bAInd/Stable-Platypus2-13B",
    "still_on_hub": true
  },
  {
    "name": "llama2-13B-sharegpt4-orca-openplatypus-8w",
    "author": "lu-vae",
    "query_name": "lu-vae/llama2-13B-sharegpt4-orca-openplatypus-8w",
    "score": 55.75,
    "likes": 0.0,
    "link": "https://huggingface.co/lu-vae/llama2-13B-sharegpt4-orca-openplatypus-8w",
    "still_on_hub": true
  },
  {
    "name": "CollectiveCognition-v1.1-Nebula-7B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/CollectiveCognition-v1.1-Nebula-7B",
    "score": 55.72,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/CollectiveCognition-v1.1-Nebula-7B",
    "still_on_hub": true
  },
  {
    "name": "openchat_v3.1",
    "author": "openchat",
    "query_name": "openchat/openchat_v3.1",
    "score": 55.71,
    "likes": 5.0,
    "link": "https://huggingface.co/openchat/openchat_v3.1",
    "still_on_hub": true
  },
  {
    "name": "Stheno-1.1-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-1.1-L2-13B",
    "score": 55.71,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Stheno-1.1-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-sharegpt4-test",
    "author": "lu-vae",
    "query_name": "lu-vae/llama2-13b-sharegpt4-test",
    "score": 55.69,
    "likes": 0.0,
    "link": "https://huggingface.co/lu-vae/llama2-13b-sharegpt4-test",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf",
    "author": "meta-llama",
    "query_name": "meta-llama/Llama-2-13b-hf",
    "score": 55.69,
    "likes": 389.0,
    "link": "https://huggingface.co/meta-llama/Llama-2-13b-hf",
    "still_on_hub": false
  },
  {
    "name": "openchat_v3.2",
    "author": "openchat",
    "query_name": "openchat/openchat_v3.2",
    "score": 55.68,
    "likes": 36.0,
    "link": "https://huggingface.co/openchat/openchat_v3.2",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama2-13b",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama2-13b",
    "score": 55.68,
    "likes": 20.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "speechless-hermes-coig-lite-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-hermes-coig-lite-13b",
    "score": 55.65,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-hermes-coig-lite-13b",
    "still_on_hub": true
  },
  {
    "name": "U-Amethyst-20B",
    "author": "Undi95",
    "query_name": "Undi95/U-Amethyst-20B",
    "score": 55.65,
    "likes": 7.0,
    "link": "https://huggingface.co/Undi95/U-Amethyst-20B",
    "still_on_hub": true
  },
  {
    "name": "ennodata-13b-8bit-raw-15epoch",
    "author": "Enno-Ai",
    "query_name": "Enno-Ai/ennodata-13b-8bit-raw-15epoch",
    "score": 55.65,
    "likes": 0.0,
    "link": "https://huggingface.co/Enno-Ai/ennodata-13b-8bit-raw-15epoch",
    "still_on_hub": true
  },
  {
    "name": "Uncensored-Frank-13B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Uncensored-Frank-13B",
    "score": 55.64,
    "likes": 3.0,
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Frank-13B",
    "still_on_hub": true
  },
  {
    "name": "Nova-13B-50-step",
    "author": "TFLai",
    "query_name": "TFLai/Nova-13B-50-step",
    "score": 55.61,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Nova-13B-50-step",
    "still_on_hub": true
  },
  {
    "name": "ANIMA-Phi-Neptune-Mistral-7B-v4",
    "author": "Severian",
    "query_name": "Severian/ANIMA-Phi-Neptune-Mistral-7B-v4",
    "score": 55.61,
    "likes": 10.0,
    "link": "https://huggingface.co/Severian/ANIMA-Phi-Neptune-Mistral-7B-v4",
    "still_on_hub": true
  },
  {
    "name": "Stable-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Stable-Platypus2-13B-QLoRA-0.80-epoch",
    "score": 55.56,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Stable-Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "ANIMA-Phi-Neptune-Mistral-7B",
    "author": "Severian",
    "query_name": "Severian/ANIMA-Phi-Neptune-Mistral-7B",
    "score": 55.54,
    "likes": 10.0,
    "link": "https://huggingface.co/Severian/ANIMA-Phi-Neptune-Mistral-7B",
    "still_on_hub": false
  },
  {
    "name": "internlm-20b-chat",
    "author": "internlm",
    "query_name": "internlm/internlm-20b-chat",
    "score": 55.53,
    "likes": 114.0,
    "link": "https://huggingface.co/internlm/internlm-20b-chat",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-dolphin_5w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-dolphin_5w",
    "score": 55.53,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-dolphin_5w",
    "still_on_hub": true
  },
  {
    "name": "speechless-hermes-coig-lite-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-hermes-coig-lite-13b",
    "score": 55.51,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-hermes-coig-lite-13b",
    "still_on_hub": true
  },
  {
    "name": "Stheno-Inverted-1.2-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-Inverted-1.2-L2-13B",
    "score": 55.5,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Stheno-Inverted-1.2-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "airolima-chronos-grad-l2-13B",
    "author": "kingbri",
    "query_name": "kingbri/airolima-chronos-grad-l2-13B",
    "score": 55.5,
    "likes": 3.0,
    "link": "https://huggingface.co/kingbri/airolima-chronos-grad-l2-13B",
    "still_on_hub": true
  },
  {
    "name": "UndiMix-v1-13b",
    "author": "Undi95",
    "query_name": "Undi95/UndiMix-v1-13b",
    "score": 55.5,
    "likes": 0.0,
    "link": "https://huggingface.co/Undi95/UndiMix-v1-13b",
    "still_on_hub": true
  },
  {
    "name": "chronolima-airo-grad-l2-13B",
    "author": "kingbri",
    "query_name": "kingbri/chronolima-airo-grad-l2-13B",
    "score": 55.5,
    "likes": 3.0,
    "link": "https://huggingface.co/kingbri/chronolima-airo-grad-l2-13B",
    "still_on_hub": true
  },
  {
    "name": "openchat_v3.2",
    "author": "openchat",
    "query_name": "openchat/openchat_v3.2",
    "score": 55.49,
    "likes": 36.0,
    "link": "https://huggingface.co/openchat/openchat_v3.2",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-v1.5",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-13b-v1.5",
    "score": 55.41,
    "likes": 100.0,
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.5",
    "still_on_hub": true
  },
  {
    "name": "model_007_13b_v2",
    "author": "psmathur",
    "query_name": "psmathur/model_007_13b_v2",
    "score": 55.41,
    "likes": 4.0,
    "link": "https://huggingface.co/psmathur/model_007_13b_v2",
    "still_on_hub": true
  },
  {
    "name": "llama2_13b_instructed_version2",
    "author": "Expert68",
    "query_name": "Expert68/llama2_13b_instructed_version2",
    "score": 55.41,
    "likes": 0.0,
    "link": "https://huggingface.co/Expert68/llama2_13b_instructed_version2",
    "still_on_hub": true
  },
  {
    "name": "Synthia-13B",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-13B",
    "score": 55.41,
    "likes": 10.0,
    "link": "https://huggingface.co/migtissera/Synthia-13B",
    "still_on_hub": true
  },
  {
    "name": "ennodata-raw-pankajmathur-13b-peft",
    "author": "Enno-Ai",
    "query_name": "Enno-Ai/ennodata-raw-pankajmathur-13b-peft",
    "score": 55.4,
    "likes": 0.0,
    "link": "https://huggingface.co/Enno-Ai/ennodata-raw-pankajmathur-13b-peft",
    "still_on_hub": true
  },
  {
    "name": "nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
    "author": "luffycodes",
    "query_name": "luffycodes/nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
    "score": 55.4,
    "likes": 2.0,
    "link": "https://huggingface.co/luffycodes/nash-vicuna-13b-v1dot5-ep2-w-rag-w-simple",
    "still_on_hub": true
  },
  {
    "name": "speechless-orca-platypus-coig-lite-2k-0.6e-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-orca-platypus-coig-lite-2k-0.6e-13b",
    "score": 55.4,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-orca-platypus-coig-lite-2k-0.6e-13b",
    "still_on_hub": true
  },
  {
    "name": "mpt-30b-chat",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-30b-chat",
    "score": 55.38,
    "likes": 183.0,
    "link": "https://huggingface.co/mosaicml/mpt-30b-chat",
    "still_on_hub": true
  },
  {
    "name": "minotaur-llama2-13b-qlora",
    "author": "ehartford",
    "query_name": "ehartford/minotaur-llama2-13b-qlora",
    "score": 55.37,
    "likes": 2.0,
    "link": "https://huggingface.co/ehartford/minotaur-llama2-13b-qlora",
    "still_on_hub": false
  },
  {
    "name": "gaodrew-gorgonzola-13b has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/215\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #215</a>",
    "author": "gaodrew",
    "query_name": "gaodrew/gaodrew-gorgonzola-13b",
    "score": 55.35,
    "likes": 0.0,
    "link": "https://huggingface.co/gaodrew/gaodrew-gorgonzola-13b",
    "still_on_hub": true
  },
  {
    "name": "Luban-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Luban-Platypus2-13B-QLora-0.80-epoch",
    "score": 55.34,
    "likes": 2.0,
    "link": "https://huggingface.co/TFLai/Luban-Platypus2-13B-QLora-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "SthenoWriter-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/SthenoWriter-L2-13B",
    "score": 55.33,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/SthenoWriter-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "chinese-alpaca-33b-merged",
    "author": "minlik",
    "query_name": "minlik/chinese-alpaca-33b-merged",
    "score": 55.33,
    "likes": 10.0,
    "link": "https://huggingface.co/minlik/chinese-alpaca-33b-merged",
    "still_on_hub": true
  },
  {
    "name": "2x-LoRA-Assemble-Platypus2-13B",
    "author": "PulsarAI",
    "query_name": "PulsarAI/2x-LoRA-Assemble-Platypus2-13B",
    "score": 55.33,
    "likes": 0.0,
    "link": "https://huggingface.co/PulsarAI/2x-LoRA-Assemble-Platypus2-13B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-Guanaco-QLoRA",
    "author": "yeontaek",
    "query_name": "yeontaek/llama-2-13b-Guanaco-QLoRA",
    "score": 55.31,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/llama-2-13b-Guanaco-QLoRA",
    "still_on_hub": true
  },
  {
    "name": "Xwin-LM-13B-V0.1",
    "author": "Xwin-LM",
    "query_name": "Xwin-LM/Xwin-LM-13B-V0.1",
    "score": 55.29,
    "likes": 57.0,
    "link": "https://huggingface.co/Xwin-LM/Xwin-LM-13B-V0.1",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-OpenOrca_20w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-OpenOrca_20w",
    "score": 55.28,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-OpenOrca_20w",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama2-13b-v11.1-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
    "score": 55.28,
    "likes": 16.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
    "still_on_hub": true
  },
  {
    "name": "chronos-13b-v2",
    "author": "elinas",
    "query_name": "elinas/chronos-13b-v2",
    "score": 55.25,
    "likes": 17.0,
    "link": "https://huggingface.co/elinas/chronos-13b-v2",
    "still_on_hub": true
  },
  {
    "name": "SOLAR-Platypus-10.7B-v2",
    "author": "kyujinpy",
    "query_name": "kyujinpy/SOLAR-Platypus-10.7B-v2",
    "score": 55.25,
    "likes": 0.0,
    "link": "https://huggingface.co/kyujinpy/SOLAR-Platypus-10.7B-v2",
    "still_on_hub": true
  },
  {
    "name": "CreativityEngine",
    "author": "Undi95",
    "query_name": "Undi95/CreativityEngine",
    "score": 55.25,
    "likes": 0.0,
    "link": "https://huggingface.co/Undi95/CreativityEngine",
    "still_on_hub": true
  },
  {
    "name": "Llama2-13b-sharegpt4",
    "author": "beaugogh",
    "query_name": "beaugogh/Llama2-13b-sharegpt4",
    "score": 55.25,
    "likes": 0.0,
    "link": "https://huggingface.co/beaugogh/Llama2-13b-sharegpt4",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-13B",
    "author": "teknium",
    "query_name": "teknium/OpenHermes-13B",
    "score": 55.24,
    "likes": 28.0,
    "link": "https://huggingface.co/teknium/OpenHermes-13B",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-v1.5-PL-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/vicuna-13b-v1.5-PL-lora_unload",
    "score": 55.24,
    "likes": 1.0,
    "link": "https://huggingface.co/Aspik101/vicuna-13b-v1.5-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-Chinese-chat",
    "author": "shareAI",
    "query_name": "shareAI/llama2-13b-Chinese-chat",
    "score": 55.22,
    "likes": 37.0,
    "link": "https://huggingface.co/shareAI/llama2-13b-Chinese-chat",
    "still_on_hub": false
  },
  {
    "name": "OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
    "score": 55.22,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/OrcaMini-Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "Chronorctypus-Limarobormes-13b",
    "author": "chargoddard",
    "query_name": "chargoddard/Chronorctypus-Limarobormes-13b",
    "score": 55.22,
    "likes": 10.0,
    "link": "https://huggingface.co/chargoddard/Chronorctypus-Limarobormes-13b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-13b-3.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-13b-3.0",
    "score": 55.21,
    "likes": 7.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-3.0",
    "still_on_hub": true
  },
  {
    "name": "Mythical-Destroyer-V2-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Mythical-Destroyer-V2-L2-13B",
    "score": 55.2,
    "likes": 10.0,
    "link": "https://huggingface.co/Sao10K/Mythical-Destroyer-V2-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "minotaur-13b-fixed",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/minotaur-13b-fixed",
    "score": 55.19,
    "likes": 10.0,
    "link": "https://huggingface.co/openaccess-ai-collective/minotaur-13b-fixed",
    "still_on_hub": true
  },
  {
    "name": "zephyr_7b_norobots",
    "author": "qblocks",
    "query_name": "qblocks/zephyr_7b_norobots",
    "score": 55.16,
    "likes": 0.0,
    "link": "https://huggingface.co/qblocks/zephyr_7b_norobots",
    "still_on_hub": false
  },
  {
    "name": "Platypus2xOpenOrca-13B-LoRa",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2xOpenOrca-13B-LoRa",
    "score": 55.15,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-LoRa",
    "still_on_hub": true
  },
  {
    "name": "airoboros-c34b-2.2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-c34b-2.2.1",
    "score": 55.15,
    "likes": 8.0,
    "link": "https://huggingface.co/jondurbin/airoboros-c34b-2.2.1",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13B-Instruct-v0.2",
    "author": "dfurman",
    "query_name": "dfurman/Llama-2-13B-Instruct-v0.2",
    "score": 55.14,
    "likes": 10.0,
    "link": "https://huggingface.co/dfurman/Llama-2-13B-Instruct-v0.2",
    "still_on_hub": false
  },
  {
    "name": "WizardLM-1.0-Uncensored-Llama2-13b",
    "author": "ehartford",
    "query_name": "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "score": 55.14,
    "likes": 36.0,
    "link": "https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "vigogne-2-13b-instruct",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-2-13b-instruct",
    "score": 55.14,
    "likes": 11.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-2-13b-instruct",
    "still_on_hub": true
  },
  {
    "name": "13B-Legerdemain-L2",
    "author": "CalderaAI",
    "query_name": "CalderaAI/13B-Legerdemain-L2",
    "score": 55.13,
    "likes": 10.0,
    "link": "https://huggingface.co/CalderaAI/13B-Legerdemain-L2",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-2-13b",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/pygmalion-2-13b",
    "score": 55.12,
    "likes": 29.0,
    "link": "https://huggingface.co/PygmalionAI/pygmalion-2-13b",
    "still_on_hub": true
  },
  {
    "name": "PuddleJumper-13b",
    "author": "totally-not-an-llm",
    "query_name": "totally-not-an-llm/PuddleJumper-13b",
    "score": 55.11,
    "likes": 6.0,
    "link": "https://huggingface.co/totally-not-an-llm/PuddleJumper-13b",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-1.0-Uncensored-Llama2-13b",
    "author": "ehartford",
    "query_name": "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "score": 55.1,
    "likes": 36.0,
    "link": "https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-FINETUNE4",
    "author": "wei123602",
    "query_name": "wei123602/Llama-2-13b-FINETUNE4",
    "score": 55.09,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-orca-8k-3319",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/llama2-13b-orca-8k-3319",
    "score": 55.09,
    "likes": 115.0,
    "link": "https://huggingface.co/OpenAssistant/llama2-13b-orca-8k-3319",
    "still_on_hub": true
  },
  {
    "name": "speechless-llama2-dolphin-orca-platypus-13b",
    "author": "speechlessai",
    "query_name": "speechlessai/speechless-llama2-dolphin-orca-platypus-13b",
    "score": 55.09,
    "likes": 0.0,
    "link": "https://huggingface.co/speechlessai/speechless-llama2-dolphin-orca-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "Llama2-Chinese-13b-Chat",
    "author": "FlagAlpha",
    "query_name": "FlagAlpha/Llama2-Chinese-13b-Chat",
    "score": 55.07,
    "likes": 206.0,
    "link": "https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-chat-german",
    "author": "jphme",
    "query_name": "jphme/Llama-2-13b-chat-german",
    "score": 55.07,
    "likes": 46.0,
    "link": "https://huggingface.co/jphme/Llama-2-13b-chat-german",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-dolphin_20w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-dolphin_20w",
    "score": 55.06,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-dolphin_20w",
    "still_on_hub": true
  },
  {
    "name": "Python-Code-33B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Python-Code-33B",
    "score": 55.06,
    "likes": 4.0,
    "link": "https://huggingface.co/ajibawa-2023/Python-Code-33B",
    "still_on_hub": true
  },
  {
    "name": "GodziLLa-30B",
    "author": "MayaPH",
    "query_name": "MayaPH/GodziLLa-30B",
    "score": 55.05,
    "likes": 8.0,
    "link": "https://huggingface.co/MayaPH/GodziLLa-30B",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-V1.1",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardLM-13B-V1.1",
    "score": 55.05,
    "likes": 69.0,
    "link": "https://huggingface.co/WizardLM/WizardLM-13B-V1.1",
    "still_on_hub": true
  },
  {
    "name": "llama-2-16b-nastychat",
    "author": "chargoddard",
    "query_name": "chargoddard/llama-2-16b-nastychat",
    "score": 55.04,
    "likes": 2.0,
    "link": "https://huggingface.co/chargoddard/llama-2-16b-nastychat",
    "still_on_hub": true
  },
  {
    "name": "shisa-7b-v1",
    "author": "augmxnt",
    "query_name": "augmxnt/shisa-7b-v1",
    "score": 55.01,
    "likes": 2.0,
    "link": "https://huggingface.co/augmxnt/shisa-7b-v1",
    "still_on_hub": true
  },
  {
    "name": "dulia-13b-8k-alpha",
    "author": "duliadotio",
    "query_name": "duliadotio/dulia-13b-8k-alpha",
    "score": 55.0,
    "likes": 0.0,
    "link": "https://huggingface.co/duliadotio/dulia-13b-8k-alpha",
    "still_on_hub": true
  },
  {
    "name": "Redmond-Puffin-13B-instruct-PL-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/Redmond-Puffin-13B-instruct-PL-lora_unload",
    "score": 55.0,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/Redmond-Puffin-13B-instruct-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "openchat_v3.2_super",
    "author": "openchat",
    "query_name": "openchat/openchat_v3.2_super",
    "score": 54.99,
    "likes": 24.0,
    "link": "https://huggingface.co/openchat/openchat_v3.2_super",
    "still_on_hub": true
  },
  {
    "name": "chinese-alpaca-2-13b",
    "author": "ziqingyang",
    "query_name": "ziqingyang/chinese-alpaca-2-13b",
    "score": 54.99,
    "likes": 64.0,
    "link": "https://huggingface.co/ziqingyang/chinese-alpaca-2-13b",
    "still_on_hub": true
  },
  {
    "name": "Asimov-7B-v1",
    "author": "prithivida",
    "query_name": "prithivida/Asimov-7B-v1",
    "score": 54.98,
    "likes": 0.0,
    "link": "https://huggingface.co/prithivida/Asimov-7B-v1",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-v1.5-16k",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-13b-v1.5-16k",
    "score": 54.97,
    "likes": 167.0,
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.5-16k",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-V1.0",
    "author": "LLMs",
    "query_name": "LLMs/WizardLM-13B-V1.0",
    "score": 54.97,
    "likes": 4.0,
    "link": "https://huggingface.co/LLMs/WizardLM-13B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-Instruct-v0.1",
    "author": "mistralai",
    "query_name": "mistralai/Mistral-7B-Instruct-v0.1",
    "score": 54.96,
    "likes": 698.0,
    "link": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1",
    "still_on_hub": true
  },
  {
    "name": "synapsellm-7b-mistral-v0.4-preview3",
    "author": "WebraftAI",
    "query_name": "WebraftAI/synapsellm-7b-mistral-v0.4-preview3",
    "score": 54.94,
    "likes": 0.0,
    "link": "https://huggingface.co/WebraftAI/synapsellm-7b-mistral-v0.4-preview3",
    "still_on_hub": true
  },
  {
    "name": "Sydney_Overthinker_13b_HF",
    "author": "FPHam",
    "query_name": "FPHam/Sydney_Overthinker_13b_HF",
    "score": 54.94,
    "likes": 1.0,
    "link": "https://huggingface.co/FPHam/Sydney_Overthinker_13b_HF",
    "still_on_hub": true
  },
  {
    "name": "wizardLM-13B-1.0-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/wizardLM-13B-1.0-fp16",
    "score": 54.93,
    "likes": 10.0,
    "link": "https://huggingface.co/TheBloke/wizardLM-13B-1.0-fp16",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-AEZAKMI-v1",
    "author": "adamo1139",
    "query_name": "adamo1139/Mistral-7B-AEZAKMI-v1",
    "score": 54.92,
    "likes": 0.0,
    "link": "https://huggingface.co/adamo1139/Mistral-7B-AEZAKMI-v1",
    "still_on_hub": true
  },
  {
    "name": "13B-Chimera",
    "author": "digitous",
    "query_name": "digitous/13B-Chimera",
    "score": 54.92,
    "likes": 6.0,
    "link": "https://huggingface.co/digitous/13B-Chimera",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-chat-hf",
    "author": "meta-llama",
    "query_name": "meta-llama/Llama-2-13b-chat-hf",
    "score": 54.91,
    "likes": 617.0,
    "link": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf",
    "still_on_hub": false
  },
  {
    "name": "Morningstar-13b-hf",
    "author": "NewstaR",
    "query_name": "NewstaR/Morningstar-13b-hf",
    "score": 54.91,
    "likes": 0.0,
    "link": "https://huggingface.co/NewstaR/Morningstar-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "CodeUp-Llama-2-13b-chat-hf",
    "author": "deepse",
    "query_name": "deepse/CodeUp-Llama-2-13b-chat-hf",
    "score": 54.91,
    "likes": 25.0,
    "link": "https://huggingface.co/deepse/CodeUp-Llama-2-13b-chat-hf",
    "still_on_hub": true
  },
  {
    "name": "Kimiko-v2-13B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Kimiko-v2-13B-fp16",
    "score": 54.91,
    "likes": 2.0,
    "link": "https://huggingface.co/TheBloke/Kimiko-v2-13B-fp16",
    "still_on_hub": true
  },
  {
    "name": "Huginn-13b-FP16",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Huginn-13b-FP16",
    "score": 54.89,
    "likes": 11.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-FP16",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-13B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Platypus2-13B",
    "score": 54.89,
    "likes": 15.0,
    "link": "https://huggingface.co/garage-bAInd/Platypus2-13B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
    "score": 54.88,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_addto15k_4.5w-r16-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "LewdEngine",
    "author": "Undi95",
    "query_name": "Undi95/LewdEngine",
    "score": 54.88,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/LewdEngine",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-guanaco-fp16",
    "author": "Mikael110",
    "query_name": "Mikael110/llama-2-13b-guanaco-fp16",
    "score": 54.86,
    "likes": 11.0,
    "link": "https://huggingface.co/Mikael110/llama-2-13b-guanaco-fp16",
    "still_on_hub": true
  },
  {
    "name": "manticore-13b",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/manticore-13b",
    "score": 54.86,
    "likes": 108.0,
    "link": "https://huggingface.co/openaccess-ai-collective/manticore-13b",
    "still_on_hub": true
  },
  {
    "name": "Redmond-Puffin-13B",
    "author": "NousResearch",
    "query_name": "NousResearch/Redmond-Puffin-13B",
    "score": 54.86,
    "likes": 99.0,
    "link": "https://huggingface.co/NousResearch/Redmond-Puffin-13B",
    "still_on_hub": true
  },
  {
    "name": "OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
    "score": 54.86,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "7B",
    "author": "CausalLM",
    "query_name": "CausalLM/7B",
    "score": 54.86,
    "likes": 103.0,
    "link": "https://huggingface.co/CausalLM/7B",
    "still_on_hub": false
  },
  {
    "name": "Code-13B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Code-13B",
    "score": 54.81,
    "likes": 0.0,
    "link": "https://huggingface.co/ajibawa-2023/Code-13B",
    "still_on_hub": true
  },
  {
    "name": "Samantha-1.11-CodeLlama-34b",
    "author": "ehartford",
    "query_name": "ehartford/Samantha-1.11-CodeLlama-34b",
    "score": 54.8,
    "likes": 41.0,
    "link": "https://huggingface.co/ehartford/Samantha-1.11-CodeLlama-34b",
    "still_on_hub": true
  },
  {
    "name": "llama-13b-FINETUNE3",
    "author": "wei123602",
    "query_name": "wei123602/llama-13b-FINETUNE3",
    "score": 54.79,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/llama-13b-FINETUNE3",
    "still_on_hub": true
  },
  {
    "name": "Ensemble5-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Ensemble5-Platypus2-13B-QLora-0.80-epoch",
    "score": 54.76,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Ensemble5-Platypus2-13B-QLora-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-V1.2",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardLM-13B-V1.2",
    "score": 54.76,
    "likes": 157.0,
    "link": "https://huggingface.co/WizardLM/WizardLM-13B-V1.2",
    "still_on_hub": true
  },
  {
    "name": "Redmond-Puffin-13B",
    "author": "NousResearch",
    "query_name": "NousResearch/Redmond-Puffin-13B",
    "score": 54.74,
    "likes": 99.0,
    "link": "https://huggingface.co/NousResearch/Redmond-Puffin-13B",
    "still_on_hub": true
  },
  {
    "name": "Chronos-Beluga-v2-13bfp16",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16",
    "score": 54.74,
    "likes": 6.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16",
    "still_on_hub": true
  },
  {
    "name": "TekniumAiroboros-Nebula-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/TekniumAiroboros-Nebula-7B",
    "score": 54.74,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/TekniumAiroboros-Nebula-7B",
    "still_on_hub": true
  },
  {
    "name": "MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
    "score": 54.74,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/MythoMix-Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "13B-Thorns-l2",
    "author": "CalderaAI",
    "query_name": "CalderaAI/13B-Thorns-l2",
    "score": 54.72,
    "likes": 5.0,
    "link": "https://huggingface.co/CalderaAI/13B-Thorns-l2",
    "still_on_hub": true
  },
  {
    "name": "Medusa-13b",
    "author": "Sao10K",
    "query_name": "Sao10K/Medusa-13b",
    "score": 54.72,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Medusa-13b",
    "still_on_hub": true
  },
  {
    "name": "Giraffe-beta-13b-32k",
    "author": "abacusai",
    "query_name": "abacusai/Giraffe-beta-13b-32k",
    "score": 54.69,
    "likes": 1.0,
    "link": "https://huggingface.co/abacusai/Giraffe-beta-13b-32k",
    "still_on_hub": true
  },
  {
    "name": "LLaMA2-13B-Psyfighter2",
    "author": "KoboldAI",
    "query_name": "KoboldAI/LLaMA2-13B-Psyfighter2",
    "score": 54.66,
    "likes": 1.0,
    "link": "https://huggingface.co/KoboldAI/LLaMA2-13B-Psyfighter2",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-34b-v1.9",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-34b-v1.9",
    "score": 54.64,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-34b-v1.9",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
    "score": 54.64,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13B-instructed",
    "author": "Secbone",
    "query_name": "Secbone/llama-2-13B-instructed",
    "score": 54.63,
    "likes": 0.0,
    "link": "https://huggingface.co/Secbone/llama-2-13B-instructed",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
    "score": 54.63,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "UltraLM-13B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/UltraLM-13B-fp16",
    "score": 54.62,
    "likes": 4.0,
    "link": "https://huggingface.co/TheBloke/UltraLM-13B-fp16",
    "still_on_hub": true
  },
  {
    "name": "Chat-Stheno-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Chat-Stheno-L2-13B",
    "score": 54.61,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Chat-Stheno-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
    "score": 54.61,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16",
    "still_on_hub": false
  },
  {
    "name": "Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
    "score": 54.6,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "Samantha-Nebula-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Samantha-Nebula-7B",
    "score": 54.58,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Samantha-Nebula-7B",
    "still_on_hub": true
  },
  {
    "name": "OpenOrca-Platypus2-13B-thera-1250",
    "author": "gaodrew",
    "query_name": "gaodrew/OpenOrca-Platypus2-13B-thera-1250",
    "score": 54.56,
    "likes": 0.0,
    "link": "https://huggingface.co/gaodrew/OpenOrca-Platypus2-13B-thera-1250",
    "still_on_hub": true
  },
  {
    "name": "Orca-2-7b",
    "author": "microsoft",
    "query_name": "microsoft/Orca-2-7b",
    "score": 54.55,
    "likes": 49.0,
    "link": "https://huggingface.co/microsoft/Orca-2-7b",
    "still_on_hub": true
  },
  {
    "name": "LLaMA2-13B-Holomax",
    "author": "KoboldAI",
    "query_name": "KoboldAI/LLaMA2-13B-Holomax",
    "score": 54.52,
    "likes": 12.0,
    "link": "https://huggingface.co/KoboldAI/LLaMA2-13B-Holomax",
    "still_on_hub": true
  },
  {
    "name": "LLaMA2-13B-Tiefighter",
    "author": "KoboldAI",
    "query_name": "KoboldAI/LLaMA2-13B-Tiefighter",
    "score": 54.51,
    "likes": 22.0,
    "link": "https://huggingface.co/KoboldAI/LLaMA2-13B-Tiefighter",
    "still_on_hub": true
  },
  {
    "name": "gpt4-alpaca-lora-13b-decapoda-1024",
    "author": "chansung",
    "query_name": "chansung/gpt4-alpaca-lora-13b-decapoda-1024",
    "score": 54.51,
    "likes": 3.0,
    "link": "https://huggingface.co/chansung/gpt4-alpaca-lora-13b-decapoda-1024",
    "still_on_hub": false
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
    "score": 54.5,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-13B-LoRa",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2-13B-LoRa",
    "score": 54.48,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2-13B-LoRa",
    "still_on_hub": true
  },
  {
    "name": "Limarp-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Limarp-Platypus2-13B-QLoRA-0.80-epoch",
    "score": 54.46,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Limarp-Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-FINETUNE4_TEST2",
    "author": "wei123602",
    "query_name": "wei123602/Llama-2-13b-FINETUNE4_TEST2",
    "score": 54.46,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_TEST2",
    "still_on_hub": true
  },
  {
    "name": "airophin-13b-pntk-16k-fp16",
    "author": "bhenrym14",
    "query_name": "bhenrym14/airophin-13b-pntk-16k-fp16",
    "score": 54.44,
    "likes": 4.0,
    "link": "https://huggingface.co/bhenrym14/airophin-13b-pntk-16k-fp16",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
    "author": "NekoPunchBBB",
    "query_name": "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
    "score": 54.4,
    "likes": 0.0,
    "link": "https://huggingface.co/NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-QLoRA-multigpu",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE1_17w-r16",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r16",
    "score": 54.37,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r16",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
    "score": 54.35,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-q_k_v_o_proj",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v3_7B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/orca_mini_v3_7B-GPTQ",
    "score": 54.35,
    "likes": 9.0,
    "link": "https://huggingface.co/TheBloke/orca_mini_v3_7B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf-instruct-pl-lora_unload",
    "author": "Lajonbot",
    "query_name": "Lajonbot/Llama-2-13b-hf-instruct-pl-lora_unload",
    "score": 54.34,
    "likes": 1.0,
    "link": "https://huggingface.co/Lajonbot/Llama-2-13b-hf-instruct-pl-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "vigogne-13b-instruct",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-13b-instruct",
    "score": 54.34,
    "likes": 13.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-13b-instruct",
    "still_on_hub": true
  },
  {
    "name": "llama-op-v4",
    "author": "anhnv125",
    "query_name": "anhnv125/llama-op-v4",
    "score": 54.34,
    "likes": 0.0,
    "link": "https://huggingface.co/anhnv125/llama-op-v4",
    "still_on_hub": false
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
    "score": 54.32,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "Camel-Platypus2-13B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Camel-Platypus2-13B",
    "score": 54.32,
    "likes": 2.0,
    "link": "https://huggingface.co/garage-bAInd/Camel-Platypus2-13B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-Open-Platypus_2.5w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-Open-Platypus_2.5w",
    "score": 54.32,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-Open-Platypus_2.5w",
    "still_on_hub": true
  },
  {
    "name": "Alpagasus-2-13b-QLoRA-merged",
    "author": "StudentLLM",
    "query_name": "StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "score": 54.31,
    "likes": 0.0,
    "link": "https://huggingface.co/StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-V1.1-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-13B-V1.1-GPTQ",
    "score": 54.28,
    "likes": 26.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-13B-V1.1-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "wizard-mega-13b",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/wizard-mega-13b",
    "score": 54.27,
    "likes": 103.0,
    "link": "https://huggingface.co/openaccess-ai-collective/wizard-mega-13b",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-v1.3",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-13b-v1.3",
    "score": 54.27,
    "likes": 160.0,
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.3",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-code-alpaca",
    "author": "layoric",
    "query_name": "layoric/llama-2-13b-code-alpaca",
    "score": 54.25,
    "likes": 5.0,
    "link": "https://huggingface.co/layoric/llama-2-13b-code-alpaca",
    "still_on_hub": true
  },
  {
    "name": "13B-HyperMantis",
    "author": "digitous",
    "query_name": "digitous/13B-HyperMantis",
    "score": 54.25,
    "likes": 26.0,
    "link": "https://huggingface.co/digitous/13B-HyperMantis",
    "still_on_hub": true
  },
  {
    "name": "EverythingLM-13b-V3-peft",
    "author": "totally-not-an-llm",
    "query_name": "totally-not-an-llm/EverythingLM-13b-V3-peft",
    "score": 54.24,
    "likes": 1.0,
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-V3-peft",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-13B-IA3",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2-13B-IA3",
    "score": 54.23,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2-13B-IA3",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-hf-platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/llama-2-13b-hf-platypus",
    "score": 54.22,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/llama-2-13b-hf-platypus",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf_Open-Platypus",
    "author": "NekoPunchBBB",
    "query_name": "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus",
    "score": 54.22,
    "likes": 0.0,
    "link": "https://huggingface.co/NekoPunchBBB/Llama-2-13b-hf_Open-Platypus",
    "still_on_hub": true
  },
  {
    "name": "Free_Sydney_13b_HF",
    "author": "FPHam",
    "query_name": "FPHam/Free_Sydney_13b_HF",
    "score": 54.22,
    "likes": 10.0,
    "link": "https://huggingface.co/FPHam/Free_Sydney_13b_HF",
    "still_on_hub": true
  },
  {
    "name": "genz-13b-v2",
    "author": "budecosystem",
    "query_name": "budecosystem/genz-13b-v2",
    "score": 54.2,
    "likes": 3.0,
    "link": "https://huggingface.co/budecosystem/genz-13b-v2",
    "still_on_hub": true
  },
  {
    "name": "Alpagasus-2-13b-QLoRA-merged",
    "author": "StudentLLM",
    "query_name": "StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "score": 54.2,
    "likes": 2.0,
    "link": "https://huggingface.co/StudentLLM/Alpagasus-2-13b-QLoRA-merged",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-math1.2",
    "author": "FelixChao",
    "query_name": "FelixChao/llama2-13b-math1.2",
    "score": 54.19,
    "likes": 0.0,
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.2",
    "still_on_hub": true
  },
  {
    "name": "PuddleJumper-13b-V2",
    "author": "totally-not-an-llm",
    "query_name": "totally-not-an-llm/PuddleJumper-13b-V2",
    "score": 54.19,
    "likes": 1.0,
    "link": "https://huggingface.co/totally-not-an-llm/PuddleJumper-13b-V2",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-math1.1",
    "author": "FelixChao",
    "query_name": "FelixChao/llama2-13b-math1.1",
    "score": 54.18,
    "likes": 0.0,
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.1",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE1_17w-r4",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r4",
    "score": 54.18,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE1_17w-r4",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
    "score": 54.16,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged",
    "still_on_hub": true
  },
  {
    "name": "Metharme-13b-Merged",
    "author": "TehVenom",
    "query_name": "TehVenom/Metharme-13b-Merged",
    "score": 54.15,
    "likes": 10.0,
    "link": "https://huggingface.co/TehVenom/Metharme-13b-Merged",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-math1.1",
    "author": "FelixChao",
    "query_name": "FelixChao/llama2-13b-math1.1",
    "score": 54.14,
    "likes": 0.0,
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.1",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-13B-Uncensored-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
    "score": 54.14,
    "likes": 197.0,
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-13B-Uncensored",
    "author": "ehartford",
    "query_name": "ehartford/Wizard-Vicuna-13B-Uncensored",
    "score": 54.14,
    "likes": 218.0,
    "link": "https://huggingface.co/ehartford/Wizard-Vicuna-13B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
    "score": 54.14,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16",
    "still_on_hub": false
  },
  {
    "name": "speechless-orca-platypus-coig-lite-4k-0.5e-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-orca-platypus-coig-lite-4k-0.5e-13b",
    "score": 54.13,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-orca-platypus-coig-lite-4k-0.5e-13b",
    "still_on_hub": true
  },
  {
    "name": "manticore-13b-chat-pyg",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/manticore-13b-chat-pyg",
    "score": 54.13,
    "likes": 24.0,
    "link": "https://huggingface.co/openaccess-ai-collective/manticore-13b-chat-pyg",
    "still_on_hub": true
  },
  {
    "name": "13B-BlueMethod",
    "author": "CalderaAI",
    "query_name": "CalderaAI/13B-BlueMethod",
    "score": 54.12,
    "likes": 7.0,
    "link": "https://huggingface.co/CalderaAI/13B-BlueMethod",
    "still_on_hub": true
  },
  {
    "name": "chinese-alpaca-2-13b-16k",
    "author": "hfl",
    "query_name": "hfl/chinese-alpaca-2-13b-16k",
    "score": 54.12,
    "likes": 24.0,
    "link": "https://huggingface.co/hfl/chinese-alpaca-2-13b-16k",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
    "score": 54.12,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w-gate_up_down_proj",
    "still_on_hub": true
  },
  {
    "name": "Athena-v1",
    "author": "IkariDev",
    "query_name": "IkariDev/Athena-v1",
    "score": 54.11,
    "likes": 11.0,
    "link": "https://huggingface.co/IkariDev/Athena-v1",
    "still_on_hub": true
  },
  {
    "name": "llama2-platypus-llama2-chat-13B-hf",
    "author": "chickencaesar",
    "query_name": "chickencaesar/llama2-platypus-llama2-chat-13B-hf",
    "score": 54.11,
    "likes": 0.0,
    "link": "https://huggingface.co/chickencaesar/llama2-platypus-llama2-chat-13B-hf",
    "still_on_hub": true
  },
  {
    "name": "Guanaco-13B-Uncensored",
    "author": "Fredithefish",
    "query_name": "Fredithefish/Guanaco-13B-Uncensored",
    "score": 54.1,
    "likes": 9.0,
    "link": "https://huggingface.co/Fredithefish/Guanaco-13B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-Beluga-QLoRA",
    "author": "yeontaek",
    "query_name": "yeontaek/llama-2-13b-Beluga-QLoRA",
    "score": 54.09,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/llama-2-13b-Beluga-QLoRA",
    "still_on_hub": true
  },
  {
    "name": "Yi-6B",
    "author": "01-ai",
    "query_name": "01-ai/Yi-6B",
    "score": 54.08,
    "likes": 287.0,
    "link": "https://huggingface.co/01-ai/Yi-6B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
    "score": 54.08,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r16-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "StableBeluga1-Delta",
    "author": "stabilityai",
    "query_name": "stabilityai/StableBeluga1-Delta",
    "score": 54.08,
    "likes": 54.0,
    "link": "https://huggingface.co/stabilityai/StableBeluga1-Delta",
    "still_on_hub": false
  },
  {
    "name": "airophin-v2-13b-PI-8k-fp16",
    "author": "bhenrym14",
    "query_name": "bhenrym14/airophin-v2-13b-PI-8k-fp16",
    "score": 54.07,
    "likes": 1.0,
    "link": "https://huggingface.co/bhenrym14/airophin-v2-13b-PI-8k-fp16",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
    "score": 54.06,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "ReMM-L2-13B-PIPPA",
    "author": "Undi95",
    "query_name": "Undi95/ReMM-L2-13B-PIPPA",
    "score": 54.06,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/ReMM-L2-13B-PIPPA",
    "still_on_hub": true
  },
  {
    "name": "ReMM-L2-13B",
    "author": "Undi95",
    "query_name": "Undi95/ReMM-L2-13B",
    "score": 54.06,
    "likes": 2.0,
    "link": "https://huggingface.co/Undi95/ReMM-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-math1.2",
    "author": "FelixChao",
    "query_name": "FelixChao/llama2-13b-math1.2",
    "score": 54.05,
    "likes": 0.0,
    "link": "https://huggingface.co/FelixChao/llama2-13b-math1.2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-FINETUNE4_compare8k2",
    "author": "wei123602",
    "query_name": "wei123602/Llama-2-13b-FINETUNE4_compare8k2",
    "score": 54.05,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_compare8k2",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/airoboros-13B-HF",
    "score": 54.05,
    "likes": 12.0,
    "link": "https://huggingface.co/TheBloke/airoboros-13B-HF",
    "still_on_hub": true
  },
  {
    "name": "Nous-Hermes-13b",
    "author": "NousResearch",
    "query_name": "NousResearch/Nous-Hermes-13b",
    "score": 54.04,
    "likes": 388.0,
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-13b",
    "still_on_hub": true
  },
  {
    "name": "Huginn-13b-V4",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Huginn-13b-V4",
    "score": 54.04,
    "likes": 0.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-V4",
    "still_on_hub": true
  },
  {
    "name": "Huginn-13b-v4.5",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Huginn-13b-v4.5",
    "score": 54.04,
    "likes": 2.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-13b-v4.5",
    "still_on_hub": true
  },
  {
    "name": "Huginn-v3-13b",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Huginn-v3-13b",
    "score": 54.04,
    "likes": 11.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-v3-13b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13b",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-13b",
    "score": 54.02,
    "likes": 93.0,
    "link": "https://huggingface.co/jondurbin/airoboros-13b",
    "still_on_hub": true
  },
  {
    "name": "Yi-6B",
    "author": "01-ai",
    "query_name": "01-ai/Yi-6B",
    "score": 54.02,
    "likes": 15.0,
    "link": "https://huggingface.co/01-ai/Yi-6B",
    "still_on_hub": true
  },
  {
    "name": "llama-13b-pretrained",
    "author": "dvruette",
    "query_name": "dvruette/llama-13b-pretrained",
    "score": 54.02,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
    "score": 54.02,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch",
    "score": 54.01,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "based-30b",
    "author": "ehartford",
    "query_name": "ehartford/based-30b",
    "score": 54.0,
    "likes": 39.0,
    "link": "https://huggingface.co/ehartford/based-30b",
    "still_on_hub": true
  },
  {
    "name": "speechless-orca-platypus-coig-lite-4k-0.6e-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-orca-platypus-coig-lite-4k-0.6e-13b",
    "score": 53.99,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-orca-platypus-coig-lite-4k-0.6e-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
    "score": 53.99,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "gpt4-alpaca-lora-13B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/gpt4-alpaca-lora-13B-HF",
    "score": 53.98,
    "likes": 4.0,
    "link": "https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-HF",
    "still_on_hub": true
  },
  {
    "name": "webMistral-7B",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/webMistral-7B",
    "score": 53.97,
    "likes": 1.0,
    "link": "https://huggingface.co/KnutJaegersberg/webMistral-7B",
    "still_on_hub": true
  },
  {
    "name": "WizardMath-13B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardMath-13B-V1.0",
    "score": 53.97,
    "likes": 16.0,
    "link": "https://huggingface.co/WizardLM/WizardMath-13B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "minotaur-13b",
    "author": "openaccess-ai-collective",
    "query_name": "openaccess-ai-collective/minotaur-13b",
    "score": 53.97,
    "likes": 9.0,
    "link": "https://huggingface.co/openaccess-ai-collective/minotaur-13b",
    "still_on_hub": true
  },
  {
    "name": "openchat_v2_w",
    "author": "openchat",
    "query_name": "openchat/openchat_v2_w",
    "score": 53.96,
    "likes": 29.0,
    "link": "https://huggingface.co/openchat/openchat_v2_w",
    "still_on_hub": true
  },
  {
    "name": "openchat_v2",
    "author": "openchat",
    "query_name": "openchat/openchat_v2",
    "score": 53.96,
    "likes": 12.0,
    "link": "https://huggingface.co/openchat/openchat_v2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-FINETUNE4_TEST3",
    "author": "wei123602",
    "query_name": "wei123602/Llama-2-13b-FINETUNE4_TEST3",
    "score": 53.95,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_TEST3",
    "still_on_hub": true
  },
  {
    "name": "Platypus-Nebula-v2-7B",
    "author": "Weyaxi",
    "query_name": "Weyaxi/Platypus-Nebula-v2-7B",
    "score": 53.95,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/Platypus-Nebula-v2-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
    "score": 53.95,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-gate_up_down_proj",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
    "score": 53.94,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_compare15k_4.5w-r16-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "trurl-2-13b-academic",
    "author": "Voicelab",
    "query_name": "Voicelab/trurl-2-13b-academic",
    "score": 53.94,
    "likes": 0.0,
    "link": "https://huggingface.co/Voicelab/trurl-2-13b-academic",
    "still_on_hub": true
  },
  {
    "name": "Pwen-7B-Chat-20_30",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/Pwen-7B-Chat-20_30",
    "score": 53.93,
    "likes": 0.0,
    "link": "https://huggingface.co/JosephusCheung/Pwen-7B-Chat-20_30",
    "still_on_hub": false
  },
  {
    "name": "Ferret-7B",
    "author": "euclaise",
    "query_name": "euclaise/Ferret-7B",
    "score": 53.93,
    "likes": 1.0,
    "link": "https://huggingface.co/euclaise/Ferret-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-chat-platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/llama-2-13b-chat-platypus",
    "score": 53.92,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/llama-2-13b-chat-platypus",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "author": "bhenrym14",
    "query_name": "bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "score": 53.92,
    "likes": 4.0,
    "link": "https://huggingface.co/bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-huangyt_Fintune_1_17w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w",
    "score": 53.91,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_Fintune_1_17w",
    "still_on_hub": true
  },
  {
    "name": "MythoBoros-13b",
    "author": "Gryphe",
    "query_name": "Gryphe/MythoBoros-13b",
    "score": 53.9,
    "likes": 12.0,
    "link": "https://huggingface.co/Gryphe/MythoBoros-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-QLoRA",
    "author": "yeontaek",
    "query_name": "yeontaek/llama-2-13b-QLoRA",
    "score": 53.87,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/llama-2-13b-QLoRA",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13b-gpt4-1.4-fp16",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-13b-gpt4-1.4-fp16",
    "score": 53.87,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.4-fp16",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13b-gpt4-1.4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-13b-gpt4-1.4",
    "score": 53.87,
    "likes": 18.0,
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.4",
    "still_on_hub": true
  },
  {
    "name": "Ferret-7B",
    "author": "euclaise",
    "query_name": "euclaise/Ferret-7B",
    "score": 53.87,
    "likes": 1.0,
    "link": "https://huggingface.co/euclaise/Ferret-7B",
    "still_on_hub": true
  },
  {
    "name": "Ferret_7B",
    "author": "euclaise",
    "query_name": "euclaise/Ferret_7B",
    "score": 53.87,
    "likes": 1.0,
    "link": "https://huggingface.co/euclaise/Ferret_7B",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-ft-openllm-leaderboard-v1",
    "author": "zyh3826",
    "query_name": "zyh3826/llama2-13b-ft-openllm-leaderboard-v1",
    "score": 53.86,
    "likes": 0.0,
    "link": "https://huggingface.co/zyh3826/llama2-13b-ft-openllm-leaderboard-v1",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
    "score": 53.86,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-V1.2-PL-lora_unload",
    "author": "Lajonbot",
    "query_name": "Lajonbot/WizardLM-13B-V1.2-PL-lora_unload",
    "score": 53.86,
    "likes": 0.0,
    "link": "https://huggingface.co/Lajonbot/WizardLM-13B-V1.2-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "MythoLogic-13b",
    "author": "Gryphe",
    "query_name": "Gryphe/MythoLogic-13b",
    "score": 53.85,
    "likes": 17.0,
    "link": "https://huggingface.co/Gryphe/MythoLogic-13b",
    "still_on_hub": true
  },
  {
    "name": "platypus-2-22b-relora",
    "author": "chargoddard",
    "query_name": "chargoddard/platypus-2-22b-relora",
    "score": 53.83,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/platypus-2-22b-relora",
    "still_on_hub": true
  },
  {
    "name": "Libra-19B",
    "author": "Envoid",
    "query_name": "Envoid/Libra-19B",
    "score": 53.83,
    "likes": 1.0,
    "link": "https://huggingface.co/Envoid/Libra-19B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
    "score": 53.8,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w-3_epoch",
    "still_on_hub": true
  },
  {
    "name": "test-help-steer-filtered-orig",
    "author": "Weyaxi",
    "query_name": "Weyaxi/test-help-steer-filtered-orig",
    "score": 53.77,
    "likes": 0.0,
    "link": "https://huggingface.co/Weyaxi/test-help-steer-filtered-orig",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf_Open-Platypus-8bit-att",
    "author": "NekoPunchBBB",
    "query_name": "NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-8bit-att",
    "score": 53.75,
    "likes": 0.0,
    "link": "https://huggingface.co/NekoPunchBBB/Llama-2-13b-hf_Open-Platypus-8bit-att",
    "still_on_hub": true
  },
  {
    "name": "Kimiko-13B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Kimiko-13B-fp16",
    "score": 53.75,
    "likes": 2.0,
    "link": "https://huggingface.co/TheBloke/Kimiko-13B-fp16",
    "still_on_hub": true
  },
  {
    "name": "GiftedConvo13bLoraNoEconsE4",
    "author": "NobodyExistsOnTheInternet",
    "query_name": "NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEconsE4",
    "score": 53.74,
    "likes": 0.0,
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEconsE4",
    "still_on_hub": false
  },
  {
    "name": "llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
    "score": 53.74,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w-q_k_v_o_proj",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-13B-QLoRa",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2-13B-QLoRa",
    "score": 53.74,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2-13B-QLoRa",
    "still_on_hub": true
  },
  {
    "name": "zarafusionex-1.2-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zarafusionex-1.2-l2-7b",
    "score": 53.73,
    "likes": 2.0,
    "link": "https://huggingface.co/zarakiquemparte/zarafusionex-1.2-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
    "score": 53.71,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
    "score": 53.71,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-v1.3-PL-lora_unload",
    "author": "Lajonbot",
    "query_name": "Lajonbot/vicuna-13b-v1.3-PL-lora_unload",
    "score": 53.7,
    "likes": 0.0,
    "link": "https://huggingface.co/Lajonbot/vicuna-13b-v1.3-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "gaodrew-gorgonzola-13b has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/215\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #215</a>",
    "author": "gaodrew",
    "query_name": "gaodrew/gaodrew-gorgonzola-13b",
    "score": 53.7,
    "likes": 0.0,
    "link": "https://huggingface.co/gaodrew/gaodrew-gorgonzola-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
    "score": 53.69,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r8-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-huangyt_FINETUNE2_3w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w",
    "score": 53.69,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-huangyt_FINETUNE2_3w",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-chat-dutch",
    "author": "BramVanroy",
    "query_name": "BramVanroy/Llama-2-13b-chat-dutch",
    "score": 53.69,
    "likes": 10.0,
    "link": "https://huggingface.co/BramVanroy/Llama-2-13b-chat-dutch",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13b-gpt4-1.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-13b-gpt4-1.1",
    "score": 53.68,
    "likes": 2.0,
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.1",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
    "score": 53.68,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "bimoGPT-llama2-13b",
    "author": "shareAI",
    "query_name": "shareAI/bimoGPT-llama2-13b",
    "score": 53.68,
    "likes": 6.0,
    "link": "https://huggingface.co/shareAI/bimoGPT-llama2-13b",
    "still_on_hub": false
  },
  {
    "name": "Llama-2-13B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Llama-2-13B-fp16",
    "score": 53.67,
    "likes": 51.0,
    "link": "https://huggingface.co/TheBloke/Llama-2-13B-fp16",
    "still_on_hub": true
  },
  {
    "name": "Starlight-13B",
    "author": "NewstaR",
    "query_name": "NewstaR/Starlight-13B",
    "score": 53.67,
    "likes": 0.0,
    "link": "https://huggingface.co/NewstaR/Starlight-13B",
    "still_on_hub": true
  },
  {
    "name": "Flash-Llama-13B",
    "author": "TaylorAI",
    "query_name": "TaylorAI/Flash-Llama-13B",
    "score": 53.67,
    "likes": 0.0,
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-13B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
    "score": 53.66,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down-test1",
    "still_on_hub": true
  },
  {
    "name": "llama2-22b-blocktriangular",
    "author": "chargoddard",
    "query_name": "chargoddard/llama2-22b-blocktriangular",
    "score": 53.65,
    "likes": 4.0,
    "link": "https://huggingface.co/chargoddard/llama2-22b-blocktriangular",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13b-gpt4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-13b-gpt4",
    "score": 53.64,
    "likes": 17.0,
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4",
    "still_on_hub": true
  },
  {
    "name": "llama2-22b",
    "author": "chargoddard",
    "query_name": "chargoddard/llama2-22b",
    "score": 53.64,
    "likes": 35.0,
    "link": "https://huggingface.co/chargoddard/llama2-22b",
    "still_on_hub": true
  },
  {
    "name": "platypus2-22b-relora",
    "author": "chargoddard",
    "query_name": "chargoddard/platypus2-22b-relora",
    "score": 53.64,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/platypus2-22b-relora",
    "still_on_hub": true
  },
  {
    "name": "PuffedLIMA13bQLORA",
    "author": "NobodyExistsOnTheInternet",
    "query_name": "NobodyExistsOnTheInternet/PuffedLIMA13bQLORA",
    "score": 53.63,
    "likes": 0.0,
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/PuffedLIMA13bQLORA",
    "still_on_hub": false
  },
  {
    "name": "deacon-13b",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/deacon-13b",
    "score": 53.63,
    "likes": 1.0,
    "link": "https://huggingface.co/KnutJaegersberg/deacon-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
    "score": 53.62,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-FINETUNE3_TEST2",
    "author": "wei123602",
    "query_name": "wei123602/llama2-13b-FINETUNE3_TEST2",
    "score": 53.62,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/llama2-13b-FINETUNE3_TEST2",
    "still_on_hub": true
  },
  {
    "name": "tora-13b-v1.0",
    "author": "llm-agents",
    "query_name": "llm-agents/tora-13b-v1.0",
    "score": 53.62,
    "likes": 2.0,
    "link": "https://huggingface.co/llm-agents/tora-13b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "MistralInstructLongish",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/MistralInstructLongish",
    "score": 53.62,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/MistralInstructLongish",
    "still_on_hub": true
  },
  {
    "name": "PuffedConvo13bLoraE4",
    "author": "NobodyExistsOnTheInternet",
    "query_name": "NobodyExistsOnTheInternet/PuffedConvo13bLoraE4",
    "score": 53.62,
    "likes": 0.0,
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/PuffedConvo13bLoraE4",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-FINETUNE4_TEST",
    "author": "wei123602",
    "query_name": "wei123602/Llama-2-13b-FINETUNE4_TEST",
    "score": 53.62,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/Llama-2-13b-FINETUNE4_TEST",
    "still_on_hub": true
  },
  {
    "name": "Nous-Hermes-13b-pl-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/Nous-Hermes-13b-pl-lora_unload",
    "score": 53.61,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/Nous-Hermes-13b-pl-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "Python-Code-13B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Python-Code-13B",
    "score": 53.61,
    "likes": 2.0,
    "link": "https://huggingface.co/ajibawa-2023/Python-Code-13B",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-ft-mc4_nl_cleaned_tiny",
    "author": "BramVanroy",
    "query_name": "BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny",
    "score": 53.6,
    "likes": 1.0,
    "link": "https://huggingface.co/BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-1.0-Uncensored-CodeLlama-34b",
    "author": "ehartford",
    "query_name": "ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b",
    "score": 53.59,
    "likes": 20.0,
    "link": "https://huggingface.co/ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
    "score": 53.58,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "tulu-13B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/tulu-13B-fp16",
    "score": 53.58,
    "likes": 2.0,
    "link": "https://huggingface.co/TheBloke/tulu-13B-fp16",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
    "score": 53.57,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged",
    "still_on_hub": true
  },
  {
    "name": "StableBeluga-7B",
    "author": "stabilityai",
    "query_name": "stabilityai/StableBeluga-7B",
    "score": 53.56,
    "likes": 112.0,
    "link": "https://huggingface.co/stabilityai/StableBeluga-7B",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-orca-v1",
    "author": "circulus",
    "query_name": "circulus/Llama-2-7b-orca-v1",
    "score": 53.56,
    "likes": 5.0,
    "link": "https://huggingface.co/circulus/Llama-2-7b-orca-v1",
    "still_on_hub": true
  },
  {
    "name": "dolphin-llama-13b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-llama-13b",
    "score": 53.56,
    "likes": 56.0,
    "link": "https://huggingface.co/ehartford/dolphin-llama-13b",
    "still_on_hub": true
  },
  {
    "name": "oasst-llama-13b-2-epochs",
    "author": "dvruette",
    "query_name": "dvruette/oasst-llama-13b-2-epochs",
    "score": 53.55,
    "likes": 8.0,
    "link": "https://huggingface.co/dvruette/oasst-llama-13b-2-epochs",
    "still_on_hub": true
  },
  {
    "name": "guanaco-13B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/guanaco-13B-HF",
    "score": 53.54,
    "likes": 7.0,
    "link": "https://huggingface.co/TheBloke/guanaco-13B-HF",
    "still_on_hub": true
  },
  {
    "name": "tableBeluga-7B-instruct-pl-lora_unload",
    "author": "Lajonbot",
    "query_name": "Lajonbot/tableBeluga-7B-instruct-pl-lora_unload",
    "score": 53.54,
    "likes": 2.0,
    "link": "https://huggingface.co/Lajonbot/tableBeluga-7B-instruct-pl-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "llama2-22b-blocktriangular",
    "author": "chargoddard",
    "query_name": "chargoddard/llama2-22b-blocktriangular",
    "score": 53.53,
    "likes": 4.0,
    "link": "https://huggingface.co/chargoddard/llama2-22b-blocktriangular",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama-13b",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama-13b",
    "score": 53.53,
    "likes": 4.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-Open_Platypus_and_ccp_2.6w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w",
    "score": 53.52,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-Open_Platypus_and_ccp_2.6w",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
    "score": 53.52,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r16-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "llama13B-quant8-testv1-openorca-customdataset",
    "author": "IGeniusDev",
    "query_name": "IGeniusDev/llama13B-quant8-testv1-openorca-customdataset",
    "score": 53.5,
    "likes": 0.0,
    "link": "https://huggingface.co/IGeniusDev/llama13B-quant8-testv1-openorca-customdataset",
    "still_on_hub": true
  },
  {
    "name": "vigogne-13b-chat",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-13b-chat",
    "score": 53.5,
    "likes": 1.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-13b-chat",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-mistral-7b-v13",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-mistral-7b-v13",
    "score": 53.5,
    "likes": 3.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-mistral-7b-v13",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama-13b-v1.2",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama-13b-v1.2",
    "score": 53.49,
    "likes": 1.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama-13b-v1.2",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
    "score": 53.48,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v3_7b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_v3_7b",
    "score": 53.47,
    "likes": 37.0,
    "link": "https://huggingface.co/psmathur/orca_mini_v3_7b",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v3_7b",
    "author": "pankajmathur",
    "query_name": "pankajmathur/orca_mini_v3_7b",
    "score": 53.47,
    "likes": 37.0,
    "link": "https://huggingface.co/pankajmathur/orca_mini_v3_7b",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama2-13b-chat",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama2-13b-chat",
    "score": 53.46,
    "likes": 0.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b-chat",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
    "score": 53.44,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r16-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
    "score": 53.43,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r8-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "tigerbot-13b-base",
    "author": "TigerResearch",
    "query_name": "TigerResearch/tigerbot-13b-base",
    "score": 53.42,
    "likes": 7.0,
    "link": "https://huggingface.co/TigerResearch/tigerbot-13b-base",
    "still_on_hub": true
  },
  {
    "name": "zarafusionex-1.1-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zarafusionex-1.1-l2-7b",
    "score": 53.41,
    "likes": 7.0,
    "link": "https://huggingface.co/zarakiquemparte/zarafusionex-1.1-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "QuantumLM",
    "author": "quantumaikr",
    "query_name": "quantumaikr/QuantumLM",
    "score": 53.41,
    "likes": 1.0,
    "link": "https://huggingface.co/quantumaikr/QuantumLM",
    "still_on_hub": true
  },
  {
    "name": "samantha-mistral-instruct-7b",
    "author": "ehartford",
    "query_name": "ehartford/samantha-mistral-instruct-7b",
    "score": 53.4,
    "likes": 14.0,
    "link": "https://huggingface.co/ehartford/samantha-mistral-instruct-7b",
    "still_on_hub": true
  },
  {
    "name": "mpt-30b-instruct",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-30b-instruct",
    "score": 53.4,
    "likes": 93.0,
    "link": "https://huggingface.co/mosaicml/mpt-30b-instruct",
    "still_on_hub": true
  },
  {
    "name": "GPT4-x-Alpasta-13b",
    "author": "Aeala",
    "query_name": "Aeala/GPT4-x-Alpasta-13b",
    "score": 53.38,
    "likes": 3.0,
    "link": "https://huggingface.co/Aeala/GPT4-x-Alpasta-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
    "score": 53.38,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "GiftedConvo13bLoraNoEcons",
    "author": "NobodyExistsOnTheInternet",
    "query_name": "NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEcons",
    "score": 53.35,
    "likes": 0.0,
    "link": "https://huggingface.co/NobodyExistsOnTheInternet/GiftedConvo13bLoraNoEcons",
    "still_on_hub": false
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
    "score": 53.35,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-13b-2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-13b-2.1",
    "score": 53.34,
    "likes": 10.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-2.1",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
    "score": 53.32,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE5_4w-r4-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-v1.3.0-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/vicuna-13b-v1.3.0-GPTQ",
    "score": 53.29,
    "likes": 19.0,
    "link": "https://huggingface.co/TheBloke/vicuna-13b-v1.3.0-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13B-1.1-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/vicuna-13B-1.1-HF",
    "score": 53.29,
    "likes": 96.0,
    "link": "https://huggingface.co/TheBloke/vicuna-13B-1.1-HF",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-1.1",
    "author": "eachadea",
    "query_name": "eachadea/vicuna-13b-1.1",
    "score": 53.29,
    "likes": 134.0,
    "link": "https://huggingface.co/eachadea/vicuna-13b-1.1",
    "still_on_hub": true
  },
  {
    "name": "delta13b",
    "author": "pillowtalks-ai",
    "query_name": "pillowtalks-ai/delta13b",
    "score": 53.29,
    "likes": 1.0,
    "link": "https://huggingface.co/pillowtalks-ai/delta13b",
    "still_on_hub": true
  },
  {
    "name": "Vicuna-13B-CoT",
    "author": "kevinpro",
    "query_name": "kevinpro/Vicuna-13B-CoT",
    "score": 53.29,
    "likes": 4.0,
    "link": "https://huggingface.co/kevinpro/Vicuna-13B-CoT",
    "still_on_hub": true
  },
  {
    "name": "Vicuna-13B-CoT-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Vicuna-13B-CoT-fp16",
    "score": 53.28,
    "likes": 3.0,
    "link": "https://huggingface.co/TheBloke/Vicuna-13B-CoT-fp16",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-v1.1",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-13b-v1.1",
    "score": 53.28,
    "likes": 96.0,
    "link": "https://huggingface.co/lmsys/vicuna-13b-v1.1",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b-delta-v1.1",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-13b-delta-v1.1",
    "score": 53.28,
    "likes": 402.0,
    "link": "https://huggingface.co/lmsys/vicuna-13b-delta-v1.1",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Llama-2-13B-GPTQ",
    "score": 53.26,
    "likes": 99.0,
    "link": "https://huggingface.co/TheBloke/Llama-2-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
    "score": 53.23,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "airoboros-2.1-llama-2-13B-QLoRa",
    "author": "yeontaek",
    "query_name": "yeontaek/airoboros-2.1-llama-2-13B-QLoRa",
    "score": 53.23,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/airoboros-2.1-llama-2-13B-QLoRa",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE2_TEST_2.2w",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE2_TEST_2.2w",
    "score": 53.2,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE2_TEST_2.2w",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-Llemma-7B",
    "author": "meta-math",
    "query_name": "meta-math/MetaMath-Llemma-7B",
    "score": 53.19,
    "likes": 6.0,
    "link": "https://huggingface.co/meta-math/MetaMath-Llemma-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
    "score": 53.18,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r4-q_k_v_o",
    "still_on_hub": true
  },
  {
    "name": "zarafusionix-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zarafusionix-l2-7b",
    "score": 53.18,
    "likes": 0.0,
    "link": "https://huggingface.co/zarakiquemparte/zarafusionix-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-V1-1-SuperHOT-8K-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-fp16",
    "score": 53.16,
    "likes": 4.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-fp16",
    "still_on_hub": true
  },
  {
    "name": "Athena-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Athena-Platypus2-13B-QLora-0.80-epoch",
    "score": 53.16,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Athena-Platypus2-13B-QLora-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "Airboros2.1-Platypus2-13B-QLora-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Airboros2.1-Platypus2-13B-QLora-0.80-epoch",
    "score": 53.15,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Airboros2.1-Platypus2-13B-QLora-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "vigogne2-enno-13b-sft-lora-4bit",
    "author": "Enno-Ai",
    "query_name": "Enno-Ai/vigogne2-enno-13b-sft-lora-4bit",
    "score": 53.15,
    "likes": 0.0,
    "link": "https://huggingface.co/Enno-Ai/vigogne2-enno-13b-sft-lora-4bit",
    "still_on_hub": true
  },
  {
    "name": "Airoboros-L2-13B-2.1-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Airoboros-L2-13B-2.1-GPTQ",
    "score": 53.14,
    "likes": 10.0,
    "link": "https://huggingface.co/TheBloke/Airoboros-L2-13B-2.1-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
    "score": 53.14,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16",
    "still_on_hub": false
  },
  {
    "name": "llama-13b-pretrained-sft-do2",
    "author": "dvruette",
    "query_name": "dvruette/llama-13b-pretrained-sft-do2",
    "score": 53.12,
    "likes": 6.0,
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained-sft-do2",
    "still_on_hub": true
  },
  {
    "name": "MLewd-L2-13B",
    "author": "Undi95",
    "query_name": "Undi95/MLewd-L2-13B",
    "score": 53.12,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/MLewd-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "posi_13b",
    "author": "jjaaaww",
    "query_name": "jjaaaww/posi_13b",
    "score": 53.12,
    "likes": 0.0,
    "link": "https://huggingface.co/jjaaaww/posi_13b",
    "still_on_hub": true
  },
  {
    "name": "llama-13b-pretrained-sft-epoch-1",
    "author": "dvruette",
    "query_name": "dvruette/llama-13b-pretrained-sft-epoch-1",
    "score": 53.11,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained-sft-epoch-1",
    "still_on_hub": true
  },
  {
    "name": "manticore-13b-chat-pyg-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/manticore-13b-chat-pyg-GPTQ",
    "score": 53.11,
    "likes": 33.0,
    "link": "https://huggingface.co/TheBloke/manticore-13b-chat-pyg-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "llama2_7b_mmlu",
    "author": "itsliupeng",
    "query_name": "itsliupeng/llama2_7b_mmlu",
    "score": 53.1,
    "likes": 0.0,
    "link": "https://huggingface.co/itsliupeng/llama2_7b_mmlu",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-FINETUNE3_TEST",
    "author": "wei123602",
    "query_name": "wei123602/llama2-13b-FINETUNE3_TEST",
    "score": 53.09,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/llama2-13b-FINETUNE3_TEST",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
    "score": 53.06,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE3_3.3w-r4-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "FINETUNE3_TEST4",
    "author": "wei123602",
    "query_name": "wei123602/FINETUNE3_TEST4",
    "score": 53.02,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/FINETUNE3_TEST4",
    "still_on_hub": true
  },
  {
    "name": "LlongOrca-7B-16k",
    "author": "Open-Orca",
    "query_name": "Open-Orca/LlongOrca-7B-16k",
    "score": 53.02,
    "likes": 39.0,
    "link": "https://huggingface.co/Open-Orca/LlongOrca-7B-16k",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-13b-gpt4-1.4.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-13b-gpt4-1.4.1",
    "score": 53.02,
    "likes": 12.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-gpt4-1.4.1",
    "still_on_hub": true
  },
  {
    "name": "Walter-Mistral-7B",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Walter-Mistral-7B",
    "score": 53.0,
    "likes": 1.0,
    "link": "https://huggingface.co/KnutJaegersberg/Walter-Mistral-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-13b-pretrained-dropout",
    "author": "dvruette",
    "query_name": "dvruette/llama-13b-pretrained-dropout",
    "score": 52.99,
    "likes": 1.0,
    "link": "https://huggingface.co/dvruette/llama-13b-pretrained-dropout",
    "still_on_hub": true
  },
  {
    "name": "Huginn-19b-prototype",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Huginn-19b-prototype",
    "score": 52.99,
    "likes": 1.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-19b-prototype",
    "still_on_hub": true
  },
  {
    "name": "LIMA2-13b-hf",
    "author": "heegyu",
    "query_name": "heegyu/LIMA2-13b-hf",
    "score": 52.98,
    "likes": 0.0,
    "link": "https://huggingface.co/heegyu/LIMA2-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "Alpacino-SuperCOT-13B",
    "author": "xzuyn",
    "query_name": "xzuyn/Alpacino-SuperCOT-13B",
    "score": 52.97,
    "likes": 4.0,
    "link": "https://huggingface.co/xzuyn/Alpacino-SuperCOT-13B",
    "still_on_hub": true
  },
  {
    "name": "digital-socrates-7b",
    "author": "allenai",
    "query_name": "allenai/digital-socrates-7b",
    "score": 52.95,
    "likes": 1.0,
    "link": "https://huggingface.co/allenai/digital-socrates-7b",
    "still_on_hub": true
  },
  {
    "name": "zaraxe-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zaraxe-l2-7b",
    "score": 52.95,
    "likes": 0.0,
    "link": "https://huggingface.co/zarakiquemparte/zaraxe-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
    "score": 52.94,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged",
    "still_on_hub": true
  },
  {
    "name": "baize-v2-13b",
    "author": "project-baize",
    "query_name": "project-baize/baize-v2-13b",
    "score": 52.94,
    "likes": 22.0,
    "link": "https://huggingface.co/project-baize/baize-v2-13b",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-llama2-13b-v11-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-llama2-13b-v11-bf16",
    "score": 52.93,
    "likes": 2.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-llama2-13b-v11-bf16",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-100step-flan-v2",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-100step-flan-v2",
    "score": 52.92,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-100step-flan-v2",
    "still_on_hub": true
  },
  {
    "name": "llama2-22b-chat-wizard-uncensored",
    "author": "nkpz",
    "query_name": "nkpz/llama2-22b-chat-wizard-uncensored",
    "score": 52.9,
    "likes": 3.0,
    "link": "https://huggingface.co/nkpz/llama2-22b-chat-wizard-uncensored",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-platypus-vicuna-wizard",
    "author": "pe-nlp",
    "query_name": "pe-nlp/llama-2-13b-platypus-vicuna-wizard",
    "score": 52.9,
    "likes": 0.0,
    "link": "https://huggingface.co/pe-nlp/llama-2-13b-platypus-vicuna-wizard",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-ft-instruct-es",
    "author": "clibrain",
    "query_name": "clibrain/Llama-2-13b-ft-instruct-es",
    "score": 52.89,
    "likes": 10.0,
    "link": "https://huggingface.co/clibrain/Llama-2-13b-ft-instruct-es",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-fintune2-4E",
    "author": "wei123602",
    "query_name": "wei123602/llama2-13b-fintune2-4E",
    "score": 52.88,
    "likes": 0.0,
    "link": "https://huggingface.co/wei123602/llama2-13b-fintune2-4E",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-100step-flan",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-100step-flan",
    "score": 52.88,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-100step-flan",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
    "author": "CHIH-HUNG",
    "query_name": "CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
    "score": 52.88,
    "likes": 0.0,
    "link": "https://huggingface.co/CHIH-HUNG/llama-2-13b-FINETUNE4_3.8w-r8-q_k_v_o_gate_up_down",
    "still_on_hub": true
  },
  {
    "name": "archangel_sft-kto_llama13b",
    "author": "ContextualAI",
    "query_name": "ContextualAI/archangel_sft-kto_llama13b",
    "score": 52.87,
    "likes": 0.0,
    "link": "https://huggingface.co/ContextualAI/archangel_sft-kto_llama13b",
    "still_on_hub": true
  },
  {
    "name": "chimera-inst-chat-13b-hf",
    "author": "Yhyu13",
    "query_name": "Yhyu13/chimera-inst-chat-13b-hf",
    "score": 52.86,
    "likes": 1.0,
    "link": "https://huggingface.co/Yhyu13/chimera-inst-chat-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "japanese-stablelm-instruct-gamma-7b",
    "author": "stabilityai",
    "query_name": "stabilityai/japanese-stablelm-instruct-gamma-7b",
    "score": 52.82,
    "likes": 36.0,
    "link": "https://huggingface.co/stabilityai/japanese-stablelm-instruct-gamma-7b",
    "still_on_hub": true
  },
  {
    "name": "mpt-30b",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-30b",
    "score": 52.77,
    "likes": 183.0,
    "link": "https://huggingface.co/mosaicml/mpt-30b",
    "still_on_hub": true
  },
  {
    "name": "Llama2-13B-no_robots-alpaca-lora",
    "author": "Undi95",
    "query_name": "Undi95/Llama2-13B-no_robots-alpaca-lora",
    "score": 52.77,
    "likes": 1.0,
    "link": "https://huggingface.co/Undi95/Llama2-13B-no_robots-alpaca-lora",
    "still_on_hub": true
  },
  {
    "name": "ypotryll-22b-epoch2-qlora",
    "author": "chargoddard",
    "query_name": "chargoddard/ypotryll-22b-epoch2-qlora",
    "score": 52.75,
    "likes": 0.0,
    "link": "https://huggingface.co/chargoddard/ypotryll-22b-epoch2-qlora",
    "still_on_hub": false
  },
  {
    "name": "wizard-vicuna-13B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/wizard-vicuna-13B-HF",
    "score": 52.75,
    "likes": 48.0,
    "link": "https://huggingface.co/TheBloke/wizard-vicuna-13B-HF",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v2_13b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_v2_13b",
    "score": 52.75,
    "likes": 30.0,
    "link": "https://huggingface.co/psmathur/orca_mini_v2_13b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-200step-flan-v2",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-200step-flan-v2",
    "score": 52.75,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-flan-v2",
    "still_on_hub": true
  },
  {
    "name": "EverythingLM-13b-V2-16k",
    "author": "totally-not-an-llm",
    "query_name": "totally-not-an-llm/EverythingLM-13b-V2-16k",
    "score": 52.75,
    "likes": 31.0,
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-V2-16k",
    "still_on_hub": true
  },
  {
    "name": "wizard-vicuna-13b",
    "author": "junelee",
    "query_name": "junelee/wizard-vicuna-13b",
    "score": 52.73,
    "likes": 70.0,
    "link": "https://huggingface.co/junelee/wizard-vicuna-13b",
    "still_on_hub": true
  },
  {
    "name": "openchat_8192",
    "author": "openchat",
    "query_name": "openchat/openchat_8192",
    "score": 52.72,
    "likes": 220.0,
    "link": "https://huggingface.co/openchat/openchat_8192",
    "still_on_hub": true
  },
  {
    "name": "Synthia-7B-v1.2",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-7B-v1.2",
    "score": 52.71,
    "likes": 10.0,
    "link": "https://huggingface.co/migtissera/Synthia-7B-v1.2",
    "still_on_hub": true
  },
  {
    "name": "Dans-PersonalityEngine-13b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-PersonalityEngine-13b",
    "score": 52.71,
    "likes": 1.0,
    "link": "https://huggingface.co/PocketDoc/Dans-PersonalityEngine-13b",
    "still_on_hub": true
  },
  {
    "name": "MetaMath-13B-V1.0",
    "author": "meta-math",
    "query_name": "meta-math/MetaMath-13B-V1.0",
    "score": 52.71,
    "likes": 6.0,
    "link": "https://huggingface.co/meta-math/MetaMath-13B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "yehoon_llama2",
    "author": "Yehoon",
    "query_name": "Yehoon/yehoon_llama2",
    "score": 52.71,
    "likes": 0.0,
    "link": "https://huggingface.co/Yehoon/yehoon_llama2",
    "still_on_hub": false
  },
  {
    "name": "mcq-hal-vicuna-13b-v1.5",
    "author": "luffycodes",
    "query_name": "luffycodes/mcq-hal-vicuna-13b-v1.5",
    "score": 52.7,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/mcq-hal-vicuna-13b-v1.5",
    "still_on_hub": true
  },
  {
    "name": "Nous-Capybara-7B",
    "author": "NousResearch",
    "query_name": "NousResearch/Nous-Capybara-7B",
    "score": 52.7,
    "likes": 15.0,
    "link": "https://huggingface.co/NousResearch/Nous-Capybara-7B",
    "still_on_hub": true
  },
  {
    "name": "Tulpar-7b-v0",
    "author": "HyperbeeAI",
    "query_name": "HyperbeeAI/Tulpar-7b-v0",
    "score": 52.69,
    "likes": 22.0,
    "link": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v0",
    "still_on_hub": true
  },
  {
    "name": "Capybara-7B",
    "author": "NousResearch",
    "query_name": "NousResearch/Capybara-7B",
    "score": 52.69,
    "likes": 15.0,
    "link": "https://huggingface.co/NousResearch/Capybara-7B",
    "still_on_hub": true
  },
  {
    "name": "CodeEngine",
    "author": "Undi95",
    "query_name": "Undi95/CodeEngine",
    "score": 52.68,
    "likes": 0.0,
    "link": "https://huggingface.co/Undi95/CodeEngine",
    "still_on_hub": true
  },
  {
    "name": "mcq-vicuna-13b-v1.5",
    "author": "luffycodes",
    "query_name": "luffycodes/mcq-vicuna-13b-v1.5",
    "score": 52.68,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/mcq-vicuna-13b-v1.5",
    "still_on_hub": true
  },
  {
    "name": "Mistral-Trismegistus-7B",
    "author": "teknium",
    "query_name": "teknium/Mistral-Trismegistus-7B",
    "score": 52.66,
    "likes": 59.0,
    "link": "https://huggingface.co/teknium/Mistral-Trismegistus-7B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-13b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-13b-gpt4-m2.0",
    "score": 52.66,
    "likes": 26.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "leo-hessianai-13b",
    "author": "LeoLM",
    "query_name": "LeoLM/leo-hessianai-13b",
    "score": 52.65,
    "likes": 16.0,
    "link": "https://huggingface.co/LeoLM/leo-hessianai-13b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-200step-flan",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-200step-flan",
    "score": 52.62,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-flan",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-mistral-7b-v13.1",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-mistral-7b-v13.1",
    "score": 52.62,
    "likes": 1.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-mistral-7b-v13.1",
    "still_on_hub": true
  },
  {
    "name": "LIMA-13b-hf",
    "author": "heegyu",
    "query_name": "heegyu/LIMA-13b-hf",
    "score": 52.61,
    "likes": 1.0,
    "link": "https://huggingface.co/heegyu/LIMA-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "Chinese-Llama-2-7b",
    "author": "LinkSoul",
    "query_name": "LinkSoul/Chinese-Llama-2-7b",
    "score": 52.59,
    "likes": 261.0,
    "link": "https://huggingface.co/LinkSoul/Chinese-Llama-2-7b",
    "still_on_hub": true
  },
  {
    "name": "japanese-stablelm-base-gamma-7b",
    "author": "stabilityai",
    "query_name": "stabilityai/japanese-stablelm-base-gamma-7b",
    "score": 52.59,
    "likes": 13.0,
    "link": "https://huggingface.co/stabilityai/japanese-stablelm-base-gamma-7b",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-13B-juniper",
    "author": "frank098",
    "query_name": "frank098/Wizard-Vicuna-13B-juniper",
    "score": 52.55,
    "likes": 0.0,
    "link": "https://huggingface.co/frank098/Wizard-Vicuna-13B-juniper",
    "still_on_hub": true
  },
  {
    "name": "llama_13b_sharegpt94k_fastchat",
    "author": "wahaha1987",
    "query_name": "wahaha1987/llama_13b_sharegpt94k_fastchat",
    "score": 52.55,
    "likes": 0.0,
    "link": "https://huggingface.co/wahaha1987/llama_13b_sharegpt94k_fastchat",
    "still_on_hub": true
  },
  {
    "name": "mcq-vicuna-13b-v1.5",
    "author": "luffycodes",
    "query_name": "luffycodes/mcq-vicuna-13b-v1.5",
    "score": 52.55,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/mcq-vicuna-13b-v1.5",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-dolphin-orca-platypus-34b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-dolphin-orca-platypus-34b",
    "score": 52.53,
    "likes": 6.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-dolphin-orca-platypus-34b",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-34b-v1.0",
    "author": "speechlessai",
    "query_name": "speechlessai/speechless-codellama-34b-v1.0",
    "score": 52.53,
    "likes": 0.0,
    "link": "https://huggingface.co/speechlessai/speechless-codellama-34b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-34b-v2.0",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-34b-v2.0",
    "score": 52.51,
    "likes": 3.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-34b-v2.0",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-hf-chat-lora-v2",
    "author": "lvkaokao",
    "query_name": "lvkaokao/llama2-7b-hf-chat-lora-v2",
    "score": 52.5,
    "likes": 0.0,
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-chat-lora-v2",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-13b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-13b-gpt4-2.0",
    "score": 52.49,
    "likes": 14.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "Mistral-7B-golden",
    "author": "liuda1",
    "query_name": "liuda1/Mistral-7B-golden",
    "score": 52.49,
    "likes": 0.0,
    "link": "https://huggingface.co/liuda1/Mistral-7B-golden",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-longlora-32k-ft",
    "author": "Yukang",
    "query_name": "Yukang/Llama-2-13b-longlora-32k-ft",
    "score": 52.49,
    "likes": 2.0,
    "link": "https://huggingface.co/Yukang/Llama-2-13b-longlora-32k-ft",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-hf-chat-lora-v3",
    "author": "lvkaokao",
    "query_name": "lvkaokao/llama2-7b-hf-chat-lora-v3",
    "score": 52.48,
    "likes": 0.0,
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-chat-lora-v3",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-10-sparsity",
    "author": "wang7776",
    "query_name": "wang7776/Llama-2-7b-chat-hf-10-sparsity",
    "score": 52.48,
    "likes": 0.0,
    "link": "https://huggingface.co/wang7776/Llama-2-7b-chat-hf-10-sparsity",
    "still_on_hub": true
  },
  {
    "name": "Llama2-7b-openorca-mc-v2",
    "author": "beaugogh",
    "query_name": "beaugogh/Llama2-7b-openorca-mc-v2",
    "score": 52.47,
    "likes": 0.0,
    "link": "https://huggingface.co/beaugogh/Llama2-7b-openorca-mc-v2",
    "still_on_hub": true
  },
  {
    "name": "llama_mirror_13b_v1.0",
    "author": "lizhuang144",
    "query_name": "lizhuang144/llama_mirror_13b_v1.0",
    "score": 52.46,
    "likes": 0.0,
    "link": "https://huggingface.co/lizhuang144/llama_mirror_13b_v1.0",
    "still_on_hub": false
  },
  {
    "name": "vigogne-2-7b-chat",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-2-7b-chat",
    "score": 52.45,
    "likes": 14.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-2-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "llama-13b-supercot",
    "author": "ausboss",
    "query_name": "ausboss/llama-13b-supercot",
    "score": 52.44,
    "likes": 8.0,
    "link": "https://huggingface.co/ausboss/llama-13b-supercot",
    "still_on_hub": true
  },
  {
    "name": "CAMEL-13B-Combined-Data",
    "author": "camel-ai",
    "query_name": "camel-ai/CAMEL-13B-Combined-Data",
    "score": 52.44,
    "likes": 11.0,
    "link": "https://huggingface.co/camel-ai/CAMEL-13B-Combined-Data",
    "still_on_hub": true
  },
  {
    "name": "Dans-PileOfSets-Mk1-llama-13b-merged",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-PileOfSets-Mk1-llama-13b-merged",
    "score": 52.43,
    "likes": 0.0,
    "link": "https://huggingface.co/PocketDoc/Dans-PileOfSets-Mk1-llama-13b-merged",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-300step-flan-v2",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-300step-flan-v2",
    "score": 52.41,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-300step-flan-v2",
    "still_on_hub": true
  },
  {
    "name": "PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch",
    "score": 52.41,
    "likes": 1.0,
    "link": "https://huggingface.co/TFLai/PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": true
  },
  {
    "name": "zararp-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zararp-l2-7b",
    "score": 52.39,
    "likes": 1.0,
    "link": "https://huggingface.co/zarakiquemparte/zararp-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "Alpacino13b",
    "author": "digitous",
    "query_name": "digitous/Alpacino13b",
    "score": 52.39,
    "likes": 29.0,
    "link": "https://huggingface.co/digitous/Alpacino13b",
    "still_on_hub": true
  },
  {
    "name": "Llama2-7B-guanaco-dolphin-500",
    "author": "mncai",
    "query_name": "mncai/Llama2-7B-guanaco-dolphin-500",
    "score": 52.38,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/Llama2-7B-guanaco-dolphin-500",
    "still_on_hub": true
  },
  {
    "name": "Huginn-22b-Prototype",
    "author": "The-Face-Of-Goonery",
    "query_name": "The-Face-Of-Goonery/Huginn-22b-Prototype",
    "score": 52.36,
    "likes": 2.0,
    "link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-22b-Prototype",
    "still_on_hub": true
  },
  {
    "name": "EverythingLM-13b-16k",
    "author": "totally-not-an-llm",
    "query_name": "totally-not-an-llm/EverythingLM-13b-16k",
    "score": 52.33,
    "likes": 29.0,
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-16k",
    "still_on_hub": true
  },
  {
    "name": "Llama2-7b-openorca-mc-v2-dpo",
    "author": "beaugogh",
    "query_name": "beaugogh/Llama2-7b-openorca-mc-v2-dpo",
    "score": 52.32,
    "likes": 0.0,
    "link": "https://huggingface.co/beaugogh/Llama2-7b-openorca-mc-v2-dpo",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-atom-13b-v9-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-atom-13b-v9-bf16",
    "score": 52.31,
    "likes": 5.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-atom-13b-v9-bf16",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13b-gpt4-1.2",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-13b-gpt4-1.2",
    "score": 52.31,
    "likes": 3.0,
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.2",
    "still_on_hub": true
  },
  {
    "name": "vicuna-13b",
    "author": "eachadea",
    "query_name": "eachadea/vicuna-13b",
    "score": 52.3,
    "likes": 95.0,
    "link": "https://huggingface.co/eachadea/vicuna-13b",
    "still_on_hub": true
  },
  {
    "name": "Asimov-7B-v2",
    "author": "prithivida",
    "query_name": "prithivida/Asimov-7B-v2",
    "score": 52.29,
    "likes": 0.0,
    "link": "https://huggingface.co/prithivida/Asimov-7B-v2",
    "still_on_hub": true
  },
  {
    "name": "Llama2-7B-guanaco-1k",
    "author": "mncai",
    "query_name": "mncai/Llama2-7B-guanaco-1k",
    "score": 52.28,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/Llama2-7B-guanaco-1k",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-441step-flan-v2",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-441step-flan-v2",
    "score": 52.28,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-441step-flan-v2",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-13B-QLoRA-0.80-epoch",
    "author": "TFLai",
    "query_name": "TFLai/Platypus2-13B-QLoRA-0.80-epoch",
    "score": 52.27,
    "likes": 0.0,
    "link": "https://huggingface.co/TFLai/Platypus2-13B-QLoRA-0.80-epoch",
    "still_on_hub": false
  },
  {
    "name": "llama-2-7B-LoRA-assemble",
    "author": "oh-yeontaek",
    "query_name": "oh-yeontaek/llama-2-7B-LoRA-assemble",
    "score": 52.26,
    "likes": 4.0,
    "link": "https://huggingface.co/oh-yeontaek/llama-2-7B-LoRA-assemble",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-200step-merged",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-200step-merged",
    "score": 52.26,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-merged",
    "still_on_hub": true
  },
  {
    "name": "Llama2-7b-openorca-mc-v1",
    "author": "beaugogh",
    "query_name": "beaugogh/Llama2-7b-openorca-mc-v1",
    "score": 52.24,
    "likes": 0.0,
    "link": "https://huggingface.co/beaugogh/Llama2-7b-openorca-mc-v1",
    "still_on_hub": true
  },
  {
    "name": "zararp-1.1-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zararp-1.1-l2-7b",
    "score": 52.22,
    "likes": 2.0,
    "link": "https://huggingface.co/zarakiquemparte/zararp-1.1-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Hermes-Synthia",
    "author": "LTC-AI-Labs",
    "query_name": "LTC-AI-Labs/L2-7b-Hermes-Synthia",
    "score": 52.21,
    "likes": 1.0,
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Hermes-Synthia",
    "still_on_hub": true
  },
  {
    "name": "Nous-Hermes-13B-SuperHOT-8K-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Nous-Hermes-13B-SuperHOT-8K-fp16",
    "score": 52.18,
    "likes": 2.0,
    "link": "https://huggingface.co/TheBloke/Nous-Hermes-13B-SuperHOT-8K-fp16",
    "still_on_hub": true
  },
  {
    "name": "oasst-llama-13b-1000-steps",
    "author": "dvruette",
    "query_name": "dvruette/oasst-llama-13b-1000-steps",
    "score": 52.18,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-llama-13b-1000-steps",
    "still_on_hub": true
  },
  {
    "name": "Tulpar-7b-v1",
    "author": "HyperbeeAI",
    "query_name": "HyperbeeAI/Tulpar-7b-v1",
    "score": 52.16,
    "likes": 1.0,
    "link": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v1",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
    "score": 52.15,
    "likes": 44.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Stheno-1.3-L2-13B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-1.3-L2-13B",
    "score": 52.15,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Stheno-1.3-L2-13B",
    "still_on_hub": true
  },
  {
    "name": "mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
    "author": "xxyyy123",
    "query_name": "xxyyy123/mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
    "score": 52.13,
    "likes": 0.0,
    "link": "https://huggingface.co/xxyyy123/mc_data_30k_from_platpus_orca_7b_10k_v1_lora_qkvo_rank14_v2",
    "still_on_hub": false
  },
  {
    "name": "Alpagasus-2-13B-QLoRA-pipeline",
    "author": "StudentLLM",
    "query_name": "StudentLLM/Alpagasus-2-13B-QLoRA-pipeline",
    "score": 52.13,
    "likes": 2.0,
    "link": "https://huggingface.co/StudentLLM/Alpagasus-2-13B-QLoRA-pipeline",
    "still_on_hub": false
  },
  {
    "name": "ANIMA-Nectar-v2",
    "author": "Biomimicry-AI",
    "query_name": "Biomimicry-AI/ANIMA-Nectar-v2",
    "score": 52.13,
    "likes": 0.0,
    "link": "https://huggingface.co/Biomimicry-AI/ANIMA-Nectar-v2",
    "still_on_hub": true
  },
  {
    "name": "Xwin-LM-7B-V0.1",
    "author": "Xwin-LM",
    "query_name": "Xwin-LM/Xwin-LM-7B-V0.1",
    "score": 52.08,
    "likes": 73.0,
    "link": "https://huggingface.co/Xwin-LM/Xwin-LM-7B-V0.1",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-7b-v1.5",
    "score": 52.06,
    "likes": 70.0,
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-layla",
    "author": "l3utterfly",
    "query_name": "l3utterfly/llama2-7b-layla",
    "score": 52.05,
    "likes": 0.0,
    "link": "https://huggingface.co/l3utterfly/llama2-7b-layla",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Beluga-WVG-Test",
    "author": "LTC-AI-Labs",
    "query_name": "LTC-AI-Labs/L2-7b-Beluga-WVG-Test",
    "score": 52.04,
    "likes": 0.0,
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Beluga-WVG-Test",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-hf-chat-lora",
    "author": "lvkaokao",
    "query_name": "lvkaokao/llama2-7b-hf-chat-lora",
    "score": 52.03,
    "likes": 0.0,
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-chat-lora",
    "still_on_hub": true
  },
  {
    "name": "vigogne-2-7b-instruct",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-2-7b-instruct",
    "score": 52.02,
    "likes": 17.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-2-7b-instruct",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-20-sparsity",
    "author": "wang7776",
    "query_name": "wang7776/Llama-2-7b-chat-hf-20-sparsity",
    "score": 52.01,
    "likes": 0.0,
    "link": "https://huggingface.co/wang7776/Llama-2-7b-chat-hf-20-sparsity",
    "still_on_hub": true
  },
  {
    "name": "bactrian-x-llama-13b-merged",
    "author": "haonan-li",
    "query_name": "haonan-li/bactrian-x-llama-13b-merged",
    "score": 52.0,
    "likes": 1.0,
    "link": "https://huggingface.co/haonan-li/bactrian-x-llama-13b-merged",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-7b-v1.5",
    "score": 51.99,
    "likes": 70.0,
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
    "still_on_hub": true
  },
  {
    "name": "Qwen-LLaMAfied-7B-Chat",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/Qwen-LLaMAfied-7B-Chat",
    "score": 51.99,
    "likes": 0.0,
    "link": "https://huggingface.co/JosephusCheung/Qwen-LLaMAfied-7B-Chat",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-mistral-7b-v13-base",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-mistral-7b-v13-base",
    "score": 51.99,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-mistral-7b-v13-base",
    "still_on_hub": true
  },
  {
    "name": "spicyboros-7b-2.2",
    "author": "jondurbin",
    "query_name": "jondurbin/spicyboros-7b-2.2",
    "score": 51.95,
    "likes": 20.0,
    "link": "https://huggingface.co/jondurbin/spicyboros-7b-2.2",
    "still_on_hub": true
  },
  {
    "name": "10k_v1_lora_qkvo_rank28_v2",
    "author": "xxyyy123",
    "query_name": "xxyyy123/10k_v1_lora_qkvo_rank28_v2",
    "score": 51.95,
    "likes": 0.0,
    "link": "https://huggingface.co/xxyyy123/10k_v1_lora_qkvo_rank28_v2",
    "still_on_hub": false
  },
  {
    "name": "llama-2-13b-vicuna-wizard",
    "author": "pe-nlp",
    "query_name": "pe-nlp/llama-2-13b-vicuna-wizard",
    "score": 51.94,
    "likes": 0.0,
    "link": "https://huggingface.co/pe-nlp/llama-2-13b-vicuna-wizard",
    "still_on_hub": true
  },
  {
    "name": "Yi-6b-200k-dpo",
    "author": "chinoll",
    "query_name": "chinoll/Yi-6b-200k-dpo",
    "score": 51.93,
    "likes": 0.0,
    "link": "https://huggingface.co/chinoll/Yi-6b-200k-dpo",
    "still_on_hub": true
  },
  {
    "name": "Yi-7b-dpo",
    "author": "chinoll",
    "query_name": "chinoll/Yi-7b-dpo",
    "score": 51.93,
    "likes": 0.0,
    "link": "https://huggingface.co/chinoll/Yi-7b-dpo",
    "still_on_hub": true
  },
  {
    "name": "Nous-Hermes-llama-2-7b",
    "author": "NousResearch",
    "query_name": "NousResearch/Nous-Hermes-llama-2-7b",
    "score": 51.87,
    "likes": 48.0,
    "link": "https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b",
    "still_on_hub": true
  },
  {
    "name": "manatee-7b",
    "author": "ashercn97",
    "query_name": "ashercn97/manatee-7b",
    "score": 51.84,
    "likes": 2.0,
    "link": "https://huggingface.co/ashercn97/manatee-7b",
    "still_on_hub": true
  },
  {
    "name": "Synthia-7B",
    "author": "migtissera",
    "query_name": "migtissera/Synthia-7B",
    "score": 51.83,
    "likes": 2.0,
    "link": "https://huggingface.co/migtissera/Synthia-7B",
    "still_on_hub": true
  },
  {
    "name": "Medusa-1.1-L2-7B",
    "author": "Sao10K",
    "query_name": "Sao10K/Medusa-1.1-L2-7B",
    "score": 51.8,
    "likes": 1.0,
    "link": "https://huggingface.co/Sao10K/Medusa-1.1-L2-7B",
    "still_on_hub": true
  },
  {
    "name": "Elliott-Chinese-LLaMa-GPTQ",
    "author": "elliotthwang",
    "query_name": "elliotthwang/Elliott-Chinese-LLaMa-GPTQ",
    "score": 51.79,
    "likes": 0.0,
    "link": "https://huggingface.co/elliotthwang/Elliott-Chinese-LLaMa-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Stheno-Mix-L2-20B",
    "author": "Sao10K",
    "query_name": "Sao10K/Stheno-Mix-L2-20B",
    "score": 51.79,
    "likes": 0.0,
    "link": "https://huggingface.co/Sao10K/Stheno-Mix-L2-20B",
    "still_on_hub": true
  },
  {
    "name": "airoboros-13b-gpt4-1.3",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-13b-gpt4-1.3",
    "score": 51.76,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-13b-gpt4-1.3",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Orca-WVG-Test",
    "author": "Lazycuber",
    "query_name": "Lazycuber/L2-7b-Orca-WVG-Test",
    "score": 51.72,
    "likes": 0.0,
    "link": "https://huggingface.co/Lazycuber/L2-7b-Orca-WVG-Test",
    "still_on_hub": true
  },
  {
    "name": "blossom-v2-llama2-7b",
    "author": "Azure99",
    "query_name": "Azure99/blossom-v2-llama2-7b",
    "score": 51.71,
    "likes": 0.0,
    "link": "https://huggingface.co/Azure99/blossom-v2-llama2-7b",
    "still_on_hub": true
  },
  {
    "name": "em_german_leo_mistral",
    "author": "jphme",
    "query_name": "jphme/em_german_leo_mistral",
    "score": 51.69,
    "likes": 4.0,
    "link": "https://huggingface.co/jphme/em_german_leo_mistral",
    "still_on_hub": true
  },
  {
    "name": "ALMA-13B-Pretrain",
    "author": "haoranxu",
    "query_name": "haoranxu/ALMA-13B-Pretrain",
    "score": 51.68,
    "likes": 4.0,
    "link": "https://huggingface.co/haoranxu/ALMA-13B-Pretrain",
    "still_on_hub": true
  },
  {
    "name": "firefly-ziya-13b",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-ziya-13b",
    "score": 51.67,
    "likes": 7.0,
    "link": "https://huggingface.co/YeungNLP/firefly-ziya-13b",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Base-test-WVG",
    "author": "LTC-AI-Labs",
    "query_name": "LTC-AI-Labs/L2-7b-Base-test-WVG",
    "score": 51.66,
    "likes": 0.0,
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Base-test-WVG",
    "still_on_hub": true
  },
  {
    "name": "LosslessMegaCoder-llama2-7b-mini",
    "author": "rombodawg",
    "query_name": "rombodawg/LosslessMegaCoder-llama2-7b-mini",
    "score": 51.66,
    "likes": 10.0,
    "link": "https://huggingface.co/rombodawg/LosslessMegaCoder-llama2-7b-mini",
    "still_on_hub": true
  },
  {
    "name": "shisa-base-7b-v1",
    "author": "augmxnt",
    "query_name": "augmxnt/shisa-base-7b-v1",
    "score": 51.64,
    "likes": 2.0,
    "link": "https://huggingface.co/augmxnt/shisa-base-7b-v1",
    "still_on_hub": true
  },
  {
    "name": "Elliott-Chinese-LLaMa-GPTQ-V1.0",
    "author": "elliotthwang",
    "query_name": "elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V1.0",
    "score": 51.64,
    "likes": 0.0,
    "link": "https://huggingface.co/elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V1.0",
    "still_on_hub": true
  },
  {
    "name": "stable-vicuna-13B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/stable-vicuna-13B-HF",
    "score": 51.64,
    "likes": 95.0,
    "link": "https://huggingface.co/TheBloke/stable-vicuna-13B-HF",
    "still_on_hub": true
  },
  {
    "name": "Platypus2xOpenOrca-13B-LoRa-v2",
    "author": "yeontaek",
    "query_name": "yeontaek/Platypus2xOpenOrca-13B-LoRa-v2",
    "score": 51.61,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/Platypus2xOpenOrca-13B-LoRa-v2",
    "still_on_hub": true
  },
  {
    "name": "llama-7b-ludwig-alpaca",
    "author": "rufjdk5480",
    "query_name": "rufjdk5480/llama-7b-ludwig-alpaca",
    "score": 51.6,
    "likes": 1.0,
    "link": "https://huggingface.co/rufjdk5480/llama-7b-ludwig-alpaca",
    "still_on_hub": false
  },
  {
    "name": "tamil-llama-13b-instruct-v0.1",
    "author": "abhinand",
    "query_name": "abhinand/tamil-llama-13b-instruct-v0.1",
    "score": 51.59,
    "likes": 0.0,
    "link": "https://huggingface.co/abhinand/tamil-llama-13b-instruct-v0.1",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-16k",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-7b-v1.5-16k",
    "score": 51.58,
    "likes": 55.0,
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5-16k",
    "still_on_hub": true
  },
  {
    "name": "Yousei-22B",
    "author": "Envoid",
    "query_name": "Envoid/Yousei-22B",
    "score": 51.56,
    "likes": 1.0,
    "link": "https://huggingface.co/Envoid/Yousei-22B",
    "still_on_hub": true
  },
  {
    "name": "Dans-MysteryModel-13b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-MysteryModel-13b",
    "score": 51.54,
    "likes": 0.0,
    "link": "https://huggingface.co/PocketDoc/Dans-MysteryModel-13b",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-hf-instruction-lora",
    "author": "lvkaokao",
    "query_name": "lvkaokao/llama2-7b-hf-instruction-lora",
    "score": 51.54,
    "likes": 0.0,
    "link": "https://huggingface.co/lvkaokao/llama2-7b-hf-instruction-lora",
    "still_on_hub": true
  },
  {
    "name": "airoboros-c34b-2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-c34b-2.1",
    "score": 51.52,
    "likes": 13.0,
    "link": "https://huggingface.co/jondurbin/airoboros-c34b-2.1",
    "still_on_hub": true
  },
  {
    "name": "Elliott-Chinese-LLaMa-GPTQ-V2.0",
    "author": "elliotthwang",
    "query_name": "elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V2.0",
    "score": 51.47,
    "likes": 0.0,
    "link": "https://huggingface.co/elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V2.0",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-PL-lora_unload",
    "author": "Lajonbot",
    "query_name": "Lajonbot/vicuna-7b-v1.5-PL-lora_unload",
    "score": 51.46,
    "likes": 0.0,
    "link": "https://huggingface.co/Lajonbot/vicuna-7b-v1.5-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "vicuna-class-tutor-7b-ep3",
    "author": "luffycodes",
    "query_name": "luffycodes/vicuna-class-tutor-7b-ep3",
    "score": 51.45,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/vicuna-class-tutor-7b-ep3",
    "still_on_hub": true
  },
  {
    "name": "Pwen-VL-Chat-20_30",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/Pwen-VL-Chat-20_30",
    "score": 51.45,
    "likes": 0.0,
    "link": "https://huggingface.co/JosephusCheung/Pwen-VL-Chat-20_30",
    "still_on_hub": true
  },
  {
    "name": "MistralLite",
    "author": "amazon",
    "query_name": "amazon/MistralLite",
    "score": 51.45,
    "likes": 334.0,
    "link": "https://huggingface.co/amazon/MistralLite",
    "still_on_hub": true
  },
  {
    "name": "WizardLM_13B_juniper",
    "author": "frank098",
    "query_name": "frank098/WizardLM_13B_juniper",
    "score": 51.45,
    "likes": 0.0,
    "link": "https://huggingface.co/frank098/WizardLM_13B_juniper",
    "still_on_hub": true
  },
  {
    "name": "llama2_7b_zh",
    "author": "itsliupeng",
    "query_name": "itsliupeng/llama2_7b_zh",
    "score": 51.44,
    "likes": 1.0,
    "link": "https://huggingface.co/itsliupeng/llama2_7b_zh",
    "still_on_hub": true
  },
  {
    "name": "zoyllm-7b-slimorca",
    "author": "tlphams",
    "query_name": "tlphams/zoyllm-7b-slimorca",
    "score": 51.44,
    "likes": 0.0,
    "link": "https://huggingface.co/tlphams/zoyllm-7b-slimorca",
    "still_on_hub": true
  },
  {
    "name": "CAMEL-13B-Role-Playing-Data",
    "author": "camel-ai",
    "query_name": "camel-ai/CAMEL-13B-Role-Playing-Data",
    "score": 51.42,
    "likes": 12.0,
    "link": "https://huggingface.co/camel-ai/CAMEL-13B-Role-Playing-Data",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-16k",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-7b-v1.5-16k",
    "score": 51.42,
    "likes": 55.0,
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.5-16k",
    "still_on_hub": true
  },
  {
    "name": "Baichuan2-7B-Chat-LLaMAfied",
    "author": "hiyouga",
    "query_name": "hiyouga/Baichuan2-7B-Chat-LLaMAfied",
    "score": 51.42,
    "likes": 3.0,
    "link": "https://huggingface.co/hiyouga/Baichuan2-7B-Chat-LLaMAfied",
    "still_on_hub": true
  },
  {
    "name": "llama2-22b-daydreamer-v3",
    "author": "nkpz",
    "query_name": "nkpz/llama2-22b-daydreamer-v3",
    "score": 51.39,
    "likes": 11.0,
    "link": "https://huggingface.co/nkpz/llama2-22b-daydreamer-v3",
    "still_on_hub": true
  },
  {
    "name": "Colossal-LLaMA-2-7b-base",
    "author": "hpcai-tech",
    "query_name": "hpcai-tech/Colossal-LLaMA-2-7b-base",
    "score": 51.39,
    "likes": 54.0,
    "link": "https://huggingface.co/hpcai-tech/Colossal-LLaMA-2-7b-base",
    "still_on_hub": true
  },
  {
    "name": "OpenOrca-Preview1-13B",
    "author": "Open-Orca",
    "query_name": "Open-Orca/OpenOrca-Preview1-13B",
    "score": 51.38,
    "likes": 143.0,
    "link": "https://huggingface.co/Open-Orca/OpenOrca-Preview1-13B",
    "still_on_hub": true
  },
  {
    "name": "kuchiki-1.1-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/kuchiki-1.1-l2-7b",
    "score": 51.36,
    "likes": 2.0,
    "link": "https://huggingface.co/zarakiquemparte/kuchiki-1.1-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-13b",
    "author": "huggingface",
    "query_name": "huggingface/llama-13b",
    "score": 51.36,
    "likes": 0.0,
    "link": "https://huggingface.co/huggingface/llama-13b",
    "still_on_hub": false
  },
  {
    "name": "L2-7b-Hermes-WVG-Test",
    "author": "LTC-AI-Labs",
    "query_name": "LTC-AI-Labs/L2-7b-Hermes-WVG-Test",
    "score": 51.35,
    "likes": 0.0,
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Hermes-WVG-Test",
    "still_on_hub": true
  },
  {
    "name": "llama-13b",
    "author": "huggyllama",
    "query_name": "huggyllama/llama-13b",
    "score": 51.33,
    "likes": 119.0,
    "link": "https://huggingface.co/huggyllama/llama-13b",
    "still_on_hub": true
  },
  {
    "name": "kuchiki-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/kuchiki-l2-7b",
    "score": 51.33,
    "likes": 7.0,
    "link": "https://huggingface.co/zarakiquemparte/kuchiki-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "gpt4all-alpaca-oa-codealpaca-lora-13b",
    "author": "jordiclive",
    "query_name": "jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b",
    "score": 51.33,
    "likes": 11.0,
    "link": "https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b",
    "still_on_hub": false
  },
  {
    "name": "Luna-AI-Llama2-Uncensored",
    "author": "Tap-M",
    "query_name": "Tap-M/Luna-AI-Llama2-Uncensored",
    "score": 51.29,
    "likes": 101.0,
    "link": "https://huggingface.co/Tap-M/Luna-AI-Llama2-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "zarablend-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zarablend-l2-7b",
    "score": 51.29,
    "likes": 10.0,
    "link": "https://huggingface.co/zarakiquemparte/zarablend-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "ko-en-llama2-13b",
    "author": "hyunseoki",
    "query_name": "hyunseoki/ko-en-llama2-13b",
    "score": 51.27,
    "likes": 13.0,
    "link": "https://huggingface.co/hyunseoki/ko-en-llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "OpenHermes-7B",
    "author": "teknium",
    "query_name": "teknium/OpenHermes-7B",
    "score": 51.26,
    "likes": 7.0,
    "link": "https://huggingface.co/teknium/OpenHermes-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-claude-chat-rp",
    "author": "Norquinal",
    "query_name": "Norquinal/llama-2-7b-claude-chat-rp",
    "score": 51.25,
    "likes": 0.0,
    "link": "https://huggingface.co/Norquinal/llama-2-7b-claude-chat-rp",
    "still_on_hub": true
  },
  {
    "name": "zarablend-1.1-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zarablend-1.1-l2-7b",
    "score": 51.25,
    "likes": 1.0,
    "link": "https://huggingface.co/zarakiquemparte/zarablend-1.1-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Synthia-WVG-Test",
    "author": "LTC-AI-Labs",
    "query_name": "LTC-AI-Labs/L2-7b-Synthia-WVG-Test",
    "score": 51.25,
    "likes": 0.0,
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Synthia-WVG-Test",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-7b-2.2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-7b-2.2.1",
    "score": 51.22,
    "likes": 2.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-2.2.1",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7B-physics",
    "author": "Harshvir",
    "query_name": "Harshvir/Llama-2-7B-physics",
    "score": 51.22,
    "likes": 0.0,
    "link": "https://huggingface.co/Harshvir/Llama-2-7B-physics",
    "still_on_hub": true
  },
  {
    "name": "MentaLLaMA-chat-7B",
    "author": "klyang",
    "query_name": "klyang/MentaLLaMA-chat-7B",
    "score": 51.17,
    "likes": 6.0,
    "link": "https://huggingface.co/klyang/MentaLLaMA-chat-7B",
    "still_on_hub": true
  },
  {
    "name": "koala-13B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/koala-13B-HF",
    "score": 51.16,
    "likes": 40.0,
    "link": "https://huggingface.co/TheBloke/koala-13B-HF",
    "still_on_hub": true
  },
  {
    "name": "LexPodLM-13B",
    "author": "64bits",
    "query_name": "64bits/LexPodLM-13B",
    "score": 51.14,
    "likes": 10.0,
    "link": "https://huggingface.co/64bits/LexPodLM-13B",
    "still_on_hub": true
  },
  {
    "name": "Llama2-Chinese-7b-Chat",
    "author": "FlagAlpha",
    "query_name": "FlagAlpha/Llama2-Chinese-7b-Chat",
    "score": 51.13,
    "likes": 104.0,
    "link": "https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat",
    "still_on_hub": true
  },
  {
    "name": "llama-2-26b-trenchcoat-stack",
    "author": "chargoddard",
    "query_name": "chargoddard/llama-2-26b-trenchcoat-stack",
    "score": 51.13,
    "likes": 1.0,
    "link": "https://huggingface.co/chargoddard/llama-2-26b-trenchcoat-stack",
    "still_on_hub": true
  },
  {
    "name": "EverythingLM-13b-V3-16k",
    "author": "totally-not-an-llm",
    "query_name": "totally-not-an-llm/EverythingLM-13b-V3-16k",
    "score": 51.11,
    "likes": 4.0,
    "link": "https://huggingface.co/totally-not-an-llm/EverythingLM-13b-V3-16k",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-2-7b",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/pygmalion-2-7b",
    "score": 51.11,
    "likes": 25.0,
    "link": "https://huggingface.co/PygmalionAI/pygmalion-2-7b",
    "still_on_hub": true
  },
  {
    "name": "finetuned-llama2-chat-5000-v1.0-squad",
    "author": "abdulrahman-nuzha",
    "query_name": "abdulrahman-nuzha/finetuned-llama2-chat-5000-v1.0-squad",
    "score": 51.09,
    "likes": 0.0,
    "link": "https://huggingface.co/abdulrahman-nuzha/finetuned-llama2-chat-5000-v1.0-squad",
    "still_on_hub": false
  },
  {
    "name": "llama2guanacotest",
    "author": "abhishek",
    "query_name": "abhishek/llama2guanacotest",
    "score": 51.08,
    "likes": 0.0,
    "link": "https://huggingface.co/abhishek/llama2guanacotest",
    "still_on_hub": true
  },
  {
    "name": "Samantha-1.11-7b",
    "author": "ehartford",
    "query_name": "ehartford/Samantha-1.11-7b",
    "score": 51.07,
    "likes": 7.0,
    "link": "https://huggingface.co/ehartford/Samantha-1.11-7b",
    "still_on_hub": true
  },
  {
    "name": "Llama2-7b-sharegpt4",
    "author": "beaugogh",
    "query_name": "beaugogh/Llama2-7b-sharegpt4",
    "score": 51.05,
    "likes": 1.0,
    "link": "https://huggingface.co/beaugogh/Llama2-7b-sharegpt4",
    "still_on_hub": false
  },
  {
    "name": "Llama2-7b-sharegpt4",
    "author": "HWERI",
    "query_name": "HWERI/Llama2-7b-sharegpt4",
    "score": 51.05,
    "likes": 1.0,
    "link": "https://huggingface.co/HWERI/Llama2-7b-sharegpt4",
    "still_on_hub": true
  },
  {
    "name": "WizardVicuna2-13b-hf",
    "author": "heegyu",
    "query_name": "heegyu/WizardVicuna2-13b-hf",
    "score": 51.05,
    "likes": 0.0,
    "link": "https://huggingface.co/heegyu/WizardVicuna2-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-guanaco-fp16",
    "author": "Mikael110",
    "query_name": "Mikael110/llama-2-7b-guanaco-fp16",
    "score": 51.04,
    "likes": 9.0,
    "link": "https://huggingface.co/Mikael110/llama-2-7b-guanaco-fp16",
    "still_on_hub": true
  },
  {
    "name": "chinese-llama-2-13b",
    "author": "ziqingyang",
    "query_name": "ziqingyang/chinese-llama-2-13b",
    "score": 51.04,
    "likes": 22.0,
    "link": "https://huggingface.co/ziqingyang/chinese-llama-2-13b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-30-sparsity",
    "author": "wang7776",
    "query_name": "wang7776/Llama-2-7b-chat-hf-30-sparsity",
    "score": 51.02,
    "likes": 0.0,
    "link": "https://huggingface.co/wang7776/Llama-2-7b-chat-hf-30-sparsity",
    "still_on_hub": true
  },
  {
    "name": "Mistral-Pygmalion-7b",
    "author": "Delcos",
    "query_name": "Delcos/Mistral-Pygmalion-7b",
    "score": 51.02,
    "likes": 1.0,
    "link": "https://huggingface.co/Delcos/Mistral-Pygmalion-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-claude-chat",
    "author": "Norquinal",
    "query_name": "Norquinal/llama-2-7b-claude-chat",
    "score": 50.98,
    "likes": 0.0,
    "link": "https://huggingface.co/Norquinal/llama-2-7b-claude-chat",
    "still_on_hub": true
  },
  {
    "name": "vic15-exp-syn-fight-cp3838",
    "author": "AlekseyKorshuk",
    "query_name": "AlekseyKorshuk/vic15-exp-syn-fight-cp3838",
    "score": 50.97,
    "likes": 0.0,
    "link": "https://huggingface.co/AlekseyKorshuk/vic15-exp-syn-fight-cp3838",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-hf",
    "author": "meta-llama",
    "query_name": "meta-llama/Llama-2-7b-hf",
    "score": 50.97,
    "likes": 679.0,
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-hf",
    "still_on_hub": false
  },
  {
    "name": "Dorflan",
    "author": "formulae",
    "query_name": "formulae/Dorflan",
    "score": 50.96,
    "likes": 0.0,
    "link": "https://huggingface.co/formulae/Dorflan",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-instruct-peft",
    "author": "dfurman",
    "query_name": "dfurman/llama-2-7b-instruct-peft",
    "score": 50.94,
    "likes": 1.0,
    "link": "https://huggingface.co/dfurman/llama-2-7b-instruct-peft",
    "still_on_hub": false
  },
  {
    "name": "LLaMa-2-PeanutButter_v18_B-7B",
    "author": "PeanutJar",
    "query_name": "PeanutJar/LLaMa-2-PeanutButter_v18_B-7B",
    "score": 50.94,
    "likes": 0.0,
    "link": "https://huggingface.co/PeanutJar/LLaMa-2-PeanutButter_v18_B-7B",
    "still_on_hub": false
  },
  {
    "name": "cria-llama2-7b-v1.3",
    "author": "davzoku",
    "query_name": "davzoku/cria-llama2-7b-v1.3",
    "score": 50.93,
    "likes": 0.0,
    "link": "https://huggingface.co/davzoku/cria-llama2-7b-v1.3",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-100step-v2",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-100step-v2",
    "score": 50.89,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-100step-v2",
    "still_on_hub": true
  },
  {
    "name": "Barcenas-7b",
    "author": "Danielbrdz",
    "query_name": "Danielbrdz/Barcenas-7b",
    "score": 50.87,
    "likes": 1.0,
    "link": "https://huggingface.co/Danielbrdz/Barcenas-7b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-13b-2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-13b-2.1",
    "score": 50.84,
    "likes": 10.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-13b-2.1",
    "still_on_hub": true
  },
  {
    "name": "Guanaco-Vicuna-7B-L2",
    "author": "LTC-AI-Labs",
    "query_name": "LTC-AI-Labs/Guanaco-Vicuna-7B-L2",
    "score": 50.83,
    "likes": 0.0,
    "link": "https://huggingface.co/LTC-AI-Labs/Guanaco-Vicuna-7B-L2",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama2-13b-pretrain",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama2-13b-pretrain",
    "score": 50.77,
    "likes": 0.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-13b-pretrain",
    "still_on_hub": true
  },
  {
    "name": "LLaMa-2-PeanutButter_v10-7B",
    "author": "PeanutJar",
    "query_name": "PeanutJar/LLaMa-2-PeanutButter_v10-7B",
    "score": 50.75,
    "likes": 0.0,
    "link": "https://huggingface.co/PeanutJar/LLaMa-2-PeanutButter_v10-7B",
    "still_on_hub": false
  },
  {
    "name": "Llama-2-7b-chat-hf",
    "author": "meta-llama",
    "query_name": "meta-llama/Llama-2-7b-chat-hf",
    "score": 50.74,
    "likes": 1415.0,
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf",
    "still_on_hub": false
  },
  {
    "name": "vicuna-7b-v1.5-lora-timedial-unit-080082",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080082",
    "score": 50.74,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080082",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-lora-timedial-unit-080091",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080091",
    "score": 50.71,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-timedial-unit-080091",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-finetune-AUTOMATE",
    "author": "revolutionarybukhari",
    "query_name": "revolutionarybukhari/Llama-2-7b-chat-finetune-AUTOMATE",
    "score": 50.68,
    "likes": 0.0,
    "link": "https://huggingface.co/revolutionarybukhari/Llama-2-7b-chat-finetune-AUTOMATE",
    "still_on_hub": true
  },
  {
    "name": "kollama2-7b-v2",
    "author": "psyche",
    "query_name": "psyche/kollama2-7b-v2",
    "score": 50.66,
    "likes": 3.0,
    "link": "https://huggingface.co/psyche/kollama2-7b-v2",
    "still_on_hub": true
  },
  {
    "name": "Qwen-LLaMAfied-HFTok-7B-Chat",
    "author": "vonjack",
    "query_name": "vonjack/Qwen-LLaMAfied-HFTok-7B-Chat",
    "score": 50.64,
    "likes": 19.0,
    "link": "https://huggingface.co/vonjack/Qwen-LLaMAfied-HFTok-7B-Chat",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Base-WVG-Uncensored",
    "author": "LTC-AI-Labs",
    "query_name": "LTC-AI-Labs/L2-7b-Base-WVG-Uncensored",
    "score": 50.63,
    "likes": 0.0,
    "link": "https://huggingface.co/LTC-AI-Labs/L2-7b-Base-WVG-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "LaOT",
    "author": "DopeorNope",
    "query_name": "DopeorNope/LaOT",
    "score": 50.62,
    "likes": 0.0,
    "link": "https://huggingface.co/DopeorNope/LaOT",
    "still_on_hub": false
  },
  {
    "name": "zaraxls-l2-7b",
    "author": "zarakiquemparte",
    "query_name": "zarakiquemparte/zaraxls-l2-7b",
    "score": 50.61,
    "likes": 1.0,
    "link": "https://huggingface.co/zarakiquemparte/zaraxls-l2-7b",
    "still_on_hub": true
  },
  {
    "name": "ANIMA-Nectar-v3",
    "author": "Severian",
    "query_name": "Severian/ANIMA-Nectar-v3",
    "score": 50.58,
    "likes": 0.0,
    "link": "https://huggingface.co/Severian/ANIMA-Nectar-v3",
    "still_on_hub": true
  },
  {
    "name": "trurl-2-7b",
    "author": "Voicelab",
    "query_name": "Voicelab/trurl-2-7b",
    "score": 50.58,
    "likes": 8.0,
    "link": "https://huggingface.co/Voicelab/trurl-2-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-guanaco-instruct-sharded",
    "author": "guardrail",
    "query_name": "guardrail/llama-2-7b-guanaco-instruct-sharded",
    "score": 50.58,
    "likes": 4.0,
    "link": "https://huggingface.co/guardrail/llama-2-7b-guanaco-instruct-sharded",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-rockwell-final",
    "author": "maximuslee07",
    "query_name": "maximuslee07/llama-2-7b-rockwell-final",
    "score": 50.55,
    "likes": 0.0,
    "link": "https://huggingface.co/maximuslee07/llama-2-7b-rockwell-final",
    "still_on_hub": true
  },
  {
    "name": "vicuna-mmlu-val-mcq-7b-ep2",
    "author": "luffycodes",
    "query_name": "luffycodes/vicuna-mmlu-val-mcq-7b-ep2",
    "score": 50.55,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/vicuna-mmlu-val-mcq-7b-ep2",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Guanaco-Uncensored",
    "author": "Lazycuber",
    "query_name": "Lazycuber/L2-7b-Guanaco-Uncensored",
    "score": 50.55,
    "likes": 0.0,
    "link": "https://huggingface.co/Lazycuber/L2-7b-Guanaco-Uncensored",
    "still_on_hub": false
  },
  {
    "name": "trurl-2-7b-pl-instruct_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/trurl-2-7b-pl-instruct_unload",
    "score": 50.52,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/trurl-2-7b-pl-instruct_unload",
    "still_on_hub": true
  },
  {
    "name": "monika-ddlc-7b-v1",
    "author": "922-CA",
    "query_name": "922-CA/monika-ddlc-7b-v1",
    "score": 50.49,
    "likes": 0.0,
    "link": "https://huggingface.co/922-CA/monika-ddlc-7b-v1",
    "still_on_hub": true
  },
  {
    "name": "WizardCoder-Python-34B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardCoder-Python-34B-V1.0",
    "score": 50.46,
    "likes": 616.0,
    "link": "https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "L2-7b-Base-Guanaco-Uncensored",
    "author": "Lazycuber",
    "query_name": "Lazycuber/L2-7b-Base-Guanaco-Uncensored",
    "score": 50.45,
    "likes": 0.0,
    "link": "https://huggingface.co/Lazycuber/L2-7b-Base-Guanaco-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "gpt4-x-alpaca",
    "author": "chavinlo",
    "query_name": "chavinlo/gpt4-x-alpaca",
    "score": 50.41,
    "likes": 456.0,
    "link": "https://huggingface.co/chavinlo/gpt4-x-alpaca",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
    "score": 50.4,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-chat-hf-dpo",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-chat-hf-dpo",
    "score": 50.38,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-dpo",
    "still_on_hub": true
  },
  {
    "name": "Koss-7B-chat",
    "author": "NewstaR",
    "query_name": "NewstaR/Koss-7B-chat",
    "score": 50.37,
    "likes": 0.0,
    "link": "https://huggingface.co/NewstaR/Koss-7B-chat",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-delta-v1.1",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-7b-delta-v1.1",
    "score": 50.37,
    "likes": 197.0,
    "link": "https://huggingface.co/lmsys/vicuna-7b-delta-v1.1",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-1.1",
    "author": "eachadea",
    "query_name": "eachadea/vicuna-7b-1.1",
    "score": 50.37,
    "likes": 109.0,
    "link": "https://huggingface.co/eachadea/vicuna-7b-1.1",
    "still_on_hub": true
  },
  {
    "name": "vicuna_7B_vanilla_1.1",
    "author": "Ejafa",
    "query_name": "Ejafa/vicuna_7B_vanilla_1.1",
    "score": 50.37,
    "likes": 2.0,
    "link": "https://huggingface.co/Ejafa/vicuna_7B_vanilla_1.1",
    "still_on_hub": true
  },
  {
    "name": "spatial-vicuna-7b-v1.5-LoRA",
    "author": "joehuangx",
    "query_name": "joehuangx/spatial-vicuna-7b-v1.5-LoRA",
    "score": 50.36,
    "likes": 0.0,
    "link": "https://huggingface.co/joehuangx/spatial-vicuna-7b-v1.5-LoRA",
    "still_on_hub": false
  },
  {
    "name": "vicuna-7b-v1.5-lora-timedial",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-timedial",
    "score": 50.35,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-timedial",
    "still_on_hub": true
  },
  {
    "name": "lacda-2-7B-chat-v0.1",
    "author": "willnguyen",
    "query_name": "willnguyen/lacda-2-7B-chat-v0.1",
    "score": 50.29,
    "likes": 0.0,
    "link": "https://huggingface.co/willnguyen/lacda-2-7B-chat-v0.1",
    "still_on_hub": true
  },
  {
    "name": "Yi-Ko-6B",
    "author": "beomi",
    "query_name": "beomi/Yi-Ko-6B",
    "score": 50.27,
    "likes": 4.0,
    "link": "https://huggingface.co/beomi/Yi-Ko-6B",
    "still_on_hub": true
  },
  {
    "name": "smol-3b",
    "author": "rishiraj",
    "query_name": "rishiraj/smol-3b",
    "score": 50.27,
    "likes": 0.0,
    "link": "https://huggingface.co/rishiraj/smol-3b",
    "still_on_hub": true
  },
  {
    "name": "Asclepius-Llama2-13B",
    "author": "starmpcc",
    "query_name": "starmpcc/Asclepius-Llama2-13B",
    "score": 50.25,
    "likes": 2.0,
    "link": "https://huggingface.co/starmpcc/Asclepius-Llama2-13B",
    "still_on_hub": true
  },
  {
    "name": "tulu-7B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/tulu-7B-fp16",
    "score": 50.24,
    "likes": 2.0,
    "link": "https://huggingface.co/TheBloke/tulu-7B-fp16",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-hf-instruct-pl-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/Llama-2-7b-hf-instruct-pl-lora_unload",
    "score": 50.23,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/Llama-2-7b-hf-instruct-pl-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "MiniChat-1.5-3B",
    "author": "GeneZC",
    "query_name": "GeneZC/MiniChat-1.5-3B",
    "score": 50.23,
    "likes": 0.0,
    "link": "https://huggingface.co/GeneZC/MiniChat-1.5-3B",
    "still_on_hub": true
  },
  {
    "name": "LLongMA-2-13b-16k",
    "author": "conceptofmind",
    "query_name": "conceptofmind/LLongMA-2-13b-16k",
    "score": 50.22,
    "likes": 0.0,
    "link": "https://huggingface.co/conceptofmind/LLongMA-2-13b-16k",
    "still_on_hub": false
  },
  {
    "name": "stack-llama-2",
    "author": "kashif",
    "query_name": "kashif/stack-llama-2",
    "score": 50.21,
    "likes": 7.0,
    "link": "https://huggingface.co/kashif/stack-llama-2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-afr-200step-v2",
    "author": "Korabbit",
    "query_name": "Korabbit/Llama-2-7b-chat-hf-afr-200step-v2",
    "score": 50.21,
    "likes": 0.0,
    "link": "https://huggingface.co/Korabbit/Llama-2-7b-chat-hf-afr-200step-v2",
    "still_on_hub": true
  },
  {
    "name": "elliott_Llama-2-7b-hf",
    "author": "elliotthwang",
    "query_name": "elliotthwang/elliott_Llama-2-7b-hf",
    "score": 50.2,
    "likes": 0.0,
    "link": "https://huggingface.co/elliotthwang/elliott_Llama-2-7b-hf",
    "still_on_hub": true
  },
  {
    "name": "Platypus2-mini-7B",
    "author": "edor",
    "query_name": "edor/Platypus2-mini-7B",
    "score": 50.18,
    "likes": 0.0,
    "link": "https://huggingface.co/edor/Platypus2-mini-7B",
    "still_on_hub": true
  },
  {
    "name": "ALMA-13B",
    "author": "haoranxu",
    "query_name": "haoranxu/ALMA-13B",
    "score": 50.16,
    "likes": 15.0,
    "link": "https://huggingface.co/haoranxu/ALMA-13B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-hf-guanaco-1k",
    "author": "quantumaikr",
    "query_name": "quantumaikr/llama-2-7b-hf-guanaco-1k",
    "score": 50.13,
    "likes": 0.0,
    "link": "https://huggingface.co/quantumaikr/llama-2-7b-hf-guanaco-1k",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-hf-guanaco",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-hf-guanaco",
    "score": 50.12,
    "likes": 1.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-hf-guanaco",
    "still_on_hub": true
  },
  {
    "name": "elm-test",
    "author": "TinyPixel",
    "query_name": "TinyPixel/elm-test",
    "score": 50.09,
    "likes": 0.0,
    "link": "https://huggingface.co/TinyPixel/elm-test",
    "still_on_hub": true
  },
  {
    "name": "LLongMA-2-13b-16k",
    "author": "conceptofmind",
    "query_name": "conceptofmind/LLongMA-2-13b-16k",
    "score": 50.09,
    "likes": 0.0,
    "link": "https://huggingface.co/conceptofmind/LLongMA-2-13b-16k",
    "still_on_hub": false
  },
  {
    "name": "Llama-2-7B-32K-Instruct",
    "author": "togethercomputer",
    "query_name": "togethercomputer/Llama-2-7B-32K-Instruct",
    "score": 50.02,
    "likes": 111.0,
    "link": "https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-chat-hf-guanaco",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-chat-hf-guanaco",
    "score": 50.02,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-guanaco",
    "still_on_hub": true
  },
  {
    "name": "llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
    "score": 50.0,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged",
    "still_on_hub": true
  },
  {
    "name": "llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
    "score": 49.98,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16",
    "still_on_hub": false
  },
  {
    "name": "Platypus2-7B",
    "author": "garage-bAInd",
    "query_name": "garage-bAInd/Platypus2-7B",
    "score": 49.97,
    "likes": 2.0,
    "link": "https://huggingface.co/garage-bAInd/Platypus2-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-hf-small-shards-Samantha-V1-SFT",
    "author": "RoversX",
    "query_name": "RoversX/llama-2-7b-hf-small-shards-Samantha-V1-SFT",
    "score": 49.96,
    "likes": 0.0,
    "link": "https://huggingface.co/RoversX/llama-2-7b-hf-small-shards-Samantha-V1-SFT",
    "still_on_hub": true
  },
  {
    "name": "mamba-gpt-7b",
    "author": "CobraMamba",
    "query_name": "CobraMamba/mamba-gpt-7b",
    "score": 49.96,
    "likes": 1.0,
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-7b",
    "still_on_hub": true
  },
  {
    "name": "lima-test",
    "author": "TinyPixel",
    "query_name": "TinyPixel/lima-test",
    "score": 49.96,
    "likes": 0.0,
    "link": "https://huggingface.co/TinyPixel/lima-test",
    "still_on_hub": true
  },
  {
    "name": "Uncensored-Jordan-7B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Uncensored-Jordan-7B",
    "score": 49.95,
    "likes": 3.0,
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Jordan-7B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-coder-7b",
    "author": "mrm8488",
    "query_name": "mrm8488/llama-2-coder-7b",
    "score": 49.95,
    "likes": 36.0,
    "link": "https://huggingface.co/mrm8488/llama-2-coder-7b",
    "still_on_hub": true
  },
  {
    "name": "LLaMa-2-PeanutButter_v18_A-7B",
    "author": "PeanutJar",
    "query_name": "PeanutJar/LLaMa-2-PeanutButter_v18_A-7B",
    "score": 49.88,
    "likes": 0.0,
    "link": "https://huggingface.co/PeanutJar/LLaMa-2-PeanutButter_v18_A-7B",
    "still_on_hub": false
  },
  {
    "name": "yayi-7b-llama2",
    "author": "wenge-research",
    "query_name": "wenge-research/yayi-7b-llama2",
    "score": 49.88,
    "likes": 8.0,
    "link": "https://huggingface.co/wenge-research/yayi-7b-llama2",
    "still_on_hub": true
  },
  {
    "name": "testmodel2",
    "author": "TinyPixel",
    "query_name": "TinyPixel/testmodel2",
    "score": 49.88,
    "likes": 0.0,
    "link": "https://huggingface.co/TinyPixel/testmodel2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-instruct-pl-lora_unload",
    "author": "Lajonbot",
    "query_name": "Lajonbot/Llama-2-7b-chat-hf-instruct-pl-lora_unload",
    "score": 49.86,
    "likes": 0.0,
    "link": "https://huggingface.co/Lajonbot/Llama-2-7b-chat-hf-instruct-pl-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "kollama2-7b",
    "author": "psyche",
    "query_name": "psyche/kollama2-7b",
    "score": 49.81,
    "likes": 2.0,
    "link": "https://huggingface.co/psyche/kollama2-7b",
    "still_on_hub": true
  },
  {
    "name": "testmodel-3",
    "author": "TinyPixel",
    "query_name": "TinyPixel/testmodel-3",
    "score": 49.79,
    "likes": 0.0,
    "link": "https://huggingface.co/TinyPixel/testmodel-3",
    "still_on_hub": true
  },
  {
    "name": "WizardMath-7B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardMath-7B-V1.0",
    "score": 49.78,
    "likes": 32.0,
    "link": "https://huggingface.co/WizardLM/WizardMath-7B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "ELYZA-japanese-Llama-2-7b-instruct",
    "author": "elyza",
    "query_name": "elyza/ELYZA-japanese-Llama-2-7b-instruct",
    "score": 49.78,
    "likes": 32.0,
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-instruct",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.3",
    "author": "lmsys",
    "query_name": "lmsys/vicuna-7b-v1.3",
    "score": 49.78,
    "likes": 112.0,
    "link": "https://huggingface.co/lmsys/vicuna-7b-v1.3",
    "still_on_hub": true
  },
  {
    "name": "llama2-to-mistral-diff",
    "author": "undi95",
    "query_name": "undi95/llama2-to-mistral-diff",
    "score": 49.78,
    "likes": 10.0,
    "link": "https://huggingface.co/undi95/llama2-to-mistral-diff",
    "still_on_hub": false
  },
  {
    "name": "llama2-7b-chat-hf-v4",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "score": 49.78,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
    "score": 49.77,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mixed-datasets-time-unit",
    "still_on_hub": true
  },
  {
    "name": "yayi-7b-llama2",
    "author": "wenge-research",
    "query_name": "wenge-research/yayi-7b-llama2",
    "score": 49.75,
    "likes": 8.0,
    "link": "https://huggingface.co/wenge-research/yayi-7b-llama2",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-hf_open-platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/llama-2-7b-hf_open-platypus",
    "score": 49.73,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/llama-2-7b-hf_open-platypus",
    "still_on_hub": true
  },
  {
    "name": "test-llama2-7b",
    "author": "bongchoi",
    "query_name": "bongchoi/test-llama2-7b",
    "score": 49.73,
    "likes": 0.0,
    "link": "https://huggingface.co/bongchoi/test-llama2-7b",
    "still_on_hub": false
  },
  {
    "name": "test_llama2_7b",
    "author": "yeen214",
    "query_name": "yeen214/test_llama2_7b",
    "score": 49.73,
    "likes": 0.0,
    "link": "https://huggingface.co/yeen214/test_llama2_7b",
    "still_on_hub": true
  },
  {
    "name": "Starlight-7B",
    "author": "NewstaR",
    "query_name": "NewstaR/Starlight-7B",
    "score": 49.73,
    "likes": 0.0,
    "link": "https://huggingface.co/NewstaR/Starlight-7B",
    "still_on_hub": true
  },
  {
    "name": "Flash-Llama-7B",
    "author": "TaylorAI",
    "query_name": "TaylorAI/Flash-Llama-7B",
    "score": 49.73,
    "likes": 1.0,
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-7B",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-chat-hf-v2",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-chat-hf-v2",
    "score": 49.73,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v2",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-chat-hf-v4",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "score": 49.73,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v4",
    "still_on_hub": true
  },
  {
    "name": "araproje-llama2-7b-hf",
    "author": "ibranze",
    "query_name": "ibranze/araproje-llama2-7b-hf",
    "score": 49.73,
    "likes": 0.0,
    "link": "https://huggingface.co/ibranze/araproje-llama2-7b-hf",
    "still_on_hub": true
  },
  {
    "name": "cria-llama2-7b-v1.3_peft",
    "author": "davzoku",
    "query_name": "davzoku/cria-llama2-7b-v1.3_peft",
    "score": 49.72,
    "likes": 0.0,
    "link": "https://huggingface.co/davzoku/cria-llama2-7b-v1.3_peft",
    "still_on_hub": false
  },
  {
    "name": "ToolLLaMA-7b-LoRA",
    "author": "ToolBench",
    "query_name": "ToolBench/ToolLLaMA-7b-LoRA",
    "score": 49.72,
    "likes": 7.0,
    "link": "https://huggingface.co/ToolBench/ToolLLaMA-7b-LoRA",
    "still_on_hub": false
  },
  {
    "name": "Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
    "score": 49.71,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-lora-mixed-datasets",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-mixed-datasets",
    "score": 49.7,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mixed-datasets",
    "still_on_hub": true
  },
  {
    "name": "finetuned-llama-v2.0",
    "author": "abdulrahman-nuzha",
    "query_name": "abdulrahman-nuzha/finetuned-llama-v2.0",
    "score": 49.67,
    "likes": 0.0,
    "link": "https://huggingface.co/abdulrahman-nuzha/finetuned-llama-v2.0",
    "still_on_hub": false
  },
  {
    "name": "llama2_7b_chat_uncensored",
    "author": "georgesung",
    "query_name": "georgesung/llama2_7b_chat_uncensored",
    "score": 49.67,
    "likes": 152.0,
    "link": "https://huggingface.co/georgesung/llama2_7b_chat_uncensored",
    "still_on_hub": true
  },
  {
    "name": "chinese-alpaca-plus-13b-hf",
    "author": "shibing624",
    "query_name": "shibing624/chinese-alpaca-plus-13b-hf",
    "score": 49.66,
    "likes": 32.0,
    "link": "https://huggingface.co/shibing624/chinese-alpaca-plus-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "starchat-beta",
    "author": "HuggingFaceH4",
    "query_name": "HuggingFaceH4/starchat-beta",
    "score": 49.66,
    "likes": 222.0,
    "link": "https://huggingface.co/HuggingFaceH4/starchat-beta",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7B-32K-Instruct",
    "author": "togethercomputer",
    "query_name": "togethercomputer/Llama-2-7B-32K-Instruct",
    "score": 49.65,
    "likes": 111.0,
    "link": "https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct",
    "still_on_hub": true
  },
  {
    "name": "FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
    "author": "TaylorAI",
    "query_name": "TaylorAI/FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
    "score": 49.64,
    "likes": 1.0,
    "link": "https://huggingface.co/TaylorAI/FLAN-Llama-7B-2_Llama2-7B-Flash_868_full_model",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-7b-2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-7b-2.1",
    "score": 49.64,
    "likes": 5.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-2.1",
    "still_on_hub": true
  },
  {
    "name": "longchat-13b-16k",
    "author": "lmsys",
    "query_name": "lmsys/longchat-13b-16k",
    "score": 49.64,
    "likes": 123.0,
    "link": "https://huggingface.co/lmsys/longchat-13b-16k",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-ft-instruct-es",
    "author": "clibrain",
    "query_name": "clibrain/Llama-2-7b-ft-instruct-es",
    "score": 49.63,
    "likes": 13.0,
    "link": "https://huggingface.co/clibrain/Llama-2-7b-ft-instruct-es",
    "still_on_hub": true
  },
  {
    "name": "airocoder-34b-2.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airocoder-34b-2.1",
    "score": 49.61,
    "likes": 4.0,
    "link": "https://huggingface.co/jondurbin/airocoder-34b-2.1",
    "still_on_hub": true
  },
  {
    "name": "meditron-7b-chat",
    "author": "malhajar",
    "query_name": "malhajar/meditron-7b-chat",
    "score": 49.59,
    "likes": 0.0,
    "link": "https://huggingface.co/malhajar/meditron-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-chinese-v2",
    "author": "gywy",
    "query_name": "gywy/llama2-13b-chinese-v2",
    "score": 49.58,
    "likes": 2.0,
    "link": "https://huggingface.co/gywy/llama2-13b-chinese-v2",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-1-percent-open-orca-1000-steps-v0",
    "author": "sia-ai",
    "query_name": "sia-ai/llama-2-7b-1-percent-open-orca-1000-steps-v0",
    "score": 49.56,
    "likes": 0.0,
    "link": "https://huggingface.co/sia-ai/llama-2-7b-1-percent-open-orca-1000-steps-v0",
    "still_on_hub": true
  },
  {
    "name": "perry-7b",
    "author": "dotvignesh",
    "query_name": "dotvignesh/perry-7b",
    "score": 49.55,
    "likes": 0.0,
    "link": "https://huggingface.co/dotvignesh/perry-7b",
    "still_on_hub": true
  },
  {
    "name": "13B-Ouroboros",
    "author": "CalderaAI",
    "query_name": "CalderaAI/13B-Ouroboros",
    "score": 49.54,
    "likes": 6.0,
    "link": "https://huggingface.co/CalderaAI/13B-Ouroboros",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-7b-gpt4-1.4.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-7b-gpt4-1.4.1",
    "score": 49.54,
    "likes": 10.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-gpt4-1.4.1",
    "still_on_hub": true
  },
  {
    "name": "llama2-ko-7B-model",
    "author": "jb723",
    "query_name": "jb723/llama2-ko-7B-model",
    "score": 49.52,
    "likes": 0.0,
    "link": "https://huggingface.co/jb723/llama2-ko-7B-model",
    "still_on_hub": true
  },
  {
    "name": "instruct-13b",
    "author": "llama-anon",
    "query_name": "llama-anon/instruct-13b",
    "score": 49.52,
    "likes": 3.0,
    "link": "https://huggingface.co/llama-anon/instruct-13b",
    "still_on_hub": true
  },
  {
    "name": "QuantumLM-7B",
    "author": "quantumaikr",
    "query_name": "quantumaikr/QuantumLM-7B",
    "score": 49.51,
    "likes": 1.0,
    "link": "https://huggingface.co/quantumaikr/QuantumLM-7B",
    "still_on_hub": true
  },
  {
    "name": "tamil-llama-13b-base-v0.1",
    "author": "abhinand",
    "query_name": "abhinand/tamil-llama-13b-base-v0.1",
    "score": 49.5,
    "likes": 0.0,
    "link": "https://huggingface.co/abhinand/tamil-llama-13b-base-v0.1",
    "still_on_hub": true
  },
  {
    "name": "Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
    "score": 49.47,
    "likes": 15.0,
    "link": "https://huggingface.co/TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Guanaco-7B-Uncensored",
    "author": "Fredithefish",
    "query_name": "Fredithefish/Guanaco-7B-Uncensored",
    "score": 49.35,
    "likes": 4.0,
    "link": "https://huggingface.co/Fredithefish/Guanaco-7B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-mathgpt-v4",
    "author": "rameshm",
    "query_name": "rameshm/llama-2-13b-mathgpt-v4",
    "score": 49.35,
    "likes": 0.0,
    "link": "https://huggingface.co/rameshm/llama-2-13b-mathgpt-v4",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-openllama-13b-v7-fp16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-openllama-13b-v7-fp16",
    "score": 49.31,
    "likes": 3.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-openllama-13b-v7-fp16",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-int4-python-code-18k",
    "author": "qualis2006",
    "query_name": "qualis2006/llama-2-7b-int4-python-code-18k",
    "score": 49.3,
    "likes": 0.0,
    "link": "https://huggingface.co/qualis2006/llama-2-7b-int4-python-code-18k",
    "still_on_hub": true
  },
  {
    "name": "leo-hessianai-7b-chat",
    "author": "LeoLM",
    "query_name": "LeoLM/leo-hessianai-7b-chat",
    "score": 49.29,
    "likes": 8.0,
    "link": "https://huggingface.co/LeoLM/leo-hessianai-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "vigogne-7b-chat",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-7b-chat",
    "score": 49.27,
    "likes": 3.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "LIMA2-7b-hf",
    "author": "heegyu",
    "query_name": "heegyu/LIMA2-7b-hf",
    "score": 49.27,
    "likes": 1.0,
    "link": "https://huggingface.co/heegyu/LIMA2-7b-hf",
    "still_on_hub": true
  },
  {
    "name": "Pygmalion-Vicuna-1.1-7b",
    "author": "TehVenom",
    "query_name": "TehVenom/Pygmalion-Vicuna-1.1-7b",
    "score": 49.25,
    "likes": 25.0,
    "link": "https://huggingface.co/TehVenom/Pygmalion-Vicuna-1.1-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
    "score": 49.22,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged",
    "still_on_hub": true
  },
  {
    "name": "llama-v2-7b-32kC-Security",
    "author": "venkycs",
    "query_name": "venkycs/llama-v2-7b-32kC-Security",
    "score": 49.19,
    "likes": 5.0,
    "link": "https://huggingface.co/venkycs/llama-v2-7b-32kC-Security",
    "still_on_hub": false
  },
  {
    "name": "llama_7b_sharegpt94k_fastchat",
    "author": "wahaha1987",
    "query_name": "wahaha1987/llama_7b_sharegpt94k_fastchat",
    "score": 49.19,
    "likes": 2.0,
    "link": "https://huggingface.co/wahaha1987/llama_7b_sharegpt94k_fastchat",
    "still_on_hub": true
  },
  {
    "name": "Dans-RetroRodeo-13b",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-RetroRodeo-13b",
    "score": 49.15,
    "likes": 2.0,
    "link": "https://huggingface.co/PocketDoc/Dans-RetroRodeo-13b",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7B-physics",
    "author": "FelixChao",
    "query_name": "FelixChao/vicuna-7B-physics",
    "score": 49.15,
    "likes": 0.0,
    "link": "https://huggingface.co/FelixChao/vicuna-7B-physics",
    "still_on_hub": true
  },
  {
    "name": "ELYZA-japanese-Llama-2-7b-fast-instruct",
    "author": "elyza",
    "query_name": "elyza/ELYZA-japanese-Llama-2-7b-fast-instruct",
    "score": 49.15,
    "likes": 42.0,
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-fast-instruct",
    "still_on_hub": true
  },
  {
    "name": "scarlett-7b",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/scarlett-7b",
    "score": 49.09,
    "likes": 3.0,
    "link": "https://huggingface.co/ajibawa-2023/scarlett-7b",
    "still_on_hub": true
  },
  {
    "name": "llama2_7b_code",
    "author": "itsliupeng",
    "query_name": "itsliupeng/llama2_7b_code",
    "score": 49.05,
    "likes": 1.0,
    "link": "https://huggingface.co/itsliupeng/llama2_7b_code",
    "still_on_hub": true
  },
  {
    "name": "Baichuan2-7B-Base-LLaMAfied",
    "author": "hiyouga",
    "query_name": "hiyouga/Baichuan2-7B-Base-LLaMAfied",
    "score": 48.99,
    "likes": 4.0,
    "link": "https://huggingface.co/hiyouga/Baichuan2-7B-Base-LLaMAfied",
    "still_on_hub": true
  },
  {
    "name": "vicuna-mmlu-val-only-correct-mcq-7b-ep2",
    "author": "luffycodes",
    "query_name": "luffycodes/vicuna-mmlu-val-only-correct-mcq-7b-ep2",
    "score": 48.96,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/vicuna-mmlu-val-only-correct-mcq-7b-ep2",
    "still_on_hub": true
  },
  {
    "name": "tora-code-34b-v1.0",
    "author": "llm-agents",
    "query_name": "llm-agents/tora-code-34b-v1.0",
    "score": 48.95,
    "likes": 4.0,
    "link": "https://huggingface.co/llm-agents/tora-code-34b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "mistral-megamerge-dare-7b",
    "author": "martyn",
    "query_name": "martyn/mistral-megamerge-dare-7b",
    "score": 48.93,
    "likes": 0.0,
    "link": "https://huggingface.co/martyn/mistral-megamerge-dare-7b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-hf",
    "author": "meta-llama",
    "query_name": "meta-llama/Llama-2-7b-hf",
    "score": 48.93,
    "likes": 0.0,
    "link": "https://huggingface.co/meta-llama/Llama-2-7b-hf",
    "still_on_hub": false
  },
  {
    "name": "MedicWizard-7B",
    "author": "xzuyn",
    "query_name": "xzuyn/MedicWizard-7B",
    "score": 48.88,
    "likes": 13.0,
    "link": "https://huggingface.co/xzuyn/MedicWizard-7B",
    "still_on_hub": true
  },
  {
    "name": "chinese-alpaca-2-7b",
    "author": "ziqingyang",
    "query_name": "ziqingyang/chinese-alpaca-2-7b",
    "score": 48.85,
    "likes": 93.0,
    "link": "https://huggingface.co/ziqingyang/chinese-alpaca-2-7b",
    "still_on_hub": true
  },
  {
    "name": "opencoderplus",
    "author": "openchat",
    "query_name": "openchat/opencoderplus",
    "score": 48.84,
    "likes": 100.0,
    "link": "https://huggingface.co/openchat/opencoderplus",
    "still_on_hub": true
  },
  {
    "name": "llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
    "author": "dhmeltzer",
    "query_name": "dhmeltzer/llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
    "score": 48.82,
    "likes": 0.0,
    "link": "https://huggingface.co/dhmeltzer/llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-chat-hf-v3",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "score": 48.81,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "still_on_hub": true
  },
  {
    "name": "vicuna-class-shishya-all-hal-7b-ep3",
    "author": "luffycodes",
    "query_name": "luffycodes/vicuna-class-shishya-all-hal-7b-ep3",
    "score": 48.75,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/vicuna-class-shishya-all-hal-7b-ep3",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.3-instruct-pl-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/vicuna-7b-v1.3-instruct-pl-lora_unload",
    "score": 48.74,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/vicuna-7b-v1.3-instruct-pl-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "leo-hessianai-7b-chat-bilingual",
    "author": "LeoLM",
    "query_name": "LeoLM/leo-hessianai-7b-chat-bilingual",
    "score": 48.72,
    "likes": 4.0,
    "link": "https://huggingface.co/LeoLM/leo-hessianai-7b-chat-bilingual",
    "still_on_hub": true
  },
  {
    "name": "GOAT-7B-Community",
    "author": "GOAT-AI",
    "query_name": "GOAT-AI/GOAT-7B-Community",
    "score": 48.71,
    "likes": 34.0,
    "link": "https://huggingface.co/GOAT-AI/GOAT-7B-Community",
    "still_on_hub": true
  },
  {
    "name": "ELYZA-japanese-Llama-2-7b",
    "author": "elyza",
    "query_name": "elyza/ELYZA-japanese-Llama-2-7b",
    "score": 48.7,
    "likes": 32.0,
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b",
    "still_on_hub": true
  },
  {
    "name": "llama2-7b-chat-hf-v3",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "score": 48.65,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/llama2-7b-chat-hf-v3",
    "still_on_hub": true
  },
  {
    "name": "Dans-CreepingSenseOfDoom",
    "author": "PocketDoc",
    "query_name": "PocketDoc/Dans-CreepingSenseOfDoom",
    "score": 48.58,
    "likes": 3.0,
    "link": "https://huggingface.co/PocketDoc/Dans-CreepingSenseOfDoom",
    "still_on_hub": true
  },
  {
    "name": "airoboros-7b-gpt4-1.1",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-7b-gpt4-1.1",
    "score": 48.57,
    "likes": 5.0,
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.1",
    "still_on_hub": true
  },
  {
    "name": "youri-7b-chat",
    "author": "rinna",
    "query_name": "rinna/youri-7b-chat",
    "score": 48.51,
    "likes": 12.0,
    "link": "https://huggingface.co/rinna/youri-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "tora-7b-v1.0",
    "author": "llm-agents",
    "query_name": "llm-agents/tora-7b-v1.0",
    "score": 48.5,
    "likes": 2.0,
    "link": "https://huggingface.co/llm-agents/tora-7b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "Pygmalion-13b-Merged",
    "author": "TehVenom",
    "query_name": "TehVenom/Pygmalion-13b-Merged",
    "score": 48.49,
    "likes": 26.0,
    "link": "https://huggingface.co/TehVenom/Pygmalion-13b-Merged",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Llama-2-7B-GPTQ",
    "score": 48.48,
    "likes": 58.0,
    "link": "https://huggingface.co/TheBloke/Llama-2-7B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-Uncensored",
    "author": "ehartford",
    "query_name": "ehartford/WizardLM-13B-Uncensored",
    "score": 48.48,
    "likes": 433.0,
    "link": "https://huggingface.co/ehartford/WizardLM-13B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "medalpaca-7b",
    "author": "medalpaca",
    "query_name": "medalpaca/medalpaca-7b",
    "score": 48.45,
    "likes": 30.0,
    "link": "https://huggingface.co/medalpaca/medalpaca-7b",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7B-chemical",
    "author": "FelixChao",
    "query_name": "FelixChao/vicuna-7B-chemical",
    "score": 48.42,
    "likes": 0.0,
    "link": "https://huggingface.co/FelixChao/vicuna-7B-chemical",
    "still_on_hub": true
  },
  {
    "name": "airoboros-7b-gpt4-1.4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-7b-gpt4-1.4",
    "score": 48.4,
    "likes": 8.0,
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.4",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-7b-gpt4-2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-7b-gpt4-2.0",
    "score": 48.38,
    "likes": 8.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-gpt4-2.0",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-instruct",
    "author": "AlpinDale",
    "query_name": "AlpinDale/pygmalion-instruct",
    "score": 48.37,
    "likes": 5.0,
    "link": "https://huggingface.co/AlpinDale/pygmalion-instruct",
    "still_on_hub": true
  },
  {
    "name": "AlpacaGPT4-7B-elina",
    "author": "LLMs",
    "query_name": "LLMs/AlpacaGPT4-7B-elina",
    "score": 48.35,
    "likes": 5.0,
    "link": "https://huggingface.co/LLMs/AlpacaGPT4-7B-elina",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13b-OpenAssistant-Uncensored",
    "author": "Monero",
    "query_name": "Monero/WizardLM-13b-OpenAssistant-Uncensored",
    "score": 48.32,
    "likes": 5.0,
    "link": "https://huggingface.co/Monero/WizardLM-13b-OpenAssistant-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "Mist_LLaMA-2-7B-1024_V3",
    "author": "Juniplayground",
    "query_name": "Juniplayground/Mist_LLaMA-2-7B-1024_V3",
    "score": 48.31,
    "likes": 0.0,
    "link": "https://huggingface.co/Juniplayground/Mist_LLaMA-2-7B-1024_V3",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-7B-Uncensored-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/Wizard-Vicuna-7B-Uncensored-HF",
    "score": 48.27,
    "likes": 19.0,
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-HF",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-7B-Uncensored",
    "author": "ehartford",
    "query_name": "ehartford/Wizard-Vicuna-7B-Uncensored",
    "score": 48.27,
    "likes": 63.0,
    "link": "https://huggingface.co/ehartford/Wizard-Vicuna-7B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "NexusRaven-V2-13B",
    "author": "Nexusflow",
    "query_name": "Nexusflow/NexusRaven-V2-13B",
    "score": 48.21,
    "likes": 180.0,
    "link": "https://huggingface.co/Nexusflow/NexusRaven-V2-13B",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-lora-mctaco",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-mctaco",
    "score": 48.02,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco",
    "still_on_hub": true
  },
  {
    "name": "OpenLlama13B-Guanaco",
    "author": "titan087",
    "query_name": "titan087/OpenLlama13B-Guanaco",
    "score": 47.99,
    "likes": 1.0,
    "link": "https://huggingface.co/titan087/OpenLlama13B-Guanaco",
    "still_on_hub": true
  },
  {
    "name": "longchat-7b-v1.5-32k",
    "author": "lmsys",
    "query_name": "lmsys/longchat-7b-v1.5-32k",
    "score": 47.95,
    "likes": 44.0,
    "link": "https://huggingface.co/lmsys/longchat-7b-v1.5-32k",
    "still_on_hub": true
  },
  {
    "name": "airoboros-l2-7b-gpt4-m2.0",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-l2-7b-gpt4-m2.0",
    "score": 47.95,
    "likes": 9.0,
    "link": "https://huggingface.co/jondurbin/airoboros-l2-7b-gpt4-m2.0",
    "still_on_hub": true
  },
  {
    "name": "Stable-Vicuna-13B",
    "author": "LLMs",
    "query_name": "LLMs/Stable-Vicuna-13B",
    "score": 47.95,
    "likes": 5.0,
    "link": "https://huggingface.co/LLMs/Stable-Vicuna-13B",
    "still_on_hub": true
  },
  {
    "name": "tigerbot-7b-base",
    "author": "TigerResearch",
    "query_name": "TigerResearch/tigerbot-7b-base",
    "score": 47.93,
    "likes": 0.0,
    "link": "https://huggingface.co/TigerResearch/tigerbot-7b-base",
    "still_on_hub": true
  },
  {
    "name": "openllama-7b-icl",
    "author": "itsliupeng",
    "query_name": "itsliupeng/openllama-7b-icl",
    "score": 47.93,
    "likes": 0.0,
    "link": "https://huggingface.co/itsliupeng/openllama-7b-icl",
    "still_on_hub": true
  },
  {
    "name": "llama-2-7b-chat-hf-phr_mental_health-2048",
    "author": "vibhorag101",
    "query_name": "vibhorag101/llama-2-7b-chat-hf-phr_mental_health-2048",
    "score": 47.92,
    "likes": 0.0,
    "link": "https://huggingface.co/vibhorag101/llama-2-7b-chat-hf-phr_mental_health-2048",
    "still_on_hub": true
  },
  {
    "name": "llama_7b_qlora_pds-eval",
    "author": "DevaMalla",
    "query_name": "DevaMalla/llama_7b_qlora_pds-eval",
    "score": 47.9,
    "likes": 0.0,
    "link": "https://huggingface.co/DevaMalla/llama_7b_qlora_pds-eval",
    "still_on_hub": false
  },
  {
    "name": "Uncensored-Frank-7B",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/Uncensored-Frank-7B",
    "score": 47.9,
    "likes": 3.0,
    "link": "https://huggingface.co/ajibawa-2023/Uncensored-Frank-7B",
    "still_on_hub": true
  },
  {
    "name": "vicuna-class-shishya-ac-hal-7b-ep3",
    "author": "luffycodes",
    "query_name": "luffycodes/vicuna-class-shishya-ac-hal-7b-ep3",
    "score": 47.89,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/vicuna-class-shishya-ac-hal-7b-ep3",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-chat-hf-flan2022-1.2M",
    "author": "synapsoft",
    "query_name": "synapsoft/Llama-2-7b-chat-hf-flan2022-1.2M",
    "score": 47.89,
    "likes": 1.0,
    "link": "https://huggingface.co/synapsoft/Llama-2-7b-chat-hf-flan2022-1.2M",
    "still_on_hub": true
  },
  {
    "name": "ALMA-7B-Ja-V2",
    "author": "webbigdata",
    "query_name": "webbigdata/ALMA-7B-Ja-V2",
    "score": 47.85,
    "likes": 6.0,
    "link": "https://huggingface.co/webbigdata/ALMA-7B-Ja-V2",
    "still_on_hub": true
  },
  {
    "name": "goims",
    "author": "golaxy",
    "query_name": "golaxy/goims",
    "score": 47.8,
    "likes": 0.0,
    "link": "https://huggingface.co/golaxy/goims",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b-8k-chat",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-7b-8k-chat",
    "score": 47.78,
    "likes": 26.0,
    "link": "https://huggingface.co/mosaicml/mpt-7b-8k-chat",
    "still_on_hub": true
  },
  {
    "name": "vigogne-7b-instruct",
    "author": "bofenghuang",
    "query_name": "bofenghuang/vigogne-7b-instruct",
    "score": 47.76,
    "likes": 21.0,
    "link": "https://huggingface.co/bofenghuang/vigogne-7b-instruct",
    "still_on_hub": true
  },
  {
    "name": "KoreanLM-hf",
    "author": "quantumaikr",
    "query_name": "quantumaikr/KoreanLM-hf",
    "score": 47.73,
    "likes": 1.0,
    "link": "https://huggingface.co/quantumaikr/KoreanLM-hf",
    "still_on_hub": true
  },
  {
    "name": "leo-hessianai-7b",
    "author": "LeoLM",
    "query_name": "LeoLM/leo-hessianai-7b",
    "score": 47.72,
    "likes": 22.0,
    "link": "https://huggingface.co/LeoLM/leo-hessianai-7b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-7b-gpt4",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-7b-gpt4",
    "score": 47.7,
    "likes": 4.0,
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4",
    "still_on_hub": true
  },
  {
    "name": "airoboros-7b-gpt4-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/airoboros-7b-gpt4-fp16",
    "score": 47.7,
    "likes": 3.0,
    "link": "https://huggingface.co/TheBloke/airoboros-7b-gpt4-fp16",
    "still_on_hub": true
  },
  {
    "name": "phi-1_5",
    "author": "microsoft",
    "query_name": "microsoft/phi-1_5",
    "score": 47.69,
    "likes": 916.0,
    "link": "https://huggingface.co/microsoft/phi-1_5",
    "still_on_hub": true
  },
  {
    "name": "ELYZA-japanese-Llama-2-7b-fast",
    "author": "elyza",
    "query_name": "elyza/ELYZA-japanese-Llama-2-7b-fast",
    "score": 47.67,
    "likes": 15.0,
    "link": "https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-fast",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v2_ger_7b",
    "author": "jphme",
    "query_name": "jphme/orca_mini_v2_ger_7b",
    "score": 47.65,
    "likes": 8.0,
    "link": "https://huggingface.co/jphme/orca_mini_v2_ger_7b",
    "still_on_hub": true
  },
  {
    "name": "openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
    "author": "openthaigpt",
    "query_name": "openthaigpt/openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
    "score": 47.65,
    "likes": 1.0,
    "link": "https://huggingface.co/openthaigpt/openthaigpt-1.0.0-alpha-7b-chat-ckpt-hf",
    "still_on_hub": true
  },
  {
    "name": "vicuna-chinese-replication-v1.1",
    "author": "keyfan",
    "query_name": "keyfan/vicuna-chinese-replication-v1.1",
    "score": 47.65,
    "likes": 4.0,
    "link": "https://huggingface.co/keyfan/vicuna-chinese-replication-v1.1",
    "still_on_hub": true
  },
  {
    "name": "gowizardlm",
    "author": "golaxy",
    "query_name": "golaxy/gowizardlm",
    "score": 47.64,
    "likes": 0.0,
    "link": "https://huggingface.co/golaxy/gowizardlm",
    "still_on_hub": true
  },
  {
    "name": "MiniMerlin-3B",
    "author": "teilomillet",
    "query_name": "teilomillet/MiniMerlin-3B",
    "score": 47.63,
    "likes": 0.0,
    "link": "https://huggingface.co/teilomillet/MiniMerlin-3B",
    "still_on_hub": true
  },
  {
    "name": "baize-healthcare-lora-7B",
    "author": "project-baize",
    "query_name": "project-baize/baize-healthcare-lora-7B",
    "score": 47.62,
    "likes": 16.0,
    "link": "https://huggingface.co/project-baize/baize-healthcare-lora-7B",
    "still_on_hub": false
  },
  {
    "name": "starcoderplus",
    "author": "bigcode",
    "query_name": "bigcode/starcoderplus",
    "score": 47.61,
    "likes": 181.0,
    "link": "https://huggingface.co/bigcode/starcoderplus",
    "still_on_hub": false
  },
  {
    "name": "metharme-7b",
    "author": "Neko-Institute-of-Science",
    "query_name": "Neko-Institute-of-Science/metharme-7b",
    "score": 47.48,
    "likes": 12.0,
    "link": "https://huggingface.co/Neko-Institute-of-Science/metharme-7b",
    "still_on_hub": true
  },
  {
    "name": "llama_7b_qlora_cds",
    "author": "DevaMalla",
    "query_name": "DevaMalla/llama_7b_qlora_cds",
    "score": 47.43,
    "likes": 0.0,
    "link": "https://huggingface.co/DevaMalla/llama_7b_qlora_cds",
    "still_on_hub": false
  },
  {
    "name": "effi-7b",
    "author": "aiplanet",
    "query_name": "aiplanet/effi-7b",
    "score": 47.42,
    "likes": 2.0,
    "link": "https://huggingface.co/aiplanet/effi-7b",
    "still_on_hub": false
  },
  {
    "name": "airoboros-7b-gpt4-1.2",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-7b-gpt4-1.2",
    "score": 47.42,
    "likes": 28.0,
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.2",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_v2_7b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_v2_7b",
    "score": 47.41,
    "likes": 34.0,
    "link": "https://huggingface.co/psmathur/orca_mini_v2_7b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-7b",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-7b",
    "score": 47.4,
    "likes": 14.0,
    "link": "https://huggingface.co/jondurbin/airoboros-7b",
    "still_on_hub": true
  },
  {
    "name": "vicuna-shishya-7b-ep3-v1",
    "author": "luffycodes",
    "query_name": "luffycodes/vicuna-shishya-7b-ep3-v1",
    "score": 47.4,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/vicuna-shishya-7b-ep3-v1",
    "still_on_hub": true
  },
  {
    "name": "CAlign-alpaca-7b",
    "author": "jxhong",
    "query_name": "jxhong/CAlign-alpaca-7b",
    "score": 47.39,
    "likes": 0.0,
    "link": "https://huggingface.co/jxhong/CAlign-alpaca-7b",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b-8k-instruct",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-7b-8k-instruct",
    "score": 47.37,
    "likes": 23.0,
    "link": "https://huggingface.co/mosaicml/mpt-7b-8k-instruct",
    "still_on_hub": true
  },
  {
    "name": "guanaco-7B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/guanaco-7B-HF",
    "score": 47.34,
    "likes": 8.0,
    "link": "https://huggingface.co/TheBloke/guanaco-7B-HF",
    "still_on_hub": true
  },
  {
    "name": "open_llama_13b",
    "author": "openlm-research",
    "query_name": "openlm-research/open_llama_13b",
    "score": 47.26,
    "likes": 434.0,
    "link": "https://huggingface.co/openlm-research/open_llama_13b",
    "still_on_hub": true
  },
  {
    "name": "Mixtral-8x7B-MoE-RP-Story",
    "author": "Undi95",
    "query_name": "Undi95/Mixtral-8x7B-MoE-RP-Story",
    "score": 47.23,
    "likes": 11.0,
    "link": "https://huggingface.co/Undi95/Mixtral-8x7B-MoE-RP-Story",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama13B-Finetune-v1",
    "author": "FelixChao",
    "query_name": "FelixChao/CodeLlama13B-Finetune-v1",
    "score": 47.19,
    "likes": 0.0,
    "link": "https://huggingface.co/FelixChao/CodeLlama13B-Finetune-v1",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b-8k-instruct",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-7b-8k-instruct",
    "score": 47.18,
    "likes": 23.0,
    "link": "https://huggingface.co/mosaicml/mpt-7b-8k-instruct",
    "still_on_hub": true
  },
  {
    "name": "Asclepius-Llama2-7B",
    "author": "starmpcc",
    "query_name": "starmpcc/Asclepius-Llama2-7B",
    "score": 47.15,
    "likes": 1.0,
    "link": "https://huggingface.co/starmpcc/Asclepius-Llama2-7B",
    "still_on_hub": true
  },
  {
    "name": "youri-7b",
    "author": "rinna",
    "query_name": "rinna/youri-7b",
    "score": 47.11,
    "likes": 15.0,
    "link": "https://huggingface.co/rinna/youri-7b",
    "still_on_hub": true
  },
  {
    "name": "openllama-7b-base",
    "author": "itsliupeng",
    "query_name": "itsliupeng/openllama-7b-base",
    "score": 47.09,
    "likes": 0.0,
    "link": "https://huggingface.co/itsliupeng/openllama-7b-base",
    "still_on_hub": true
  },
  {
    "name": "LLaMA-2-7B-32K",
    "author": "togethercomputer",
    "query_name": "togethercomputer/LLaMA-2-7B-32K",
    "score": 47.07,
    "likes": 465.0,
    "link": "https://huggingface.co/togethercomputer/LLaMA-2-7B-32K",
    "still_on_hub": true
  },
  {
    "name": "airoboros-gpt-3.5-turbo-100k-7b",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-gpt-3.5-turbo-100k-7b",
    "score": 47.05,
    "likes": 11.0,
    "link": "https://huggingface.co/jondurbin/airoboros-gpt-3.5-turbo-100k-7b",
    "still_on_hub": true
  },
  {
    "name": "PygmalionCoT-7b",
    "author": "notstoic",
    "query_name": "notstoic/PygmalionCoT-7b",
    "score": 47.0,
    "likes": 15.0,
    "link": "https://huggingface.co/notstoic/PygmalionCoT-7b",
    "still_on_hub": true
  },
  {
    "name": "chatdoctor",
    "author": "mncai",
    "query_name": "mncai/chatdoctor",
    "score": 46.95,
    "likes": 8.0,
    "link": "https://huggingface.co/mncai/chatdoctor",
    "still_on_hub": true
  },
  {
    "name": "llama7b-wizardlm-unfiltered",
    "author": "ausboss",
    "query_name": "ausboss/llama7b-wizardlm-unfiltered",
    "score": 46.94,
    "likes": 5.0,
    "link": "https://huggingface.co/ausboss/llama7b-wizardlm-unfiltered",
    "still_on_hub": true
  },
  {
    "name": "dolphin-llama2-7b",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-llama2-7b",
    "score": 46.94,
    "likes": 64.0,
    "link": "https://huggingface.co/ehartford/dolphin-llama2-7b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-7b-gpt4-1.3",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-7b-gpt4-1.3",
    "score": 46.91,
    "likes": 0.0,
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.3",
    "still_on_hub": true
  },
  {
    "name": "llama_7b_lora",
    "author": "DevaMalla",
    "query_name": "DevaMalla/llama_7b_lora",
    "score": 46.77,
    "likes": 0.0,
    "link": "https://huggingface.co/DevaMalla/llama_7b_lora",
    "still_on_hub": false
  },
  {
    "name": "baize-v2-7b",
    "author": "project-baize",
    "query_name": "project-baize/baize-v2-7b",
    "score": 46.72,
    "likes": 23.0,
    "link": "https://huggingface.co/project-baize/baize-v2-7b",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-dolphin-orca-platypus-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-dolphin-orca-platypus-13b",
    "score": 46.7,
    "likes": 2.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-dolphin-orca-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-platypus-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-platypus-13b",
    "score": 46.68,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "dolphin-2.2-yi-34b-200k",
    "author": "ehartford",
    "query_name": "ehartford/dolphin-2.2-yi-34b-200k",
    "score": 46.67,
    "likes": 1.0,
    "link": "https://huggingface.co/ehartford/dolphin-2.2-yi-34b-200k",
    "still_on_hub": true
  },
  {
    "name": "gogpt2-7b",
    "author": "golaxy",
    "query_name": "golaxy/gogpt2-7b",
    "score": 46.65,
    "likes": 5.0,
    "link": "https://huggingface.co/golaxy/gogpt2-7b",
    "still_on_hub": true
  },
  {
    "name": "OpenHathi-7B-Hi-v0.1-Base",
    "author": "sarvamai",
    "query_name": "sarvamai/OpenHathi-7B-Hi-v0.1-Base",
    "score": 46.64,
    "likes": 15.0,
    "link": "https://huggingface.co/sarvamai/OpenHathi-7B-Hi-v0.1-Base",
    "still_on_hub": true
  },
  {
    "name": "llama_7b_qlora",
    "author": "DevaMalla",
    "query_name": "DevaMalla/llama_7b_qlora",
    "score": 46.61,
    "likes": 0.0,
    "link": "https://huggingface.co/DevaMalla/llama_7b_qlora",
    "still_on_hub": false
  },
  {
    "name": "stablelm-3b-4e1t",
    "author": "stabilityai",
    "query_name": "stabilityai/stablelm-3b-4e1t",
    "score": 46.58,
    "likes": 192.0,
    "link": "https://huggingface.co/stabilityai/stablelm-3b-4e1t",
    "still_on_hub": false
  },
  {
    "name": "alpaca-native",
    "author": "chavinlo",
    "query_name": "chavinlo/alpaca-native",
    "score": 46.58,
    "likes": 249.0,
    "link": "https://huggingface.co/chavinlo/alpaca-native",
    "still_on_hub": true
  },
  {
    "name": "gogpt2-13b",
    "author": "golaxy",
    "query_name": "golaxy/gogpt2-13b",
    "score": 46.55,
    "likes": 4.0,
    "link": "https://huggingface.co/golaxy/gogpt2-13b",
    "still_on_hub": true
  },
  {
    "name": "llama7b_alpaca_1gpu_bf16",
    "author": "DevaMalla",
    "query_name": "DevaMalla/llama7b_alpaca_1gpu_bf16",
    "score": 46.49,
    "likes": 0.0,
    "link": "https://huggingface.co/DevaMalla/llama7b_alpaca_1gpu_bf16",
    "still_on_hub": true
  },
  {
    "name": "Pygmalion_AlpacaLora-7b",
    "author": "TehVenom",
    "query_name": "TehVenom/Pygmalion_AlpacaLora-7b",
    "score": 46.49,
    "likes": 3.0,
    "link": "https://huggingface.co/TehVenom/Pygmalion_AlpacaLora-7b",
    "still_on_hub": true
  },
  {
    "name": "nart-100k-7b",
    "author": "jerryjalapeno",
    "query_name": "jerryjalapeno/nart-100k-7b",
    "score": 46.39,
    "likes": 13.0,
    "link": "https://huggingface.co/jerryjalapeno/nart-100k-7b",
    "still_on_hub": true
  },
  {
    "name": "gogpt-7b",
    "author": "golaxy",
    "query_name": "golaxy/gogpt-7b",
    "score": 46.38,
    "likes": 2.0,
    "link": "https://huggingface.co/golaxy/gogpt-7b",
    "still_on_hub": true
  },
  {
    "name": "llama-7b",
    "author": "huggyllama",
    "query_name": "huggyllama/llama-7b",
    "score": 46.37,
    "likes": 226.0,
    "link": "https://huggingface.co/huggyllama/llama-7b",
    "still_on_hub": true
  },
  {
    "name": "airoboros-7b-gpt4-1.4.1-qlora",
    "author": "jondurbin",
    "query_name": "jondurbin/airoboros-7b-gpt4-1.4.1-qlora",
    "score": 46.34,
    "likes": 1.0,
    "link": "https://huggingface.co/jondurbin/airoboros-7b-gpt4-1.4.1-qlora",
    "still_on_hub": true
  },
  {
    "name": "yayi-13b-llama2",
    "author": "wenge-research",
    "query_name": "wenge-research/yayi-13b-llama2",
    "score": 46.32,
    "likes": 6.0,
    "link": "https://huggingface.co/wenge-research/yayi-13b-llama2",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-dolphin-orca-platypus-13b",
    "author": "speechlessai",
    "query_name": "speechlessai/speechless-codellama-dolphin-orca-platypus-13b",
    "score": 46.32,
    "likes": 0.0,
    "link": "https://huggingface.co/speechlessai/speechless-codellama-dolphin-orca-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-orca-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-orca-13b",
    "score": 46.28,
    "likes": 2.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-13b",
    "still_on_hub": true
  },
  {
    "name": "open_llama_7b_v2_med_instruct",
    "author": "yhyhy3",
    "query_name": "yhyhy3/open_llama_7b_v2_med_instruct",
    "score": 46.24,
    "likes": 3.0,
    "link": "https://huggingface.co/yhyhy3/open_llama_7b_v2_med_instruct",
    "still_on_hub": true
  },
  {
    "name": "firefly-llama2-7b-pretrain",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-llama2-7b-pretrain",
    "score": 46.18,
    "likes": 0.0,
    "link": "https://huggingface.co/YeungNLP/firefly-llama2-7b-pretrain",
    "still_on_hub": true
  },
  {
    "name": "stablelm-base-alpha-7b-v2",
    "author": "stabilityai",
    "query_name": "stabilityai/stablelm-base-alpha-7b-v2",
    "score": 46.18,
    "likes": 36.0,
    "link": "https://huggingface.co/stabilityai/stablelm-base-alpha-7b-v2",
    "still_on_hub": true
  },
  {
    "name": "carl-7b",
    "author": "ajibawa-2023",
    "query_name": "ajibawa-2023/carl-7b",
    "score": 46.16,
    "likes": 2.0,
    "link": "https://huggingface.co/ajibawa-2023/carl-7b",
    "still_on_hub": true
  },
  {
    "name": "vicuna-class-shishya-7b-ep3",
    "author": "luffycodes",
    "query_name": "luffycodes/vicuna-class-shishya-7b-ep3",
    "score": 46.14,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/vicuna-class-shishya-7b-ep3",
    "still_on_hub": true
  },
  {
    "name": "bloom",
    "author": "bigscience",
    "query_name": "bigscience/bloom",
    "score": 46.07,
    "likes": 461.0,
    "link": "https://huggingface.co/bigscience/bloom",
    "still_on_hub": true
  },
  {
    "name": "baichuan-vicuna-chinese-7b",
    "author": "fireballoon",
    "query_name": "fireballoon/baichuan-vicuna-chinese-7b",
    "score": 46.06,
    "likes": 61.0,
    "link": "https://huggingface.co/fireballoon/baichuan-vicuna-chinese-7b",
    "still_on_hub": true
  },
  {
    "name": "test-custom-llama",
    "author": "illuin",
    "query_name": "illuin/test-custom-llama",
    "score": 46.05,
    "likes": 0.0,
    "link": "https://huggingface.co/illuin/test-custom-llama",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-7b",
    "author": "Neko-Institute-of-Science",
    "query_name": "Neko-Institute-of-Science/pygmalion-7b",
    "score": 46.04,
    "likes": 38.0,
    "link": "https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-lora-mctaco-modified2",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified2",
    "score": 46.03,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco-modified2",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-13b-Instruct-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-13b-Instruct-hf",
    "score": 45.82,
    "likes": 66.0,
    "link": "https://huggingface.co/codellama/CodeLlama-13b-Instruct-hf",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-13B-Instruct-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/CodeLlama-13B-Instruct-fp16",
    "score": 45.82,
    "likes": 28.0,
    "link": "https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-fp16",
    "still_on_hub": true
  },
  {
    "name": "Planner-7B-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/Planner-7B-fp16",
    "score": 45.65,
    "likes": 1.0,
    "link": "https://huggingface.co/TheBloke/Planner-7B-fp16",
    "still_on_hub": true
  },
  {
    "name": "llama-7b",
    "author": "huggingface",
    "query_name": "huggingface/llama-7b",
    "score": 45.65,
    "likes": 0.0,
    "link": "https://huggingface.co/huggingface/llama-7b",
    "still_on_hub": false
  },
  {
    "name": "speechless-codellama-platypus-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-platypus-13b",
    "score": 45.64,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "llama-base-7b",
    "author": "DevaMalla",
    "query_name": "DevaMalla/llama-base-7b",
    "score": 45.62,
    "likes": 0.0,
    "link": "https://huggingface.co/DevaMalla/llama-base-7b",
    "still_on_hub": true
  },
  {
    "name": "PandaLM-Alpaca-7B-v1",
    "author": "WeOpenML",
    "query_name": "WeOpenML/PandaLM-Alpaca-7B-v1",
    "score": 45.59,
    "likes": 0.0,
    "link": "https://huggingface.co/WeOpenML/PandaLM-Alpaca-7B-v1",
    "still_on_hub": true
  },
  {
    "name": "WizardCoder-Python-13B-LoRa",
    "author": "yeontaek",
    "query_name": "yeontaek/WizardCoder-Python-13B-LoRa",
    "score": 45.56,
    "likes": 0.0,
    "link": "https://huggingface.co/yeontaek/WizardCoder-Python-13B-LoRa",
    "still_on_hub": true
  },
  {
    "name": "tamil-llama-7b-instruct-v0.1",
    "author": "abhinand",
    "query_name": "abhinand/tamil-llama-7b-instruct-v0.1",
    "score": 45.52,
    "likes": 1.0,
    "link": "https://huggingface.co/abhinand/tamil-llama-7b-instruct-v0.1",
    "still_on_hub": true
  },
  {
    "name": "Chinese-LLaMA-2-7B-hf",
    "author": "Linly-AI",
    "query_name": "Linly-AI/Chinese-LLaMA-2-7B-hf",
    "score": 45.44,
    "likes": 15.0,
    "link": "https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf",
    "still_on_hub": true
  },
  {
    "name": "chinese-llama-plus-13b-hf",
    "author": "shibing624",
    "query_name": "shibing624/chinese-llama-plus-13b-hf",
    "score": 45.39,
    "likes": 17.0,
    "link": "https://huggingface.co/shibing624/chinese-llama-plus-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b-chat",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-7b-chat",
    "score": 45.39,
    "likes": 485.0,
    "link": "https://huggingface.co/mosaicml/mpt-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-lora-mctaco-modified1",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified1",
    "score": 45.38,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco-modified1",
    "still_on_hub": true
  },
  {
    "name": "llama-2-ko-7b",
    "author": "beomi",
    "query_name": "beomi/llama-2-ko-7b",
    "score": 45.32,
    "likes": 85.0,
    "link": "https://huggingface.co/beomi/llama-2-ko-7b",
    "still_on_hub": true
  },
  {
    "name": "ALMA-7B",
    "author": "haoranxu",
    "query_name": "haoranxu/ALMA-7B",
    "score": 45.32,
    "likes": 12.0,
    "link": "https://huggingface.co/haoranxu/ALMA-7B",
    "still_on_hub": true
  },
  {
    "name": "MiniChat-3B",
    "author": "GeneZC",
    "query_name": "GeneZC/MiniChat-3B",
    "score": 45.31,
    "likes": 3.0,
    "link": "https://huggingface.co/GeneZC/MiniChat-3B",
    "still_on_hub": true
  },
  {
    "name": "giraffe-7b",
    "author": "ashercn97",
    "query_name": "ashercn97/giraffe-7b",
    "score": 45.29,
    "likes": 0.0,
    "link": "https://huggingface.co/ashercn97/giraffe-7b",
    "still_on_hub": true
  },
  {
    "name": "opt-iml-max-30b",
    "author": "facebook",
    "query_name": "facebook/opt-iml-max-30b",
    "score": 45.28,
    "likes": 34.0,
    "link": "https://huggingface.co/facebook/opt-iml-max-30b",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-openllama-7b-v12-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-openllama-7b-v12-bf16",
    "score": 45.28,
    "likes": 1.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-openllama-7b-v12-bf16",
    "still_on_hub": true
  },
  {
    "name": "Orca-2-13B-16k",
    "author": "NurtureAI",
    "query_name": "NurtureAI/Orca-2-13B-16k",
    "score": 45.22,
    "likes": 3.0,
    "link": "https://huggingface.co/NurtureAI/Orca-2-13B-16k",
    "still_on_hub": true
  },
  {
    "name": "llama-shishya-7b-ep3-v1",
    "author": "luffycodes",
    "query_name": "luffycodes/llama-shishya-7b-ep3-v1",
    "score": 45.19,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/llama-shishya-7b-ep3-v1",
    "still_on_hub": true
  },
  {
    "name": "ennodata-7b",
    "author": "Enno-Ai",
    "query_name": "Enno-Ai/ennodata-7b",
    "score": 45.13,
    "likes": 0.0,
    "link": "https://huggingface.co/Enno-Ai/ennodata-7b",
    "still_on_hub": true
  },
  {
    "name": "guanaco-unchained-llama-2-7b",
    "author": "jlevin",
    "query_name": "jlevin/guanaco-unchained-llama-2-7b",
    "score": 45.11,
    "likes": 0.0,
    "link": "https://huggingface.co/jlevin/guanaco-unchained-llama-2-7b",
    "still_on_hub": false
  },
  {
    "name": "speechless-coding-7b-16k-tora",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-coding-7b-16k-tora",
    "score": 45.1,
    "likes": 1.0,
    "link": "https://huggingface.co/uukuguy/speechless-coding-7b-16k-tora",
    "still_on_hub": true
  },
  {
    "name": "vicuna-7b-v1.5-lora-mctaco-modified4",
    "author": "Charlie911",
    "query_name": "Charlie911/vicuna-7b-v1.5-lora-mctaco-modified4",
    "score": 45.1,
    "likes": 0.0,
    "link": "https://huggingface.co/Charlie911/vicuna-7b-v1.5-lora-mctaco-modified4",
    "still_on_hub": true
  },
  {
    "name": "speechless-coding-7b-16k-tora",
    "author": "speechlessai",
    "query_name": "speechlessai/speechless-coding-7b-16k-tora",
    "score": 45.05,
    "likes": 0.0,
    "link": "https://huggingface.co/speechlessai/speechless-coding-7b-16k-tora",
    "still_on_hub": true
  },
  {
    "name": "Qwen-VL-LLaMAfied-7B-Chat",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/Qwen-VL-LLaMAfied-7B-Chat",
    "score": 45.0,
    "likes": 0.0,
    "link": "https://huggingface.co/JosephusCheung/Qwen-VL-LLaMAfied-7B-Chat",
    "still_on_hub": true
  },
  {
    "name": "llama-7b-logicot",
    "author": "csitfun",
    "query_name": "csitfun/llama-7b-logicot",
    "score": 44.95,
    "likes": 2.0,
    "link": "https://huggingface.co/csitfun/llama-7b-logicot",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-7B-Uncensored",
    "author": "ehartford",
    "query_name": "ehartford/WizardLM-7B-Uncensored",
    "score": 44.92,
    "likes": 339.0,
    "link": "https://huggingface.co/ehartford/WizardLM-7B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "codellama-13b-oasst-sft-v10",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/codellama-13b-oasst-sft-v10",
    "score": 44.85,
    "likes": 42.0,
    "link": "https://huggingface.co/OpenAssistant/codellama-13b-oasst-sft-v10",
    "still_on_hub": true
  },
  {
    "name": "CodeLLaMA-chat-13b-Chinese",
    "author": "shareAI",
    "query_name": "shareAI/CodeLLaMA-chat-13b-Chinese",
    "score": 44.84,
    "likes": 13.0,
    "link": "https://huggingface.co/shareAI/CodeLLaMA-chat-13b-Chinese",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b-instruct",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-7b-instruct",
    "score": 44.83,
    "likes": 437.0,
    "link": "https://huggingface.co/mosaicml/mpt-7b-instruct",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-orca-13b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-orca-13b",
    "score": 44.83,
    "likes": 2.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-13b",
    "still_on_hub": true
  },
  {
    "name": "chinese-alpaca-plus-7b-hf",
    "author": "shibing624",
    "query_name": "shibing624/chinese-alpaca-plus-7b-hf",
    "score": 44.77,
    "likes": 46.0,
    "link": "https://huggingface.co/shibing624/chinese-alpaca-plus-7b-hf",
    "still_on_hub": true
  },
  {
    "name": "palmyra-med-20b",
    "author": "Writer",
    "query_name": "Writer/palmyra-med-20b",
    "score": 44.71,
    "likes": 14.0,
    "link": "https://huggingface.co/Writer/palmyra-med-20b",
    "still_on_hub": true
  },
  {
    "name": "Poro-34B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Poro-34B-GPTQ",
    "score": 44.67,
    "likes": 2.0,
    "link": "https://huggingface.co/TheBloke/Poro-34B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "tamil-llama-7b-base-v0.1",
    "author": "abhinand",
    "query_name": "abhinand/tamil-llama-7b-base-v0.1",
    "score": 44.52,
    "likes": 2.0,
    "link": "https://huggingface.co/abhinand/tamil-llama-7b-base-v0.1",
    "still_on_hub": true
  },
  {
    "name": "Project-Baize-v2-7B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Project-Baize-v2-7B-GPTQ",
    "score": 44.5,
    "likes": 4.0,
    "link": "https://huggingface.co/TheBloke/Project-Baize-v2-7B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "falcon_7b_norobots",
    "author": "qblocks",
    "query_name": "qblocks/falcon_7b_norobots",
    "score": 44.46,
    "likes": 0.0,
    "link": "https://huggingface.co/qblocks/falcon_7b_norobots",
    "still_on_hub": false
  },
  {
    "name": "Alpaca-7B-v1",
    "author": "WeOpenML",
    "query_name": "WeOpenML/Alpaca-7B-v1",
    "score": 44.41,
    "likes": 0.0,
    "link": "https://huggingface.co/WeOpenML/Alpaca-7B-v1",
    "still_on_hub": true
  },
  {
    "name": "falcon_7b_norobots",
    "author": "qblocks",
    "query_name": "qblocks/falcon_7b_norobots",
    "score": 44.4,
    "likes": 0.0,
    "link": "https://huggingface.co/qblocks/falcon_7b_norobots",
    "still_on_hub": false
  },
  {
    "name": "llama-shishya-7b-ep3-v2",
    "author": "luffycodes",
    "query_name": "luffycodes/llama-shishya-7b-ep3-v2",
    "score": 44.33,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/llama-shishya-7b-ep3-v2",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-34b-Instruct-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-34b-Instruct-hf",
    "score": 44.33,
    "likes": 154.0,
    "link": "https://huggingface.co/codellama/CodeLlama-34b-Instruct-hf",
    "still_on_hub": true
  },
  {
    "name": "koala-7B-HF",
    "author": "TheBloke",
    "query_name": "TheBloke/koala-7B-HF",
    "score": 44.29,
    "likes": 18.0,
    "link": "https://huggingface.co/TheBloke/koala-7B-HF",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b",
    "author": "anas-awadalla",
    "query_name": "anas-awadalla/mpt-7b",
    "score": 44.28,
    "likes": 1.0,
    "link": "https://huggingface.co/anas-awadalla/mpt-7b",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-7b",
    "score": 44.28,
    "likes": 1083.0,
    "link": "https://huggingface.co/mosaicml/mpt-7b",
    "still_on_hub": true
  },
  {
    "name": "open_llama_7b_v2",
    "author": "openlm-research",
    "query_name": "openlm-research/open_llama_7b_v2",
    "score": 44.26,
    "likes": 86.0,
    "link": "https://huggingface.co/openlm-research/open_llama_7b_v2",
    "still_on_hub": true
  },
  {
    "name": "palmyra-20b-chat",
    "author": "Writer",
    "query_name": "Writer/palmyra-20b-chat",
    "score": 44.18,
    "likes": 5.0,
    "link": "https://huggingface.co/Writer/palmyra-20b-chat",
    "still_on_hub": true
  },
  {
    "name": "falcon-7b",
    "author": "tiiuae",
    "query_name": "tiiuae/falcon-7b",
    "score": 44.17,
    "likes": 885.0,
    "link": "https://huggingface.co/tiiuae/falcon-7b",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-airoboros-orca-platypus-13b",
    "author": "speechlessai",
    "query_name": "speechlessai/speechless-codellama-airoboros-orca-platypus-13b",
    "score": 44.1,
    "likes": 0.0,
    "link": "https://huggingface.co/speechlessai/speechless-codellama-airoboros-orca-platypus-13b",
    "still_on_hub": true
  },
  {
    "name": "GPT-JT-6B-v0",
    "author": "togethercomputer",
    "query_name": "togethercomputer/GPT-JT-6B-v0",
    "score": 44.05,
    "likes": 2.0,
    "link": "https://huggingface.co/togethercomputer/GPT-JT-6B-v0",
    "still_on_hub": true
  },
  {
    "name": "llama-class-shishya-7b-ep3",
    "author": "luffycodes",
    "query_name": "luffycodes/llama-class-shishya-7b-ep3",
    "score": 43.88,
    "likes": 0.0,
    "link": "https://huggingface.co/luffycodes/llama-class-shishya-7b-ep3",
    "still_on_hub": true
  },
  {
    "name": "BigTranslate-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/BigTranslate-13B-GPTQ",
    "score": 43.86,
    "likes": 15.0,
    "link": "https://huggingface.co/TheBloke/BigTranslate-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-20b-instruct",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-20b-instruct",
    "score": 43.7,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-20b-instruct",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-hf-flan2022-1.2M",
    "author": "synapsoft",
    "query_name": "synapsoft/Llama-2-7b-hf-flan2022-1.2M",
    "score": 43.68,
    "likes": 1.0,
    "link": "https://huggingface.co/synapsoft/Llama-2-7b-hf-flan2022-1.2M",
    "still_on_hub": true
  },
  {
    "name": "falcon_7b_3epoch_norobots",
    "author": "souvik0306",
    "query_name": "souvik0306/falcon_7b_3epoch_norobots",
    "score": 43.65,
    "likes": 0.0,
    "link": "https://huggingface.co/souvik0306/falcon_7b_3epoch_norobots",
    "still_on_hub": false
  },
  {
    "name": "ko-ref-llama2-13b",
    "author": "hyunseoki",
    "query_name": "hyunseoki/ko-ref-llama2-13b",
    "score": 43.62,
    "likes": 1.0,
    "link": "https://huggingface.co/hyunseoki/ko-ref-llama2-13b",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-40b",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-40b",
    "score": 43.42,
    "likes": 4.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-40b",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-13b-hf",
    "author": "NousResearch",
    "query_name": "NousResearch/CodeLlama-13b-hf",
    "score": 43.35,
    "likes": 0.0,
    "link": "https://huggingface.co/NousResearch/CodeLlama-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-13b-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-13b-hf",
    "score": 43.35,
    "likes": 48.0,
    "link": "https://huggingface.co/codellama/CodeLlama-13b-hf",
    "still_on_hub": true
  },
  {
    "name": "tigerbot-7b-sft",
    "author": "TigerResearch",
    "query_name": "TigerResearch/tigerbot-7b-sft",
    "score": 43.35,
    "likes": 13.0,
    "link": "https://huggingface.co/TigerResearch/tigerbot-7b-sft",
    "still_on_hub": false
  },
  {
    "name": "calm2-7b-chat",
    "author": "cyberagent",
    "query_name": "cyberagent/calm2-7b-chat",
    "score": 43.27,
    "likes": 43.0,
    "link": "https://huggingface.co/cyberagent/calm2-7b-chat",
    "still_on_hub": true
  },
  {
    "name": "falcon-7b-instruct",
    "author": "tiiuae",
    "query_name": "tiiuae/falcon-7b-instruct",
    "score": 43.26,
    "likes": 676.0,
    "link": "https://huggingface.co/tiiuae/falcon-7b-instruct",
    "still_on_hub": true
  },
  {
    "name": "Guanaco",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/Guanaco",
    "score": 43.25,
    "likes": 213.0,
    "link": "https://huggingface.co/JosephusCheung/Guanaco",
    "still_on_hub": true
  },
  {
    "name": "minima-3b-layla-v1",
    "author": "l3utterfly",
    "query_name": "l3utterfly/minima-3b-layla-v1",
    "score": 43.21,
    "likes": 1.0,
    "link": "https://huggingface.co/l3utterfly/minima-3b-layla-v1",
    "still_on_hub": true
  },
  {
    "name": "falcon-7b-instruct",
    "author": "tiiuae",
    "query_name": "tiiuae/falcon-7b-instruct",
    "score": 43.16,
    "likes": 676.0,
    "link": "https://huggingface.co/tiiuae/falcon-7b-instruct",
    "still_on_hub": true
  },
  {
    "name": "chinese-llama-2-7b",
    "author": "ziqingyang",
    "query_name": "ziqingyang/chinese-llama-2-7b",
    "score": 43.14,
    "likes": 64.0,
    "link": "https://huggingface.co/ziqingyang/chinese-llama-2-7b",
    "still_on_hub": true
  },
  {
    "name": "GPT-JT-6B-v1",
    "author": "togethercomputer",
    "query_name": "togethercomputer/GPT-JT-6B-v1",
    "score": 43.13,
    "likes": 302.0,
    "link": "https://huggingface.co/togethercomputer/GPT-JT-6B-v1",
    "still_on_hub": true
  },
  {
    "name": "ex-llm-e1",
    "author": "u-chom",
    "query_name": "u-chom/ex-llm-e1",
    "score": 43.11,
    "likes": 0.0,
    "link": "https://huggingface.co/u-chom/ex-llm-e1",
    "still_on_hub": false
  },
  {
    "name": "FinanceConnect-13B",
    "author": "ceadar-ie",
    "query_name": "ceadar-ie/FinanceConnect-13B",
    "score": 43.06,
    "likes": 0.0,
    "link": "https://huggingface.co/ceadar-ie/FinanceConnect-13B",
    "still_on_hub": true
  },
  {
    "name": "phoenix-inst-chat-7b",
    "author": "FreedomIntelligence",
    "query_name": "FreedomIntelligence/phoenix-inst-chat-7b",
    "score": 43.03,
    "likes": 44.0,
    "link": "https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b",
    "still_on_hub": true
  },
  {
    "name": "GPT-NeoXT-Chat-Base-20B",
    "author": "togethercomputer",
    "query_name": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "score": 43.02,
    "likes": 691.0,
    "link": "https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "still_on_hub": true
  },
  {
    "name": "galpaca-30b",
    "author": "GeorgiaTechResearchInstitute",
    "query_name": "GeorgiaTechResearchInstitute/galpaca-30b",
    "score": 43.0,
    "likes": 55.0,
    "link": "https://huggingface.co/GeorgiaTechResearchInstitute/galpaca-30b",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-34B-Instruct-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/CodeLlama-34B-Instruct-fp16",
    "score": 43.0,
    "likes": 9.0,
    "link": "https://huggingface.co/TheBloke/CodeLlama-34B-Instruct-fp16",
    "still_on_hub": true
  },
  {
    "name": "Anima-7B-100K",
    "author": "lyogavin",
    "query_name": "lyogavin/Anima-7B-100K",
    "score": 42.98,
    "likes": 14.0,
    "link": "https://huggingface.co/lyogavin/Anima-7B-100K",
    "still_on_hub": true
  },
  {
    "name": "InstructPalmyra-20b",
    "author": "Writer",
    "query_name": "Writer/InstructPalmyra-20b",
    "score": 42.91,
    "likes": 36.0,
    "link": "https://huggingface.co/Writer/InstructPalmyra-20b",
    "still_on_hub": true
  },
  {
    "name": "dopeyshearedplats-2.7b-v1",
    "author": "vihangd",
    "query_name": "vihangd/dopeyshearedplats-2.7b-v1",
    "score": 42.9,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/dopeyshearedplats-2.7b-v1",
    "still_on_hub": true
  },
  {
    "name": "gpt-neox-20b-full-precision",
    "author": "dvruette",
    "query_name": "dvruette/gpt-neox-20b-full-precision",
    "score": 42.87,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/gpt-neox-20b-full-precision",
    "still_on_hub": true
  },
  {
    "name": "landmark-attention-llama7b-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/landmark-attention-llama7b-fp16",
    "score": 42.84,
    "likes": 8.0,
    "link": "https://huggingface.co/TheBloke/landmark-attention-llama7b-fp16",
    "still_on_hub": false
  },
  {
    "name": "opt-66b",
    "author": "facebook",
    "query_name": "facebook/opt-66b",
    "score": 42.78,
    "likes": 171.0,
    "link": "https://huggingface.co/facebook/opt-66b",
    "still_on_hub": true
  },
  {
    "name": "open-llama-7b-v2-open-instruct",
    "author": "Vmware",
    "query_name": "Vmware/open-llama-7b-v2-open-instruct",
    "score": 42.75,
    "likes": 25.0,
    "link": "https://huggingface.co/Vmware/open-llama-7b-v2-open-instruct",
    "still_on_hub": true
  },
  {
    "name": "tora-code-13b-v1.0",
    "author": "llm-agents",
    "query_name": "llm-agents/tora-code-13b-v1.0",
    "score": 42.7,
    "likes": 1.0,
    "link": "https://huggingface.co/llm-agents/tora-code-13b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "open-llama-7b-open-instruct",
    "author": "VMware",
    "query_name": "VMware/open-llama-7b-open-instruct",
    "score": 42.59,
    "likes": 25.0,
    "link": "https://huggingface.co/VMware/open-llama-7b-open-instruct",
    "still_on_hub": true
  },
  {
    "name": "codegen-16B-nl",
    "author": "Salesforce",
    "query_name": "Salesforce/codegen-16B-nl",
    "score": 42.59,
    "likes": 17.0,
    "link": "https://huggingface.co/Salesforce/codegen-16B-nl",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-gm-oasst1-en-1024-20b",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-gm-oasst1-en-1024-20b",
    "score": 42.58,
    "likes": 4.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-1024-20b",
    "still_on_hub": true
  },
  {
    "name": "oasst-gpt-neox-20b-1000-steps",
    "author": "dvruette",
    "query_name": "dvruette/oasst-gpt-neox-20b-1000-steps",
    "score": 42.51,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-gpt-neox-20b-1000-steps",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-chat-hf-phr_mental_therapy",
    "author": "vibhorag101",
    "query_name": "vibhorag101/llama-2-13b-chat-hf-phr_mental_therapy",
    "score": 42.5,
    "likes": 0.0,
    "link": "https://huggingface.co/vibhorag101/llama-2-13b-chat-hf-phr_mental_therapy",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-oasst1-512-20b",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-oasst1-512-20b",
    "score": 42.44,
    "likes": 38.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b",
    "still_on_hub": true
  },
  {
    "name": "LL7M",
    "author": "JosephusCheung",
    "query_name": "JosephusCheung/LL7M",
    "score": 42.38,
    "likes": 34.0,
    "link": "https://huggingface.co/JosephusCheung/LL7M",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-7B-Instruct",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-7B-Instruct",
    "score": 42.38,
    "likes": 103.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Instruct-7B-v0.1",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1",
    "score": 42.38,
    "likes": 103.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1",
    "still_on_hub": true
  },
  {
    "name": "open_llama_7b",
    "author": "openlm-research",
    "query_name": "openlm-research/open_llama_7b",
    "score": 42.31,
    "likes": 99.0,
    "link": "https://huggingface.co/openlm-research/open_llama_7b",
    "still_on_hub": true
  },
  {
    "name": "bloomz-7b1-mt-sft-chat",
    "author": "cmarkea",
    "query_name": "cmarkea/bloomz-7b1-mt-sft-chat",
    "score": 42.24,
    "likes": 9.0,
    "link": "https://huggingface.co/cmarkea/bloomz-7b1-mt-sft-chat",
    "still_on_hub": true
  },
  {
    "name": "Galpaca-30b-MiniOrca",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Galpaca-30b-MiniOrca",
    "score": 42.23,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/Galpaca-30b-MiniOrca",
    "still_on_hub": true
  },
  {
    "name": "pythia-12b-sft-v8-7k-steps",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/pythia-12b-sft-v8-7k-steps",
    "score": 42.21,
    "likes": 21.0,
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-7k-steps",
    "still_on_hub": true
  },
  {
    "name": "bloomz-7b1",
    "author": "bigscience",
    "query_name": "bigscience/bloomz-7b1",
    "score": 42.21,
    "likes": 110.0,
    "link": "https://huggingface.co/bigscience/bloomz-7b1",
    "still_on_hub": true
  },
  {
    "name": "open_llama_13b_600bt_preview",
    "author": "klosax",
    "query_name": "klosax/open_llama_13b_600bt_preview",
    "score": 42.21,
    "likes": 0.0,
    "link": "https://huggingface.co/klosax/open_llama_13b_600bt_preview",
    "still_on_hub": true
  },
  {
    "name": "Moderator-Chan_GPT-JT-6b",
    "author": "TehVenom",
    "query_name": "TehVenom/Moderator-Chan_GPT-JT-6b",
    "score": 42.17,
    "likes": 0.0,
    "link": "https://huggingface.co/TehVenom/Moderator-Chan_GPT-JT-6b",
    "still_on_hub": true
  },
  {
    "name": "bloomz-7b1-mt",
    "author": "bigscience",
    "query_name": "bigscience/bloomz-7b1-mt",
    "score": 42.14,
    "likes": 120.0,
    "link": "https://huggingface.co/bigscience/bloomz-7b1-mt",
    "still_on_hub": true
  },
  {
    "name": "palmyra-large",
    "author": "Writer",
    "query_name": "Writer/palmyra-large",
    "score": 42.09,
    "likes": 17.0,
    "link": "https://huggingface.co/Writer/palmyra-large",
    "still_on_hub": true
  },
  {
    "name": "rwkv-raven-14b",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-raven-14b",
    "score": 42.09,
    "likes": 47.0,
    "link": "https://huggingface.co/RWKV/rwkv-raven-14b",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-6b-vicuna-chatml",
    "author": "AlekseyKorshuk",
    "query_name": "AlekseyKorshuk/pygmalion-6b-vicuna-chatml",
    "score": 42.08,
    "likes": 2.0,
    "link": "https://huggingface.co/AlekseyKorshuk/pygmalion-6b-vicuna-chatml",
    "still_on_hub": true
  },
  {
    "name": "Marx-3B-V2",
    "author": "acrastt",
    "query_name": "acrastt/Marx-3B-V2",
    "score": 42.08,
    "likes": 21.0,
    "link": "https://huggingface.co/acrastt/Marx-3B-V2",
    "still_on_hub": true
  },
  {
    "name": "Orca-2-7B-16k",
    "author": "NurtureAI",
    "query_name": "NurtureAI/Orca-2-7B-16k",
    "score": 42.05,
    "likes": 1.0,
    "link": "https://huggingface.co/NurtureAI/Orca-2-7B-16k",
    "still_on_hub": true
  },
  {
    "name": "speechless-tora-code-7b-v1.0",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-tora-code-7b-v1.0",
    "score": 42.04,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-tora-code-7b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-v2-instruct",
    "author": "mediocredev",
    "query_name": "mediocredev/open-llama-3b-v2-instruct",
    "score": 42.02,
    "likes": 0.0,
    "link": "https://huggingface.co/mediocredev/open-llama-3b-v2-instruct",
    "still_on_hub": true
  },
  {
    "name": "opt-30b",
    "author": "facebook",
    "query_name": "facebook/opt-30b",
    "score": 42.0,
    "likes": 133.0,
    "link": "https://huggingface.co/facebook/opt-30b",
    "still_on_hub": true
  },
  {
    "name": "oasst-gpt-neox-20b-3000-steps",
    "author": "dvruette",
    "query_name": "dvruette/oasst-gpt-neox-20b-3000-steps",
    "score": 41.97,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-gpt-neox-20b-3000-steps",
    "still_on_hub": true
  },
  {
    "name": "pythia-12b-sft-v8-2.5k-steps",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/pythia-12b-sft-v8-2.5k-steps",
    "score": 41.97,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-2.5k-steps",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-gm-oasst1-multilang-1024-20b",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-gm-oasst1-multilang-1024-20b",
    "score": 41.9,
    "likes": 9.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-multilang-1024-20b",
    "still_on_hub": true
  },
  {
    "name": "yayi-7b",
    "author": "wenge-research",
    "query_name": "wenge-research/yayi-7b",
    "score": 41.88,
    "likes": 28.0,
    "link": "https://huggingface.co/wenge-research/yayi-7b",
    "still_on_hub": true
  },
  {
    "name": "GPT-JT-Moderation-6B",
    "author": "togethercomputer",
    "query_name": "togethercomputer/GPT-JT-Moderation-6B",
    "score": 41.8,
    "likes": 30.0,
    "link": "https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B",
    "still_on_hub": true
  },
  {
    "name": "LongAlpaca-13B",
    "author": "Yukang",
    "query_name": "Yukang/LongAlpaca-13B",
    "score": 41.74,
    "likes": 4.0,
    "link": "https://huggingface.co/Yukang/LongAlpaca-13B",
    "still_on_hub": true
  },
  {
    "name": "Barcenas-3b",
    "author": "Danielbrdz",
    "query_name": "Danielbrdz/Barcenas-3b",
    "score": 41.74,
    "likes": 2.0,
    "link": "https://huggingface.co/Danielbrdz/Barcenas-3b",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-6.7b-v2-instruct",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct",
    "score": 41.72,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct",
    "still_on_hub": true
  },
  {
    "name": "Marx-3B",
    "author": "acrastt",
    "query_name": "acrastt/Marx-3B",
    "score": 41.71,
    "likes": 11.0,
    "link": "https://huggingface.co/acrastt/Marx-3B",
    "still_on_hub": true
  },
  {
    "name": "gpt-neox-20b",
    "author": "EleutherAI",
    "query_name": "EleutherAI/gpt-neox-20b",
    "score": 41.69,
    "likes": 433.0,
    "link": "https://huggingface.co/EleutherAI/gpt-neox-20b",
    "still_on_hub": true
  },
  {
    "name": "pythia-12b-sft-v8-rlhf-2k-steps",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/pythia-12b-sft-v8-rlhf-2k-steps",
    "score": 41.65,
    "likes": 0.0,
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-rlhf-2k-steps",
    "still_on_hub": true
  },
  {
    "name": "shearedplats-2.7b-v2",
    "author": "vihangd",
    "query_name": "vihangd/shearedplats-2.7b-v2",
    "score": 41.61,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/shearedplats-2.7b-v2",
    "still_on_hub": true
  },
  {
    "name": "MiniMerlin-3b-v0.1",
    "author": "teilomillet",
    "query_name": "teilomillet/MiniMerlin-3b-v0.1",
    "score": 41.6,
    "likes": 0.0,
    "link": "https://huggingface.co/teilomillet/MiniMerlin-3b-v0.1",
    "still_on_hub": true
  },
  {
    "name": "glaive-coder-7b",
    "author": "glaiveai",
    "query_name": "glaiveai/glaive-coder-7b",
    "score": 41.56,
    "likes": 43.0,
    "link": "https://huggingface.co/glaiveai/glaive-coder-7b",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-7B-Base",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-7B-Base",
    "score": 41.49,
    "likes": 89.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base",
    "still_on_hub": true
  },
  {
    "name": "gpt4all-j",
    "author": "nomic-ai",
    "query_name": "nomic-ai/gpt4all-j",
    "score": 41.49,
    "likes": 250.0,
    "link": "https://huggingface.co/nomic-ai/gpt4all-j",
    "still_on_hub": true
  },
  {
    "name": "oasst-pythia-12b-pretrained-sft",
    "author": "dvruette",
    "query_name": "dvruette/oasst-pythia-12b-pretrained-sft",
    "score": 41.48,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-pretrained-sft",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "author": "harborwater",
    "query_name": "harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "score": 41.46,
    "likes": 2.0,
    "link": "https://huggingface.co/harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "still_on_hub": true
  },
  {
    "name": "MiniMA-3B",
    "author": "GeneZC",
    "query_name": "GeneZC/MiniMA-3B",
    "score": 41.44,
    "likes": 6.0,
    "link": "https://huggingface.co/GeneZC/MiniMA-3B",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-everything-v2",
    "author": "harborwater",
    "query_name": "harborwater/open-llama-3b-everything-v2",
    "score": 41.41,
    "likes": 1.0,
    "link": "https://huggingface.co/harborwater/open-llama-3b-everything-v2",
    "still_on_hub": true
  },
  {
    "name": "ReasonixPajama-3B-HF has been flagged! <a target=\"_blank\" href=\"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard/discussions/236\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">See discussion #236</a>",
    "author": "Fredithefish",
    "query_name": "Fredithefish/ReasonixPajama-3B-HF",
    "score": 41.41,
    "likes": 3.0,
    "link": "https://huggingface.co/Fredithefish/ReasonixPajama-3B-HF",
    "still_on_hub": true
  },
  {
    "name": "mommygpt-3B",
    "author": "hakurei",
    "query_name": "hakurei/mommygpt-3B",
    "score": 41.36,
    "likes": 5.0,
    "link": "https://huggingface.co/hakurei/mommygpt-3B",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_13b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_13b",
    "score": 41.36,
    "likes": 95.0,
    "link": "https://huggingface.co/psmathur/orca_mini_13b",
    "still_on_hub": true
  },
  {
    "name": "nucleus-22B-token-500B",
    "author": "NucleusAI",
    "query_name": "NucleusAI/nucleus-22B-token-500B",
    "score": 41.33,
    "likes": 19.0,
    "link": "https://huggingface.co/NucleusAI/nucleus-22B-token-500B",
    "still_on_hub": true
  },
  {
    "name": "llama-2-34b-uncode",
    "author": "chargoddard",
    "query_name": "chargoddard/llama-2-34b-uncode",
    "score": 41.33,
    "likes": 3.0,
    "link": "https://huggingface.co/chargoddard/llama-2-34b-uncode",
    "still_on_hub": true
  },
  {
    "name": "oasst-sft-4-pythia-12b-epoch-3.5",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "score": 41.31,
    "likes": 335.0,
    "link": "https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_7b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_7b",
    "score": 41.27,
    "likes": 17.0,
    "link": "https://huggingface.co/psmathur/orca_mini_7b",
    "still_on_hub": true
  },
  {
    "name": "GPT-NeoX-20B-Erebus",
    "author": "KoboldAI",
    "query_name": "KoboldAI/GPT-NeoX-20B-Erebus",
    "score": 41.26,
    "likes": 70.0,
    "link": "https://huggingface.co/KoboldAI/GPT-NeoX-20B-Erebus",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Base-7B-v0.1",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-Base-7B-v0.1",
    "score": 41.25,
    "likes": 89.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-7B-v0.1",
    "still_on_hub": true
  },
  {
    "name": "mamba-gpt-3b-v4",
    "author": "CobraMamba",
    "query_name": "CobraMamba/mamba-gpt-3b-v4",
    "score": 41.24,
    "likes": 3.0,
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-3b-v4",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-v2-elmv3",
    "author": "aloobun",
    "query_name": "aloobun/open-llama-3b-v2-elmv3",
    "score": 41.14,
    "likes": 0.0,
    "link": "https://huggingface.co/aloobun/open-llama-3b-v2-elmv3",
    "still_on_hub": true
  },
  {
    "name": "Griffin-3B",
    "author": "acrastt",
    "query_name": "acrastt/Griffin-3B",
    "score": 41.13,
    "likes": 3.0,
    "link": "https://huggingface.co/acrastt/Griffin-3B",
    "still_on_hub": true
  },
  {
    "name": "shearedplats-2.7b-v2-instruct-v0.1",
    "author": "mwitiderrick",
    "query_name": "mwitiderrick/shearedplats-2.7b-v2-instruct-v0.1",
    "score": 41.13,
    "likes": 0.0,
    "link": "https://huggingface.co/mwitiderrick/shearedplats-2.7b-v2-instruct-v0.1",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-v2-elmv3",
    "author": "aloobun",
    "query_name": "aloobun/open-llama-3b-v2-elmv3",
    "score": 41.13,
    "likes": 0.0,
    "link": "https://huggingface.co/aloobun/open-llama-3b-v2-elmv3",
    "still_on_hub": true
  },
  {
    "name": "open-llama-0.7T-7B-open-instruct-v1.1",
    "author": "VMware",
    "query_name": "VMware/open-llama-0.7T-7B-open-instruct-v1.1",
    "score": 41.11,
    "likes": 4.0,
    "link": "https://huggingface.co/VMware/open-llama-0.7T-7B-open-instruct-v1.1",
    "still_on_hub": true
  },
  {
    "name": "mamba-gpt-3b-v3",
    "author": "CobraMamba",
    "query_name": "CobraMamba/mamba-gpt-3b-v3",
    "score": 41.11,
    "likes": 12.0,
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-3b-v3",
    "still_on_hub": true
  },
  {
    "name": "pythia-12b-pre-v8-12.5k-steps",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/pythia-12b-pre-v8-12.5k-steps",
    "score": 41.1,
    "likes": 6.0,
    "link": "https://huggingface.co/OpenAssistant/pythia-12b-pre-v8-12.5k-steps",
    "still_on_hub": true
  },
  {
    "name": "GPT-NeoX-20B-Skein",
    "author": "KoboldAI",
    "query_name": "KoboldAI/GPT-NeoX-20B-Skein",
    "score": 41.1,
    "likes": 9.0,
    "link": "https://huggingface.co/KoboldAI/GPT-NeoX-20B-Skein",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "author": "harborwater",
    "query_name": "harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "score": 41.09,
    "likes": 2.0,
    "link": "https://huggingface.co/harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k",
    "still_on_hub": true
  },
  {
    "name": "OpenLlama-Platypus-3B",
    "author": "RobbeD",
    "query_name": "RobbeD/OpenLlama-Platypus-3B",
    "score": 41.05,
    "likes": 1.0,
    "link": "https://huggingface.co/RobbeD/OpenLlama-Platypus-3B",
    "still_on_hub": true
  },
  {
    "name": "Puma-3B",
    "author": "acrastt",
    "query_name": "acrastt/Puma-3B",
    "score": 41.02,
    "likes": 3.0,
    "link": "https://huggingface.co/acrastt/Puma-3B",
    "still_on_hub": true
  },
  {
    "name": "wizard-orca-3b",
    "author": "harborwater",
    "query_name": "harborwater/wizard-orca-3b",
    "score": 41.0,
    "likes": 2.0,
    "link": "https://huggingface.co/harborwater/wizard-orca-3b",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-claude-30k",
    "author": "harborwater",
    "query_name": "harborwater/open-llama-3b-claude-30k",
    "score": 40.93,
    "likes": 0.0,
    "link": "https://huggingface.co/harborwater/open-llama-3b-claude-30k",
    "still_on_hub": true
  },
  {
    "name": "Sheared-LLaMA-2.7B",
    "author": "princeton-nlp",
    "query_name": "princeton-nlp/Sheared-LLaMA-2.7B",
    "score": 40.84,
    "likes": 24.0,
    "link": "https://huggingface.co/princeton-nlp/Sheared-LLaMA-2.7B",
    "still_on_hub": true
  },
  {
    "name": "GPT-R",
    "author": "digitous",
    "query_name": "digitous/GPT-R",
    "score": 40.8,
    "likes": 9.0,
    "link": "https://huggingface.co/digitous/GPT-R",
    "still_on_hub": true
  },
  {
    "name": "ShortKing-3b-v0.3",
    "author": "AtAndDev",
    "query_name": "AtAndDev/ShortKing-3b-v0.3",
    "score": 40.8,
    "likes": 2.0,
    "link": "https://huggingface.co/AtAndDev/ShortKing-3b-v0.3",
    "still_on_hub": true
  },
  {
    "name": "oasst-pythia-12b-6000-steps",
    "author": "dvruette",
    "query_name": "dvruette/oasst-pythia-12b-6000-steps",
    "score": 40.77,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-6000-steps",
    "still_on_hub": true
  },
  {
    "name": "oasst-sft-1-pythia-12b",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/oasst-sft-1-pythia-12b",
    "score": 40.77,
    "likes": 277.0,
    "link": "https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b",
    "still_on_hub": true
  },
  {
    "name": "gogpt-7b-bloom",
    "author": "golaxy",
    "query_name": "golaxy/gogpt-7b-bloom",
    "score": 40.75,
    "likes": 3.0,
    "link": "https://huggingface.co/golaxy/gogpt-7b-bloom",
    "still_on_hub": true
  },
  {
    "name": "ko-ref-llama2-7b",
    "author": "hyunseoki",
    "query_name": "hyunseoki/ko-ref-llama2-7b",
    "score": 40.75,
    "likes": 0.0,
    "link": "https://huggingface.co/hyunseoki/ko-ref-llama2-7b",
    "still_on_hub": true
  },
  {
    "name": "oasst-pythia-12b-flash-attn-5000-steps",
    "author": "dvruette",
    "query_name": "dvruette/oasst-pythia-12b-flash-attn-5000-steps",
    "score": 40.73,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-flash-attn-5000-steps",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-20b",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-20b",
    "score": 40.71,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-20b",
    "still_on_hub": true
  },
  {
    "name": "chatml-pyg-v1",
    "author": "AlekseyKorshuk",
    "query_name": "AlekseyKorshuk/chatml-pyg-v1",
    "score": 40.7,
    "likes": 1.0,
    "link": "https://huggingface.co/AlekseyKorshuk/chatml-pyg-v1",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-gm-oasst1-en-1024-12b",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-gm-oasst1-en-1024-12b",
    "score": 40.65,
    "likes": 5.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-1024-12b",
    "still_on_hub": true
  },
  {
    "name": "fairseq-dense-13B",
    "author": "KoboldAI",
    "query_name": "KoboldAI/fairseq-dense-13B",
    "score": 40.62,
    "likes": 13.0,
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-13B",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-everythingLM-2048",
    "author": "harborwater",
    "query_name": "harborwater/open-llama-3b-everythingLM-2048",
    "score": 40.62,
    "likes": 1.0,
    "link": "https://huggingface.co/harborwater/open-llama-3b-everythingLM-2048",
    "still_on_hub": true
  },
  {
    "name": "7B-redpajama-conditional-alpha",
    "author": "Rallio67",
    "query_name": "Rallio67/7B-redpajama-conditional-alpha",
    "score": 40.56,
    "likes": 7.0,
    "link": "https://huggingface.co/Rallio67/7B-redpajama-conditional-alpha",
    "still_on_hub": true
  },
  {
    "name": "Javalion-R",
    "author": "digitous",
    "query_name": "digitous/Javalion-R",
    "score": 40.51,
    "likes": 5.0,
    "link": "https://huggingface.co/digitous/Javalion-R",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-oasst1-512-12b",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-oasst1-512-12b",
    "score": 40.48,
    "likes": 26.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-oasst1-512-12b",
    "still_on_hub": true
  },
  {
    "name": "Javelin-R",
    "author": "digitous",
    "query_name": "digitous/Javelin-R",
    "score": 40.39,
    "likes": 2.0,
    "link": "https://huggingface.co/digitous/Javelin-R",
    "still_on_hub": true
  },
  {
    "name": "oasst-pythia-12b-reference",
    "author": "dvruette",
    "query_name": "dvruette/oasst-pythia-12b-reference",
    "score": 40.33,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-pythia-12b-reference",
    "still_on_hub": true
  },
  {
    "name": "WizardCoder-Python-7B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardCoder-Python-7B-V1.0",
    "score": 40.32,
    "likes": 44.0,
    "link": "https://huggingface.co/WizardLM/WizardCoder-Python-7B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "pythia-13b-deduped-green_devil",
    "author": "Pirr",
    "query_name": "Pirr/pythia-13b-deduped-green_devil",
    "score": 40.31,
    "likes": 9.0,
    "link": "https://huggingface.co/Pirr/pythia-13b-deduped-green_devil",
    "still_on_hub": true
  },
  {
    "name": "smartyplats-3b-v2",
    "author": "vihangd",
    "query_name": "vihangd/smartyplats-3b-v2",
    "score": 40.29,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/smartyplats-3b-v2",
    "still_on_hub": true
  },
  {
    "name": "openllama_3b_EvolInstruct_lora_merged",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/openllama_3b_EvolInstruct_lora_merged",
    "score": 40.28,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/openllama_3b_EvolInstruct_lora_merged",
    "still_on_hub": true
  },
  {
    "name": "open_llama_3b_v2",
    "author": "openlm-research",
    "query_name": "openlm-research/open_llama_3b_v2",
    "score": 40.28,
    "likes": 61.0,
    "link": "https://huggingface.co/openlm-research/open_llama_3b_v2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-ko-7b-Chat",
    "author": "kfkas",
    "query_name": "kfkas/Llama-2-ko-7b-Chat",
    "score": 40.27,
    "likes": 51.0,
    "link": "https://huggingface.co/kfkas/Llama-2-ko-7b-Chat",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-34B-Python-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/CodeLlama-34B-Python-fp16",
    "score": 40.27,
    "likes": 11.0,
    "link": "https://huggingface.co/TheBloke/CodeLlama-34B-Python-fp16",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-34b-Python-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-34b-Python-hf",
    "score": 40.27,
    "likes": 61.0,
    "link": "https://huggingface.co/codellama/CodeLlama-34b-Python-hf",
    "still_on_hub": true
  },
  {
    "name": "open-llama-3b-v2-layla",
    "author": "l3utterfly",
    "query_name": "l3utterfly/open-llama-3b-v2-layla",
    "score": 40.25,
    "likes": 0.0,
    "link": "https://huggingface.co/l3utterfly/open-llama-3b-v2-layla",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-ko-7b-Chat",
    "author": "kfkas",
    "query_name": "kfkas/Llama-2-ko-7b-Chat",
    "score": 40.25,
    "likes": 51.0,
    "link": "https://huggingface.co/kfkas/Llama-2-ko-7b-Chat",
    "still_on_hub": true
  },
  {
    "name": "Javelin-GPTJ",
    "author": "digitous",
    "query_name": "digitous/Javelin-GPTJ",
    "score": 40.23,
    "likes": 4.0,
    "link": "https://huggingface.co/digitous/Javelin-GPTJ",
    "still_on_hub": true
  },
  {
    "name": "tora-code-7b-v1.0",
    "author": "llm-agents",
    "query_name": "llm-agents/tora-code-7b-v1.0",
    "score": 40.21,
    "likes": 7.0,
    "link": "https://huggingface.co/llm-agents/tora-code-7b-v1.0",
    "still_on_hub": true
  },
  {
    "name": "Janin-R",
    "author": "digitous",
    "query_name": "digitous/Janin-R",
    "score": 40.19,
    "likes": 1.0,
    "link": "https://huggingface.co/digitous/Janin-R",
    "still_on_hub": true
  },
  {
    "name": "Bean-3B",
    "author": "acrastt",
    "query_name": "acrastt/Bean-3B",
    "score": 40.18,
    "likes": 2.0,
    "link": "https://huggingface.co/acrastt/Bean-3B",
    "still_on_hub": true
  },
  {
    "name": "Flash-Llama-3B",
    "author": "TaylorAI",
    "query_name": "TaylorAI/Flash-Llama-3B",
    "score": 40.13,
    "likes": 2.0,
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-3B",
    "still_on_hub": true
  },
  {
    "name": "Dolly_Shygmalion-6b-Dev_V8P2",
    "author": "TehVenom",
    "query_name": "TehVenom/Dolly_Shygmalion-6b-Dev_V8P2",
    "score": 40.11,
    "likes": 5.0,
    "link": "https://huggingface.co/TehVenom/Dolly_Shygmalion-6b-Dev_V8P2",
    "still_on_hub": true
  },
  {
    "name": "gpt-j-6b",
    "author": "EleutherAI",
    "query_name": "EleutherAI/gpt-j-6b",
    "score": 40.1,
    "likes": 1290.0,
    "link": "https://huggingface.co/EleutherAI/gpt-j-6b",
    "still_on_hub": true
  },
  {
    "name": "calypso-3b-alpha-v2",
    "author": "Xilabs",
    "query_name": "Xilabs/calypso-3b-alpha-v2",
    "score": 40.09,
    "likes": 4.0,
    "link": "https://huggingface.co/Xilabs/calypso-3b-alpha-v2",
    "still_on_hub": true
  },
  {
    "name": "CodeBarcenas-7b",
    "author": "Danielbrdz",
    "query_name": "Danielbrdz/CodeBarcenas-7b",
    "score": 40.09,
    "likes": 0.0,
    "link": "https://huggingface.co/Danielbrdz/CodeBarcenas-7b",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-34b-hf",
    "author": "NousResearch",
    "query_name": "NousResearch/CodeLlama-34b-hf",
    "score": 40.08,
    "likes": 3.0,
    "link": "https://huggingface.co/NousResearch/CodeLlama-34b-hf",
    "still_on_hub": true
  },
  {
    "name": "opt-13b",
    "author": "facebook",
    "query_name": "facebook/opt-13b",
    "score": 40.06,
    "likes": 59.0,
    "link": "https://huggingface.co/facebook/opt-13b",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-7b-Instruct-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-7b-Instruct-hf",
    "score": 40.05,
    "likes": 76.0,
    "link": "https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf",
    "still_on_hub": true
  },
  {
    "name": "GPT-J-6B-Skein",
    "author": "KoboldAI",
    "query_name": "KoboldAI/GPT-J-6B-Skein",
    "score": 40.02,
    "likes": 12.0,
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Skein",
    "still_on_hub": true
  },
  {
    "name": "smartyplats-3b-v1",
    "author": "vihangd",
    "query_name": "vihangd/smartyplats-3b-v1",
    "score": 40.0,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/smartyplats-3b-v1",
    "still_on_hub": true
  },
  {
    "name": "speechless-tools-7b",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-tools-7b",
    "score": 40.0,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-tools-7b",
    "still_on_hub": true
  },
  {
    "name": "codegen-6B-nl",
    "author": "Salesforce",
    "query_name": "Salesforce/codegen-6B-nl",
    "score": 40.0,
    "likes": 4.0,
    "link": "https://huggingface.co/Salesforce/codegen-6B-nl",
    "still_on_hub": true
  },
  {
    "name": "Javalion-GPTJ",
    "author": "digitous",
    "query_name": "digitous/Javalion-GPTJ",
    "score": 39.97,
    "likes": 1.0,
    "link": "https://huggingface.co/digitous/Javalion-GPTJ",
    "still_on_hub": true
  },
  {
    "name": "WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
    "score": 39.95,
    "likes": 1.0,
    "link": "https://huggingface.co/Aspik101/WizardVicuna-Uncensored-3B-instruct-PL-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "rwkv-4-14b-pile",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-4-14b-pile",
    "score": 39.92,
    "likes": 2.0,
    "link": "https://huggingface.co/RWKV/rwkv-4-14b-pile",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-30B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-30B-GPTQ",
    "score": 39.9,
    "likes": 19.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-30B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
    "score": 39.89,
    "likes": 3.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-1024-open-llama-7b-preview-400bt",
    "still_on_hub": true
  },
  {
    "name": "Dolly_Shygmalion-6b",
    "author": "TehVenom",
    "query_name": "TehVenom/Dolly_Shygmalion-6b",
    "score": 39.89,
    "likes": 14.0,
    "link": "https://huggingface.co/TehVenom/Dolly_Shygmalion-6b",
    "still_on_hub": true
  },
  {
    "name": "Skegma-GPTJ",
    "author": "digitous",
    "query_name": "digitous/Skegma-GPTJ",
    "score": 39.87,
    "likes": 0.0,
    "link": "https://huggingface.co/digitous/Skegma-GPTJ",
    "still_on_hub": true
  },
  {
    "name": "PPO_Shygmalion-V8p4_Dev-6b",
    "author": "TehVenom",
    "query_name": "TehVenom/PPO_Shygmalion-V8p4_Dev-6b",
    "score": 39.85,
    "likes": 3.0,
    "link": "https://huggingface.co/TehVenom/PPO_Shygmalion-V8p4_Dev-6b",
    "still_on_hub": true
  },
  {
    "name": "PPO_Pygway-V8p4_Dev-6b",
    "author": "TehVenom",
    "query_name": "TehVenom/PPO_Pygway-V8p4_Dev-6b",
    "score": 39.85,
    "likes": 7.0,
    "link": "https://huggingface.co/TehVenom/PPO_Pygway-V8p4_Dev-6b",
    "still_on_hub": true
  },
  {
    "name": "Pythia-Chat-Base-7B",
    "author": "togethercomputer",
    "query_name": "togethercomputer/Pythia-Chat-Base-7B",
    "score": 39.81,
    "likes": 61.0,
    "link": "https://huggingface.co/togethercomputer/Pythia-Chat-Base-7B",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-7b-hf",
    "author": "NousResearch",
    "query_name": "NousResearch/CodeLlama-7b-hf",
    "score": 39.81,
    "likes": 3.0,
    "link": "https://huggingface.co/NousResearch/CodeLlama-7b-hf",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-7b-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-7b-hf",
    "score": 39.81,
    "likes": 145.0,
    "link": "https://huggingface.co/codellama/CodeLlama-7b-hf",
    "still_on_hub": true
  },
  {
    "name": "Dolly_Malion-6b",
    "author": "TehVenom",
    "query_name": "TehVenom/Dolly_Malion-6b",
    "score": 39.77,
    "likes": 1.0,
    "link": "https://huggingface.co/TehVenom/Dolly_Malion-6b",
    "still_on_hub": true
  },
  {
    "name": "WizardVicuna-Uncensored-3B-0719",
    "author": "heegyu",
    "query_name": "heegyu/WizardVicuna-Uncensored-3B-0719",
    "score": 39.73,
    "likes": 4.0,
    "link": "https://huggingface.co/heegyu/WizardVicuna-Uncensored-3B-0719",
    "still_on_hub": true
  },
  {
    "name": "ChanMalion",
    "author": "TehVenom",
    "query_name": "TehVenom/ChanMalion",
    "score": 39.73,
    "likes": 9.0,
    "link": "https://huggingface.co/TehVenom/ChanMalion",
    "still_on_hub": true
  },
  {
    "name": "open_llama_3b_code_instruct_0.1",
    "author": "mwitiderrick",
    "query_name": "mwitiderrick/open_llama_3b_code_instruct_0.1",
    "score": 39.72,
    "likes": 1.0,
    "link": "https://huggingface.co/mwitiderrick/open_llama_3b_code_instruct_0.1",
    "still_on_hub": true
  },
  {
    "name": "pythia-12b-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-12b-deduped",
    "score": 39.7,
    "likes": 48.0,
    "link": "https://huggingface.co/EleutherAI/pythia-12b-deduped",
    "still_on_hub": true
  },
  {
    "name": "Janin-GPTJ",
    "author": "digitous",
    "query_name": "digitous/Janin-GPTJ",
    "score": 39.67,
    "likes": 0.0,
    "link": "https://huggingface.co/digitous/Janin-GPTJ",
    "still_on_hub": true
  },
  {
    "name": "GPT-J-Pyg_PPO-6B-Dev-V8p4",
    "author": "TehVenom",
    "query_name": "TehVenom/GPT-J-Pyg_PPO-6B-Dev-V8p4",
    "score": 39.61,
    "likes": 1.0,
    "link": "https://huggingface.co/TehVenom/GPT-J-Pyg_PPO-6B-Dev-V8p4",
    "still_on_hub": true
  },
  {
    "name": "OPT-13B-Erebus",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-13B-Erebus",
    "score": 39.61,
    "likes": 149.0,
    "link": "https://huggingface.co/KoboldAI/OPT-13B-Erebus",
    "still_on_hub": true
  },
  {
    "name": "OPT-13B-Nerybus-Mix",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-13B-Nerybus-Mix",
    "score": 39.61,
    "likes": 25.0,
    "link": "https://huggingface.co/KoboldAI/OPT-13B-Nerybus-Mix",
    "still_on_hub": true
  },
  {
    "name": "GPT-J-6B-Shinen",
    "author": "KoboldAI",
    "query_name": "KoboldAI/GPT-J-6B-Shinen",
    "score": 39.6,
    "likes": 15.0,
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Shinen",
    "still_on_hub": true
  },
  {
    "name": "gpt-j-6B-Dolly",
    "author": "Corianas",
    "query_name": "Corianas/gpt-j-6B-Dolly",
    "score": 39.6,
    "likes": 1.0,
    "link": "https://huggingface.co/Corianas/gpt-j-6B-Dolly",
    "still_on_hub": true
  },
  {
    "name": "GPT-J-Pyg_PPO-6B",
    "author": "TehVenom",
    "query_name": "TehVenom/GPT-J-Pyg_PPO-6B",
    "score": 39.6,
    "likes": 6.0,
    "link": "https://huggingface.co/TehVenom/GPT-J-Pyg_PPO-6B",
    "still_on_hub": true
  },
  {
    "name": "GPT-J-6B-Janeway",
    "author": "KoboldAI",
    "query_name": "KoboldAI/GPT-J-6B-Janeway",
    "score": 39.54,
    "likes": 11.0,
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Janeway",
    "still_on_hub": true
  },
  {
    "name": "LightGPT",
    "author": "amazon",
    "query_name": "amazon/LightGPT",
    "score": 39.54,
    "likes": 64.0,
    "link": "https://huggingface.co/amazon/LightGPT",
    "still_on_hub": true
  },
  {
    "name": "OPT-13B-Nerys-v2",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-13B-Nerys-v2",
    "score": 39.53,
    "likes": 9.0,
    "link": "https://huggingface.co/KoboldAI/OPT-13B-Nerys-v2",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Chat-3B-v1",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "score": 39.53,
    "likes": 115.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-6.7b-v2",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-6.7b-v2",
    "score": 39.49,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-6.7b-v2",
    "still_on_hub": true
  },
  {
    "name": "WizardVicuna-3B-0719",
    "author": "heegyu",
    "query_name": "heegyu/WizardVicuna-3B-0719",
    "score": 39.48,
    "likes": 0.0,
    "link": "https://huggingface.co/heegyu/WizardVicuna-3B-0719",
    "still_on_hub": true
  },
  {
    "name": "dolly-v2-12b",
    "author": "databricks",
    "query_name": "databricks/dolly-v2-12b",
    "score": 39.46,
    "likes": 1872.0,
    "link": "https://huggingface.co/databricks/dolly-v2-12b",
    "still_on_hub": true
  },
  {
    "name": "PPO_Pygway-6b-Mix",
    "author": "KoboldAI",
    "query_name": "KoboldAI/PPO_Pygway-6b-Mix",
    "score": 39.43,
    "likes": 19.0,
    "link": "https://huggingface.co/KoboldAI/PPO_Pygway-6b-Mix",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
    "author": "Fredithefish",
    "query_name": "Fredithefish/RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
    "score": 39.38,
    "likes": 2.0,
    "link": "https://huggingface.co/Fredithefish/RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-7B-Chat",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-7B-Chat",
    "score": 39.37,
    "likes": 87.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Chat-7B-v0.1",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-Chat-7B-v0.1",
    "score": 39.37,
    "likes": 87.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-7B-v0.1",
    "still_on_hub": true
  },
  {
    "name": "LongAlpaca-7B",
    "author": "Yukang",
    "query_name": "Yukang/LongAlpaca-7B",
    "score": 39.36,
    "likes": 6.0,
    "link": "https://huggingface.co/Yukang/LongAlpaca-7B",
    "still_on_hub": true
  },
  {
    "name": "PPO_Shygmalion-6b",
    "author": "TehVenom",
    "query_name": "TehVenom/PPO_Shygmalion-6b",
    "score": 39.35,
    "likes": 5.0,
    "link": "https://huggingface.co/TehVenom/PPO_Shygmalion-6b",
    "still_on_hub": true
  },
  {
    "name": "Adventien-GPTJ",
    "author": "digitous",
    "query_name": "digitous/Adventien-GPTJ",
    "score": 39.31,
    "likes": 0.0,
    "link": "https://huggingface.co/digitous/Adventien-GPTJ",
    "still_on_hub": true
  },
  {
    "name": "mpt-7b-storywriter",
    "author": "mosaicml",
    "query_name": "mosaicml/mpt-7b-storywriter",
    "score": 39.31,
    "likes": 690.0,
    "link": "https://huggingface.co/mosaicml/mpt-7b-storywriter",
    "still_on_hub": true
  },
  {
    "name": "pythia-6.9b-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-6.9b-deduped",
    "score": 39.3,
    "likes": 6.0,
    "link": "https://huggingface.co/EleutherAI/pythia-6.9b-deduped",
    "still_on_hub": true
  },
  {
    "name": "fairseq-dense-6.7B",
    "author": "KoboldAI",
    "query_name": "KoboldAI/fairseq-dense-6.7B",
    "score": 39.26,
    "likes": 2.0,
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-6.7B",
    "still_on_hub": true
  },
  {
    "name": "dolly-v2-7b",
    "author": "databricks",
    "query_name": "databricks/dolly-v2-7b",
    "score": 39.24,
    "likes": 132.0,
    "link": "https://huggingface.co/databricks/dolly-v2-7b",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Chat-Instruct-3B-V1",
    "author": "acrastt",
    "query_name": "acrastt/RedPajama-INCITE-Chat-Instruct-3B-V1",
    "score": 39.23,
    "likes": 1.0,
    "link": "https://huggingface.co/acrastt/RedPajama-INCITE-Chat-Instruct-3B-V1",
    "still_on_hub": true
  },
  {
    "name": "RedTulu-Uncensored-3B-0719",
    "author": "heegyu",
    "query_name": "heegyu/RedTulu-Uncensored-3B-0719",
    "score": 39.19,
    "likes": 0.0,
    "link": "https://huggingface.co/heegyu/RedTulu-Uncensored-3B-0719",
    "still_on_hub": true
  },
  {
    "name": "bloom-7b1",
    "author": "bigscience",
    "query_name": "bigscience/bloom-7b1",
    "score": 39.18,
    "likes": 137.0,
    "link": "https://huggingface.co/bigscience/bloom-7b1",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
    "author": "DanielSc4",
    "query_name": "DanielSc4/RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
    "score": 39.16,
    "likes": 0.0,
    "link": "https://huggingface.co/DanielSc4/RedPajama-INCITE-Chat-3B-v1-RL-LoRA-8bit-test1",
    "still_on_hub": false
  },
  {
    "name": "oasst-pythia-6.9b-4000-steps",
    "author": "dvruette",
    "query_name": "dvruette/oasst-pythia-6.9b-4000-steps",
    "score": 39.15,
    "likes": 0.0,
    "link": "https://huggingface.co/dvruette/oasst-pythia-6.9b-4000-steps",
    "still_on_hub": true
  },
  {
    "name": "weblab-10b-instruction-sft",
    "author": "matsuo-lab",
    "query_name": "matsuo-lab/weblab-10b-instruction-sft",
    "score": 39.13,
    "likes": 68.0,
    "link": "https://huggingface.co/matsuo-lab/weblab-10b-instruction-sft",
    "still_on_hub": true
  },
  {
    "name": "robin-33B-v2-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/robin-33B-v2-GPTQ",
    "score": 39.1,
    "likes": 13.0,
    "link": "https://huggingface.co/TheBloke/robin-33B-v2-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "OPT-6.7B-Erebus",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-6.7B-Erebus",
    "score": 39.09,
    "likes": 84.0,
    "link": "https://huggingface.co/KoboldAI/OPT-6.7B-Erebus",
    "still_on_hub": true
  },
  {
    "name": "firefly-bloom-7b1",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-bloom-7b1",
    "score": 39.09,
    "likes": 1.0,
    "link": "https://huggingface.co/YeungNLP/firefly-bloom-7b1",
    "still_on_hub": true
  },
  {
    "name": "opt-6.7b",
    "author": "facebook",
    "query_name": "facebook/opt-6.7b",
    "score": 39.08,
    "likes": 77.0,
    "link": "https://huggingface.co/facebook/opt-6.7b",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Instruct-3B-v1",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "score": 39.06,
    "likes": 84.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "still_on_hub": true
  },
  {
    "name": "deacon-3b",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/deacon-3b",
    "score": 39.05,
    "likes": 2.0,
    "link": "https://huggingface.co/KnutJaegersberg/deacon-3b",
    "still_on_hub": true
  },
  {
    "name": "ScarletPajama-3B-HF",
    "author": "Fredithefish",
    "query_name": "Fredithefish/ScarletPajama-3B-HF",
    "score": 39.04,
    "likes": 9.0,
    "link": "https://huggingface.co/Fredithefish/ScarletPajama-3B-HF",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_3b",
    "author": "psmathur",
    "query_name": "psmathur/orca_mini_3b",
    "score": 39.03,
    "likes": 129.0,
    "link": "https://huggingface.co/psmathur/orca_mini_3b",
    "still_on_hub": true
  },
  {
    "name": "black_goo_recipe_c",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/black_goo_recipe_c",
    "score": 39.01,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_c",
    "still_on_hub": true
  },
  {
    "name": "Guanaco-3B-Uncensored-v2",
    "author": "Fredithefish",
    "query_name": "Fredithefish/Guanaco-3B-Uncensored-v2",
    "score": 38.98,
    "likes": 9.0,
    "link": "https://huggingface.co/Fredithefish/Guanaco-3B-Uncensored-v2",
    "still_on_hub": true
  },
  {
    "name": "cross_lingual_epoch2",
    "author": "jb723",
    "query_name": "jb723/cross_lingual_epoch2",
    "score": 38.97,
    "likes": 0.0,
    "link": "https://huggingface.co/jb723/cross_lingual_epoch2",
    "still_on_hub": true
  },
  {
    "name": "open_llama_3b_instruct_v_0.2",
    "author": "mwitiderrick",
    "query_name": "mwitiderrick/open_llama_3b_instruct_v_0.2",
    "score": 38.97,
    "likes": 0.0,
    "link": "https://huggingface.co/mwitiderrick/open_llama_3b_instruct_v_0.2",
    "still_on_hub": true
  },
  {
    "name": "Guanaco-3B-Uncensored-v2-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Guanaco-3B-Uncensored-v2-GPTQ",
    "score": 38.95,
    "likes": 8.0,
    "link": "https://huggingface.co/TheBloke/Guanaco-3B-Uncensored-v2-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "Guanaco-3B-Uncensored",
    "author": "Fredithefish",
    "query_name": "Fredithefish/Guanaco-3B-Uncensored",
    "score": 38.94,
    "likes": 0.0,
    "link": "https://huggingface.co/Fredithefish/Guanaco-3B-Uncensored",
    "still_on_hub": true
  },
  {
    "name": "Healix-3B",
    "author": "health360",
    "query_name": "health360/Healix-3B",
    "score": 38.93,
    "likes": 0.0,
    "link": "https://huggingface.co/health360/Healix-3B",
    "still_on_hub": true
  },
  {
    "name": "mamba-gpt-3b",
    "author": "CobraMamba",
    "query_name": "CobraMamba/mamba-gpt-3b",
    "score": 38.87,
    "likes": 3.0,
    "link": "https://huggingface.co/CobraMamba/mamba-gpt-3b",
    "still_on_hub": true
  },
  {
    "name": "FinanceConnect-13B",
    "author": "ceadar-ie",
    "query_name": "ceadar-ie/FinanceConnect-13B",
    "score": 38.84,
    "likes": 0.0,
    "link": "https://huggingface.co/ceadar-ie/FinanceConnect-13B",
    "still_on_hub": true
  },
  {
    "name": "galactica-6.7b-finetuned",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/galactica-6.7b-finetuned",
    "score": 38.84,
    "likes": 34.0,
    "link": "https://huggingface.co/OpenAssistant/galactica-6.7b-finetuned",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_3b_juniper",
    "author": "frank098",
    "query_name": "frank098/orca_mini_3b_juniper",
    "score": 38.83,
    "likes": 1.0,
    "link": "https://huggingface.co/frank098/orca_mini_3b_juniper",
    "still_on_hub": true
  },
  {
    "name": "OPT-6.7B-Nerybus-Mix",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-6.7B-Nerybus-Mix",
    "score": 38.83,
    "likes": 18.0,
    "link": "https://huggingface.co/KoboldAI/OPT-6.7B-Nerybus-Mix",
    "still_on_hub": true
  },
  {
    "name": "pythia-12b",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-12b",
    "score": 38.82,
    "likes": 111.0,
    "link": "https://huggingface.co/EleutherAI/pythia-12b",
    "still_on_hub": true
  },
  {
    "name": "WizardVicuna-open-llama-3b-v2",
    "author": "heegyu",
    "query_name": "heegyu/WizardVicuna-open-llama-3b-v2",
    "score": 38.77,
    "likes": 0.0,
    "link": "https://huggingface.co/heegyu/WizardVicuna-open-llama-3b-v2",
    "still_on_hub": true
  },
  {
    "name": "black_goo_recipe_a",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/black_goo_recipe_a",
    "score": 38.73,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_a",
    "still_on_hub": true
  },
  {
    "name": "OPT-6B-nerys-v2",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-6B-nerys-v2",
    "score": 38.72,
    "likes": 21.0,
    "link": "https://huggingface.co/KoboldAI/OPT-6B-nerys-v2",
    "still_on_hub": true
  },
  {
    "name": "instruct-12b",
    "author": "hakurei",
    "query_name": "hakurei/instruct-12b",
    "score": 38.63,
    "likes": 17.0,
    "link": "https://huggingface.co/hakurei/instruct-12b",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-oig-oasst1-256-6_9b",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-oig-oasst1-256-6_9b",
    "score": 38.62,
    "likes": 5.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-6_9b",
    "still_on_hub": true
  },
  {
    "name": "weblab-10b",
    "author": "matsuo-lab",
    "query_name": "matsuo-lab/weblab-10b",
    "score": 38.59,
    "likes": 55.0,
    "link": "https://huggingface.co/matsuo-lab/weblab-10b",
    "still_on_hub": true
  },
  {
    "name": "black_goo_recipe_d",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/black_goo_recipe_d",
    "score": 38.57,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_d",
    "still_on_hub": true
  },
  {
    "name": "rwkv-raven-7b",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-raven-7b",
    "score": 38.55,
    "likes": 16.0,
    "link": "https://huggingface.co/RWKV/rwkv-raven-7b",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Base-3B-v1",
    "author": "togethercomputer",
    "query_name": "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "score": 38.54,
    "likes": 80.0,
    "link": "https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "still_on_hub": true
  },
  {
    "name": "pyg-instruct-wizardlm",
    "author": "Lazycuber",
    "query_name": "Lazycuber/pyg-instruct-wizardlm",
    "score": 38.54,
    "likes": 1.0,
    "link": "https://huggingface.co/Lazycuber/pyg-instruct-wizardlm",
    "still_on_hub": true
  },
  {
    "name": "OPT-30B-Erebus",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-30B-Erebus",
    "score": 38.53,
    "likes": 40.0,
    "link": "https://huggingface.co/KoboldAI/OPT-30B-Erebus",
    "still_on_hub": true
  },
  {
    "name": "CrimsonPajama",
    "author": "Fredithefish",
    "query_name": "Fredithefish/CrimsonPajama",
    "score": 38.52,
    "likes": 4.0,
    "link": "https://huggingface.co/Fredithefish/CrimsonPajama",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-oig-oasst1-512-6_9b",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-oig-oasst1-512-6_9b",
    "score": 38.52,
    "likes": 16.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-oig-oasst1-512-6_9b",
    "still_on_hub": true
  },
  {
    "name": "guanaco-33B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/guanaco-33B-GPTQ",
    "score": 38.51,
    "likes": 71.0,
    "link": "https://huggingface.co/TheBloke/guanaco-33B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "LLongMA-3b-LIMA",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/LLongMA-3b-LIMA",
    "score": 38.51,
    "likes": 2.0,
    "link": "https://huggingface.co/KnutJaegersberg/LLongMA-3b-LIMA",
    "still_on_hub": true
  },
  {
    "name": "pythia-6.9b-HC3",
    "author": "pszemraj",
    "query_name": "pszemraj/pythia-6.9b-HC3",
    "score": 38.51,
    "likes": 2.0,
    "link": "https://huggingface.co/pszemraj/pythia-6.9b-HC3",
    "still_on_hub": true
  },
  {
    "name": "black_goo_recipe_b",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/black_goo_recipe_b",
    "score": 38.49,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/black_goo_recipe_b",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Chat-3B-ShareGPT-11K",
    "author": "Fredithefish",
    "query_name": "Fredithefish/RedPajama-INCITE-Chat-3B-ShareGPT-11K",
    "score": 38.47,
    "likes": 2.0,
    "link": "https://huggingface.co/Fredithefish/RedPajama-INCITE-Chat-3B-ShareGPT-11K",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-6b",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/pygmalion-6b",
    "score": 38.47,
    "likes": 690.0,
    "link": "https://huggingface.co/PygmalionAI/pygmalion-6b",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-33B-V1.0-Uncensored-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ",
    "score": 38.43,
    "likes": 37.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-6b-roleplay",
    "author": "anhnv125",
    "query_name": "anhnv125/pygmalion-6b-roleplay",
    "score": 38.34,
    "likes": 1.0,
    "link": "https://huggingface.co/anhnv125/pygmalion-6b-roleplay",
    "still_on_hub": true
  },
  {
    "name": "DiffMerge_Pygmalion_Main-onto-V8P4",
    "author": "TehVenom",
    "query_name": "TehVenom/DiffMerge_Pygmalion_Main-onto-V8P4",
    "score": 38.31,
    "likes": 1.0,
    "link": "https://huggingface.co/TehVenom/DiffMerge_Pygmalion_Main-onto-V8P4",
    "still_on_hub": true
  },
  {
    "name": "OmegLLaMA-3B",
    "author": "acrastt",
    "query_name": "acrastt/OmegLLaMA-3B",
    "score": 38.28,
    "likes": 5.0,
    "link": "https://huggingface.co/acrastt/OmegLLaMA-3B",
    "still_on_hub": true
  },
  {
    "name": "open_llama_3b",
    "author": "openlm-research",
    "query_name": "openlm-research/open_llama_3b",
    "score": 38.26,
    "likes": 112.0,
    "link": "https://huggingface.co/openlm-research/open_llama_3b",
    "still_on_hub": true
  },
  {
    "name": "koishi-instruct-3b",
    "author": "ewof",
    "query_name": "ewof/koishi-instruct-3b",
    "score": 38.16,
    "likes": 2.0,
    "link": "https://huggingface.co/ewof/koishi-instruct-3b",
    "still_on_hub": true
  },
  {
    "name": "pythia-6.7b",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-6.7b",
    "score": 38.06,
    "likes": 8.0,
    "link": "https://huggingface.co/EleutherAI/pythia-6.7b",
    "still_on_hub": true
  },
  {
    "name": "rwkv-4-7b-pile",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-4-7b-pile",
    "score": 37.95,
    "likes": 0.0,
    "link": "https://huggingface.co/RWKV/rwkv-4-7b-pile",
    "still_on_hub": true
  },
  {
    "name": "Galactica-6.7B-EssayWriter",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Galactica-6.7B-EssayWriter",
    "score": 37.75,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/Galactica-6.7B-EssayWriter",
    "still_on_hub": true
  },
  {
    "name": "test-22B",
    "author": "Devio",
    "query_name": "Devio/test-22B",
    "score": 37.71,
    "likes": 0.0,
    "link": "https://huggingface.co/Devio/test-22B",
    "still_on_hub": true
  },
  {
    "name": "falcon-rw-1b-instruct-openorca",
    "author": "ericzzz",
    "query_name": "ericzzz/falcon-rw-1b-instruct-openorca",
    "score": 37.63,
    "likes": 1.0,
    "link": "https://huggingface.co/ericzzz/falcon-rw-1b-instruct-openorca",
    "still_on_hub": true
  },
  {
    "name": "falcon_1b_stage2",
    "author": "euclaise",
    "query_name": "euclaise/falcon_1b_stage2",
    "score": 37.59,
    "likes": 1.0,
    "link": "https://huggingface.co/euclaise/falcon_1b_stage2",
    "still_on_hub": true
  },
  {
    "name": "bloom-zh-3b-chat",
    "author": "ikala",
    "query_name": "ikala/bloom-zh-3b-chat",
    "score": 37.58,
    "likes": 10.0,
    "link": "https://huggingface.co/ikala/bloom-zh-3b-chat",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
    "score": 37.55,
    "likes": 4.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt-v2",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-13B-Python-fp16",
    "author": "TheBloke",
    "query_name": "TheBloke/CodeLlama-13B-Python-fp16",
    "score": 37.52,
    "likes": 26.0,
    "link": "https://huggingface.co/TheBloke/CodeLlama-13B-Python-fp16",
    "still_on_hub": true
  },
  {
    "name": "GoLLIE-7B",
    "author": "HiTZ",
    "query_name": "HiTZ/GoLLIE-7B",
    "score": 37.48,
    "likes": 11.0,
    "link": "https://huggingface.co/HiTZ/GoLLIE-7B",
    "still_on_hub": true
  },
  {
    "name": "fairseq-dense-2.7B",
    "author": "KoboldAI",
    "query_name": "KoboldAI/fairseq-dense-2.7B",
    "score": 37.41,
    "likes": 2.0,
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-2.7B",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-13B",
    "author": "cerebras",
    "query_name": "cerebras/Cerebras-GPT-13B",
    "score": 37.4,
    "likes": 632.0,
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-13B",
    "still_on_hub": true
  },
  {
    "name": "falcon-rw-1b-chat",
    "author": "ericzzz",
    "query_name": "ericzzz/falcon-rw-1b-chat",
    "score": 37.37,
    "likes": 1.0,
    "link": "https://huggingface.co/ericzzz/falcon-rw-1b-chat",
    "still_on_hub": true
  },
  {
    "name": "StellarX-4B-V0",
    "author": "Dampish",
    "query_name": "Dampish/StellarX-4B-V0",
    "score": 37.31,
    "likes": 1.0,
    "link": "https://huggingface.co/Dampish/StellarX-4B-V0",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-30B-Uncensored-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-30B-Uncensored-GPTQ",
    "score": 37.27,
    "likes": 107.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
    "author": "DanielSc4",
    "query_name": "DanielSc4/RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
    "score": 37.27,
    "likes": 0.0,
    "link": "https://huggingface.co/DanielSc4/RedPajama-INCITE-Chat-3B-v1-FT-LoRA-8bit-test1",
    "still_on_hub": false
  },
  {
    "name": "galactica-6.7b-evol-instruct-70k",
    "author": "GeorgiaTechResearchInstitute",
    "query_name": "GeorgiaTechResearchInstitute/galactica-6.7b-evol-instruct-70k",
    "score": 37.27,
    "likes": 16.0,
    "link": "https://huggingface.co/GeorgiaTechResearchInstitute/galactica-6.7b-evol-instruct-70k",
    "still_on_hub": true
  },
  {
    "name": "falcon_1b_stage1",
    "author": "euclaise",
    "query_name": "euclaise/falcon_1b_stage1",
    "score": 37.25,
    "likes": 0.0,
    "link": "https://huggingface.co/euclaise/falcon_1b_stage1",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-6.7b",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-6.7b",
    "score": 37.23,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-6.7b",
    "still_on_hub": true
  },
  {
    "name": "pythia-2.7b",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-2.7b",
    "score": 37.09,
    "likes": 5.0,
    "link": "https://huggingface.co/EleutherAI/pythia-2.7b",
    "still_on_hub": true
  },
  {
    "name": "falcon-rw-1b",
    "author": "tiiuae",
    "query_name": "tiiuae/falcon-rw-1b",
    "score": 37.07,
    "likes": 58.0,
    "link": "https://huggingface.co/tiiuae/falcon-rw-1b",
    "still_on_hub": true
  },
  {
    "name": "Phind-CodeLlama-34B-v1",
    "author": "Phind",
    "query_name": "Phind/Phind-CodeLlama-34B-v1",
    "score": 37.06,
    "likes": 317.0,
    "link": "https://huggingface.co/Phind/Phind-CodeLlama-34B-v1",
    "still_on_hub": true
  },
  {
    "name": "bloomz-3b",
    "author": "bigscience",
    "query_name": "bigscience/bloomz-3b",
    "score": 37.03,
    "likes": 70.0,
    "link": "https://huggingface.co/bigscience/bloomz-3b",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-13b-Python-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-13b-Python-hf",
    "score": 37.0,
    "likes": 22.0,
    "link": "https://huggingface.co/codellama/CodeLlama-13b-Python-hf",
    "still_on_hub": true
  },
  {
    "name": "OPT-2.7B-Erebus",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-2.7B-Erebus",
    "score": 36.96,
    "likes": 32.0,
    "link": "https://huggingface.co/KoboldAI/OPT-2.7B-Erebus",
    "still_on_hub": true
  },
  {
    "name": "bloomz-3b-sft-chat",
    "author": "cmarkea",
    "query_name": "cmarkea/bloomz-3b-sft-chat",
    "score": 36.94,
    "likes": 8.0,
    "link": "https://huggingface.co/cmarkea/bloomz-3b-sft-chat",
    "still_on_hub": true
  },
  {
    "name": "blossom-v1-3b",
    "author": "Azure99",
    "query_name": "Azure99/blossom-v1-3b",
    "score": 36.9,
    "likes": 0.0,
    "link": "https://huggingface.co/Azure99/blossom-v1-3b",
    "still_on_hub": true
  },
  {
    "name": "Phind-CodeLlama-34B-v2",
    "author": "Phind",
    "query_name": "Phind/Phind-CodeLlama-34B-v2",
    "score": 36.89,
    "likes": 365.0,
    "link": "https://huggingface.co/Phind/Phind-CodeLlama-34B-v2",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-7b-Python-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-7b-Python-hf",
    "score": 36.89,
    "likes": 54.0,
    "link": "https://huggingface.co/codellama/CodeLlama-7b-Python-hf",
    "still_on_hub": true
  },
  {
    "name": "3B-redpajama-conditional-alpha",
    "author": "Rallio67",
    "query_name": "Rallio67/3B-redpajama-conditional-alpha",
    "score": 36.88,
    "likes": 0.0,
    "link": "https://huggingface.co/Rallio67/3B-redpajama-conditional-alpha",
    "still_on_hub": true
  },
  {
    "name": "falcon_1b_stage2",
    "author": "euclaise",
    "query_name": "euclaise/falcon_1b_stage2",
    "score": 36.88,
    "likes": 1.0,
    "link": "https://huggingface.co/euclaise/falcon_1b_stage2",
    "still_on_hub": true
  },
  {
    "name": "OPT-2.7B-Nerybus-Mix",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-2.7B-Nerybus-Mix",
    "score": 36.88,
    "likes": 9.0,
    "link": "https://huggingface.co/KoboldAI/OPT-2.7B-Nerybus-Mix",
    "still_on_hub": true
  },
  {
    "name": "openbuddy-openllama-3b-v10-bf16",
    "author": "OpenBuddy",
    "query_name": "OpenBuddy/openbuddy-openllama-3b-v10-bf16",
    "score": 36.87,
    "likes": 6.0,
    "link": "https://huggingface.co/OpenBuddy/openbuddy-openllama-3b-v10-bf16",
    "still_on_hub": true
  },
  {
    "name": "camel-5b-hf",
    "author": "Writer",
    "query_name": "Writer/camel-5b-hf",
    "score": 36.81,
    "likes": 103.0,
    "link": "https://huggingface.co/Writer/camel-5b-hf",
    "still_on_hub": true
  },
  {
    "name": "pythia-2.8b-4bit-alpaca",
    "author": "TFLai",
    "query_name": "TFLai/pythia-2.8b-4bit-alpaca",
    "score": 36.77,
    "likes": 1.0,
    "link": "https://huggingface.co/TFLai/pythia-2.8b-4bit-alpaca",
    "still_on_hub": false
  },
  {
    "name": "OPT-2.7B-Nerys-v2",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-2.7B-Nerys-v2",
    "score": 36.75,
    "likes": 5.0,
    "link": "https://huggingface.co/KoboldAI/OPT-2.7B-Nerys-v2",
    "still_on_hub": true
  },
  {
    "name": "dopeyshearedplats-1.3b-v1",
    "author": "vihangd",
    "query_name": "vihangd/dopeyshearedplats-1.3b-v1",
    "score": 36.74,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/dopeyshearedplats-1.3b-v1",
    "still_on_hub": true
  },
  {
    "name": "opt-2.7b",
    "author": "facebook",
    "query_name": "facebook/opt-2.7b",
    "score": 36.74,
    "likes": 46.0,
    "link": "https://huggingface.co/facebook/opt-2.7b",
    "still_on_hub": true
  },
  {
    "name": "LLmRa-2.7B",
    "author": "L-R",
    "query_name": "L-R/LLmRa-2.7B",
    "score": 36.72,
    "likes": 0.0,
    "link": "https://huggingface.co/L-R/LLmRa-2.7B",
    "still_on_hub": true
  },
  {
    "name": "pythia-2.8b-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-2.8b-deduped",
    "score": 36.72,
    "likes": 12.0,
    "link": "https://huggingface.co/EleutherAI/pythia-2.8b-deduped",
    "still_on_hub": true
  },
  {
    "name": "chopt-2_7b",
    "author": "aisquared",
    "query_name": "aisquared/chopt-2_7b",
    "score": 36.72,
    "likes": 0.0,
    "link": "https://huggingface.co/aisquared/chopt-2_7b",
    "still_on_hub": true
  },
  {
    "name": "open_llama_3b_600bt_preview",
    "author": "danielhanchen",
    "query_name": "danielhanchen/open_llama_3b_600bt_preview",
    "score": 36.65,
    "likes": 0.0,
    "link": "https://huggingface.co/danielhanchen/open_llama_3b_600bt_preview",
    "still_on_hub": true
  },
  {
    "name": "42dot_LLM-SFT-1.3B",
    "author": "42dot",
    "query_name": "42dot/42dot_LLM-SFT-1.3B",
    "score": 36.61,
    "likes": 12.0,
    "link": "https://huggingface.co/42dot/42dot_LLM-SFT-1.3B",
    "still_on_hub": true
  },
  {
    "name": "Deer-3b",
    "author": "PSanni",
    "query_name": "PSanni/Deer-3b",
    "score": 36.55,
    "likes": 2.0,
    "link": "https://huggingface.co/PSanni/Deer-3b",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-7b-Python-hf",
    "author": "codellama",
    "query_name": "codellama/CodeLlama-7b-Python-hf",
    "score": 36.42,
    "likes": 54.0,
    "link": "https://huggingface.co/codellama/CodeLlama-7b-Python-hf",
    "still_on_hub": true
  },
  {
    "name": "xglm-7.5B",
    "author": "facebook",
    "query_name": "facebook/xglm-7.5B",
    "score": 36.38,
    "likes": 43.0,
    "link": "https://huggingface.co/facebook/xglm-7.5B",
    "still_on_hub": true
  },
  {
    "name": "Phind-CodeLlama-34B-Python-v1",
    "author": "Phind",
    "query_name": "Phind/Phind-CodeLlama-34B-Python-v1",
    "score": 36.33,
    "likes": 231.0,
    "link": "https://huggingface.co/Phind/Phind-CodeLlama-34B-Python-v1",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-6.7B",
    "author": "cerebras",
    "query_name": "cerebras/Cerebras-GPT-6.7B",
    "score": 36.27,
    "likes": 61.0,
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-6.7B",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
    "author": "TinyLlama",
    "query_name": "TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
    "score": 36.26,
    "likes": 1.0,
    "link": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
    "still_on_hub": true
  },
  {
    "name": "gpt-neo-2.7B",
    "author": "EleutherAI",
    "query_name": "EleutherAI/gpt-neo-2.7B",
    "score": 36.2,
    "likes": 361.0,
    "link": "https://huggingface.co/EleutherAI/gpt-neo-2.7B",
    "still_on_hub": true
  },
  {
    "name": "bertin-gpt-j-6B-alpaca",
    "author": "bertin-project",
    "query_name": "bertin-project/bertin-gpt-j-6B-alpaca",
    "score": 36.19,
    "likes": 8.0,
    "link": "https://huggingface.co/bertin-project/bertin-gpt-j-6B-alpaca",
    "still_on_hub": true
  },
  {
    "name": "falcon_1b_stage3_2",
    "author": "euclaise",
    "query_name": "euclaise/falcon_1b_stage3_2",
    "score": 36.19,
    "likes": 0.0,
    "link": "https://huggingface.co/euclaise/falcon_1b_stage3_2",
    "still_on_hub": true
  },
  {
    "name": "StellarX-4B-V0.2",
    "author": "Dampish",
    "query_name": "Dampish/StellarX-4B-V0.2",
    "score": 36.15,
    "likes": 1.0,
    "link": "https://huggingface.co/Dampish/StellarX-4B-V0.2",
    "still_on_hub": true
  },
  {
    "name": "bloom-3b",
    "author": "bigscience",
    "query_name": "bigscience/bloom-3b",
    "score": 36.07,
    "likes": 70.0,
    "link": "https://huggingface.co/bigscience/bloom-3b",
    "still_on_hub": true
  },
  {
    "name": "Wizard-Vicuna-13B-Uncensored-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ",
    "score": 36.06,
    "likes": 242.0,
    "link": "https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "blossom-v2-3b",
    "author": "Azure99",
    "query_name": "Azure99/blossom-v2-3b",
    "score": 35.98,
    "likes": 0.0,
    "link": "https://huggingface.co/Azure99/blossom-v2-3b",
    "still_on_hub": true
  },
  {
    "name": "shearedplats-1.3b-v1",
    "author": "vihangd",
    "query_name": "vihangd/shearedplats-1.3b-v1",
    "score": 35.97,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/shearedplats-1.3b-v1",
    "still_on_hub": true
  },
  {
    "name": "Sheared-LLaMA-1.3B",
    "author": "princeton-nlp",
    "query_name": "princeton-nlp/Sheared-LLaMA-1.3B",
    "score": 35.95,
    "likes": 28.0,
    "link": "https://huggingface.co/princeton-nlp/Sheared-LLaMA-1.3B",
    "still_on_hub": true
  },
  {
    "name": "GPT-J-6B-Adventure",
    "author": "KoboldAI",
    "query_name": "KoboldAI/GPT-J-6B-Adventure",
    "score": 35.95,
    "likes": 15.0,
    "link": "https://huggingface.co/KoboldAI/GPT-J-6B-Adventure",
    "still_on_hub": true
  },
  {
    "name": "CodeLlama-34b-Python-hf",
    "author": "ehartford",
    "query_name": "ehartford/CodeLlama-34b-Python-hf",
    "score": 35.92,
    "likes": 2.0,
    "link": "https://huggingface.co/ehartford/CodeLlama-34b-Python-hf",
    "still_on_hub": true
  },
  {
    "name": "opt-flan-iml-6.7b",
    "author": "MayaPH",
    "query_name": "MayaPH/opt-flan-iml-6.7b",
    "score": 35.84,
    "likes": 1.0,
    "link": "https://huggingface.co/MayaPH/opt-flan-iml-6.7b",
    "still_on_hub": true
  },
  {
    "name": "rwkv-raven-3b",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-raven-3b",
    "score": 35.81,
    "likes": 6.0,
    "link": "https://huggingface.co/RWKV/rwkv-raven-3b",
    "still_on_hub": true
  },
  {
    "name": "ShearedLlama-1.3b-FFT-Test1",
    "author": "Dans-DiscountModels",
    "query_name": "Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1",
    "score": 35.71,
    "likes": 0.0,
    "link": "https://huggingface.co/Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1",
    "still_on_hub": true
  },
  {
    "name": "42dot_LLM-PLM-1.3B",
    "author": "42dot",
    "query_name": "42dot/42dot_LLM-PLM-1.3B",
    "score": 35.7,
    "likes": 12.0,
    "link": "https://huggingface.co/42dot/42dot_LLM-PLM-1.3B",
    "still_on_hub": true
  },
  {
    "name": "starcoder-finetune-selfinstruct",
    "author": "sartmis1",
    "query_name": "sartmis1/starcoder-finetune-selfinstruct",
    "score": 35.65,
    "likes": 0.0,
    "link": "https://huggingface.co/sartmis1/starcoder-finetune-selfinstruct",
    "still_on_hub": false
  },
  {
    "name": "20231206094523-pretrain-Llama-2-13b-hf-76000",
    "author": "zyh3826",
    "query_name": "zyh3826/20231206094523-pretrain-Llama-2-13b-hf-76000",
    "score": 35.58,
    "likes": 0.0,
    "link": "https://huggingface.co/zyh3826/20231206094523-pretrain-Llama-2-13b-hf-76000",
    "still_on_hub": true
  },
  {
    "name": "tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
    "author": "habanoz",
    "query_name": "habanoz/tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
    "score": 35.58,
    "likes": 0.0,
    "link": "https://huggingface.co/habanoz/tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1",
    "still_on_hub": true
  },
  {
    "name": "wizard-vicuna-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/wizard-vicuna-13B-GPTQ",
    "score": 35.56,
    "likes": 99.0,
    "link": "https://huggingface.co/TheBloke/wizard-vicuna-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-Chat-v0.3",
    "author": "PY007",
    "query_name": "PY007/TinyLlama-1.1B-Chat-v0.3",
    "score": 35.56,
    "likes": 5.0,
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-Chat-v0.3",
    "still_on_hub": false
  },
  {
    "name": "wangchanglm-7.5B-sft-en-sharded",
    "author": "pythainlp",
    "query_name": "pythainlp/wangchanglm-7.5B-sft-en-sharded",
    "score": 35.55,
    "likes": 0.0,
    "link": "https://huggingface.co/pythainlp/wangchanglm-7.5B-sft-en-sharded",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-FFT-Test2",
    "author": "Dans-DiscountModels",
    "query_name": "Dans-DiscountModels/TinyLlama-1.1B-FFT-Test2",
    "score": 35.53,
    "likes": 0.0,
    "link": "https://huggingface.co/Dans-DiscountModels/TinyLlama-1.1B-FFT-Test2",
    "still_on_hub": true
  },
  {
    "name": "starchat-alpha",
    "author": "HuggingFaceH4",
    "query_name": "HuggingFaceH4/starchat-alpha",
    "score": 35.49,
    "likes": 220.0,
    "link": "https://huggingface.co/HuggingFaceH4/starchat-alpha",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-1.4.1-PI-8192-fp16",
    "author": "bhenrym14",
    "query_name": "bhenrym14/airoboros-33b-gpt4-1.4.1-PI-8192-fp16",
    "score": 35.46,
    "likes": 1.0,
    "link": "https://huggingface.co/bhenrym14/airoboros-33b-gpt4-1.4.1-PI-8192-fp16",
    "still_on_hub": true
  },
  {
    "name": "ShortKingv0.1",
    "author": "AtAndDev",
    "query_name": "AtAndDev/ShortKingv0.1",
    "score": 35.45,
    "likes": 2.0,
    "link": "https://huggingface.co/AtAndDev/ShortKingv0.1",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1",
    "author": "habanoz",
    "query_name": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1",
    "score": 35.45,
    "likes": 0.0,
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1",
    "still_on_hub": true
  },
  {
    "name": "Nape-0",
    "author": "nnpy",
    "query_name": "nnpy/Nape-0",
    "score": 35.43,
    "likes": 0.0,
    "link": "https://huggingface.co/nnpy/Nape-0",
    "still_on_hub": true
  },
  {
    "name": "starcoder_mirror",
    "author": "lizhuang144",
    "query_name": "lizhuang144/starcoder_mirror",
    "score": 35.43,
    "likes": 0.0,
    "link": "https://huggingface.co/lizhuang144/starcoder_mirror",
    "still_on_hub": false
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
    "author": "habanoz",
    "query_name": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
    "score": 35.42,
    "likes": 0.0,
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1",
    "still_on_hub": true
  },
  {
    "name": "openchat_v2_openorca_preview-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/openchat_v2_openorca_preview-GPTQ",
    "score": 35.38,
    "likes": 14.0,
    "link": "https://huggingface.co/TheBloke/openchat_v2_openorca_preview-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "chopt-1_3b",
    "author": "aisquared",
    "query_name": "aisquared/chopt-1_3b",
    "score": 35.32,
    "likes": 0.0,
    "link": "https://huggingface.co/aisquared/chopt-1_3b",
    "still_on_hub": true
  },
  {
    "name": "Walter-Llama-1B",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Walter-Llama-1B",
    "score": 35.29,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/Walter-Llama-1B",
    "still_on_hub": true
  },
  {
    "name": "dopeyplats-1.1b-2T-v1",
    "author": "vihangd",
    "query_name": "vihangd/dopeyplats-1.1b-2T-v1",
    "score": 35.28,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/dopeyplats-1.1b-2T-v1",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
    "author": "habanoz",
    "query_name": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
    "score": 35.28,
    "likes": 0.0,
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1",
    "still_on_hub": true
  },
  {
    "name": "rwkv-4-3b-pile",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-4-3b-pile",
    "score": 35.25,
    "likes": 2.0,
    "link": "https://huggingface.co/RWKV/rwkv-4-3b-pile",
    "still_on_hub": true
  },
  {
    "name": "Deacon-1b",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Deacon-1b",
    "score": 35.21,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/Deacon-1b",
    "still_on_hub": true
  },
  {
    "name": "opt-iml-max-1.3b",
    "author": "facebook",
    "query_name": "facebook/opt-iml-max-1.3b",
    "score": 35.21,
    "likes": 34.0,
    "link": "https://huggingface.co/facebook/opt-iml-max-1.3b",
    "still_on_hub": true
  },
  {
    "name": "palmyra-base",
    "author": "Writer",
    "query_name": "Writer/palmyra-base",
    "score": 35.18,
    "likes": 33.0,
    "link": "https://huggingface.co/Writer/palmyra-base",
    "still_on_hub": true
  },
  {
    "name": "wizard-mega-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/wizard-mega-13B-GPTQ",
    "score": 35.18,
    "likes": 102.0,
    "link": "https://huggingface.co/TheBloke/wizard-mega-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "fairseq-dense-1.3B",
    "author": "KoboldAI",
    "query_name": "KoboldAI/fairseq-dense-1.3B",
    "score": 35.16,
    "likes": 4.0,
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-1.3B",
    "still_on_hub": true
  },
  {
    "name": "chronos-wizardlm-uc-scot-st-13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/chronos-wizardlm-uc-scot-st-13B-GPTQ",
    "score": 35.15,
    "likes": 6.0,
    "link": "https://huggingface.co/TheBloke/chronos-wizardlm-uc-scot-st-13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "pythia-1.4b-deduped-sharegpt",
    "author": "HWERI",
    "query_name": "HWERI/pythia-1.4b-deduped-sharegpt",
    "score": 35.11,
    "likes": 1.0,
    "link": "https://huggingface.co/HWERI/pythia-1.4b-deduped-sharegpt",
    "still_on_hub": true
  },
  {
    "name": "pythia-1.4b-deduped-sharegpt",
    "author": "beaugogh",
    "query_name": "beaugogh/pythia-1.4b-deduped-sharegpt",
    "score": 35.11,
    "likes": 0.0,
    "link": "https://huggingface.co/beaugogh/pythia-1.4b-deduped-sharegpt",
    "still_on_hub": true
  },
  {
    "name": "wangchanglm-7.5B-sft-enth",
    "author": "pythainlp",
    "query_name": "pythainlp/wangchanglm-7.5B-sft-enth",
    "score": 35.11,
    "likes": 6.0,
    "link": "https://huggingface.co/pythainlp/wangchanglm-7.5B-sft-enth",
    "still_on_hub": true
  },
  {
    "name": "metharme-1.3b",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/metharme-1.3b",
    "score": 35.04,
    "likes": 18.0,
    "link": "https://huggingface.co/PygmalionAI/metharme-1.3b",
    "still_on_hub": true
  },
  {
    "name": "falcon-1b-t-sft",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/falcon-1b-t-sft",
    "score": 35.02,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/falcon-1b-t-sft",
    "still_on_hub": true
  },
  {
    "name": "LLmRa-1.3B",
    "author": "L-R",
    "query_name": "L-R/LLmRa-1.3B",
    "score": 35.0,
    "likes": 0.0,
    "link": "https://huggingface.co/L-R/LLmRa-1.3B",
    "still_on_hub": true
  },
  {
    "name": "pythia-1.4b-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-1.4b-deduped",
    "score": 35.0,
    "likes": 18.0,
    "link": "https://huggingface.co/EleutherAI/pythia-1.4b-deduped",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1",
    "author": "habanoz",
    "query_name": "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1",
    "score": 34.98,
    "likes": 0.0,
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1",
    "still_on_hub": true
  },
  {
    "name": "falcon_1b_stage3",
    "author": "euclaise",
    "query_name": "euclaise/falcon_1b_stage3",
    "score": 34.95,
    "likes": 0.0,
    "link": "https://huggingface.co/euclaise/falcon_1b_stage3",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-Chat-v0.6",
    "author": "TinyLlama",
    "query_name": "TinyLlama/TinyLlama-1.1B-Chat-v0.6",
    "score": 34.94,
    "likes": 3.0,
    "link": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.6",
    "still_on_hub": true
  },
  {
    "name": "stablelm-7b-sft-v7-epoch-3",
    "author": "OpenAssistant",
    "query_name": "OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "score": 34.85,
    "likes": 65.0,
    "link": "https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3",
    "still_on_hub": true
  },
  {
    "name": "Tiny-Vicuna-1B",
    "author": "Jiayi-Pan",
    "query_name": "Jiayi-Pan/Tiny-Vicuna-1B",
    "score": 34.76,
    "likes": 0.0,
    "link": "https://huggingface.co/Jiayi-Pan/Tiny-Vicuna-1B",
    "still_on_hub": true
  },
  {
    "name": "megachat",
    "author": "w95",
    "query_name": "w95/megachat",
    "score": 34.75,
    "likes": 0.0,
    "link": "https://huggingface.co/w95/megachat",
    "still_on_hub": true
  },
  {
    "name": "lamini-neo-1.3b",
    "author": "MBZUAI",
    "query_name": "MBZUAI/lamini-neo-1.3b",
    "score": 34.73,
    "likes": 11.0,
    "link": "https://huggingface.co/MBZUAI/lamini-neo-1.3b",
    "still_on_hub": true
  },
  {
    "name": "LaMini-GPT-1.5B",
    "author": "MBZUAI",
    "query_name": "MBZUAI/LaMini-GPT-1.5B",
    "score": 34.67,
    "likes": 32.0,
    "link": "https://huggingface.co/MBZUAI/LaMini-GPT-1.5B",
    "still_on_hub": true
  },
  {
    "name": "WizardCoder-15B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardCoder-15B-V1.0",
    "score": 34.64,
    "likes": 621.0,
    "link": "https://huggingface.co/WizardLM/WizardCoder-15B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "opt-1.3b",
    "author": "facebook",
    "query_name": "facebook/opt-1.3b",
    "score": 34.6,
    "likes": 117.0,
    "link": "https://huggingface.co/facebook/opt-1.3b",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-Chat-v0.1",
    "author": "PY007",
    "query_name": "PY007/TinyLlama-1.1B-Chat-v0.1",
    "score": 34.57,
    "likes": 22.0,
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-Chat-v0.1",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-955k-token-2T",
    "author": "TinyLlama",
    "query_name": "TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T",
    "score": 34.56,
    "likes": 12.0,
    "link": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-1.3b-instruct",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-1.3b-instruct",
    "score": 34.54,
    "likes": 1.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-1.3b-instruct",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
    "author": "habanoz",
    "query_name": "habanoz/TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
    "score": 34.53,
    "likes": 0.0,
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "author": "bhenrym14",
    "query_name": "bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "score": 34.53,
    "likes": 4.0,
    "link": "https://huggingface.co/bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16",
    "still_on_hub": true
  },
  {
    "name": "tinyllama-1.1b-chat-v0.3_platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/tinyllama-1.1b-chat-v0.3_platypus",
    "score": 34.5,
    "likes": 3.0,
    "link": "https://huggingface.co/lgaalves/tinyllama-1.1b-chat-v0.3_platypus",
    "still_on_hub": true
  },
  {
    "name": "pythia-1.3b",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-1.3b",
    "score": 34.46,
    "likes": 7.0,
    "link": "https://huggingface.co/EleutherAI/pythia-1.3b",
    "still_on_hub": true
  },
  {
    "name": "PULI-GPTrio",
    "author": "NYTK",
    "query_name": "NYTK/PULI-GPTrio",
    "score": 34.42,
    "likes": 5.0,
    "link": "https://huggingface.co/NYTK/PULI-GPTrio",
    "still_on_hub": true
  },
  {
    "name": "gpt2-xl",
    "author": "gpt2-xl",
    "query_name": "gpt2-xl",
    "score": 34.38,
    "likes": 194.0,
    "link": "https://huggingface.co/gpt2-xl",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-480k-1T",
    "author": "PY007",
    "query_name": "PY007/TinyLlama-1.1B-intermediate-step-480k-1T",
    "score": 34.37,
    "likes": 15.0,
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-intermediate-step-480k-1T",
    "still_on_hub": true
  },
  {
    "name": "EverythingLM-13B-16K-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/EverythingLM-13B-16K-GPTQ",
    "score": 34.37,
    "likes": 10.0,
    "link": "https://huggingface.co/TheBloke/EverythingLM-13B-16K-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "stablelm-base-alpha-7b",
    "author": "stabilityai",
    "query_name": "stabilityai/stablelm-base-alpha-7b",
    "score": 34.37,
    "likes": 208.0,
    "link": "https://huggingface.co/stabilityai/stablelm-base-alpha-7b",
    "still_on_hub": true
  },
  {
    "name": "h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt",
    "author": "h2oai",
    "query_name": "h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt",
    "score": 34.32,
    "likes": 12.0,
    "link": "https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b-preview-300bt",
    "still_on_hub": true
  },
  {
    "name": "xglm-4.5B",
    "author": "facebook",
    "query_name": "facebook/xglm-4.5B",
    "score": 34.31,
    "likes": 11.0,
    "link": "https://huggingface.co/facebook/xglm-4.5B",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-1.3b",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-1.3b",
    "score": 34.31,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-1.3b",
    "still_on_hub": true
  },
  {
    "name": "llama-2-4b",
    "author": "winglian",
    "query_name": "winglian/llama-2-4b",
    "score": 34.23,
    "likes": 2.0,
    "link": "https://huggingface.co/winglian/llama-2-4b",
    "still_on_hub": true
  },
  {
    "name": "LLmRa-1.3B_V2",
    "author": "L-R",
    "query_name": "L-R/LLmRa-1.3B_V2",
    "score": 34.21,
    "likes": 0.0,
    "link": "https://huggingface.co/L-R/LLmRa-1.3B_V2",
    "still_on_hub": true
  },
  {
    "name": "dlite-v2-1_5b",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v2-1_5b",
    "score": 34.2,
    "likes": 10.0,
    "link": "https://huggingface.co/aisquared/dlite-v2-1_5b",
    "still_on_hub": true
  },
  {
    "name": "WizardCoder-Guanaco-15B-V1.1",
    "author": "LoupGarou",
    "query_name": "LoupGarou/WizardCoder-Guanaco-15B-V1.1",
    "score": 34.19,
    "likes": 11.0,
    "link": "https://huggingface.co/LoupGarou/WizardCoder-Guanaco-15B-V1.1",
    "still_on_hub": true
  },
  {
    "name": "starcoder-gpteacher-code-instruct",
    "author": "GeorgiaTechResearchInstitute",
    "query_name": "GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct",
    "score": 34.15,
    "likes": 74.0,
    "link": "https://huggingface.co/GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct",
    "still_on_hub": true
  },
  {
    "name": "gpt2-xl_lima",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2-xl_lima",
    "score": 34.12,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/gpt2-xl_lima",
    "still_on_hub": true
  },
  {
    "name": "Walter-Falcon-1B",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/Walter-Falcon-1B",
    "score": 34.07,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/Walter-Falcon-1B",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1",
    "author": "habanoz",
    "query_name": "habanoz/TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1",
    "score": 34.04,
    "likes": 0.0,
    "link": "https://huggingface.co/habanoz/TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1",
    "still_on_hub": true
  },
  {
    "name": "stablelm-tuned-alpha-7b",
    "author": "stabilityai",
    "query_name": "stabilityai/stablelm-tuned-alpha-7b",
    "score": 34.04,
    "likes": 350.0,
    "link": "https://huggingface.co/stabilityai/stablelm-tuned-alpha-7b",
    "still_on_hub": true
  },
  {
    "name": "opt-1.3b-rlhf",
    "author": "jzjiao",
    "query_name": "jzjiao/opt-1.3b-rlhf",
    "score": 33.99,
    "likes": 0.0,
    "link": "https://huggingface.co/jzjiao/opt-1.3b-rlhf",
    "still_on_hub": true
  },
  {
    "name": "bloom-1b7",
    "author": "bigscience",
    "query_name": "bigscience/bloom-1b7",
    "score": 33.98,
    "likes": 100.0,
    "link": "https://huggingface.co/bigscience/bloom-1b7",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-2.7b",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/pygmalion-2.7b",
    "score": 33.98,
    "likes": 48.0,
    "link": "https://huggingface.co/PygmalionAI/pygmalion-2.7b",
    "still_on_hub": true
  },
  {
    "name": "WizardCoder-Guanaco-15B-V1.0",
    "author": "LoupGarou",
    "query_name": "LoupGarou/WizardCoder-Guanaco-15B-V1.0",
    "score": 33.96,
    "likes": 6.0,
    "link": "https://huggingface.co/LoupGarou/WizardCoder-Guanaco-15B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "gogpt-3b-bloom",
    "author": "golaxy",
    "query_name": "golaxy/gogpt-3b-bloom",
    "score": 33.96,
    "likes": 5.0,
    "link": "https://huggingface.co/golaxy/gogpt-3b-bloom",
    "still_on_hub": true
  },
  {
    "name": "gpt-2-xl_camel-ai-physics",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt-2-xl_camel-ai-physics",
    "score": 33.96,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/gpt-2-xl_camel-ai-physics",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
    "score": 33.78,
    "likes": 69.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-intermediate-step-240k-503b",
    "author": "PY007",
    "query_name": "PY007/TinyLlama-1.1B-intermediate-step-240k-503b",
    "score": 33.72,
    "likes": 14.0,
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-intermediate-step-240k-503b",
    "still_on_hub": true
  },
  {
    "name": "gpt-neo-1.3B",
    "author": "EleutherAI",
    "query_name": "EleutherAI/gpt-neo-1.3B",
    "score": 33.58,
    "likes": 206.0,
    "link": "https://huggingface.co/EleutherAI/gpt-neo-1.3B",
    "still_on_hub": true
  },
  {
    "name": "rwkv-raven-1b5",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-raven-1b5",
    "score": 33.56,
    "likes": 7.0,
    "link": "https://huggingface.co/RWKV/rwkv-raven-1b5",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-2.7B-Alpaca-SP",
    "author": "lxe",
    "query_name": "lxe/Cerebras-GPT-2.7B-Alpaca-SP",
    "score": 33.5,
    "likes": 10.0,
    "link": "https://huggingface.co/lxe/Cerebras-GPT-2.7B-Alpaca-SP",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1bee",
    "author": "BEE-spoke-data",
    "query_name": "BEE-spoke-data/TinyLlama-1.1bee",
    "score": 33.38,
    "likes": 1.0,
    "link": "https://huggingface.co/BEE-spoke-data/TinyLlama-1.1bee",
    "still_on_hub": true
  },
  {
    "name": "llama2-3b-distilled-layla-v1",
    "author": "l3utterfly",
    "query_name": "l3utterfly/llama2-3b-distilled-layla-v1",
    "score": 33.36,
    "likes": 0.0,
    "link": "https://huggingface.co/l3utterfly/llama2-3b-distilled-layla-v1",
    "still_on_hub": false
  },
  {
    "name": "dlite-v1-1_5b",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v1-1_5b",
    "score": 33.35,
    "likes": 1.0,
    "link": "https://huggingface.co/aisquared/dlite-v1-1_5b",
    "still_on_hub": true
  },
  {
    "name": "polyglot-ko-12.8b",
    "author": "EleutherAI",
    "query_name": "EleutherAI/polyglot-ko-12.8b",
    "score": 33.33,
    "likes": 59.0,
    "link": "https://huggingface.co/EleutherAI/polyglot-ko-12.8b",
    "still_on_hub": true
  },
  {
    "name": "gpt2-xl-sft",
    "author": "MrNJK",
    "query_name": "MrNJK/gpt2-xl-sft",
    "score": 33.31,
    "likes": 0.0,
    "link": "https://huggingface.co/MrNJK/gpt2-xl-sft",
    "still_on_hub": true
  },
  {
    "name": "Quokka_2.7b",
    "author": "Corianas",
    "query_name": "Corianas/Quokka_2.7b",
    "score": 33.26,
    "likes": 0.0,
    "link": "https://huggingface.co/Corianas/Quokka_2.7b",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-2.7B",
    "author": "cerebras",
    "query_name": "cerebras/Cerebras-GPT-2.7B",
    "score": 33.25,
    "likes": 41.0,
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-2.7B",
    "still_on_hub": true
  },
  {
    "name": "rwkv-4-1b5-pile",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-4-1b5-pile",
    "score": 33.25,
    "likes": 5.0,
    "link": "https://huggingface.co/RWKV/rwkv-4-1b5-pile",
    "still_on_hub": true
  },
  {
    "name": "Sparse0.5_OPT-1.3",
    "author": "shaohang",
    "query_name": "shaohang/Sparse0.5_OPT-1.3",
    "score": 33.19,
    "likes": 0.0,
    "link": "https://huggingface.co/shaohang/Sparse0.5_OPT-1.3",
    "still_on_hub": true
  },
  {
    "name": "SparseOPT-1.3B",
    "author": "shaohang",
    "query_name": "shaohang/SparseOPT-1.3B",
    "score": 33.19,
    "likes": 0.0,
    "link": "https://huggingface.co/shaohang/SparseOPT-1.3B",
    "still_on_hub": true
  },
  {
    "name": "gpt3-finnish-13B",
    "author": "TurkuNLP",
    "query_name": "TurkuNLP/gpt3-finnish-13B",
    "score": 32.95,
    "likes": 10.0,
    "link": "https://huggingface.co/TurkuNLP/gpt3-finnish-13B",
    "still_on_hub": true
  },
  {
    "name": "dlite-v2-774m",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v2-774m",
    "score": 32.86,
    "likes": 8.0,
    "link": "https://huggingface.co/aisquared/dlite-v2-774m",
    "still_on_hub": true
  },
  {
    "name": "pythia-1b-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-1b-deduped",
    "score": 32.78,
    "likes": 13.0,
    "link": "https://huggingface.co/EleutherAI/pythia-1b-deduped",
    "still_on_hub": true
  },
  {
    "name": "RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096",
    "score": 32.68,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/RWKV-4-PilePlus-1B5-20230520-2942-486Gtokens-ctx4096",
    "still_on_hub": true
  },
  {
    "name": "b1ade-1b",
    "author": "w601sxs",
    "query_name": "w601sxs/b1ade-1b",
    "score": 32.59,
    "likes": 0.0,
    "link": "https://huggingface.co/w601sxs/b1ade-1b",
    "still_on_hub": true
  },
  {
    "name": "gpt-neo-1.3B-4bit-alpaca",
    "author": "TFLai",
    "query_name": "TFLai/gpt-neo-1.3B-4bit-alpaca",
    "score": 32.58,
    "likes": 1.0,
    "link": "https://huggingface.co/TFLai/gpt-neo-1.3B-4bit-alpaca",
    "still_on_hub": false
  },
  {
    "name": "bloom-1b1",
    "author": "bigscience",
    "query_name": "bigscience/bloom-1b1",
    "score": 32.47,
    "likes": 41.0,
    "link": "https://huggingface.co/bigscience/bloom-1b1",
    "still_on_hub": true
  },
  {
    "name": "bilingual-gpt-neox-4b-instruction-sft",
    "author": "rinna",
    "query_name": "rinna/bilingual-gpt-neox-4b-instruction-sft",
    "score": 32.46,
    "likes": 14.0,
    "link": "https://huggingface.co/rinna/bilingual-gpt-neox-4b-instruction-sft",
    "still_on_hub": true
  },
  {
    "name": "pile-7b-250b-tokens",
    "author": "Kunhao",
    "query_name": "Kunhao/pile-7b-250b-tokens",
    "score": 32.44,
    "likes": 0.0,
    "link": "https://huggingface.co/Kunhao/pile-7b-250b-tokens",
    "still_on_hub": true
  },
  {
    "name": "LaMini-GPT-774M",
    "author": "MBZUAI",
    "query_name": "MBZUAI/LaMini-GPT-774M",
    "score": 32.43,
    "likes": 8.0,
    "link": "https://huggingface.co/MBZUAI/LaMini-GPT-774M",
    "still_on_hub": true
  },
  {
    "name": "codegen-6B-multi",
    "author": "Salesforce",
    "query_name": "Salesforce/codegen-6B-multi",
    "score": 32.43,
    "likes": 18.0,
    "link": "https://huggingface.co/Salesforce/codegen-6B-multi",
    "still_on_hub": true
  },
  {
    "name": "Bloom_1b_Quantized",
    "author": "FabbriSimo01",
    "query_name": "FabbriSimo01/Bloom_1b_Quantized",
    "score": 32.41,
    "likes": 0.0,
    "link": "https://huggingface.co/FabbriSimo01/Bloom_1b_Quantized",
    "still_on_hub": true
  },
  {
    "name": "deepseek-coder-1.3b-instruct",
    "author": "deepseek-ai",
    "query_name": "deepseek-ai/deepseek-coder-1.3b-instruct",
    "score": 32.4,
    "likes": 28.0,
    "link": "https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct",
    "still_on_hub": true
  },
  {
    "name": "gpt2-large-conversational",
    "author": "Locutusque",
    "query_name": "Locutusque/gpt2-large-conversational",
    "score": 32.33,
    "likes": 2.0,
    "link": "https://huggingface.co/Locutusque/gpt2-large-conversational",
    "still_on_hub": true
  },
  {
    "name": "bilingual-gpt-neox-4b-8k",
    "author": "rinna",
    "query_name": "rinna/bilingual-gpt-neox-4b-8k",
    "score": 32.23,
    "likes": 22.0,
    "link": "https://huggingface.co/rinna/bilingual-gpt-neox-4b-8k",
    "still_on_hub": true
  },
  {
    "name": "gpt2-xl-alpaca",
    "author": "Rachneet",
    "query_name": "Rachneet/gpt2-xl-alpaca",
    "score": 32.21,
    "likes": 0.0,
    "link": "https://huggingface.co/Rachneet/gpt2-xl-alpaca",
    "still_on_hub": true
  },
  {
    "name": "test-3b",
    "author": "Devio",
    "query_name": "Devio/test-3b",
    "score": 32.2,
    "likes": 0.0,
    "link": "https://huggingface.co/Devio/test-3b",
    "still_on_hub": true
  },
  {
    "name": "bilingual-gpt-neox-4b",
    "author": "rinna",
    "query_name": "rinna/bilingual-gpt-neox-4b",
    "score": 32.14,
    "likes": 21.0,
    "link": "https://huggingface.co/rinna/bilingual-gpt-neox-4b",
    "still_on_hub": true
  },
  {
    "name": "stablelm-tuned-alpha-3b",
    "author": "stabilityai",
    "query_name": "stabilityai/stablelm-tuned-alpha-3b",
    "score": 32.14,
    "likes": 106.0,
    "link": "https://huggingface.co/stabilityai/stablelm-tuned-alpha-3b",
    "still_on_hub": true
  },
  {
    "name": "Medical-ChatBot",
    "author": "Mohammed-Altaf",
    "query_name": "Mohammed-Altaf/Medical-ChatBot",
    "score": 32.13,
    "likes": 0.0,
    "link": "https://huggingface.co/Mohammed-Altaf/Medical-ChatBot",
    "still_on_hub": true
  },
  {
    "name": "Medical-ChatBot",
    "author": "Mohammed-Altaf",
    "query_name": "Mohammed-Altaf/Medical-ChatBot",
    "score": 31.98,
    "likes": 0.0,
    "link": "https://huggingface.co/Mohammed-Altaf/Medical-ChatBot",
    "still_on_hub": true
  },
  {
    "name": "Medical-ChatBot",
    "author": "Mohammed-Altaf",
    "query_name": "Mohammed-Altaf/Medical-ChatBot",
    "score": 31.87,
    "likes": 0.0,
    "link": "https://huggingface.co/Mohammed-Altaf/Medical-ChatBot",
    "still_on_hub": true
  },
  {
    "name": "TinyLlama-1.1B-step-50K-105b",
    "author": "PY007",
    "query_name": "PY007/TinyLlama-1.1B-step-50K-105b",
    "score": 31.86,
    "likes": 102.0,
    "link": "https://huggingface.co/PY007/TinyLlama-1.1B-step-50K-105b",
    "still_on_hub": true
  },
  {
    "name": "gpt2-large-lora-sft",
    "author": "Mikivis",
    "query_name": "Mikivis/gpt2-large-lora-sft",
    "score": 31.82,
    "likes": 1.0,
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-sft",
    "still_on_hub": true
  },
  {
    "name": "firefly-bloom-2b6-v2",
    "author": "YeungNLP",
    "query_name": "YeungNLP/firefly-bloom-2b6-v2",
    "score": 31.82,
    "likes": 9.0,
    "link": "https://huggingface.co/YeungNLP/firefly-bloom-2b6-v2",
    "still_on_hub": true
  },
  {
    "name": "llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
    "author": "llm-jp",
    "query_name": "llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
    "score": 31.77,
    "likes": 6.0,
    "link": "https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0",
    "still_on_hub": true
  },
  {
    "name": "orca_mini_13B-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/orca_mini_13B-GPTQ",
    "score": 31.73,
    "likes": 43.0,
    "link": "https://huggingface.co/TheBloke/orca_mini_13B-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "llm-jp-13b-instruct-full-jaster-v1.0",
    "author": "llm-jp",
    "query_name": "llm-jp/llm-jp-13b-instruct-full-jaster-v1.0",
    "score": 31.63,
    "likes": 13.0,
    "link": "https://huggingface.co/llm-jp/llm-jp-13b-instruct-full-jaster-v1.0",
    "still_on_hub": true
  },
  {
    "name": "fairseq-dense-355M",
    "author": "KoboldAI",
    "query_name": "KoboldAI/fairseq-dense-355M",
    "score": 31.58,
    "likes": 6.0,
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-355M",
    "still_on_hub": true
  },
  {
    "name": "pythia-410m",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-410m",
    "score": 31.55,
    "likes": 8.0,
    "link": "https://huggingface.co/EleutherAI/pythia-410m",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-chat-longlora-32k-sft",
    "author": "Yukang",
    "query_name": "Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "score": 31.54,
    "likes": 19.0,
    "link": "https://huggingface.co/Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "still_on_hub": true
  },
  {
    "name": "dlite-v1-774m",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v1-774m",
    "score": 31.51,
    "likes": 0.0,
    "link": "https://huggingface.co/aisquared/dlite-v1-774m",
    "still_on_hub": true
  },
  {
    "name": "gpt2-large-lora-stf4",
    "author": "Mikivis",
    "query_name": "Mikivis/gpt2-large-lora-stf4",
    "score": 31.5,
    "likes": 0.0,
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-stf4",
    "still_on_hub": true
  },
  {
    "name": "stablelm-base-alpha-3b",
    "author": "stabilityai",
    "query_name": "stabilityai/stablelm-base-alpha-3b",
    "score": 31.5,
    "likes": 82.0,
    "link": "https://huggingface.co/stabilityai/stablelm-base-alpha-3b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-chat-longlora-32k-sft",
    "author": "Yukang",
    "query_name": "Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "score": 31.43,
    "likes": 19.0,
    "link": "https://huggingface.co/Yukang/Llama-2-13b-chat-longlora-32k-sft",
    "still_on_hub": true
  },
  {
    "name": "xglm-1.7B",
    "author": "facebook",
    "query_name": "facebook/xglm-1.7B",
    "score": 31.42,
    "likes": 8.0,
    "link": "https://huggingface.co/facebook/xglm-1.7B",
    "still_on_hub": true
  },
  {
    "name": "gpt2-large-lora-sft2",
    "author": "Mikivis",
    "query_name": "Mikivis/gpt2-large-lora-sft2",
    "score": 31.33,
    "likes": 0.0,
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-sft2",
    "still_on_hub": true
  },
  {
    "name": "Aira-2-774M",
    "author": "nicholasKluge",
    "query_name": "nicholasKluge/Aira-2-774M",
    "score": 31.33,
    "likes": 2.0,
    "link": "https://huggingface.co/nicholasKluge/Aira-2-774M",
    "still_on_hub": false
  },
  {
    "name": "gpt-2-xl-EvolInstruct",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/gpt-2-xl-EvolInstruct",
    "score": 31.32,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/gpt-2-xl-EvolInstruct",
    "still_on_hub": true
  },
  {
    "name": "Cerebras_1.3b_Quantized",
    "author": "FabbriSimo01",
    "query_name": "FabbriSimo01/Cerebras_1.3b_Quantized",
    "score": 31.31,
    "likes": 0.0,
    "link": "https://huggingface.co/FabbriSimo01/Cerebras_1.3b_Quantized",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-1.3B",
    "author": "cerebras",
    "query_name": "cerebras/Cerebras-GPT-1.3B",
    "score": 31.3,
    "likes": 43.0,
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-1.3B",
    "still_on_hub": true
  },
  {
    "name": "pythia-410m-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-410m-deduped",
    "score": 31.29,
    "likes": 13.0,
    "link": "https://huggingface.co/EleutherAI/pythia-410m-deduped",
    "still_on_hub": true
  },
  {
    "name": "dlite-v2-355m",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v2-355m",
    "score": 31.2,
    "likes": 7.0,
    "link": "https://huggingface.co/aisquared/dlite-v2-355m",
    "still_on_hub": true
  },
  {
    "name": "basilisk-4b",
    "author": "winglian",
    "query_name": "winglian/basilisk-4b",
    "score": 31.15,
    "likes": 3.0,
    "link": "https://huggingface.co/winglian/basilisk-4b",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-1.3b",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/pygmalion-1.3b",
    "score": 31.14,
    "likes": 51.0,
    "link": "https://huggingface.co/PygmalionAI/pygmalion-1.3b",
    "still_on_hub": true
  },
  {
    "name": "gpt2-large-lora-sft1",
    "author": "Mikivis",
    "query_name": "Mikivis/gpt2-large-lora-sft1",
    "score": 31.01,
    "likes": 0.0,
    "link": "https://huggingface.co/Mikivis/gpt2-large-lora-sft1",
    "still_on_hub": true
  },
  {
    "name": "Aira-2-355M",
    "author": "nicholasKluge",
    "query_name": "nicholasKluge/Aira-2-355M",
    "score": 31.0,
    "likes": 0.0,
    "link": "https://huggingface.co/nicholasKluge/Aira-2-355M",
    "still_on_hub": false
  },
  {
    "name": "<p>Baseline</p>",
    "author": null,
    "query_name": "baseline",
    "score": 31.0,
    "likes": null,
    "link": null,
    "still_on_hub": null
  },
  {
    "name": "GPTNeo350M-Instruct-SFT",
    "author": "SummerSigh",
    "query_name": "SummerSigh/GPTNeo350M-Instruct-SFT",
    "score": 31.0,
    "likes": 0.0,
    "link": "https://huggingface.co/SummerSigh/GPTNeo350M-Instruct-SFT",
    "still_on_hub": true
  },
  {
    "name": "emailgen-pythia-410m-deduped",
    "author": "postbot",
    "query_name": "postbot/emailgen-pythia-410m-deduped",
    "score": 30.93,
    "likes": 0.0,
    "link": "https://huggingface.co/postbot/emailgen-pythia-410m-deduped",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-356m-instruct",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-356m-instruct",
    "score": 30.93,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-356m-instruct",
    "still_on_hub": true
  },
  {
    "name": "Quokka_1.3b",
    "author": "Corianas",
    "query_name": "Corianas/Quokka_1.3b",
    "score": 30.86,
    "likes": 0.0,
    "link": "https://huggingface.co/Corianas/Quokka_1.3b",
    "still_on_hub": true
  },
  {
    "name": "1.3b",
    "author": "Corianas",
    "query_name": "Corianas/1.3b",
    "score": 30.76,
    "likes": 2.0,
    "link": "https://huggingface.co/Corianas/1.3b",
    "still_on_hub": true
  },
  {
    "name": "bloomz-560m-sft-chat",
    "author": "cmarkea",
    "query_name": "cmarkea/bloomz-560m-sft-chat",
    "score": 30.72,
    "likes": 8.0,
    "link": "https://huggingface.co/cmarkea/bloomz-560m-sft-chat",
    "still_on_hub": true
  },
  {
    "name": "dolphinette",
    "author": "player1537",
    "query_name": "player1537/dolphinette",
    "score": 30.65,
    "likes": 0.0,
    "link": "https://huggingface.co/player1537/dolphinette",
    "still_on_hub": true
  },
  {
    "name": "bloomz-560m",
    "author": "bigscience",
    "query_name": "bigscience/bloomz-560m",
    "score": 30.63,
    "likes": 81.0,
    "link": "https://huggingface.co/bigscience/bloomz-560m",
    "still_on_hub": true
  },
  {
    "name": "medalpaca-13B-GPTQ-4bit",
    "author": "TheBloke",
    "query_name": "TheBloke/medalpaca-13B-GPTQ-4bit",
    "score": 30.62,
    "likes": 28.0,
    "link": "https://huggingface.co/TheBloke/medalpaca-13B-GPTQ-4bit",
    "still_on_hub": true
  },
  {
    "name": "dlite-v1-355m",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v1-355m",
    "score": 30.54,
    "likes": 1.0,
    "link": "https://huggingface.co/aisquared/dlite-v1-355m",
    "still_on_hub": true
  },
  {
    "name": "PT_GPTNEO350_ATG",
    "author": "xhyi",
    "query_name": "xhyi/PT_GPTNEO350_ATG",
    "score": 30.46,
    "likes": 18.0,
    "link": "https://huggingface.co/xhyi/PT_GPTNEO350_ATG",
    "still_on_hub": true
  },
  {
    "name": "DiffMerge-DollyGPT-Pygmalion",
    "author": "TehVenom",
    "query_name": "TehVenom/DiffMerge-DollyGPT-Pygmalion",
    "score": 30.45,
    "likes": 2.0,
    "link": "https://huggingface.co/TehVenom/DiffMerge-DollyGPT-Pygmalion",
    "still_on_hub": true
  },
  {
    "name": "rwkv-4-430m-pile",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-4-430m-pile",
    "score": 30.45,
    "likes": 3.0,
    "link": "https://huggingface.co/RWKV/rwkv-4-430m-pile",
    "still_on_hub": true
  },
  {
    "name": "bloom-560m-RLHF-v2",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/bloom-560m-RLHF-v2",
    "score": 30.43,
    "likes": 3.0,
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-560m-RLHF-v2",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-356m",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-356m",
    "score": 30.41,
    "likes": 1.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-356m",
    "still_on_hub": true
  },
  {
    "name": "megatron-gpt2-345m",
    "author": "robowaifudev",
    "query_name": "robowaifudev/megatron-gpt2-345m",
    "score": 30.4,
    "likes": 4.0,
    "link": "https://huggingface.co/robowaifudev/megatron-gpt2-345m",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-orca-airoboros-13b-0.10e",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "score": 30.36,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "still_on_hub": true
  },
  {
    "name": "megatron-gpt2-345m-evol_instruct_v2",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/megatron-gpt2-345m-evol_instruct_v2",
    "score": 30.31,
    "likes": 1.0,
    "link": "https://huggingface.co/KnutJaegersberg/megatron-gpt2-345m-evol_instruct_v2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-sf",
    "author": "porkorbeef",
    "query_name": "porkorbeef/Llama-2-13b-sf",
    "score": 30.22,
    "likes": 0.0,
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b-sf",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-orca-airoboros-13b-0.10e",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "score": 30.22,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-airoboros-13b-0.10e",
    "still_on_hub": true
  },
  {
    "name": "fbopt-350m-8bit",
    "author": "yec019",
    "query_name": "yec019/fbopt-350m-8bit",
    "score": 30.21,
    "likes": 0.0,
    "link": "https://huggingface.co/yec019/fbopt-350m-8bit",
    "still_on_hub": true
  },
  {
    "name": "RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
    "score": 30.18,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/RWKV-4-PilePlus-430M-20230520-6162-1018Gtokens-ctx4098",
    "still_on_hub": true
  },
  {
    "name": "llama2_xs_460M_experimental",
    "author": "ahxt",
    "query_name": "ahxt/llama2_xs_460M_experimental",
    "score": 30.17,
    "likes": 4.0,
    "link": "https://huggingface.co/ahxt/llama2_xs_460M_experimental",
    "still_on_hub": true
  },
  {
    "name": "Orca-2-7b-f16",
    "author": "uukuguy",
    "query_name": "uukuguy/Orca-2-7b-f16",
    "score": 30.15,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/Orca-2-7b-f16",
    "still_on_hub": true
  },
  {
    "name": "OPT-350M-Erebus",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-350M-Erebus",
    "score": 30.14,
    "likes": 11.0,
    "link": "https://huggingface.co/KoboldAI/OPT-350M-Erebus",
    "still_on_hub": true
  },
  {
    "name": "bloom-1b1-RLHF",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/bloom-1b1-RLHF",
    "score": 30.14,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-1b1-RLHF",
    "still_on_hub": true
  },
  {
    "name": "bloom-560m",
    "author": "bigscience",
    "query_name": "bigscience/bloom-560m",
    "score": 30.13,
    "likes": 263.0,
    "link": "https://huggingface.co/bigscience/bloom-560m",
    "still_on_hub": true
  },
  {
    "name": "med-orca-instruct-33b",
    "author": "yhyhy3",
    "query_name": "yhyhy3/med-orca-instruct-33b",
    "score": 30.12,
    "likes": 0.0,
    "link": "https://huggingface.co/yhyhy3/med-orca-instruct-33b",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b",
    "author": "porkorbeef",
    "query_name": "porkorbeef/Llama-2-13b",
    "score": 30.11,
    "likes": 0.0,
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b",
    "still_on_hub": true
  },
  {
    "name": "Healix-410M",
    "author": "health360",
    "query_name": "health360/Healix-410M",
    "score": 30.1,
    "likes": 0.0,
    "link": "https://huggingface.co/health360/Healix-410M",
    "still_on_hub": false
  },
  {
    "name": "Marcoroni-7B-LaMini-80K",
    "author": "marcchew",
    "query_name": "marcchew/Marcoroni-7B-LaMini-80K",
    "score": 30.09,
    "likes": 0.0,
    "link": "https://huggingface.co/marcchew/Marcoroni-7B-LaMini-80K",
    "still_on_hub": true
  },
  {
    "name": "test5",
    "author": "doas",
    "query_name": "doas/test5",
    "score": 30.06,
    "likes": 0.0,
    "link": "https://huggingface.co/doas/test5",
    "still_on_hub": true
  },
  {
    "name": "lamini-cerebras-1.3b",
    "author": "MBZUAI",
    "query_name": "MBZUAI/lamini-cerebras-1.3b",
    "score": 30.05,
    "likes": 1.0,
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-1.3b",
    "still_on_hub": true
  },
  {
    "name": "megatron-GPT-2-345m-EvolInstruct",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/megatron-GPT-2-345m-EvolInstruct",
    "score": 30.01,
    "likes": 4.0,
    "link": "https://huggingface.co/KnutJaegersberg/megatron-GPT-2-345m-EvolInstruct",
    "still_on_hub": true
  },
  {
    "name": "opt-350m",
    "author": "facebook",
    "query_name": "facebook/opt-350m",
    "score": 30.01,
    "likes": 75.0,
    "link": "https://huggingface.co/facebook/opt-350m",
    "still_on_hub": true
  },
  {
    "name": "test_llama2_ko_7b",
    "author": "yeen214",
    "query_name": "yeen214/test_llama2_ko_7b",
    "score": 29.99,
    "likes": 0.0,
    "link": "https://huggingface.co/yeen214/test_llama2_ko_7b",
    "still_on_hub": true
  },
  {
    "name": "phi2",
    "author": "vikp",
    "query_name": "vikp/phi2",
    "score": 29.98,
    "likes": 0.0,
    "link": "https://huggingface.co/vikp/phi2",
    "still_on_hub": false
  },
  {
    "name": "speechless-codellama-orca-platypus-13b-0.10e",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "score": 29.96,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "still_on_hub": true
  },
  {
    "name": "Ziya-LLaMA-13B-Pretrain-v1",
    "author": "IDEA-CCNL",
    "query_name": "IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1",
    "score": 29.96,
    "likes": 20.0,
    "link": "https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1",
    "still_on_hub": true
  },
  {
    "name": "pygmalion-350m",
    "author": "PygmalionAI",
    "query_name": "PygmalionAI/pygmalion-350m",
    "score": 29.95,
    "likes": 48.0,
    "link": "https://huggingface.co/PygmalionAI/pygmalion-350m",
    "still_on_hub": true
  },
  {
    "name": "proofGPT-v0.1",
    "author": "hoskinson-center",
    "query_name": "hoskinson-center/proofGPT-v0.1",
    "score": 29.94,
    "likes": 3.0,
    "link": "https://huggingface.co/hoskinson-center/proofGPT-v0.1",
    "still_on_hub": true
  },
  {
    "name": "LaMini-40k-Platypus2-7B",
    "author": "marcchew",
    "query_name": "marcchew/LaMini-40k-Platypus2-7B",
    "score": 29.91,
    "likes": 0.0,
    "link": "https://huggingface.co/marcchew/LaMini-40k-Platypus2-7B",
    "still_on_hub": true
  },
  {
    "name": "OPT-350M-Nerys-v2",
    "author": "KoboldAI",
    "query_name": "KoboldAI/OPT-350M-Nerys-v2",
    "score": 29.9,
    "likes": 4.0,
    "link": "https://huggingface.co/KoboldAI/OPT-350M-Nerys-v2",
    "still_on_hub": true
  },
  {
    "name": "gpt2-medium-emailgen",
    "author": "postbot",
    "query_name": "postbot/gpt2-medium-emailgen",
    "score": 29.87,
    "likes": 2.0,
    "link": "https://huggingface.co/postbot/gpt2-medium-emailgen",
    "still_on_hub": true
  },
  {
    "name": "cutie",
    "author": "rishiraj",
    "query_name": "rishiraj/cutie",
    "score": 29.87,
    "likes": 1.0,
    "link": "https://huggingface.co/rishiraj/cutie",
    "still_on_hub": false
  },
  {
    "name": "test2",
    "author": "doas",
    "query_name": "doas/test2",
    "score": 29.87,
    "likes": 0.0,
    "link": "https://huggingface.co/doas/test2",
    "still_on_hub": true
  },
  {
    "name": "bloom-560m-RLHF",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/bloom-560m-RLHF",
    "score": 29.86,
    "likes": 1.0,
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-560m-RLHF",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-7B-uncensored-GPTQ",
    "author": "TheBloke",
    "query_name": "TheBloke/WizardLM-7B-uncensored-GPTQ",
    "score": 29.86,
    "likes": 150.0,
    "link": "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GPTQ",
    "still_on_hub": true
  },
  {
    "name": "speechless-codellama-orca-platypus-13b-0.10e",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "score": 29.83,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-codellama-orca-platypus-13b-0.10e",
    "still_on_hub": true
  },
  {
    "name": "Ziya-LLaMA-13B-v1",
    "author": "IDEA-CCNL",
    "query_name": "IDEA-CCNL/Ziya-LLaMA-13B-v1",
    "score": 29.82,
    "likes": 251.0,
    "link": "https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-33B-V1.0-Uncensored-SuperHOT-8k",
    "author": "Panchovix",
    "query_name": "Panchovix/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k",
    "score": 29.81,
    "likes": 7.0,
    "link": "https://huggingface.co/Panchovix/WizardLM-33B-V1.0-Uncensored-SuperHOT-8k",
    "still_on_hub": true
  },
  {
    "name": "Marcoroni-7B-LaMini-40K",
    "author": "marcchew",
    "query_name": "marcchew/Marcoroni-7B-LaMini-40K",
    "score": 29.78,
    "likes": 0.0,
    "link": "https://huggingface.co/marcchew/Marcoroni-7B-LaMini-40K",
    "still_on_hub": true
  },
  {
    "name": "FinOPT-Franklin",
    "author": "MayaPH",
    "query_name": "MayaPH/FinOPT-Franklin",
    "score": 29.78,
    "likes": 4.0,
    "link": "https://huggingface.co/MayaPH/FinOPT-Franklin",
    "still_on_hub": true
  },
  {
    "name": "mental-alpaca",
    "author": "NEU-HAI",
    "query_name": "NEU-HAI/mental-alpaca",
    "score": 29.77,
    "likes": 0.0,
    "link": "https://huggingface.co/NEU-HAI/mental-alpaca",
    "still_on_hub": true
  },
  {
    "name": "PM_modelV2",
    "author": "BreadAi",
    "query_name": "BreadAi/PM_modelV2",
    "score": 29.77,
    "likes": 0.0,
    "link": "https://huggingface.co/BreadAi/PM_modelV2",
    "still_on_hub": true
  },
  {
    "name": "proofGPT-v0.1-6.7B",
    "author": "hoskinson-center",
    "query_name": "hoskinson-center/proofGPT-v0.1-6.7B",
    "score": 29.72,
    "likes": 9.0,
    "link": "https://huggingface.co/hoskinson-center/proofGPT-v0.1-6.7B",
    "still_on_hub": true
  },
  {
    "name": "neuralfalcon-1b-v1",
    "author": "vihangd",
    "query_name": "vihangd/neuralfalcon-1b-v1",
    "score": 29.72,
    "likes": 0.0,
    "link": "https://huggingface.co/vihangd/neuralfalcon-1b-v1",
    "still_on_hub": true
  },
  {
    "name": "gorani-100k-llama2-13b-instruct",
    "author": "danielpark",
    "query_name": "danielpark/gorani-100k-llama2-13b-instruct",
    "score": 29.69,
    "likes": 0.0,
    "link": "https://huggingface.co/danielpark/gorani-100k-llama2-13b-instruct",
    "still_on_hub": true
  },
  {
    "name": "gpt2-turkish-uncased",
    "author": "TFLai",
    "query_name": "TFLai/gpt2-turkish-uncased",
    "score": 29.68,
    "likes": 1.0,
    "link": "https://huggingface.co/TFLai/gpt2-turkish-uncased",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-12_153950",
    "author": "porkorbeef",
    "query_name": "porkorbeef/Llama-2-13b-12_153950",
    "score": 29.68,
    "likes": 0.0,
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b-12_153950",
    "still_on_hub": true
  },
  {
    "name": "Platypus-2-7B-LaMini-14K",
    "author": "marcchew",
    "query_name": "marcchew/Platypus-2-7B-LaMini-14K",
    "score": 29.64,
    "likes": 0.0,
    "link": "https://huggingface.co/marcchew/Platypus-2-7B-LaMini-14K",
    "still_on_hub": true
  },
  {
    "name": "UltraRM-13b",
    "author": "openbmb",
    "query_name": "openbmb/UltraRM-13b",
    "score": 29.58,
    "likes": 8.0,
    "link": "https://huggingface.co/openbmb/UltraRM-13b",
    "still_on_hub": true
  },
  {
    "name": "alpaca-7b",
    "author": "vicgalle",
    "query_name": "vicgalle/alpaca-7b",
    "score": 29.57,
    "likes": 2.0,
    "link": "https://huggingface.co/vicgalle/alpaca-7b",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-111M-instruction",
    "author": "SebastianSchramm",
    "query_name": "SebastianSchramm/Cerebras-GPT-111M-instruction",
    "score": 29.57,
    "likes": 1.0,
    "link": "https://huggingface.co/SebastianSchramm/Cerebras-GPT-111M-instruction",
    "still_on_hub": true
  },
  {
    "name": "gogpt-560m",
    "author": "golaxy",
    "query_name": "golaxy/gogpt-560m",
    "score": 29.56,
    "likes": 0.0,
    "link": "https://huggingface.co/golaxy/gogpt-560m",
    "still_on_hub": true
  },
  {
    "name": "pythia-70m-deduped-cleansharegpt",
    "author": "HWERI",
    "query_name": "HWERI/pythia-70m-deduped-cleansharegpt",
    "score": 29.56,
    "likes": 0.0,
    "link": "https://huggingface.co/HWERI/pythia-70m-deduped-cleansharegpt",
    "still_on_hub": true
  },
  {
    "name": "xglm-564M",
    "author": "facebook",
    "query_name": "facebook/xglm-564M",
    "score": 29.55,
    "likes": 28.0,
    "link": "https://huggingface.co/facebook/xglm-564M",
    "still_on_hub": true
  },
  {
    "name": "juniper-certificate-Llama-2-7b-chat-hf",
    "author": "Abe13",
    "query_name": "Abe13/juniper-certificate-Llama-2-7b-chat-hf",
    "score": 29.55,
    "likes": 0.0,
    "link": "https://huggingface.co/Abe13/juniper-certificate-Llama-2-7b-chat-hf",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-3b-hf",
    "author": "winglian",
    "query_name": "winglian/Llama-2-3b-hf",
    "score": 29.53,
    "likes": 2.0,
    "link": "https://huggingface.co/winglian/Llama-2-3b-hf",
    "still_on_hub": true
  },
  {
    "name": "rugpt3large_based_on_gpt2",
    "author": "ai-forever",
    "query_name": "ai-forever/rugpt3large_based_on_gpt2",
    "score": 29.53,
    "likes": 60.0,
    "link": "https://huggingface.co/ai-forever/rugpt3large_based_on_gpt2",
    "still_on_hub": true
  },
  {
    "name": "santacoder",
    "author": "bigcode",
    "query_name": "bigcode/santacoder",
    "score": 29.51,
    "likes": 300.0,
    "link": "https://huggingface.co/bigcode/santacoder",
    "still_on_hub": true
  },
  {
    "name": "bloom-820m-chat",
    "author": "WangZeJun",
    "query_name": "WangZeJun/bloom-820m-chat",
    "score": 29.5,
    "likes": 2.0,
    "link": "https://huggingface.co/WangZeJun/bloom-820m-chat",
    "still_on_hub": true
  },
  {
    "name": "supermario-v1",
    "author": "janhq",
    "query_name": "janhq/supermario-v1",
    "score": 29.49,
    "likes": 0.0,
    "link": "https://huggingface.co/janhq/supermario-v1",
    "still_on_hub": true
  },
  {
    "name": "bladeecity-jerma985",
    "author": "huggingtweets",
    "query_name": "huggingtweets/bladeecity-jerma985",
    "score": 29.49,
    "likes": 0.0,
    "link": "https://huggingface.co/huggingtweets/bladeecity-jerma985",
    "still_on_hub": true
  },
  {
    "name": "airoboros-33b-gpt4-1.2-SuperHOT-8k",
    "author": "Panchovix",
    "query_name": "Panchovix/airoboros-33b-gpt4-1.2-SuperHOT-8k",
    "score": 29.48,
    "likes": 1.0,
    "link": "https://huggingface.co/Panchovix/airoboros-33b-gpt4-1.2-SuperHOT-8k",
    "still_on_hub": true
  },
  {
    "name": "test1",
    "author": "marcchew",
    "query_name": "marcchew/test1",
    "score": 29.48,
    "likes": 0.0,
    "link": "https://huggingface.co/marcchew/test1",
    "still_on_hub": false
  },
  {
    "name": "codeparrot",
    "author": "codeparrot",
    "query_name": "codeparrot/codeparrot",
    "score": 29.48,
    "likes": 87.0,
    "link": "https://huggingface.co/codeparrot/codeparrot",
    "still_on_hub": true
  },
  {
    "name": "gpt-neo-125m",
    "author": "EleutherAI",
    "query_name": "EleutherAI/gpt-neo-125m",
    "score": 29.47,
    "likes": 132.0,
    "link": "https://huggingface.co/EleutherAI/gpt-neo-125m",
    "still_on_hub": true
  },
  {
    "name": "KoAlpaca-Polyglot-5.8B",
    "author": "beomi",
    "query_name": "beomi/KoAlpaca-Polyglot-5.8B",
    "score": 29.46,
    "likes": 48.0,
    "link": "https://huggingface.co/beomi/KoAlpaca-Polyglot-5.8B",
    "still_on_hub": true
  },
  {
    "name": "MusePy-1-2",
    "author": "BreadAi",
    "query_name": "BreadAi/MusePy-1-2",
    "score": 29.46,
    "likes": 0.0,
    "link": "https://huggingface.co/BreadAi/MusePy-1-2",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-public",
    "author": "porkorbeef",
    "query_name": "porkorbeef/Llama-2-13b-public",
    "score": 29.45,
    "likes": 0.0,
    "link": "https://huggingface.co/porkorbeef/Llama-2-13b-public",
    "still_on_hub": true
  },
  {
    "name": "UltraLM-13b",
    "author": "openbmb",
    "query_name": "openbmb/UltraLM-13b",
    "score": 29.45,
    "likes": 67.0,
    "link": "https://huggingface.co/openbmb/UltraLM-13b",
    "still_on_hub": true
  },
  {
    "name": "lamini-neo-125m",
    "author": "MBZUAI",
    "query_name": "MBZUAI/lamini-neo-125m",
    "score": 29.44,
    "likes": 13.0,
    "link": "https://huggingface.co/MBZUAI/lamini-neo-125m",
    "still_on_hub": true
  },
  {
    "name": "fairseq-dense-125M",
    "author": "KoboldAI",
    "query_name": "KoboldAI/fairseq-dense-125M",
    "score": 29.41,
    "likes": 1.0,
    "link": "https://huggingface.co/KoboldAI/fairseq-dense-125M",
    "still_on_hub": true
  },
  {
    "name": "tiny_starcoder_py",
    "author": "bigcode",
    "query_name": "bigcode/tiny_starcoder_py",
    "score": 29.41,
    "likes": 57.0,
    "link": "https://huggingface.co/bigcode/tiny_starcoder_py",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-256M",
    "author": "cerebras",
    "query_name": "cerebras/Cerebras-GPT-256M",
    "score": 29.38,
    "likes": 20.0,
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-256M",
    "still_on_hub": true
  },
  {
    "name": "pythia-160m-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-160m-deduped",
    "score": 29.38,
    "likes": 0.0,
    "link": "https://huggingface.co/EleutherAI/pythia-160m-deduped",
    "still_on_hub": true
  },
  {
    "name": "dough-instruct-base-001",
    "author": "breadlicker45",
    "query_name": "breadlicker45/dough-instruct-base-001",
    "score": 29.37,
    "likes": 0.0,
    "link": "https://huggingface.co/breadlicker45/dough-instruct-base-001",
    "still_on_hub": true
  },
  {
    "name": "dough-base-001",
    "author": "breadlicker45",
    "query_name": "breadlicker45/dough-base-001",
    "score": 29.37,
    "likes": 0.0,
    "link": "https://huggingface.co/breadlicker45/dough-base-001",
    "still_on_hub": true
  },
  {
    "name": "DeciCoder-1b",
    "author": "Deci",
    "query_name": "Deci/DeciCoder-1b",
    "score": 29.37,
    "likes": 221.0,
    "link": "https://huggingface.co/Deci/DeciCoder-1b",
    "still_on_hub": true
  },
  {
    "name": "zephyr-smol_llama-100m-dpo-full",
    "author": "amazingvince",
    "query_name": "amazingvince/zephyr-smol_llama-100m-dpo-full",
    "score": 29.37,
    "likes": 0.0,
    "link": "https://huggingface.co/amazingvince/zephyr-smol_llama-100m-dpo-full",
    "still_on_hub": true
  },
  {
    "name": "med-orca-instruct-33b",
    "author": "yhyhy3",
    "query_name": "yhyhy3/med-orca-instruct-33b",
    "score": 29.36,
    "likes": 0.0,
    "link": "https://huggingface.co/yhyhy3/med-orca-instruct-33b",
    "still_on_hub": true
  },
  {
    "name": "llama-r",
    "author": "FINDA-FIT",
    "query_name": "FINDA-FIT/llama-r",
    "score": 29.34,
    "likes": 0.0,
    "link": "https://huggingface.co/FINDA-FIT/llama-r",
    "still_on_hub": true
  },
  {
    "name": "Aira-2-1B1",
    "author": "nicholasKluge",
    "query_name": "nicholasKluge/Aira-2-1B1",
    "score": 29.32,
    "likes": 0.0,
    "link": "https://huggingface.co/nicholasKluge/Aira-2-1B1",
    "still_on_hub": true
  },
  {
    "name": "test-model",
    "author": "yyjjtt",
    "query_name": "yyjjtt/test-model",
    "score": 29.31,
    "likes": 0.0,
    "link": "https://huggingface.co/yyjjtt/test-model",
    "still_on_hub": true
  },
  {
    "name": "Flash-Llama-30M-20001",
    "author": "TaylorAI",
    "query_name": "TaylorAI/Flash-Llama-30M-20001",
    "score": 29.31,
    "likes": 0.0,
    "link": "https://huggingface.co/TaylorAI/Flash-Llama-30M-20001",
    "still_on_hub": true
  },
  {
    "name": "LaMini-Neo-1.3B-Mental-Health_lora",
    "author": "Harshvir",
    "query_name": "Harshvir/LaMini-Neo-1.3B-Mental-Health_lora",
    "score": 29.3,
    "likes": 1.0,
    "link": "https://huggingface.co/Harshvir/LaMini-Neo-1.3B-Mental-Health_lora",
    "still_on_hub": true
  },
  {
    "name": "pythia-160m-deduped-step92k-193bt",
    "author": "klosax",
    "query_name": "klosax/pythia-160m-deduped-step92k-193bt",
    "score": 29.3,
    "likes": 0.0,
    "link": "https://huggingface.co/klosax/pythia-160m-deduped-step92k-193bt",
    "still_on_hub": true
  },
  {
    "name": "llama2-13b-platypus-ckpt-1000",
    "author": "bsp-albz",
    "query_name": "bsp-albz/llama2-13b-platypus-ckpt-1000",
    "score": 29.28,
    "likes": 0.0,
    "link": "https://huggingface.co/bsp-albz/llama2-13b-platypus-ckpt-1000",
    "still_on_hub": true
  },
  {
    "name": "DialoGPT-large",
    "author": "microsoft",
    "query_name": "microsoft/DialoGPT-large",
    "score": 29.27,
    "likes": 203.0,
    "link": "https://huggingface.co/microsoft/DialoGPT-large",
    "still_on_hub": true
  },
  {
    "name": "changpt-bart",
    "author": "voidful",
    "query_name": "voidful/changpt-bart",
    "score": 29.27,
    "likes": 0.0,
    "link": "https://huggingface.co/voidful/changpt-bart",
    "still_on_hub": true
  },
  {
    "name": "FinOPT-Lincoln",
    "author": "MayaPH",
    "query_name": "MayaPH/FinOPT-Lincoln",
    "score": 29.27,
    "likes": 1.0,
    "link": "https://huggingface.co/MayaPH/FinOPT-Lincoln",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-13B-1.0",
    "author": "victor123",
    "query_name": "victor123/WizardLM-13B-1.0",
    "score": 29.27,
    "likes": 66.0,
    "link": "https://huggingface.co/victor123/WizardLM-13B-1.0",
    "still_on_hub": true
  },
  {
    "name": "pythia-160m-hq-emails",
    "author": "postbot",
    "query_name": "postbot/pythia-160m-hq-emails",
    "score": 29.26,
    "likes": 0.0,
    "link": "https://huggingface.co/postbot/pythia-160m-hq-emails",
    "still_on_hub": true
  },
  {
    "name": "NanoLlama-GQA-L10-A32_KV8-v13-KI",
    "author": "BEE-spoke-data",
    "query_name": "BEE-spoke-data/NanoLlama-GQA-L10-A32_KV8-v13-KI",
    "score": 29.23,
    "likes": 0.0,
    "link": "https://huggingface.co/BEE-spoke-data/NanoLlama-GQA-L10-A32_KV8-v13-KI",
    "still_on_hub": true
  },
  {
    "name": "GPT_Large_Quantized",
    "author": "FabbriSimo01",
    "query_name": "FabbriSimo01/GPT_Large_Quantized",
    "score": 29.21,
    "likes": 0.0,
    "link": "https://huggingface.co/FabbriSimo01/GPT_Large_Quantized",
    "still_on_hub": true
  },
  {
    "name": "gpt2-dolly",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2-dolly",
    "score": 29.21,
    "likes": 1.0,
    "link": "https://huggingface.co/lgaalves/gpt2-dolly",
    "still_on_hub": true
  },
  {
    "name": "Pythia-70M-ChatSalad",
    "author": "concedo",
    "query_name": "concedo/Pythia-70M-ChatSalad",
    "score": 29.2,
    "likes": 5.0,
    "link": "https://huggingface.co/concedo/Pythia-70M-ChatSalad",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-longlora-32k-ft",
    "author": "Yukang",
    "query_name": "Yukang/Llama-2-7b-longlora-32k-ft",
    "score": 29.2,
    "likes": 1.0,
    "link": "https://huggingface.co/Yukang/Llama-2-7b-longlora-32k-ft",
    "still_on_hub": true
  },
  {
    "name": "DialoGPT-small",
    "author": "microsoft",
    "query_name": "microsoft/DialoGPT-small",
    "score": 29.19,
    "likes": 55.0,
    "link": "https://huggingface.co/microsoft/DialoGPT-small",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-13b-longlora-16k-ft",
    "author": "Yukang",
    "query_name": "Yukang/Llama-2-13b-longlora-16k-ft",
    "score": 29.17,
    "likes": 1.0,
    "link": "https://huggingface.co/Yukang/Llama-2-13b-longlora-16k-ft",
    "still_on_hub": true
  },
  {
    "name": "CodeGPT-small-py",
    "author": "microsoft",
    "query_name": "microsoft/CodeGPT-small-py",
    "score": 29.17,
    "likes": 18.0,
    "link": "https://huggingface.co/microsoft/CodeGPT-small-py",
    "still_on_hub": true
  },
  {
    "name": "pythia-31m-KI_v1-2048-scratch",
    "author": "pszemraj",
    "query_name": "pszemraj/pythia-31m-KI_v1-2048-scratch",
    "score": 29.15,
    "likes": 0.0,
    "link": "https://huggingface.co/pszemraj/pythia-31m-KI_v1-2048-scratch",
    "still_on_hub": true
  },
  {
    "name": "opt-125m",
    "author": "facebook",
    "query_name": "facebook/opt-125m",
    "score": 29.15,
    "likes": 81.0,
    "link": "https://huggingface.co/facebook/opt-125m",
    "still_on_hub": true
  },
  {
    "name": "gpt-neo-125m-neurallinguisticpioneers",
    "author": "ogimgio",
    "query_name": "ogimgio/gpt-neo-125m-neurallinguisticpioneers",
    "score": 29.15,
    "likes": 1.0,
    "link": "https://huggingface.co/ogimgio/gpt-neo-125m-neurallinguisticpioneers",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-590M",
    "author": "cerebras",
    "query_name": "cerebras/Cerebras-GPT-590M",
    "score": 29.14,
    "likes": 17.0,
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-590M",
    "still_on_hub": true
  },
  {
    "name": "TinyStories-1M",
    "author": "roneneldan",
    "query_name": "roneneldan/TinyStories-1M",
    "score": 29.14,
    "likes": 20.0,
    "link": "https://huggingface.co/roneneldan/TinyStories-1M",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-Chat-AWQ",
    "author": "TheBloke",
    "query_name": "TheBloke/Llama-2-7b-Chat-AWQ",
    "score": 29.14,
    "likes": 1.0,
    "link": "https://huggingface.co/TheBloke/Llama-2-7b-Chat-AWQ",
    "still_on_hub": true
  },
  {
    "name": "tulu-7b-instruct-pl-lora_unload",
    "author": "Aspik101",
    "query_name": "Aspik101/tulu-7b-instruct-pl-lora_unload",
    "score": 29.11,
    "likes": 0.0,
    "link": "https://huggingface.co/Aspik101/tulu-7b-instruct-pl-lora_unload",
    "still_on_hub": true
  },
  {
    "name": "gpt3-finnish-large",
    "author": "TurkuNLP",
    "query_name": "TurkuNLP/gpt3-finnish-large",
    "score": 29.11,
    "likes": 3.0,
    "link": "https://huggingface.co/TurkuNLP/gpt3-finnish-large",
    "still_on_hub": true
  },
  {
    "name": "gpt-neox-122m-minipile-digits",
    "author": "euclaise",
    "query_name": "euclaise/gpt-neox-122m-minipile-digits",
    "score": 29.1,
    "likes": 2.0,
    "link": "https://huggingface.co/euclaise/gpt-neox-122m-minipile-digits",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-longlora-100k-ft",
    "author": "Yukang",
    "query_name": "Yukang/Llama-2-7b-longlora-100k-ft",
    "score": 29.08,
    "likes": 37.0,
    "link": "https://huggingface.co/Yukang/Llama-2-7b-longlora-100k-ft",
    "still_on_hub": true
  },
  {
    "name": "mpt-1b-redpajama-200b",
    "author": "anas-awadalla",
    "query_name": "anas-awadalla/mpt-1b-redpajama-200b",
    "score": 29.05,
    "likes": 2.0,
    "link": "https://huggingface.co/anas-awadalla/mpt-1b-redpajama-200b",
    "still_on_hub": true
  },
  {
    "name": "gpt-YA-1-1_160M",
    "author": "BreadAi",
    "query_name": "BreadAi/gpt-YA-1-1_160M",
    "score": 29.03,
    "likes": 0.0,
    "link": "https://huggingface.co/BreadAi/gpt-YA-1-1_160M",
    "still_on_hub": true
  },
  {
    "name": "medical_transcription_generator",
    "author": "alibidaran",
    "query_name": "alibidaran/medical_transcription_generator",
    "score": 29.03,
    "likes": 1.0,
    "link": "https://huggingface.co/alibidaran/medical_transcription_generator",
    "still_on_hub": true
  },
  {
    "name": "pythia-160m",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-160m",
    "score": 29.02,
    "likes": 12.0,
    "link": "https://huggingface.co/EleutherAI/pythia-160m",
    "still_on_hub": true
  },
  {
    "name": "gpt2-conversational-or-qa",
    "author": "Locutusque",
    "query_name": "Locutusque/gpt2-conversational-or-qa",
    "score": 29.01,
    "likes": 1.0,
    "link": "https://huggingface.co/Locutusque/gpt2-conversational-or-qa",
    "still_on_hub": true
  },
  {
    "name": "hepu-o4zf-ravz-7-0",
    "author": "abhishek",
    "query_name": "abhishek/hepu-o4zf-ravz-7-0",
    "score": 29.01,
    "likes": 0.0,
    "link": "https://huggingface.co/abhishek/hepu-o4zf-ravz-7-0",
    "still_on_hub": true
  },
  {
    "name": "pythia-70m-deduped-step44k-92bt",
    "author": "klosax",
    "query_name": "klosax/pythia-70m-deduped-step44k-92bt",
    "score": 29.0,
    "likes": 0.0,
    "link": "https://huggingface.co/klosax/pythia-70m-deduped-step44k-92bt",
    "still_on_hub": true
  },
  {
    "name": "jerma985",
    "author": "huggingtweets",
    "query_name": "huggingtweets/jerma985",
    "score": 28.97,
    "likes": 0.0,
    "link": "https://huggingface.co/huggingtweets/jerma985",
    "still_on_hub": true
  },
  {
    "name": "smol_llama-101M-GQA",
    "author": "BEE-spoke-data",
    "query_name": "BEE-spoke-data/smol_llama-101M-GQA",
    "score": 28.97,
    "likes": 1.0,
    "link": "https://huggingface.co/BEE-spoke-data/smol_llama-101M-GQA",
    "still_on_hub": true
  },
  {
    "name": "smol_llama-101M-GQA",
    "author": "BEE-spoke-data",
    "query_name": "BEE-spoke-data/smol_llama-101M-GQA",
    "score": 28.96,
    "likes": 1.0,
    "link": "https://huggingface.co/BEE-spoke-data/smol_llama-101M-GQA",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-30B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardLM-30B-V1.0",
    "score": 28.96,
    "likes": 70.0,
    "link": "https://huggingface.co/WizardLM/WizardLM-30B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "OPT-19M-ChatSalad",
    "author": "concedo",
    "query_name": "concedo/OPT-19M-ChatSalad",
    "score": 28.96,
    "likes": 15.0,
    "link": "https://huggingface.co/concedo/OPT-19M-ChatSalad",
    "still_on_hub": true
  },
  {
    "name": "WizardLM-30B-V1.0",
    "author": "WizardLM",
    "query_name": "WizardLM/WizardLM-30B-V1.0",
    "score": 28.95,
    "likes": 70.0,
    "link": "https://huggingface.co/WizardLM/WizardLM-30B-V1.0",
    "still_on_hub": true
  },
  {
    "name": "DiscordPy",
    "author": "BreadAi",
    "query_name": "BreadAi/DiscordPy",
    "score": 28.94,
    "likes": 0.0,
    "link": "https://huggingface.co/BreadAi/DiscordPy",
    "still_on_hub": true
  },
  {
    "name": "pythia-70m",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-70m",
    "score": 28.93,
    "likes": 14.0,
    "link": "https://huggingface.co/EleutherAI/pythia-70m",
    "still_on_hub": true
  },
  {
    "name": "gpt-j-tiny-random",
    "author": "anton-l",
    "query_name": "anton-l/gpt-j-tiny-random",
    "score": 28.92,
    "likes": 1.0,
    "link": "https://huggingface.co/anton-l/gpt-j-tiny-random",
    "still_on_hub": true
  },
  {
    "name": "590m",
    "author": "Corianas",
    "query_name": "Corianas/590m",
    "score": 28.88,
    "likes": 0.0,
    "link": "https://huggingface.co/Corianas/590m",
    "still_on_hub": true
  },
  {
    "name": "gpt-YA-1-1_70M",
    "author": "BreadAi",
    "query_name": "BreadAi/gpt-YA-1-1_70M",
    "score": 28.88,
    "likes": 0.0,
    "link": "https://huggingface.co/BreadAi/gpt-YA-1-1_70M",
    "still_on_hub": true
  },
  {
    "name": "open-calm-large",
    "author": "cyberagent",
    "query_name": "cyberagent/open-calm-large",
    "score": 28.88,
    "likes": 9.0,
    "link": "https://huggingface.co/cyberagent/open-calm-large",
    "still_on_hub": true
  },
  {
    "name": "DialoGPT-medium",
    "author": "microsoft",
    "query_name": "microsoft/DialoGPT-medium",
    "score": 28.86,
    "likes": 240.0,
    "link": "https://huggingface.co/microsoft/DialoGPT-medium",
    "still_on_hub": true
  },
  {
    "name": "easyTermsSummerizer",
    "author": "Quake24",
    "query_name": "Quake24/easyTermsSummerizer",
    "score": 28.86,
    "likes": 0.0,
    "link": "https://huggingface.co/Quake24/easyTermsSummerizer",
    "still_on_hub": true
  },
  {
    "name": "FinOPT-Washington",
    "author": "MayaPH",
    "query_name": "MayaPH/FinOPT-Washington",
    "score": 28.85,
    "likes": 1.0,
    "link": "https://huggingface.co/MayaPH/FinOPT-Washington",
    "still_on_hub": true
  },
  {
    "name": "pythia-31m-goodwiki-deduped-2048-scratch",
    "author": "pszemraj",
    "query_name": "pszemraj/pythia-31m-goodwiki-deduped-2048-scratch",
    "score": 28.85,
    "likes": 0.0,
    "link": "https://huggingface.co/pszemraj/pythia-31m-goodwiki-deduped-2048-scratch",
    "still_on_hub": true
  },
  {
    "name": "StoryPy",
    "author": "BreadAi",
    "query_name": "BreadAi/StoryPy",
    "score": 28.85,
    "likes": 1.0,
    "link": "https://huggingface.co/BreadAi/StoryPy",
    "still_on_hub": true
  },
  {
    "name": "distilgpt2-emailgen",
    "author": "postbot",
    "query_name": "postbot/distilgpt2-emailgen",
    "score": 28.84,
    "likes": 2.0,
    "link": "https://huggingface.co/postbot/distilgpt2-emailgen",
    "still_on_hub": true
  },
  {
    "name": "pythia-31m",
    "author": "ethzanalytics",
    "query_name": "ethzanalytics/pythia-31m",
    "score": 28.81,
    "likes": 0.0,
    "link": "https://huggingface.co/ethzanalytics/pythia-31m",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-7b-longlora-16k-ft",
    "author": "Yukang",
    "query_name": "Yukang/Llama-2-7b-longlora-16k-ft",
    "score": 28.81,
    "likes": 0.0,
    "link": "https://huggingface.co/Yukang/Llama-2-7b-longlora-16k-ft",
    "still_on_hub": true
  },
  {
    "name": "Yi-8B-Llama",
    "author": "ByteWave",
    "query_name": "ByteWave/Yi-8B-Llama",
    "score": 28.78,
    "likes": 1.0,
    "link": "https://huggingface.co/ByteWave/Yi-8B-Llama",
    "still_on_hub": false
  },
  {
    "name": "pythia-owt2-70m-100k",
    "author": "nthngdy",
    "query_name": "nthngdy/pythia-owt2-70m-100k",
    "score": 28.78,
    "likes": 0.0,
    "link": "https://huggingface.co/nthngdy/pythia-owt2-70m-100k",
    "still_on_hub": false
  },
  {
    "name": "fiction_story_generator",
    "author": "Tincando",
    "query_name": "Tincando/fiction_story_generator",
    "score": 28.77,
    "likes": 2.0,
    "link": "https://huggingface.co/Tincando/fiction_story_generator",
    "still_on_hub": true
  },
  {
    "name": "256_5epoch",
    "author": "Corianas",
    "query_name": "Corianas/256_5epoch",
    "score": 28.76,
    "likes": 0.0,
    "link": "https://huggingface.co/Corianas/256_5epoch",
    "still_on_hub": true
  },
  {
    "name": "DialoGPT-sarcastic-medium",
    "author": "abhiramtirumala",
    "query_name": "abhiramtirumala/DialoGPT-sarcastic-medium",
    "score": 28.73,
    "likes": 1.0,
    "link": "https://huggingface.co/abhiramtirumala/DialoGPT-sarcastic-medium",
    "still_on_hub": true
  },
  {
    "name": "pythia-owt2-70m-50k",
    "author": "nthngdy",
    "query_name": "nthngdy/pythia-owt2-70m-50k",
    "score": 28.71,
    "likes": 0.0,
    "link": "https://huggingface.co/nthngdy/pythia-owt2-70m-50k",
    "still_on_hub": false
  },
  {
    "name": "distilgpt2",
    "author": "distilgpt2",
    "query_name": "distilgpt2",
    "score": 28.71,
    "likes": 262.0,
    "link": "https://huggingface.co/distilgpt2",
    "still_on_hub": true
  },
  {
    "name": "pythia-70m-deduped-cleansharegpt-en",
    "author": "HWERI",
    "query_name": "HWERI/pythia-70m-deduped-cleansharegpt-en",
    "score": 28.71,
    "likes": 0.0,
    "link": "https://huggingface.co/HWERI/pythia-70m-deduped-cleansharegpt-en",
    "still_on_hub": true
  },
  {
    "name": "verysmol_llama-v11-KIx2",
    "author": "BEE-spoke-data",
    "query_name": "BEE-spoke-data/verysmol_llama-v11-KIx2",
    "score": 28.7,
    "likes": 0.0,
    "link": "https://huggingface.co/BEE-spoke-data/verysmol_llama-v11-KIx2",
    "still_on_hub": true
  },
  {
    "name": "rwkv-4-169m-pile",
    "author": "RWKV",
    "query_name": "RWKV/rwkv-4-169m-pile",
    "score": 28.64,
    "likes": 5.0,
    "link": "https://huggingface.co/RWKV/rwkv-4-169m-pile",
    "still_on_hub": true
  },
  {
    "name": "distilgpt2-emailgen-V2",
    "author": "postbot",
    "query_name": "postbot/distilgpt2-emailgen-V2",
    "score": 28.64,
    "likes": 2.0,
    "link": "https://huggingface.co/postbot/distilgpt2-emailgen-V2",
    "still_on_hub": true
  },
  {
    "name": "pythia-31m-simplewiki-scratch-bf16",
    "author": "pszemraj",
    "query_name": "pszemraj/pythia-31m-simplewiki-scratch-bf16",
    "score": 28.61,
    "likes": 0.0,
    "link": "https://huggingface.co/pszemraj/pythia-31m-simplewiki-scratch-bf16",
    "still_on_hub": true
  },
  {
    "name": "pythia-31m-simplepile-lite-2048-scratch-2e",
    "author": "pszemraj",
    "query_name": "pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e",
    "score": 28.6,
    "likes": 0.0,
    "link": "https://huggingface.co/pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e",
    "still_on_hub": true
  },
  {
    "name": "gpt2_open-platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2_open-platypus",
    "score": 28.58,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/gpt2_open-platypus",
    "still_on_hub": true
  },
  {
    "name": "KoAlpaca-KoRWKV-6B",
    "author": "beomi",
    "query_name": "beomi/KoAlpaca-KoRWKV-6B",
    "score": 28.57,
    "likes": 7.0,
    "link": "https://huggingface.co/beomi/KoAlpaca-KoRWKV-6B",
    "still_on_hub": true
  },
  {
    "name": "RWKV-4-PilePlus-169M-20230520-done-ctx4096",
    "author": "KnutJaegersberg",
    "query_name": "KnutJaegersberg/RWKV-4-PilePlus-169M-20230520-done-ctx4096",
    "score": 28.57,
    "likes": 0.0,
    "link": "https://huggingface.co/KnutJaegersberg/RWKV-4-PilePlus-169M-20230520-done-ctx4096",
    "still_on_hub": true
  },
  {
    "name": "llama2_7b_small_tuning_v1",
    "author": "yeen214",
    "query_name": "yeen214/llama2_7b_small_tuning_v1",
    "score": 28.56,
    "likes": 0.0,
    "link": "https://huggingface.co/yeen214/llama2_7b_small_tuning_v1",
    "still_on_hub": true
  },
  {
    "name": "gpt2",
    "author": "gpt2",
    "query_name": "gpt2",
    "score": 28.55,
    "likes": 1422.0,
    "link": "https://huggingface.co/gpt2",
    "still_on_hub": true
  },
  {
    "name": "My_GPT2",
    "author": "qiyinmiss",
    "query_name": "qiyinmiss/My_GPT2",
    "score": 28.55,
    "likes": 0.0,
    "link": "https://huggingface.co/qiyinmiss/My_GPT2",
    "still_on_hub": true
  },
  {
    "name": "Quokka_590m",
    "author": "Corianas",
    "query_name": "Corianas/Quokka_590m",
    "score": 28.53,
    "likes": 0.0,
    "link": "https://huggingface.co/Corianas/Quokka_590m",
    "still_on_hub": true
  },
  {
    "name": "gpt2_guanaco-dolly-platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2_guanaco-dolly-platypus",
    "score": 28.52,
    "likes": 1.0,
    "link": "https://huggingface.co/lgaalves/gpt2_guanaco-dolly-platypus",
    "still_on_hub": true
  },
  {
    "name": "gpt2_platypus-dolly-guanaco",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2_platypus-dolly-guanaco",
    "score": 28.51,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/gpt2_platypus-dolly-guanaco",
    "still_on_hub": true
  },
  {
    "name": "gpt_bigcode-santacoder",
    "author": "bigcode",
    "query_name": "bigcode/gpt_bigcode-santacoder",
    "score": 28.49,
    "likes": 21.0,
    "link": "https://huggingface.co/bigcode/gpt_bigcode-santacoder",
    "still_on_hub": true
  },
  {
    "name": "lamini-cerebras-256m",
    "author": "MBZUAI",
    "query_name": "MBZUAI/lamini-cerebras-256m",
    "score": 28.49,
    "likes": 3.0,
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-256m",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-126m",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-126m",
    "score": 28.49,
    "likes": 0.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-126m",
    "still_on_hub": true
  },
  {
    "name": "TinyStories-Alpaca",
    "author": "blueapple8259",
    "query_name": "blueapple8259/TinyStories-Alpaca",
    "score": 28.46,
    "likes": 0.0,
    "link": "https://huggingface.co/blueapple8259/TinyStories-Alpaca",
    "still_on_hub": true
  },
  {
    "name": "gpt-Youtube",
    "author": "BreadAi",
    "query_name": "BreadAi/gpt-Youtube",
    "score": 28.46,
    "likes": 1.0,
    "link": "https://huggingface.co/BreadAi/gpt-Youtube",
    "still_on_hub": true
  },
  {
    "name": "Llama-Flan-XL2base",
    "author": "Sayan01",
    "query_name": "Sayan01/Llama-Flan-XL2base",
    "score": 28.44,
    "likes": 0.0,
    "link": "https://huggingface.co/Sayan01/Llama-Flan-XL2base",
    "still_on_hub": true
  },
  {
    "name": "TinyStories-28M",
    "author": "roneneldan",
    "query_name": "roneneldan/TinyStories-28M",
    "score": 28.44,
    "likes": 5.0,
    "link": "https://huggingface.co/roneneldan/TinyStories-28M",
    "still_on_hub": true
  },
  {
    "name": "pythia-70m-deduped",
    "author": "EleutherAI",
    "query_name": "EleutherAI/pythia-70m-deduped",
    "score": 28.44,
    "likes": 14.0,
    "link": "https://huggingface.co/EleutherAI/pythia-70m-deduped",
    "still_on_hub": true
  },
  {
    "name": "boomer-1b",
    "author": "budecosystem",
    "query_name": "budecosystem/boomer-1b",
    "score": 28.44,
    "likes": 1.0,
    "link": "https://huggingface.co/budecosystem/boomer-1b",
    "still_on_hub": true
  },
  {
    "name": "TinyStories-33M",
    "author": "roneneldan",
    "query_name": "roneneldan/TinyStories-33M",
    "score": 28.41,
    "likes": 61.0,
    "link": "https://huggingface.co/roneneldan/TinyStories-33M",
    "still_on_hub": true
  },
  {
    "name": "gpt2_platypus-camel_physics",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2_platypus-camel_physics",
    "score": 28.41,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/gpt2_platypus-camel_physics",
    "still_on_hub": true
  },
  {
    "name": "gpt2_camel_physics-platypus",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2_camel_physics-platypus",
    "score": 28.41,
    "likes": 0.0,
    "link": "https://huggingface.co/lgaalves/gpt2_camel_physics-platypus",
    "still_on_hub": true
  },
  {
    "name": "gpt2_test",
    "author": "SaylorTwift",
    "query_name": "SaylorTwift/gpt2_test",
    "score": 28.4,
    "likes": 0.0,
    "link": "https://huggingface.co/SaylorTwift/gpt2_test",
    "still_on_hub": true
  },
  {
    "name": "finetuned-gpt2-tiny",
    "author": "dpv",
    "query_name": "dpv/finetuned-gpt2-tiny",
    "score": 28.4,
    "likes": 1.0,
    "link": "https://huggingface.co/dpv/finetuned-gpt2-tiny",
    "still_on_hub": true
  },
  {
    "name": "gpt2_platypus-camel_physics",
    "author": "behnamsh",
    "query_name": "behnamsh/gpt2_platypus-camel_physics",
    "score": 28.4,
    "likes": 0.0,
    "link": "https://huggingface.co/behnamsh/gpt2_platypus-camel_physics",
    "still_on_hub": true
  },
  {
    "name": "lamini-cerebras-590m",
    "author": "MBZUAI",
    "query_name": "MBZUAI/lamini-cerebras-590m",
    "score": 28.38,
    "likes": 5.0,
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-590m",
    "still_on_hub": true
  },
  {
    "name": "SGPT-1.3B-insurance-epoch10",
    "author": "mncai",
    "query_name": "mncai/SGPT-1.3B-insurance-epoch10",
    "score": 28.37,
    "likes": 0.0,
    "link": "https://huggingface.co/mncai/SGPT-1.3B-insurance-epoch10",
    "still_on_hub": true
  },
  {
    "name": "gpt2-alpaca-gpt4",
    "author": "vicgalle",
    "query_name": "vicgalle/gpt2-alpaca-gpt4",
    "score": 28.34,
    "likes": 14.0,
    "link": "https://huggingface.co/vicgalle/gpt2-alpaca-gpt4",
    "still_on_hub": true
  },
  {
    "name": "Quokka_256m",
    "author": "Corianas",
    "query_name": "Corianas/Quokka_256m",
    "score": 28.32,
    "likes": 1.0,
    "link": "https://huggingface.co/Corianas/Quokka_256m",
    "still_on_hub": true
  },
  {
    "name": "TinyStories-8M",
    "author": "roneneldan",
    "query_name": "roneneldan/TinyStories-8M",
    "score": 28.31,
    "likes": 3.0,
    "link": "https://huggingface.co/roneneldan/TinyStories-8M",
    "still_on_hub": true
  },
  {
    "name": "GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
    "author": "xzuyn",
    "query_name": "xzuyn/GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
    "score": 28.3,
    "likes": 0.0,
    "link": "https://huggingface.co/xzuyn/GPT-2-SlimOrcaDeduped-airoboros-3.1-MetaMathQA-SFT-124M",
    "still_on_hub": false
  },
  {
    "name": "pythia-31m",
    "author": "ethzanalytics",
    "query_name": "ethzanalytics/pythia-31m",
    "score": 28.3,
    "likes": 0.0,
    "link": "https://huggingface.co/ethzanalytics/pythia-31m",
    "still_on_hub": true
  },
  {
    "name": "dlite-v2-124m",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v2-124m",
    "score": 28.3,
    "likes": 4.0,
    "link": "https://huggingface.co/aisquared/dlite-v2-124m",
    "still_on_hub": true
  },
  {
    "name": "gladosystem",
    "author": "huggingtweets",
    "query_name": "huggingtweets/gladosystem",
    "score": 28.29,
    "likes": 1.0,
    "link": "https://huggingface.co/huggingtweets/gladosystem",
    "still_on_hub": true
  },
  {
    "name": "lamini-cerebras-111m",
    "author": "MBZUAI",
    "query_name": "MBZUAI/lamini-cerebras-111m",
    "score": 28.29,
    "likes": 3.0,
    "link": "https://huggingface.co/MBZUAI/lamini-cerebras-111m",
    "still_on_hub": true
  },
  {
    "name": "gpt2",
    "author": "gpt2",
    "query_name": "gpt2",
    "score": 28.28,
    "likes": 1504.0,
    "link": "https://huggingface.co/gpt2",
    "still_on_hub": true
  },
  {
    "name": "pythia-31m-simplewiki-2048",
    "author": "pszemraj",
    "query_name": "pszemraj/pythia-31m-simplewiki-2048",
    "score": 28.27,
    "likes": 0.0,
    "link": "https://huggingface.co/pszemraj/pythia-31m-simplewiki-2048",
    "still_on_hub": true
  },
  {
    "name": "open-calm-7b",
    "author": "cyberagent",
    "query_name": "cyberagent/open-calm-7b",
    "score": 28.21,
    "likes": 188.0,
    "link": "https://huggingface.co/cyberagent/open-calm-7b",
    "still_on_hub": true
  },
  {
    "name": "gpt2023",
    "author": "crumb",
    "query_name": "crumb/gpt2023",
    "score": 28.2,
    "likes": 12.0,
    "link": "https://huggingface.co/crumb/gpt2023",
    "still_on_hub": true
  },
  {
    "name": "gpt-sw3-126m-instruct",
    "author": "AI-Sweden-Models",
    "query_name": "AI-Sweden-Models/gpt-sw3-126m-instruct",
    "score": 28.2,
    "likes": 2.0,
    "link": "https://huggingface.co/AI-Sweden-Models/gpt-sw3-126m-instruct",
    "still_on_hub": true
  },
  {
    "name": "TinyMistral-248M-SFT-v4",
    "author": "Felladrin",
    "query_name": "Felladrin/TinyMistral-248M-SFT-v4",
    "score": 28.2,
    "likes": 12.0,
    "link": "https://huggingface.co/Felladrin/TinyMistral-248M-SFT-v4",
    "still_on_hub": true
  },
  {
    "name": "KoRWKV-6B",
    "author": "beomi",
    "query_name": "beomi/KoRWKV-6B",
    "score": 28.19,
    "likes": 3.0,
    "link": "https://huggingface.co/beomi/KoRWKV-6B",
    "still_on_hub": true
  },
  {
    "name": "TinyStories-3M",
    "author": "roneneldan",
    "query_name": "roneneldan/TinyStories-3M",
    "score": 28.19,
    "likes": 2.0,
    "link": "https://huggingface.co/roneneldan/TinyStories-3M",
    "still_on_hub": true
  },
  {
    "name": "TinyMistral-248M-Instruct",
    "author": "Locutusque",
    "query_name": "Locutusque/TinyMistral-248M-Instruct",
    "score": 28.19,
    "likes": 2.0,
    "link": "https://huggingface.co/Locutusque/TinyMistral-248M-Instruct",
    "still_on_hub": true
  },
  {
    "name": "distilgpt2-HC3",
    "author": "pszemraj",
    "query_name": "pszemraj/distilgpt2-HC3",
    "score": 28.18,
    "likes": 0.0,
    "link": "https://huggingface.co/pszemraj/distilgpt2-HC3",
    "still_on_hub": true
  },
  {
    "name": "gpt2-dolly",
    "author": "lgaalves",
    "query_name": "lgaalves/gpt2-dolly",
    "score": 28.18,
    "likes": 1.0,
    "link": "https://huggingface.co/lgaalves/gpt2-dolly",
    "still_on_hub": true
  },
  {
    "name": "smol_llama-81M-tied",
    "author": "BEE-spoke-data",
    "query_name": "BEE-spoke-data/smol_llama-81M-tied",
    "score": 28.17,
    "likes": 1.0,
    "link": "https://huggingface.co/BEE-spoke-data/smol_llama-81M-tied",
    "still_on_hub": true
  },
  {
    "name": "LaMini-GPT-124M",
    "author": "MBZUAI",
    "query_name": "MBZUAI/LaMini-GPT-124M",
    "score": 28.01,
    "likes": 14.0,
    "link": "https://huggingface.co/MBZUAI/LaMini-GPT-124M",
    "still_on_hub": true
  },
  {
    "name": "LocutusqueXFelladrin-TinyMistral248M-Instruct",
    "author": "Locutusque",
    "query_name": "Locutusque/LocutusqueXFelladrin-TinyMistral248M-Instruct",
    "score": 27.98,
    "likes": 1.0,
    "link": "https://huggingface.co/Locutusque/LocutusqueXFelladrin-TinyMistral248M-Instruct",
    "still_on_hub": true
  },
  {
    "name": "gpt3-finnish-small",
    "author": "TurkuNLP",
    "query_name": "TurkuNLP/gpt3-finnish-small",
    "score": 27.95,
    "likes": 9.0,
    "link": "https://huggingface.co/TurkuNLP/gpt3-finnish-small",
    "still_on_hub": true
  },
  {
    "name": "xuanxuan",
    "author": "Mikivis",
    "query_name": "Mikivis/xuanxuan",
    "score": 27.88,
    "likes": 0.0,
    "link": "https://huggingface.co/Mikivis/xuanxuan",
    "still_on_hub": true
  },
  {
    "name": "gpt2-alpaca",
    "author": "vicgalle",
    "query_name": "vicgalle/gpt2-alpaca",
    "score": 27.86,
    "likes": 8.0,
    "link": "https://huggingface.co/vicgalle/gpt2-alpaca",
    "still_on_hub": true
  },
  {
    "name": "dlite-v1-124m",
    "author": "aisquared",
    "query_name": "aisquared/dlite-v1-124m",
    "score": 27.86,
    "likes": 0.0,
    "link": "https://huggingface.co/aisquared/dlite-v1-124m",
    "still_on_hub": true
  },
  {
    "name": "kogpt",
    "author": "psyche",
    "query_name": "psyche/kogpt",
    "score": 27.83,
    "likes": 3.0,
    "link": "https://huggingface.co/psyche/kogpt",
    "still_on_hub": true
  },
  {
    "name": "Cerebras-GPT-111M",
    "author": "cerebras",
    "query_name": "cerebras/Cerebras-GPT-111M",
    "score": 27.75,
    "likes": 62.0,
    "link": "https://huggingface.co/cerebras/Cerebras-GPT-111M",
    "still_on_hub": true
  },
  {
    "name": "TinyMistral-248m",
    "author": "Locutusque",
    "query_name": "Locutusque/TinyMistral-248m",
    "score": 27.73,
    "likes": 6.0,
    "link": "https://huggingface.co/Locutusque/TinyMistral-248m",
    "still_on_hub": true
  },
  {
    "name": "testmodel",
    "author": "huashiyiqike",
    "query_name": "huashiyiqike/testmodel",
    "score": 27.6,
    "likes": 1.0,
    "link": "https://huggingface.co/huashiyiqike/testmodel",
    "still_on_hub": true
  },
  {
    "name": "111m",
    "author": "Corianas",
    "query_name": "Corianas/111m",
    "score": 27.6,
    "likes": 2.0,
    "link": "https://huggingface.co/Corianas/111m",
    "still_on_hub": true
  },
  {
    "name": "TinyMistral-248M-SFT-v3",
    "author": "Felladrin",
    "query_name": "Felladrin/TinyMistral-248M-SFT-v3",
    "score": 27.45,
    "likes": 12.0,
    "link": "https://huggingface.co/Felladrin/TinyMistral-248M-SFT-v3",
    "still_on_hub": true
  },
  {
    "name": "dolly-v2-3b",
    "author": "databricks",
    "query_name": "databricks/dolly-v2-3b",
    "score": 22.83,
    "likes": 232.0,
    "link": "https://huggingface.co/databricks/dolly-v2-3b",
    "still_on_hub": true
  },
  {
    "name": "v1olet_marcoroni-go-bruins-7B",
    "author": "v1olet",
    "query_name": "v1olet/v1olet_marcoroni-go-bruins-7B",
    "score": 22.43,
    "likes": 0.0,
    "link": "https://huggingface.co/v1olet/v1olet_marcoroni-go-bruins-7B",
    "still_on_hub": false
  },
  {
    "name": "v1olet_mistral_7B",
    "author": "v1olet",
    "query_name": "v1olet/v1olet_mistral_7B",
    "score": 22.16,
    "likes": 0.0,
    "link": "https://huggingface.co/v1olet/v1olet_mistral_7B",
    "still_on_hub": false
  },
  {
    "name": "Facebook_opt_1.3b_Quantized",
    "author": "FabbriSimo01",
    "query_name": "FabbriSimo01/Facebook_opt_1.3b_Quantized",
    "score": 21.78,
    "likes": 0.0,
    "link": "https://huggingface.co/FabbriSimo01/Facebook_opt_1.3b_Quantized",
    "still_on_hub": true
  },
  {
    "name": "mistral-class-bio-tutor",
    "author": "KevinNi",
    "query_name": "KevinNi/mistral-class-bio-tutor",
    "score": 21.59,
    "likes": 0.0,
    "link": "https://huggingface.co/KevinNi/mistral-class-bio-tutor",
    "still_on_hub": true
  },
  {
    "name": "bloom-560m-finetuned-fraud",
    "author": "jslin09",
    "query_name": "jslin09/bloom-560m-finetuned-fraud",
    "score": 21.37,
    "likes": 1.0,
    "link": "https://huggingface.co/jslin09/bloom-560m-finetuned-fraud",
    "still_on_hub": true
  },
  {
    "name": "OpenOrca-AYT-13B",
    "author": "ahnyeonchan",
    "query_name": "ahnyeonchan/OpenOrca-AYT-13B",
    "score": 21.35,
    "likes": 0.0,
    "link": "https://huggingface.co/ahnyeonchan/OpenOrca-AYT-13B",
    "still_on_hub": true
  },
  {
    "name": "YetAnother_Open-Llama-3B-LoRA",
    "author": "Andron00e",
    "query_name": "Andron00e/YetAnother_Open-Llama-3B-LoRA",
    "score": 21.29,
    "likes": 0.0,
    "link": "https://huggingface.co/Andron00e/YetAnother_Open-Llama-3B-LoRA",
    "still_on_hub": true
  },
  {
    "name": "YetAnother_Open-Llama-3B-LoRA-OpenOrca",
    "author": "Andron00e",
    "query_name": "Andron00e/YetAnother_Open-Llama-3B-LoRA-OpenOrca",
    "score": 21.2,
    "likes": 0.0,
    "link": "https://huggingface.co/Andron00e/YetAnother_Open-Llama-3B-LoRA-OpenOrca",
    "still_on_hub": true
  },
  {
    "name": "Dante-2.8B",
    "author": "Dampish",
    "query_name": "Dampish/Dante-2.8B",
    "score": 21.12,
    "likes": 0.0,
    "link": "https://huggingface.co/Dampish/Dante-2.8B",
    "still_on_hub": true
  },
  {
    "name": "MuseCan",
    "author": "BreadAi",
    "query_name": "BreadAi/MuseCan",
    "score": 21.06,
    "likes": 0.0,
    "link": "https://huggingface.co/BreadAi/MuseCan",
    "still_on_hub": true
  },
  {
    "name": "mptk-1b",
    "author": "team-lucid",
    "query_name": "team-lucid/mptk-1b",
    "score": 20.84,
    "likes": 0.0,
    "link": "https://huggingface.co/team-lucid/mptk-1b",
    "still_on_hub": true
  },
  {
    "name": "bloom-1b1-RLHF-v2",
    "author": "TheTravellingEngineer",
    "query_name": "TheTravellingEngineer/bloom-1b1-RLHF-v2",
    "score": 20.07,
    "likes": 0.0,
    "link": "https://huggingface.co/TheTravellingEngineer/bloom-1b1-RLHF-v2",
    "still_on_hub": true
  },
  {
    "name": "panda-coder-13B",
    "author": "aiplanet",
    "query_name": "aiplanet/panda-coder-13B",
    "score": 20.07,
    "likes": 2.0,
    "link": "https://huggingface.co/aiplanet/panda-coder-13B",
    "still_on_hub": true
  },
  {
    "name": "caigun-lora-model-33B",
    "author": "APMIC",
    "query_name": "APMIC/caigun-lora-model-33B",
    "score": 20.07,
    "likes": 0.0,
    "link": "https://huggingface.co/APMIC/caigun-lora-model-33B",
    "still_on_hub": true
  },
  {
    "name": "Llama-2-ft-instruct-es",
    "author": "clibrain",
    "query_name": "clibrain/Llama-2-ft-instruct-es",
    "score": 20.07,
    "likes": 16.0,
    "link": "https://huggingface.co/clibrain/Llama-2-ft-instruct-es",
    "still_on_hub": true
  },
  {
    "name": "llama-2-13b-dolphin-peft",
    "author": "dfurman",
    "query_name": "dfurman/llama-2-13b-dolphin-peft",
    "score": 20.07,
    "likes": 10.0,
    "link": "https://huggingface.co/dfurman/llama-2-13b-dolphin-peft",
    "still_on_hub": false
  },
  {
    "name": "speechless-mistral-six-in-one-7b-orth-1.0",
    "author": "uukuguy",
    "query_name": "uukuguy/speechless-mistral-six-in-one-7b-orth-1.0",
    "score": 20.07,
    "likes": 0.0,
    "link": "https://huggingface.co/uukuguy/speechless-mistral-six-in-one-7b-orth-1.0",
    "still_on_hub": true
  },
  {
    "name": "Panther_v1",
    "author": "Rardilit",
    "query_name": "Rardilit/Panther_v1",
    "score": 20.07,
    "likes": 1.0,
    "link": "https://huggingface.co/Rardilit/Panther_v1",
    "still_on_hub": false
  },
  {
    "name": "mpt-125m-c4",
    "author": "wtang06",
    "query_name": "wtang06/mpt-125m-c4",
    "score": 20.07,
    "likes": 1.0,
    "link": "https://huggingface.co/wtang06/mpt-125m-c4",
    "still_on_hub": true
  }
]
